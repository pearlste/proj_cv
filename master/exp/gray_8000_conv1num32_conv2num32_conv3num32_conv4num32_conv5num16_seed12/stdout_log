I0204 19:41:44.093756  5898 caffe.cpp:177] Use CPU.
I0204 19:41:44.094718  5898 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap_"
solver_mode: CPU
random_seed: 12
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/train_val.prototxt"
I0204 19:41:44.094897  5898 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/train_val.prototxt
I0204 19:41:44.095543  5898 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 19:41:44.095580  5898 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 19:41:44.095836  5898 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 19:41:44.095988  5898 layer_factory.hpp:77] Creating layer data
I0204 19:41:44.096202  5898 net.cpp:106] Creating Layer data
I0204 19:41:44.096227  5898 net.cpp:411] data -> data
I0204 19:41:44.096312  5898 net.cpp:411] data -> label
I0204 19:41:44.096338  5898 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 19:41:44.096493  5899 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 19:41:44.097628  5898 data_layer.cpp:41] output data size: 100,1,227,227
I0204 19:41:44.131878  5898 net.cpp:150] Setting up data
I0204 19:41:44.131976  5898 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 19:41:44.131988  5898 net.cpp:157] Top shape: 100 (100)
I0204 19:41:44.131994  5898 net.cpp:165] Memory required for data: 20612000
I0204 19:41:44.132016  5898 layer_factory.hpp:77] Creating layer conv1
I0204 19:41:44.132047  5898 net.cpp:106] Creating Layer conv1
I0204 19:41:44.132057  5898 net.cpp:454] conv1 <- data
I0204 19:41:44.132081  5898 net.cpp:411] conv1 -> conv1
I0204 19:41:44.132236  5898 net.cpp:150] Setting up conv1
I0204 19:41:44.132249  5898 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 19:41:44.132256  5898 net.cpp:165] Memory required for data: 59332000
I0204 19:41:44.132275  5898 layer_factory.hpp:77] Creating layer relu1
I0204 19:41:44.132288  5898 net.cpp:106] Creating Layer relu1
I0204 19:41:44.132294  5898 net.cpp:454] relu1 <- conv1
I0204 19:41:44.132304  5898 net.cpp:397] relu1 -> conv1 (in-place)
I0204 19:41:44.132318  5898 net.cpp:150] Setting up relu1
I0204 19:41:44.132326  5898 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 19:41:44.132331  5898 net.cpp:165] Memory required for data: 98052000
I0204 19:41:44.132338  5898 layer_factory.hpp:77] Creating layer pool1
I0204 19:41:44.132349  5898 net.cpp:106] Creating Layer pool1
I0204 19:41:44.132355  5898 net.cpp:454] pool1 <- conv1
I0204 19:41:44.132364  5898 net.cpp:411] pool1 -> pool1
I0204 19:41:44.132395  5898 net.cpp:150] Setting up pool1
I0204 19:41:44.132403  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.132410  5898 net.cpp:165] Memory required for data: 107383200
I0204 19:41:44.132416  5898 layer_factory.hpp:77] Creating layer norm1
I0204 19:41:44.132447  5898 net.cpp:106] Creating Layer norm1
I0204 19:41:44.132454  5898 net.cpp:454] norm1 <- pool1
I0204 19:41:44.132462  5898 net.cpp:411] norm1 -> norm1
I0204 19:41:44.132482  5898 net.cpp:150] Setting up norm1
I0204 19:41:44.132490  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.132496  5898 net.cpp:165] Memory required for data: 116714400
I0204 19:41:44.132504  5898 layer_factory.hpp:77] Creating layer conv2
I0204 19:41:44.132516  5898 net.cpp:106] Creating Layer conv2
I0204 19:41:44.132522  5898 net.cpp:454] conv2 <- norm1
I0204 19:41:44.132531  5898 net.cpp:411] conv2 -> conv2
I0204 19:41:44.132665  5898 net.cpp:150] Setting up conv2
I0204 19:41:44.132675  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.132680  5898 net.cpp:165] Memory required for data: 126045600
I0204 19:41:44.132691  5898 layer_factory.hpp:77] Creating layer relu2
I0204 19:41:44.132701  5898 net.cpp:106] Creating Layer relu2
I0204 19:41:44.132707  5898 net.cpp:454] relu2 <- conv2
I0204 19:41:44.132715  5898 net.cpp:397] relu2 -> conv2 (in-place)
I0204 19:41:44.132725  5898 net.cpp:150] Setting up relu2
I0204 19:41:44.132732  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.132737  5898 net.cpp:165] Memory required for data: 135376800
I0204 19:41:44.132743  5898 layer_factory.hpp:77] Creating layer pool2
I0204 19:41:44.132761  5898 net.cpp:106] Creating Layer pool2
I0204 19:41:44.132769  5898 net.cpp:454] pool2 <- conv2
I0204 19:41:44.132779  5898 net.cpp:411] pool2 -> pool2
I0204 19:41:44.132791  5898 net.cpp:150] Setting up pool2
I0204 19:41:44.132798  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.132804  5898 net.cpp:165] Memory required for data: 137540000
I0204 19:41:44.132809  5898 layer_factory.hpp:77] Creating layer norm2
I0204 19:41:44.132820  5898 net.cpp:106] Creating Layer norm2
I0204 19:41:44.132825  5898 net.cpp:454] norm2 <- pool2
I0204 19:41:44.132838  5898 net.cpp:411] norm2 -> norm2
I0204 19:41:44.132848  5898 net.cpp:150] Setting up norm2
I0204 19:41:44.132854  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.132859  5898 net.cpp:165] Memory required for data: 139703200
I0204 19:41:44.132865  5898 layer_factory.hpp:77] Creating layer conv3
I0204 19:41:44.132876  5898 net.cpp:106] Creating Layer conv3
I0204 19:41:44.132882  5898 net.cpp:454] conv3 <- norm2
I0204 19:41:44.132891  5898 net.cpp:411] conv3 -> conv3
I0204 19:41:44.133008  5898 net.cpp:150] Setting up conv3
I0204 19:41:44.133018  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.133023  5898 net.cpp:165] Memory required for data: 141866400
I0204 19:41:44.133036  5898 layer_factory.hpp:77] Creating layer relu3
I0204 19:41:44.133049  5898 net.cpp:106] Creating Layer relu3
I0204 19:41:44.133056  5898 net.cpp:454] relu3 <- conv3
I0204 19:41:44.133064  5898 net.cpp:397] relu3 -> conv3 (in-place)
I0204 19:41:44.133074  5898 net.cpp:150] Setting up relu3
I0204 19:41:44.133080  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.133085  5898 net.cpp:165] Memory required for data: 144029600
I0204 19:41:44.133097  5898 layer_factory.hpp:77] Creating layer conv4
I0204 19:41:44.133111  5898 net.cpp:106] Creating Layer conv4
I0204 19:41:44.133117  5898 net.cpp:454] conv4 <- conv3
I0204 19:41:44.133128  5898 net.cpp:411] conv4 -> conv4
I0204 19:41:44.133203  5898 net.cpp:150] Setting up conv4
I0204 19:41:44.133213  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.133219  5898 net.cpp:165] Memory required for data: 146192800
I0204 19:41:44.133226  5898 layer_factory.hpp:77] Creating layer relu4
I0204 19:41:44.133235  5898 net.cpp:106] Creating Layer relu4
I0204 19:41:44.133241  5898 net.cpp:454] relu4 <- conv4
I0204 19:41:44.133249  5898 net.cpp:397] relu4 -> conv4 (in-place)
I0204 19:41:44.133257  5898 net.cpp:150] Setting up relu4
I0204 19:41:44.133265  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.133270  5898 net.cpp:165] Memory required for data: 148356000
I0204 19:41:44.133280  5898 layer_factory.hpp:77] Creating layer conv5
I0204 19:41:44.133303  5898 net.cpp:106] Creating Layer conv5
I0204 19:41:44.133311  5898 net.cpp:454] conv5 <- conv4
I0204 19:41:44.133322  5898 net.cpp:411] conv5 -> conv5
I0204 19:41:44.133369  5898 net.cpp:150] Setting up conv5
I0204 19:41:44.133378  5898 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 19:41:44.133384  5898 net.cpp:165] Memory required for data: 149437600
I0204 19:41:44.133394  5898 layer_factory.hpp:77] Creating layer relu5
I0204 19:41:44.133404  5898 net.cpp:106] Creating Layer relu5
I0204 19:41:44.133409  5898 net.cpp:454] relu5 <- conv5
I0204 19:41:44.133419  5898 net.cpp:397] relu5 -> conv5 (in-place)
I0204 19:41:44.133429  5898 net.cpp:150] Setting up relu5
I0204 19:41:44.133435  5898 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 19:41:44.133440  5898 net.cpp:165] Memory required for data: 150519200
I0204 19:41:44.133448  5898 layer_factory.hpp:77] Creating layer pool5
I0204 19:41:44.133457  5898 net.cpp:106] Creating Layer pool5
I0204 19:41:44.133463  5898 net.cpp:454] pool5 <- conv5
I0204 19:41:44.133474  5898 net.cpp:411] pool5 -> pool5
I0204 19:41:44.133486  5898 net.cpp:150] Setting up pool5
I0204 19:41:44.133492  5898 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 19:41:44.133498  5898 net.cpp:165] Memory required for data: 150749600
I0204 19:41:44.133503  5898 layer_factory.hpp:77] Creating layer fc6
I0204 19:41:44.133520  5898 net.cpp:106] Creating Layer fc6
I0204 19:41:44.133527  5898 net.cpp:454] fc6 <- pool5
I0204 19:41:44.133538  5898 net.cpp:411] fc6 -> fc6
I0204 19:41:44.135138  5898 net.cpp:150] Setting up fc6
I0204 19:41:44.135152  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.135159  5898 net.cpp:165] Memory required for data: 150852000
I0204 19:41:44.135169  5898 layer_factory.hpp:77] Creating layer relu6
I0204 19:41:44.135180  5898 net.cpp:106] Creating Layer relu6
I0204 19:41:44.135186  5898 net.cpp:454] relu6 <- fc6
I0204 19:41:44.135193  5898 net.cpp:397] relu6 -> fc6 (in-place)
I0204 19:41:44.135203  5898 net.cpp:150] Setting up relu6
I0204 19:41:44.135212  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.135218  5898 net.cpp:165] Memory required for data: 150954400
I0204 19:41:44.135224  5898 layer_factory.hpp:77] Creating layer drop6
I0204 19:41:44.135234  5898 net.cpp:106] Creating Layer drop6
I0204 19:41:44.135241  5898 net.cpp:454] drop6 <- fc6
I0204 19:41:44.135248  5898 net.cpp:397] drop6 -> fc6 (in-place)
I0204 19:41:44.135267  5898 net.cpp:150] Setting up drop6
I0204 19:41:44.135275  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.135280  5898 net.cpp:165] Memory required for data: 151056800
I0204 19:41:44.135287  5898 layer_factory.hpp:77] Creating layer fc7
I0204 19:41:44.135295  5898 net.cpp:106] Creating Layer fc7
I0204 19:41:44.135301  5898 net.cpp:454] fc7 <- fc6
I0204 19:41:44.135313  5898 net.cpp:411] fc7 -> fc7
I0204 19:41:44.136003  5898 net.cpp:150] Setting up fc7
I0204 19:41:44.136018  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.136023  5898 net.cpp:165] Memory required for data: 151159200
I0204 19:41:44.136031  5898 layer_factory.hpp:77] Creating layer relu7
I0204 19:41:44.136039  5898 net.cpp:106] Creating Layer relu7
I0204 19:41:44.136045  5898 net.cpp:454] relu7 <- fc7
I0204 19:41:44.136056  5898 net.cpp:397] relu7 -> fc7 (in-place)
I0204 19:41:44.136065  5898 net.cpp:150] Setting up relu7
I0204 19:41:44.136072  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.136077  5898 net.cpp:165] Memory required for data: 151261600
I0204 19:41:44.136083  5898 layer_factory.hpp:77] Creating layer drop7
I0204 19:41:44.136098  5898 net.cpp:106] Creating Layer drop7
I0204 19:41:44.136104  5898 net.cpp:454] drop7 <- fc7
I0204 19:41:44.136114  5898 net.cpp:397] drop7 -> fc7 (in-place)
I0204 19:41:44.136126  5898 net.cpp:150] Setting up drop7
I0204 19:41:44.136132  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.136137  5898 net.cpp:165] Memory required for data: 151364000
I0204 19:41:44.136145  5898 layer_factory.hpp:77] Creating layer fc8
I0204 19:41:44.136160  5898 net.cpp:106] Creating Layer fc8
I0204 19:41:44.136175  5898 net.cpp:454] fc8 <- fc7
I0204 19:41:44.136186  5898 net.cpp:411] fc8 -> fc8
I0204 19:41:44.136211  5898 net.cpp:150] Setting up fc8
I0204 19:41:44.136219  5898 net.cpp:157] Top shape: 100 2 (200)
I0204 19:41:44.136224  5898 net.cpp:165] Memory required for data: 151364800
I0204 19:41:44.136232  5898 layer_factory.hpp:77] Creating layer loss
I0204 19:41:44.136245  5898 net.cpp:106] Creating Layer loss
I0204 19:41:44.136250  5898 net.cpp:454] loss <- fc8
I0204 19:41:44.136260  5898 net.cpp:454] loss <- label
I0204 19:41:44.136270  5898 net.cpp:411] loss -> loss
I0204 19:41:44.136286  5898 layer_factory.hpp:77] Creating layer loss
I0204 19:41:44.136313  5898 net.cpp:150] Setting up loss
I0204 19:41:44.136322  5898 net.cpp:157] Top shape: (1)
I0204 19:41:44.136327  5898 net.cpp:160]     with loss weight 1
I0204 19:41:44.136363  5898 net.cpp:165] Memory required for data: 151364804
I0204 19:41:44.136371  5898 net.cpp:226] loss needs backward computation.
I0204 19:41:44.136379  5898 net.cpp:226] fc8 needs backward computation.
I0204 19:41:44.136384  5898 net.cpp:226] drop7 needs backward computation.
I0204 19:41:44.136390  5898 net.cpp:226] relu7 needs backward computation.
I0204 19:41:44.136395  5898 net.cpp:226] fc7 needs backward computation.
I0204 19:41:44.136401  5898 net.cpp:226] drop6 needs backward computation.
I0204 19:41:44.136407  5898 net.cpp:226] relu6 needs backward computation.
I0204 19:41:44.136412  5898 net.cpp:226] fc6 needs backward computation.
I0204 19:41:44.136418  5898 net.cpp:226] pool5 needs backward computation.
I0204 19:41:44.136425  5898 net.cpp:226] relu5 needs backward computation.
I0204 19:41:44.136432  5898 net.cpp:226] conv5 needs backward computation.
I0204 19:41:44.136440  5898 net.cpp:226] relu4 needs backward computation.
I0204 19:41:44.136445  5898 net.cpp:226] conv4 needs backward computation.
I0204 19:41:44.136451  5898 net.cpp:226] relu3 needs backward computation.
I0204 19:41:44.136456  5898 net.cpp:226] conv3 needs backward computation.
I0204 19:41:44.136467  5898 net.cpp:226] norm2 needs backward computation.
I0204 19:41:44.136474  5898 net.cpp:226] pool2 needs backward computation.
I0204 19:41:44.136481  5898 net.cpp:226] relu2 needs backward computation.
I0204 19:41:44.136487  5898 net.cpp:226] conv2 needs backward computation.
I0204 19:41:44.136492  5898 net.cpp:226] norm1 needs backward computation.
I0204 19:41:44.136498  5898 net.cpp:226] pool1 needs backward computation.
I0204 19:41:44.136504  5898 net.cpp:226] relu1 needs backward computation.
I0204 19:41:44.136510  5898 net.cpp:226] conv1 needs backward computation.
I0204 19:41:44.136518  5898 net.cpp:228] data does not need backward computation.
I0204 19:41:44.136525  5898 net.cpp:270] This network produces output loss
I0204 19:41:44.136554  5898 net.cpp:283] Network initialization done.
I0204 19:41:44.137361  5898 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/train_val.prototxt
I0204 19:41:44.137423  5898 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 19:41:44.137732  5898 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 19:41:44.137918  5898 layer_factory.hpp:77] Creating layer data
I0204 19:41:44.138074  5898 net.cpp:106] Creating Layer data
I0204 19:41:44.138099  5898 net.cpp:411] data -> data
I0204 19:41:44.138114  5898 net.cpp:411] data -> label
I0204 19:41:44.138126  5898 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 19:41:44.138314  5903 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 19:41:44.139063  5898 data_layer.cpp:41] output data size: 100,1,227,227
I0204 19:41:44.169361  5898 net.cpp:150] Setting up data
I0204 19:41:44.169402  5898 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 19:41:44.169411  5898 net.cpp:157] Top shape: 100 (100)
I0204 19:41:44.169417  5898 net.cpp:165] Memory required for data: 20612000
I0204 19:41:44.169428  5898 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 19:41:44.169450  5898 net.cpp:106] Creating Layer label_data_1_split
I0204 19:41:44.169457  5898 net.cpp:454] label_data_1_split <- label
I0204 19:41:44.169471  5898 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 19:41:44.169500  5898 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 19:41:44.169513  5898 net.cpp:150] Setting up label_data_1_split
I0204 19:41:44.169522  5898 net.cpp:157] Top shape: 100 (100)
I0204 19:41:44.169528  5898 net.cpp:157] Top shape: 100 (100)
I0204 19:41:44.169533  5898 net.cpp:165] Memory required for data: 20612800
I0204 19:41:44.169539  5898 layer_factory.hpp:77] Creating layer conv1
I0204 19:41:44.169558  5898 net.cpp:106] Creating Layer conv1
I0204 19:41:44.169564  5898 net.cpp:454] conv1 <- data
I0204 19:41:44.169574  5898 net.cpp:411] conv1 -> conv1
I0204 19:41:44.169651  5898 net.cpp:150] Setting up conv1
I0204 19:41:44.169662  5898 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 19:41:44.169667  5898 net.cpp:165] Memory required for data: 59332800
I0204 19:41:44.169682  5898 layer_factory.hpp:77] Creating layer relu1
I0204 19:41:44.169694  5898 net.cpp:106] Creating Layer relu1
I0204 19:41:44.169702  5898 net.cpp:454] relu1 <- conv1
I0204 19:41:44.169710  5898 net.cpp:397] relu1 -> conv1 (in-place)
I0204 19:41:44.169720  5898 net.cpp:150] Setting up relu1
I0204 19:41:44.169728  5898 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 19:41:44.169734  5898 net.cpp:165] Memory required for data: 98052800
I0204 19:41:44.169739  5898 layer_factory.hpp:77] Creating layer pool1
I0204 19:41:44.169750  5898 net.cpp:106] Creating Layer pool1
I0204 19:41:44.169759  5898 net.cpp:454] pool1 <- conv1
I0204 19:41:44.169767  5898 net.cpp:411] pool1 -> pool1
I0204 19:41:44.169782  5898 net.cpp:150] Setting up pool1
I0204 19:41:44.169790  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.169795  5898 net.cpp:165] Memory required for data: 107384000
I0204 19:41:44.169801  5898 layer_factory.hpp:77] Creating layer norm1
I0204 19:41:44.169812  5898 net.cpp:106] Creating Layer norm1
I0204 19:41:44.169818  5898 net.cpp:454] norm1 <- pool1
I0204 19:41:44.169828  5898 net.cpp:411] norm1 -> norm1
I0204 19:41:44.169841  5898 net.cpp:150] Setting up norm1
I0204 19:41:44.169847  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.169853  5898 net.cpp:165] Memory required for data: 116715200
I0204 19:41:44.169859  5898 layer_factory.hpp:77] Creating layer conv2
I0204 19:41:44.169870  5898 net.cpp:106] Creating Layer conv2
I0204 19:41:44.169877  5898 net.cpp:454] conv2 <- norm1
I0204 19:41:44.169886  5898 net.cpp:411] conv2 -> conv2
I0204 19:41:44.170019  5898 net.cpp:150] Setting up conv2
I0204 19:41:44.170029  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.170035  5898 net.cpp:165] Memory required for data: 126046400
I0204 19:41:44.170047  5898 layer_factory.hpp:77] Creating layer relu2
I0204 19:41:44.170058  5898 net.cpp:106] Creating Layer relu2
I0204 19:41:44.170063  5898 net.cpp:454] relu2 <- conv2
I0204 19:41:44.170083  5898 net.cpp:397] relu2 -> conv2 (in-place)
I0204 19:41:44.170109  5898 net.cpp:150] Setting up relu2
I0204 19:41:44.170116  5898 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 19:41:44.170122  5898 net.cpp:165] Memory required for data: 135377600
I0204 19:41:44.170130  5898 layer_factory.hpp:77] Creating layer pool2
I0204 19:41:44.170140  5898 net.cpp:106] Creating Layer pool2
I0204 19:41:44.170146  5898 net.cpp:454] pool2 <- conv2
I0204 19:41:44.170156  5898 net.cpp:411] pool2 -> pool2
I0204 19:41:44.170168  5898 net.cpp:150] Setting up pool2
I0204 19:41:44.170176  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170181  5898 net.cpp:165] Memory required for data: 137540800
I0204 19:41:44.170186  5898 layer_factory.hpp:77] Creating layer norm2
I0204 19:41:44.170197  5898 net.cpp:106] Creating Layer norm2
I0204 19:41:44.170203  5898 net.cpp:454] norm2 <- pool2
I0204 19:41:44.170212  5898 net.cpp:411] norm2 -> norm2
I0204 19:41:44.170222  5898 net.cpp:150] Setting up norm2
I0204 19:41:44.170229  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170235  5898 net.cpp:165] Memory required for data: 139704000
I0204 19:41:44.170240  5898 layer_factory.hpp:77] Creating layer conv3
I0204 19:41:44.170253  5898 net.cpp:106] Creating Layer conv3
I0204 19:41:44.170258  5898 net.cpp:454] conv3 <- norm2
I0204 19:41:44.170269  5898 net.cpp:411] conv3 -> conv3
I0204 19:41:44.170369  5898 net.cpp:150] Setting up conv3
I0204 19:41:44.170378  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170383  5898 net.cpp:165] Memory required for data: 141867200
I0204 19:41:44.170394  5898 layer_factory.hpp:77] Creating layer relu3
I0204 19:41:44.170404  5898 net.cpp:106] Creating Layer relu3
I0204 19:41:44.170411  5898 net.cpp:454] relu3 <- conv3
I0204 19:41:44.170420  5898 net.cpp:397] relu3 -> conv3 (in-place)
I0204 19:41:44.170429  5898 net.cpp:150] Setting up relu3
I0204 19:41:44.170436  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170441  5898 net.cpp:165] Memory required for data: 144030400
I0204 19:41:44.170447  5898 layer_factory.hpp:77] Creating layer conv4
I0204 19:41:44.170459  5898 net.cpp:106] Creating Layer conv4
I0204 19:41:44.170464  5898 net.cpp:454] conv4 <- conv3
I0204 19:41:44.170475  5898 net.cpp:411] conv4 -> conv4
I0204 19:41:44.170536  5898 net.cpp:150] Setting up conv4
I0204 19:41:44.170547  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170552  5898 net.cpp:165] Memory required for data: 146193600
I0204 19:41:44.170560  5898 layer_factory.hpp:77] Creating layer relu4
I0204 19:41:44.170568  5898 net.cpp:106] Creating Layer relu4
I0204 19:41:44.170574  5898 net.cpp:454] relu4 <- conv4
I0204 19:41:44.170583  5898 net.cpp:397] relu4 -> conv4 (in-place)
I0204 19:41:44.170591  5898 net.cpp:150] Setting up relu4
I0204 19:41:44.170598  5898 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 19:41:44.170603  5898 net.cpp:165] Memory required for data: 148356800
I0204 19:41:44.170611  5898 layer_factory.hpp:77] Creating layer conv5
I0204 19:41:44.170622  5898 net.cpp:106] Creating Layer conv5
I0204 19:41:44.170629  5898 net.cpp:454] conv5 <- conv4
I0204 19:41:44.170637  5898 net.cpp:411] conv5 -> conv5
I0204 19:41:44.170680  5898 net.cpp:150] Setting up conv5
I0204 19:41:44.170687  5898 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 19:41:44.170692  5898 net.cpp:165] Memory required for data: 149438400
I0204 19:41:44.170704  5898 layer_factory.hpp:77] Creating layer relu5
I0204 19:41:44.170713  5898 net.cpp:106] Creating Layer relu5
I0204 19:41:44.170718  5898 net.cpp:454] relu5 <- conv5
I0204 19:41:44.170727  5898 net.cpp:397] relu5 -> conv5 (in-place)
I0204 19:41:44.170735  5898 net.cpp:150] Setting up relu5
I0204 19:41:44.170742  5898 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 19:41:44.170749  5898 net.cpp:165] Memory required for data: 150520000
I0204 19:41:44.170755  5898 layer_factory.hpp:77] Creating layer pool5
I0204 19:41:44.170766  5898 net.cpp:106] Creating Layer pool5
I0204 19:41:44.170776  5898 net.cpp:454] pool5 <- conv5
I0204 19:41:44.170794  5898 net.cpp:411] pool5 -> pool5
I0204 19:41:44.170806  5898 net.cpp:150] Setting up pool5
I0204 19:41:44.170815  5898 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 19:41:44.170821  5898 net.cpp:165] Memory required for data: 150750400
I0204 19:41:44.170826  5898 layer_factory.hpp:77] Creating layer fc6
I0204 19:41:44.170840  5898 net.cpp:106] Creating Layer fc6
I0204 19:41:44.170845  5898 net.cpp:454] fc6 <- pool5
I0204 19:41:44.170853  5898 net.cpp:411] fc6 -> fc6
I0204 19:41:44.172502  5898 net.cpp:150] Setting up fc6
I0204 19:41:44.172515  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.172523  5898 net.cpp:165] Memory required for data: 150852800
I0204 19:41:44.172533  5898 layer_factory.hpp:77] Creating layer relu6
I0204 19:41:44.172543  5898 net.cpp:106] Creating Layer relu6
I0204 19:41:44.172549  5898 net.cpp:454] relu6 <- fc6
I0204 19:41:44.172559  5898 net.cpp:397] relu6 -> fc6 (in-place)
I0204 19:41:44.172569  5898 net.cpp:150] Setting up relu6
I0204 19:41:44.172575  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.172580  5898 net.cpp:165] Memory required for data: 150955200
I0204 19:41:44.172586  5898 layer_factory.hpp:77] Creating layer drop6
I0204 19:41:44.172597  5898 net.cpp:106] Creating Layer drop6
I0204 19:41:44.172603  5898 net.cpp:454] drop6 <- fc6
I0204 19:41:44.172611  5898 net.cpp:397] drop6 -> fc6 (in-place)
I0204 19:41:44.172623  5898 net.cpp:150] Setting up drop6
I0204 19:41:44.172629  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.172634  5898 net.cpp:165] Memory required for data: 151057600
I0204 19:41:44.172641  5898 layer_factory.hpp:77] Creating layer fc7
I0204 19:41:44.172651  5898 net.cpp:106] Creating Layer fc7
I0204 19:41:44.172657  5898 net.cpp:454] fc7 <- fc6
I0204 19:41:44.172664  5898 net.cpp:411] fc7 -> fc7
I0204 19:41:44.173373  5898 net.cpp:150] Setting up fc7
I0204 19:41:44.173387  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.173391  5898 net.cpp:165] Memory required for data: 151160000
I0204 19:41:44.173400  5898 layer_factory.hpp:77] Creating layer relu7
I0204 19:41:44.173408  5898 net.cpp:106] Creating Layer relu7
I0204 19:41:44.173414  5898 net.cpp:454] relu7 <- fc7
I0204 19:41:44.173421  5898 net.cpp:397] relu7 -> fc7 (in-place)
I0204 19:41:44.173430  5898 net.cpp:150] Setting up relu7
I0204 19:41:44.173437  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.173442  5898 net.cpp:165] Memory required for data: 151262400
I0204 19:41:44.173449  5898 layer_factory.hpp:77] Creating layer drop7
I0204 19:41:44.173459  5898 net.cpp:106] Creating Layer drop7
I0204 19:41:44.173465  5898 net.cpp:454] drop7 <- fc7
I0204 19:41:44.173472  5898 net.cpp:397] drop7 -> fc7 (in-place)
I0204 19:41:44.173482  5898 net.cpp:150] Setting up drop7
I0204 19:41:44.173491  5898 net.cpp:157] Top shape: 100 256 (25600)
I0204 19:41:44.173497  5898 net.cpp:165] Memory required for data: 151364800
I0204 19:41:44.173503  5898 layer_factory.hpp:77] Creating layer fc8
I0204 19:41:44.173516  5898 net.cpp:106] Creating Layer fc8
I0204 19:41:44.173521  5898 net.cpp:454] fc8 <- fc7
I0204 19:41:44.173529  5898 net.cpp:411] fc8 -> fc8
I0204 19:41:44.173555  5898 net.cpp:150] Setting up fc8
I0204 19:41:44.173564  5898 net.cpp:157] Top shape: 100 2 (200)
I0204 19:41:44.173569  5898 net.cpp:165] Memory required for data: 151365600
I0204 19:41:44.173578  5898 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 19:41:44.173586  5898 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 19:41:44.173591  5898 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 19:41:44.173601  5898 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 19:41:44.173610  5898 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 19:41:44.173619  5898 net.cpp:150] Setting up fc8_fc8_0_split
I0204 19:41:44.173635  5898 net.cpp:157] Top shape: 100 2 (200)
I0204 19:41:44.173642  5898 net.cpp:157] Top shape: 100 2 (200)
I0204 19:41:44.173648  5898 net.cpp:165] Memory required for data: 151367200
I0204 19:41:44.173653  5898 layer_factory.hpp:77] Creating layer accuracy
I0204 19:41:44.173678  5898 net.cpp:106] Creating Layer accuracy
I0204 19:41:44.173686  5898 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 19:41:44.173692  5898 net.cpp:454] accuracy <- label_data_1_split_0
I0204 19:41:44.173702  5898 net.cpp:411] accuracy -> accuracy
I0204 19:41:44.173713  5898 net.cpp:150] Setting up accuracy
I0204 19:41:44.173720  5898 net.cpp:157] Top shape: (1)
I0204 19:41:44.173725  5898 net.cpp:165] Memory required for data: 151367204
I0204 19:41:44.173732  5898 layer_factory.hpp:77] Creating layer loss
I0204 19:41:44.173743  5898 net.cpp:106] Creating Layer loss
I0204 19:41:44.173748  5898 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 19:41:44.173755  5898 net.cpp:454] loss <- label_data_1_split_1
I0204 19:41:44.173763  5898 net.cpp:411] loss -> loss
I0204 19:41:44.173774  5898 layer_factory.hpp:77] Creating layer loss
I0204 19:41:44.173811  5898 net.cpp:150] Setting up loss
I0204 19:41:44.173823  5898 net.cpp:157] Top shape: (1)
I0204 19:41:44.173828  5898 net.cpp:160]     with loss weight 1
I0204 19:41:44.173846  5898 net.cpp:165] Memory required for data: 151367208
I0204 19:41:44.173852  5898 net.cpp:226] loss needs backward computation.
I0204 19:41:44.173859  5898 net.cpp:228] accuracy does not need backward computation.
I0204 19:41:44.173866  5898 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 19:41:44.173872  5898 net.cpp:226] fc8 needs backward computation.
I0204 19:41:44.173878  5898 net.cpp:226] drop7 needs backward computation.
I0204 19:41:44.173884  5898 net.cpp:226] relu7 needs backward computation.
I0204 19:41:44.173890  5898 net.cpp:226] fc7 needs backward computation.
I0204 19:41:44.173897  5898 net.cpp:226] drop6 needs backward computation.
I0204 19:41:44.173902  5898 net.cpp:226] relu6 needs backward computation.
I0204 19:41:44.173908  5898 net.cpp:226] fc6 needs backward computation.
I0204 19:41:44.173914  5898 net.cpp:226] pool5 needs backward computation.
I0204 19:41:44.173920  5898 net.cpp:226] relu5 needs backward computation.
I0204 19:41:44.173925  5898 net.cpp:226] conv5 needs backward computation.
I0204 19:41:44.173933  5898 net.cpp:226] relu4 needs backward computation.
I0204 19:41:44.173941  5898 net.cpp:226] conv4 needs backward computation.
I0204 19:41:44.173951  5898 net.cpp:226] relu3 needs backward computation.
I0204 19:41:44.173957  5898 net.cpp:226] conv3 needs backward computation.
I0204 19:41:44.173964  5898 net.cpp:226] norm2 needs backward computation.
I0204 19:41:44.173970  5898 net.cpp:226] pool2 needs backward computation.
I0204 19:41:44.173976  5898 net.cpp:226] relu2 needs backward computation.
I0204 19:41:44.173982  5898 net.cpp:226] conv2 needs backward computation.
I0204 19:41:44.173988  5898 net.cpp:226] norm1 needs backward computation.
I0204 19:41:44.173995  5898 net.cpp:226] pool1 needs backward computation.
I0204 19:41:44.174001  5898 net.cpp:226] relu1 needs backward computation.
I0204 19:41:44.174007  5898 net.cpp:226] conv1 needs backward computation.
I0204 19:41:44.174015  5898 net.cpp:228] label_data_1_split does not need backward computation.
I0204 19:41:44.174021  5898 net.cpp:228] data does not need backward computation.
I0204 19:41:44.174026  5898 net.cpp:270] This network produces output accuracy
I0204 19:41:44.174033  5898 net.cpp:270] This network produces output loss
I0204 19:41:44.174064  5898 net.cpp:283] Network initialization done.
I0204 19:41:44.174185  5898 solver.cpp:60] Solver scaffolding done.
I0204 19:41:44.174263  5898 caffe.cpp:212] Starting Optimization
I0204 19:41:44.174273  5898 solver.cpp:288] Solving CaffeNet
I0204 19:41:44.174278  5898 solver.cpp:289] Learning Rate Policy: step
I0204 19:41:44.175088  5898 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 19:41:44.175246  5898 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 19:41:51.396352  5898 solver.cpp:409]     Test net output #0: accuracy = 0.502
I0204 19:41:51.396415  5898 solver.cpp:409]     Test net output #1: loss = 1.90532 (* 1 = 1.90532 loss)
I0204 19:41:53.020772  5898 solver.cpp:237] Iteration 0, loss = 8.53662
I0204 19:41:53.020855  5898 solver.cpp:253]     Train net output #0: loss = 8.53662 (* 1 = 8.53662 loss)
I0204 19:41:53.020869  5898 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 19:42:09.458039  5898 solver.cpp:237] Iteration 10, loss = 1.13602
I0204 19:42:09.458113  5898 solver.cpp:253]     Train net output #0: loss = 1.13602 (* 1 = 1.13602 loss)
I0204 19:42:09.458125  5898 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 19:42:27.073266  5898 solver.cpp:237] Iteration 20, loss = 0.925755
I0204 19:42:27.073410  5898 solver.cpp:253]     Train net output #0: loss = 0.925755 (* 1 = 0.925755 loss)
I0204 19:42:27.073421  5898 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 19:42:44.562010  5898 solver.cpp:237] Iteration 30, loss = 0.896608
I0204 19:42:44.562083  5898 solver.cpp:253]     Train net output #0: loss = 0.896608 (* 1 = 0.896608 loss)
I0204 19:42:44.562099  5898 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 19:43:02.083045  5898 solver.cpp:237] Iteration 40, loss = 0.803974
I0204 19:43:02.083246  5898 solver.cpp:253]     Train net output #0: loss = 0.803974 (* 1 = 0.803974 loss)
I0204 19:43:02.083261  5898 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 19:43:19.644350  5898 solver.cpp:237] Iteration 50, loss = 0.81022
I0204 19:43:19.644413  5898 solver.cpp:253]     Train net output #0: loss = 0.81022 (* 1 = 0.81022 loss)
I0204 19:43:19.644425  5898 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 19:43:37.250635  5898 solver.cpp:237] Iteration 60, loss = 0.847587
I0204 19:43:37.250815  5898 solver.cpp:253]     Train net output #0: loss = 0.847587 (* 1 = 0.847587 loss)
I0204 19:43:37.250830  5898 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 19:43:54.875766  5898 solver.cpp:237] Iteration 70, loss = 0.732063
I0204 19:43:54.875828  5898 solver.cpp:253]     Train net output #0: loss = 0.732063 (* 1 = 0.732063 loss)
I0204 19:43:54.875839  5898 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 19:44:12.523212  5898 solver.cpp:237] Iteration 80, loss = 0.693655
I0204 19:44:12.523442  5898 solver.cpp:253]     Train net output #0: loss = 0.693655 (* 1 = 0.693655 loss)
I0204 19:44:12.523458  5898 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 19:44:30.070436  5898 solver.cpp:237] Iteration 90, loss = 0.742728
I0204 19:44:30.070515  5898 solver.cpp:253]     Train net output #0: loss = 0.742728 (* 1 = 0.742728 loss)
I0204 19:44:30.070528  5898 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 19:44:45.913341  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_100.caffemodel
I0204 19:44:45.917168  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_100.solverstate
I0204 19:44:45.918576  5898 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 19:44:54.150825  5898 solver.cpp:409]     Test net output #0: accuracy = 0.709
I0204 19:44:54.150897  5898 solver.cpp:409]     Test net output #1: loss = 0.590914 (* 1 = 0.590914 loss)
I0204 19:44:55.915163  5898 solver.cpp:237] Iteration 100, loss = 0.676278
I0204 19:44:55.915236  5898 solver.cpp:253]     Train net output #0: loss = 0.676278 (* 1 = 0.676278 loss)
I0204 19:44:55.915249  5898 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 19:45:13.697657  5898 solver.cpp:237] Iteration 110, loss = 0.58927
I0204 19:45:13.697731  5898 solver.cpp:253]     Train net output #0: loss = 0.58927 (* 1 = 0.58927 loss)
I0204 19:45:13.697742  5898 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 19:45:31.707404  5898 solver.cpp:237] Iteration 120, loss = 0.615733
I0204 19:45:31.707630  5898 solver.cpp:253]     Train net output #0: loss = 0.615733 (* 1 = 0.615733 loss)
I0204 19:45:31.707645  5898 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 19:45:50.122910  5898 solver.cpp:237] Iteration 130, loss = 0.56879
I0204 19:45:50.122982  5898 solver.cpp:253]     Train net output #0: loss = 0.56879 (* 1 = 0.56879 loss)
I0204 19:45:50.123008  5898 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 19:46:09.233563  5898 solver.cpp:237] Iteration 140, loss = 0.63272
I0204 19:46:09.233783  5898 solver.cpp:253]     Train net output #0: loss = 0.63272 (* 1 = 0.63272 loss)
I0204 19:46:09.233796  5898 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 19:46:29.460760  5898 solver.cpp:237] Iteration 150, loss = 0.618538
I0204 19:46:29.460824  5898 solver.cpp:253]     Train net output #0: loss = 0.618538 (* 1 = 0.618538 loss)
I0204 19:46:29.460836  5898 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 19:46:50.340538  5898 solver.cpp:237] Iteration 160, loss = 0.464606
I0204 19:46:50.340733  5898 solver.cpp:253]     Train net output #0: loss = 0.464606 (* 1 = 0.464606 loss)
I0204 19:46:50.340747  5898 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 19:47:12.292439  5898 solver.cpp:237] Iteration 170, loss = 0.447093
I0204 19:47:12.292501  5898 solver.cpp:253]     Train net output #0: loss = 0.447093 (* 1 = 0.447093 loss)
I0204 19:47:12.292513  5898 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 19:47:35.724603  5898 solver.cpp:237] Iteration 180, loss = 0.446997
I0204 19:47:35.724792  5898 solver.cpp:253]     Train net output #0: loss = 0.446997 (* 1 = 0.446997 loss)
I0204 19:47:35.724807  5898 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 19:47:59.713078  5898 solver.cpp:237] Iteration 190, loss = 0.458601
I0204 19:47:59.713143  5898 solver.cpp:253]     Train net output #0: loss = 0.458601 (* 1 = 0.458601 loss)
I0204 19:47:59.713155  5898 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 19:48:21.270618  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_200.caffemodel
I0204 19:48:21.274408  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_200.solverstate
I0204 19:48:21.275831  5898 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 19:48:32.288429  5898 solver.cpp:409]     Test net output #0: accuracy = 0.891
I0204 19:48:32.288485  5898 solver.cpp:409]     Test net output #1: loss = 0.27762 (* 1 = 0.27762 loss)
I0204 19:48:34.632761  5898 solver.cpp:237] Iteration 200, loss = 0.383906
I0204 19:48:34.632822  5898 solver.cpp:253]     Train net output #0: loss = 0.383906 (* 1 = 0.383906 loss)
I0204 19:48:34.632834  5898 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 19:48:58.264101  5898 solver.cpp:237] Iteration 210, loss = 0.363246
I0204 19:48:58.264293  5898 solver.cpp:253]     Train net output #0: loss = 0.363246 (* 1 = 0.363246 loss)
I0204 19:48:58.264307  5898 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 19:49:21.925792  5898 solver.cpp:237] Iteration 220, loss = 0.231982
I0204 19:49:21.925853  5898 solver.cpp:253]     Train net output #0: loss = 0.231982 (* 1 = 0.231982 loss)
I0204 19:49:21.925864  5898 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 19:49:46.480221  5898 solver.cpp:237] Iteration 230, loss = 0.117959
I0204 19:49:46.480409  5898 solver.cpp:253]     Train net output #0: loss = 0.117959 (* 1 = 0.117959 loss)
I0204 19:49:46.480423  5898 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 19:50:11.692692  5898 solver.cpp:237] Iteration 240, loss = 0.239829
I0204 19:50:11.692750  5898 solver.cpp:253]     Train net output #0: loss = 0.239829 (* 1 = 0.239829 loss)
I0204 19:50:11.692762  5898 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 19:50:36.807081  5898 solver.cpp:237] Iteration 250, loss = 0.132981
I0204 19:50:36.807272  5898 solver.cpp:253]     Train net output #0: loss = 0.132981 (* 1 = 0.132981 loss)
I0204 19:50:36.807286  5898 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 19:51:01.787878  5898 solver.cpp:237] Iteration 260, loss = 0.162983
I0204 19:51:01.787945  5898 solver.cpp:253]     Train net output #0: loss = 0.162983 (* 1 = 0.162983 loss)
I0204 19:51:01.788002  5898 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 19:51:26.744663  5898 solver.cpp:237] Iteration 270, loss = 0.11615
I0204 19:51:26.744877  5898 solver.cpp:253]     Train net output #0: loss = 0.11615 (* 1 = 0.11615 loss)
I0204 19:51:26.744891  5898 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 19:51:51.930759  5898 solver.cpp:237] Iteration 280, loss = 0.0719074
I0204 19:51:51.930821  5898 solver.cpp:253]     Train net output #0: loss = 0.0719074 (* 1 = 0.0719074 loss)
I0204 19:51:51.930832  5898 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 19:52:17.002337  5898 solver.cpp:237] Iteration 290, loss = 0.130561
I0204 19:52:17.002524  5898 solver.cpp:253]     Train net output #0: loss = 0.130561 (* 1 = 0.130561 loss)
I0204 19:52:17.002538  5898 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 19:52:39.378989  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_300.caffemodel
I0204 19:52:39.383242  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_300.solverstate
I0204 19:52:39.384595  5898 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 19:52:51.303349  5898 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 19:52:51.303531  5898 solver.cpp:409]     Test net output #1: loss = 0.0318651 (* 1 = 0.0318651 loss)
I0204 19:52:53.849928  5898 solver.cpp:237] Iteration 300, loss = 0.0322621
I0204 19:52:53.849987  5898 solver.cpp:253]     Train net output #0: loss = 0.0322622 (* 1 = 0.0322622 loss)
I0204 19:52:53.849997  5898 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 19:53:19.279829  5898 solver.cpp:237] Iteration 310, loss = 0.10566
I0204 19:53:19.279892  5898 solver.cpp:253]     Train net output #0: loss = 0.10566 (* 1 = 0.10566 loss)
I0204 19:53:19.279903  5898 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 19:53:44.733348  5898 solver.cpp:237] Iteration 320, loss = 0.0821219
I0204 19:53:44.733541  5898 solver.cpp:253]     Train net output #0: loss = 0.0821219 (* 1 = 0.0821219 loss)
I0204 19:53:44.733556  5898 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 19:54:10.019875  5898 solver.cpp:237] Iteration 330, loss = 0.0533173
I0204 19:54:10.019948  5898 solver.cpp:253]     Train net output #0: loss = 0.0533174 (* 1 = 0.0533174 loss)
I0204 19:54:10.019959  5898 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 19:54:35.360158  5898 solver.cpp:237] Iteration 340, loss = 0.0760877
I0204 19:54:35.361068  5898 solver.cpp:253]     Train net output #0: loss = 0.0760877 (* 1 = 0.0760877 loss)
I0204 19:54:35.361098  5898 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 19:55:00.426915  5898 solver.cpp:237] Iteration 350, loss = 0.111732
I0204 19:55:00.426985  5898 solver.cpp:253]     Train net output #0: loss = 0.111732 (* 1 = 0.111732 loss)
I0204 19:55:00.426997  5898 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 19:55:25.983182  5898 solver.cpp:237] Iteration 360, loss = 0.0204872
I0204 19:55:25.983379  5898 solver.cpp:253]     Train net output #0: loss = 0.0204873 (* 1 = 0.0204873 loss)
I0204 19:55:25.983394  5898 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 19:55:51.691185  5898 solver.cpp:237] Iteration 370, loss = 0.142023
I0204 19:55:51.691249  5898 solver.cpp:253]     Train net output #0: loss = 0.142023 (* 1 = 0.142023 loss)
I0204 19:55:51.691261  5898 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 19:56:16.968561  5898 solver.cpp:237] Iteration 380, loss = 0.0541357
I0204 19:56:16.968741  5898 solver.cpp:253]     Train net output #0: loss = 0.0541357 (* 1 = 0.0541357 loss)
I0204 19:56:16.968755  5898 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 19:56:43.099820  5898 solver.cpp:237] Iteration 390, loss = 0.0632749
I0204 19:56:43.099903  5898 solver.cpp:253]     Train net output #0: loss = 0.063275 (* 1 = 0.063275 loss)
I0204 19:56:43.099916  5898 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 19:57:06.407232  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_400.caffemodel
I0204 19:57:06.411157  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_400.solverstate
I0204 19:57:06.412451  5898 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 19:57:18.833847  5898 solver.cpp:409]     Test net output #0: accuracy = 0.984
I0204 19:57:18.833917  5898 solver.cpp:409]     Test net output #1: loss = 0.0454984 (* 1 = 0.0454984 loss)
I0204 19:57:21.440534  5898 solver.cpp:237] Iteration 400, loss = 0.0758056
I0204 19:57:21.440603  5898 solver.cpp:253]     Train net output #0: loss = 0.0758057 (* 1 = 0.0758057 loss)
I0204 19:57:21.440615  5898 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 19:57:47.148831  5898 solver.cpp:237] Iteration 410, loss = 0.0134697
I0204 19:57:47.149075  5898 solver.cpp:253]     Train net output #0: loss = 0.0134698 (* 1 = 0.0134698 loss)
I0204 19:57:47.149091  5898 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 19:58:13.348687  5898 solver.cpp:237] Iteration 420, loss = 0.0184999
I0204 19:58:13.348760  5898 solver.cpp:253]     Train net output #0: loss = 0.0184999 (* 1 = 0.0184999 loss)
I0204 19:58:13.348773  5898 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 19:58:39.726974  5898 solver.cpp:237] Iteration 430, loss = 0.097623
I0204 19:58:39.727211  5898 solver.cpp:253]     Train net output #0: loss = 0.0976231 (* 1 = 0.0976231 loss)
I0204 19:58:39.727227  5898 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 19:59:06.122947  5898 solver.cpp:237] Iteration 440, loss = 0.0110033
I0204 19:59:06.123028  5898 solver.cpp:253]     Train net output #0: loss = 0.0110033 (* 1 = 0.0110033 loss)
I0204 19:59:06.123041  5898 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 19:59:32.239544  5898 solver.cpp:237] Iteration 450, loss = 0.0201671
I0204 19:59:32.239944  5898 solver.cpp:253]     Train net output #0: loss = 0.0201672 (* 1 = 0.0201672 loss)
I0204 19:59:32.239970  5898 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 19:59:58.425009  5898 solver.cpp:237] Iteration 460, loss = 0.00173014
I0204 19:59:58.425101  5898 solver.cpp:253]     Train net output #0: loss = 0.00173018 (* 1 = 0.00173018 loss)
I0204 19:59:58.425114  5898 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 20:00:24.340648  5898 solver.cpp:237] Iteration 470, loss = 0.0460865
I0204 20:00:24.340869  5898 solver.cpp:253]     Train net output #0: loss = 0.0460865 (* 1 = 0.0460865 loss)
I0204 20:00:24.340884  5898 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 20:00:50.359421  5898 solver.cpp:237] Iteration 480, loss = 0.12646
I0204 20:00:50.359499  5898 solver.cpp:253]     Train net output #0: loss = 0.12646 (* 1 = 0.12646 loss)
I0204 20:00:50.359513  5898 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 20:01:16.355383  5898 solver.cpp:237] Iteration 490, loss = 0.0268626
I0204 20:01:16.355618  5898 solver.cpp:253]     Train net output #0: loss = 0.0268627 (* 1 = 0.0268627 loss)
I0204 20:01:16.355633  5898 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 20:01:39.780444  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_500.caffemodel
I0204 20:01:39.784040  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_500.solverstate
I0204 20:01:39.785442  5898 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 20:01:52.029352  5898 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 20:01:52.029577  5898 solver.cpp:409]     Test net output #1: loss = 0.0170721 (* 1 = 0.0170721 loss)
I0204 20:01:54.631225  5898 solver.cpp:237] Iteration 500, loss = 0.0346324
I0204 20:01:54.631315  5898 solver.cpp:253]     Train net output #0: loss = 0.0346325 (* 1 = 0.0346325 loss)
I0204 20:01:54.631327  5898 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 20:02:20.649152  5898 solver.cpp:237] Iteration 510, loss = 0.00580292
I0204 20:02:20.649229  5898 solver.cpp:253]     Train net output #0: loss = 0.00580295 (* 1 = 0.00580295 loss)
I0204 20:02:20.649241  5898 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 20:02:46.720253  5898 solver.cpp:237] Iteration 520, loss = 0.0425708
I0204 20:02:46.720510  5898 solver.cpp:253]     Train net output #0: loss = 0.0425708 (* 1 = 0.0425708 loss)
I0204 20:02:46.720525  5898 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 20:03:13.225673  5898 solver.cpp:237] Iteration 530, loss = 0.0401206
I0204 20:03:13.225747  5898 solver.cpp:253]     Train net output #0: loss = 0.0401207 (* 1 = 0.0401207 loss)
I0204 20:03:13.225760  5898 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 20:03:39.900980  5898 solver.cpp:237] Iteration 540, loss = 0.00334598
I0204 20:03:39.901211  5898 solver.cpp:253]     Train net output #0: loss = 0.003346 (* 1 = 0.003346 loss)
I0204 20:03:39.901226  5898 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 20:04:06.662504  5898 solver.cpp:237] Iteration 550, loss = 0.00361563
I0204 20:04:06.662585  5898 solver.cpp:253]     Train net output #0: loss = 0.00361564 (* 1 = 0.00361564 loss)
I0204 20:04:06.662600  5898 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 20:04:33.641481  5898 solver.cpp:237] Iteration 560, loss = 0.00500173
I0204 20:04:33.641713  5898 solver.cpp:253]     Train net output #0: loss = 0.00500174 (* 1 = 0.00500174 loss)
I0204 20:04:33.641728  5898 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 20:05:00.669834  5898 solver.cpp:237] Iteration 570, loss = 0.026559
I0204 20:05:00.669914  5898 solver.cpp:253]     Train net output #0: loss = 0.026559 (* 1 = 0.026559 loss)
I0204 20:05:00.669926  5898 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 20:05:27.093415  5898 solver.cpp:237] Iteration 580, loss = 0.044922
I0204 20:05:27.093621  5898 solver.cpp:253]     Train net output #0: loss = 0.044922 (* 1 = 0.044922 loss)
I0204 20:05:27.093636  5898 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 20:05:53.746431  5898 solver.cpp:237] Iteration 590, loss = 0.0547392
I0204 20:05:53.746515  5898 solver.cpp:253]     Train net output #0: loss = 0.0547392 (* 1 = 0.0547392 loss)
I0204 20:05:53.746526  5898 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 20:06:17.963019  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_600.caffemodel
I0204 20:06:17.966989  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_600.solverstate
I0204 20:06:17.968381  5898 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 20:06:30.763836  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:06:30.763908  5898 solver.cpp:409]     Test net output #1: loss = 0.0106903 (* 1 = 0.0106903 loss)
I0204 20:06:33.424901  5898 solver.cpp:237] Iteration 600, loss = 0.00815338
I0204 20:06:33.424976  5898 solver.cpp:253]     Train net output #0: loss = 0.00815338 (* 1 = 0.00815338 loss)
I0204 20:06:33.424989  5898 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 20:07:00.541759  5898 solver.cpp:237] Iteration 610, loss = 0.100934
I0204 20:07:00.541990  5898 solver.cpp:253]     Train net output #0: loss = 0.100934 (* 1 = 0.100934 loss)
I0204 20:07:00.542004  5898 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 20:07:27.313738  5898 solver.cpp:237] Iteration 620, loss = 0.00470274
I0204 20:07:27.313817  5898 solver.cpp:253]     Train net output #0: loss = 0.00470275 (* 1 = 0.00470275 loss)
I0204 20:07:27.313829  5898 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 20:07:54.453793  5898 solver.cpp:237] Iteration 630, loss = 0.0396997
I0204 20:07:54.454080  5898 solver.cpp:253]     Train net output #0: loss = 0.0396997 (* 1 = 0.0396997 loss)
I0204 20:07:54.454095  5898 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 20:08:21.297174  5898 solver.cpp:237] Iteration 640, loss = 0.0149174
I0204 20:08:21.297255  5898 solver.cpp:253]     Train net output #0: loss = 0.0149174 (* 1 = 0.0149174 loss)
I0204 20:08:21.297267  5898 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 20:08:47.989478  5898 solver.cpp:237] Iteration 650, loss = 0.00210442
I0204 20:08:47.989694  5898 solver.cpp:253]     Train net output #0: loss = 0.00210442 (* 1 = 0.00210442 loss)
I0204 20:08:47.989711  5898 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 20:09:14.772609  5898 solver.cpp:237] Iteration 660, loss = 0.0493127
I0204 20:09:14.772689  5898 solver.cpp:253]     Train net output #0: loss = 0.0493128 (* 1 = 0.0493128 loss)
I0204 20:09:14.772701  5898 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 20:09:41.466680  5898 solver.cpp:237] Iteration 670, loss = 0.0071446
I0204 20:09:41.989912  5898 solver.cpp:253]     Train net output #0: loss = 0.00714462 (* 1 = 0.00714462 loss)
I0204 20:09:41.989949  5898 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 20:10:08.926831  5898 solver.cpp:237] Iteration 680, loss = 0.102454
I0204 20:10:08.926908  5898 solver.cpp:253]     Train net output #0: loss = 0.102454 (* 1 = 0.102454 loss)
I0204 20:10:08.926921  5898 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 20:10:36.016633  5898 solver.cpp:237] Iteration 690, loss = 0.0165982
I0204 20:10:36.016849  5898 solver.cpp:253]     Train net output #0: loss = 0.0165982 (* 1 = 0.0165982 loss)
I0204 20:10:36.016865  5898 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 20:11:00.279532  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_700.caffemodel
I0204 20:11:00.283140  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_700.solverstate
I0204 20:11:00.284538  5898 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 20:11:13.226032  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:11:13.226258  5898 solver.cpp:409]     Test net output #1: loss = 0.00766204 (* 1 = 0.00766204 loss)
I0204 20:11:15.957916  5898 solver.cpp:237] Iteration 700, loss = 0.00550342
I0204 20:11:15.957991  5898 solver.cpp:253]     Train net output #0: loss = 0.00550344 (* 1 = 0.00550344 loss)
I0204 20:11:15.958003  5898 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 20:11:43.488858  5898 solver.cpp:237] Iteration 710, loss = 0.0267194
I0204 20:11:43.489259  5898 solver.cpp:253]     Train net output #0: loss = 0.0267194 (* 1 = 0.0267194 loss)
I0204 20:11:43.489275  5898 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 20:12:10.542197  5898 solver.cpp:237] Iteration 720, loss = 0.00442957
I0204 20:12:10.542278  5898 solver.cpp:253]     Train net output #0: loss = 0.00442958 (* 1 = 0.00442958 loss)
I0204 20:12:10.542290  5898 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 20:12:37.701107  5898 solver.cpp:237] Iteration 730, loss = 0.0184109
I0204 20:12:37.701318  5898 solver.cpp:253]     Train net output #0: loss = 0.0184109 (* 1 = 0.0184109 loss)
I0204 20:12:37.701333  5898 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 20:13:04.891000  5898 solver.cpp:237] Iteration 740, loss = 0.00520562
I0204 20:13:04.891088  5898 solver.cpp:253]     Train net output #0: loss = 0.00520564 (* 1 = 0.00520564 loss)
I0204 20:13:04.891100  5898 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 20:13:32.156455  5898 solver.cpp:237] Iteration 750, loss = 0.00128052
I0204 20:13:32.156877  5898 solver.cpp:253]     Train net output #0: loss = 0.00128054 (* 1 = 0.00128054 loss)
I0204 20:13:32.156903  5898 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 20:13:59.702644  5898 solver.cpp:237] Iteration 760, loss = 0.00328248
I0204 20:13:59.702740  5898 solver.cpp:253]     Train net output #0: loss = 0.0032825 (* 1 = 0.0032825 loss)
I0204 20:13:59.702754  5898 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 20:14:27.039551  5898 solver.cpp:237] Iteration 770, loss = 0.00121724
I0204 20:14:27.039818  5898 solver.cpp:253]     Train net output #0: loss = 0.00121726 (* 1 = 0.00121726 loss)
I0204 20:14:27.039834  5898 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 20:14:54.136548  5898 solver.cpp:237] Iteration 780, loss = 0.00279344
I0204 20:14:54.136628  5898 solver.cpp:253]     Train net output #0: loss = 0.00279346 (* 1 = 0.00279346 loss)
I0204 20:14:54.136641  5898 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 20:15:21.309772  5898 solver.cpp:237] Iteration 790, loss = 0.00228217
I0204 20:15:21.310009  5898 solver.cpp:253]     Train net output #0: loss = 0.00228219 (* 1 = 0.00228219 loss)
I0204 20:15:21.310024  5898 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 20:15:45.974092  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_800.caffemodel
I0204 20:15:45.977695  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_800.solverstate
I0204 20:15:45.979110  5898 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 20:15:59.035259  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:15:59.035476  5898 solver.cpp:409]     Test net output #1: loss = 0.00793804 (* 1 = 0.00793804 loss)
I0204 20:16:01.752467  5898 solver.cpp:237] Iteration 800, loss = 0.00196712
I0204 20:16:01.752545  5898 solver.cpp:253]     Train net output #0: loss = 0.00196714 (* 1 = 0.00196714 loss)
I0204 20:16:01.752558  5898 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 20:16:29.199489  5898 solver.cpp:237] Iteration 810, loss = 0.00581624
I0204 20:16:29.199705  5898 solver.cpp:253]     Train net output #0: loss = 0.00581624 (* 1 = 0.00581624 loss)
I0204 20:16:29.199722  5898 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 20:16:57.026223  5898 solver.cpp:237] Iteration 820, loss = 0.0290056
I0204 20:16:57.026310  5898 solver.cpp:253]     Train net output #0: loss = 0.0290056 (* 1 = 0.0290056 loss)
I0204 20:16:57.026321  5898 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 20:17:24.945271  5898 solver.cpp:237] Iteration 830, loss = 0.00698909
I0204 20:17:24.945488  5898 solver.cpp:253]     Train net output #0: loss = 0.00698909 (* 1 = 0.00698909 loss)
I0204 20:17:24.945503  5898 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 20:17:52.865782  5898 solver.cpp:237] Iteration 840, loss = 0.00362172
I0204 20:17:52.865869  5898 solver.cpp:253]     Train net output #0: loss = 0.00362171 (* 1 = 0.00362171 loss)
I0204 20:17:52.865882  5898 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 20:18:20.563091  5898 solver.cpp:237] Iteration 850, loss = 0.00334882
I0204 20:18:20.563319  5898 solver.cpp:253]     Train net output #0: loss = 0.00334882 (* 1 = 0.00334882 loss)
I0204 20:18:20.563334  5898 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 20:18:48.326114  5898 solver.cpp:237] Iteration 860, loss = 0.0125398
I0204 20:18:48.326205  5898 solver.cpp:253]     Train net output #0: loss = 0.0125398 (* 1 = 0.0125398 loss)
I0204 20:18:48.326216  5898 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 20:19:16.523191  5898 solver.cpp:237] Iteration 870, loss = 0.00170142
I0204 20:19:16.523403  5898 solver.cpp:253]     Train net output #0: loss = 0.00170142 (* 1 = 0.00170142 loss)
I0204 20:19:16.523418  5898 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 20:19:44.734532  5898 solver.cpp:237] Iteration 880, loss = 0.0092553
I0204 20:19:44.734599  5898 solver.cpp:253]     Train net output #0: loss = 0.00925531 (* 1 = 0.00925531 loss)
I0204 20:19:44.734611  5898 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 20:20:12.678789  5898 solver.cpp:237] Iteration 890, loss = 0.0119622
I0204 20:20:12.679046  5898 solver.cpp:253]     Train net output #0: loss = 0.0119622 (* 1 = 0.0119622 loss)
I0204 20:20:12.679069  5898 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 20:20:37.671360  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_900.caffemodel
I0204 20:20:37.674983  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_900.solverstate
I0204 20:20:37.676403  5898 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 20:20:51.037159  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:20:51.037364  5898 solver.cpp:409]     Test net output #1: loss = 0.00436735 (* 1 = 0.00436735 loss)
I0204 20:20:53.873356  5898 solver.cpp:237] Iteration 900, loss = 0.0090018
I0204 20:20:53.873432  5898 solver.cpp:253]     Train net output #0: loss = 0.0090018 (* 1 = 0.0090018 loss)
I0204 20:20:53.873445  5898 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 20:21:22.155068  5898 solver.cpp:237] Iteration 910, loss = 0.00873493
I0204 20:21:22.155272  5898 solver.cpp:253]     Train net output #0: loss = 0.00873493 (* 1 = 0.00873493 loss)
I0204 20:21:22.155287  5898 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 20:21:49.826190  5898 solver.cpp:237] Iteration 920, loss = 0.00187788
I0204 20:21:49.826267  5898 solver.cpp:253]     Train net output #0: loss = 0.00187788 (* 1 = 0.00187788 loss)
I0204 20:21:49.826280  5898 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 20:22:17.162041  5898 solver.cpp:237] Iteration 930, loss = 0.00252343
I0204 20:22:17.162245  5898 solver.cpp:253]     Train net output #0: loss = 0.00252343 (* 1 = 0.00252343 loss)
I0204 20:22:17.162258  5898 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 20:22:44.510279  5898 solver.cpp:237] Iteration 940, loss = 0.00153194
I0204 20:22:44.510351  5898 solver.cpp:253]     Train net output #0: loss = 0.00153194 (* 1 = 0.00153194 loss)
I0204 20:22:44.510362  5898 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 20:23:11.657009  5898 solver.cpp:237] Iteration 950, loss = 0.00638515
I0204 20:23:11.657210  5898 solver.cpp:253]     Train net output #0: loss = 0.00638515 (* 1 = 0.00638515 loss)
I0204 20:23:11.657224  5898 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 20:23:38.694830  5898 solver.cpp:237] Iteration 960, loss = 0.055959
I0204 20:23:38.694907  5898 solver.cpp:253]     Train net output #0: loss = 0.055959 (* 1 = 0.055959 loss)
I0204 20:23:38.694918  5898 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 20:24:05.702858  5898 solver.cpp:237] Iteration 970, loss = 0.0235825
I0204 20:24:05.703091  5898 solver.cpp:253]     Train net output #0: loss = 0.0235825 (* 1 = 0.0235825 loss)
I0204 20:24:05.703106  5898 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 20:24:32.921131  5898 solver.cpp:237] Iteration 980, loss = 0.00143874
I0204 20:24:32.921211  5898 solver.cpp:253]     Train net output #0: loss = 0.00143874 (* 1 = 0.00143874 loss)
I0204 20:24:32.921222  5898 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 20:24:59.916187  5898 solver.cpp:237] Iteration 990, loss = 0.000493761
I0204 20:24:59.916414  5898 solver.cpp:253]     Train net output #0: loss = 0.000493758 (* 1 = 0.000493758 loss)
I0204 20:24:59.916429  5898 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 20:25:24.421955  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1000.caffemodel
I0204 20:25:24.426237  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1000.solverstate
I0204 20:25:24.427639  5898 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 20:25:37.277487  5898 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 20:25:37.277711  5898 solver.cpp:409]     Test net output #1: loss = 0.00160889 (* 1 = 0.00160889 loss)
I0204 20:25:39.973150  5898 solver.cpp:237] Iteration 1000, loss = 0.00268476
I0204 20:25:39.973222  5898 solver.cpp:253]     Train net output #0: loss = 0.00268476 (* 1 = 0.00268476 loss)
I0204 20:25:39.973233  5898 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 20:26:07.094624  5898 solver.cpp:237] Iteration 1010, loss = 0.000390694
I0204 20:26:07.094704  5898 solver.cpp:253]     Train net output #0: loss = 0.000390691 (* 1 = 0.000390691 loss)
I0204 20:26:07.094717  5898 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 20:26:33.976042  5898 solver.cpp:237] Iteration 1020, loss = 0.0026612
I0204 20:26:33.976265  5898 solver.cpp:253]     Train net output #0: loss = 0.0026612 (* 1 = 0.0026612 loss)
I0204 20:26:33.976279  5898 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 20:27:01.180446  5898 solver.cpp:237] Iteration 1030, loss = 0.000251209
I0204 20:27:01.180510  5898 solver.cpp:253]     Train net output #0: loss = 0.000251205 (* 1 = 0.000251205 loss)
I0204 20:27:01.180521  5898 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 20:27:28.042778  5898 solver.cpp:237] Iteration 1040, loss = 0.00339191
I0204 20:27:28.042979  5898 solver.cpp:253]     Train net output #0: loss = 0.00339191 (* 1 = 0.00339191 loss)
I0204 20:27:28.042994  5898 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 20:27:54.724274  5898 solver.cpp:237] Iteration 1050, loss = 0.00237154
I0204 20:27:54.724349  5898 solver.cpp:253]     Train net output #0: loss = 0.00237153 (* 1 = 0.00237153 loss)
I0204 20:27:54.724360  5898 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 20:28:21.964607  5898 solver.cpp:237] Iteration 1060, loss = 0.00459508
I0204 20:28:21.964856  5898 solver.cpp:253]     Train net output #0: loss = 0.00459508 (* 1 = 0.00459508 loss)
I0204 20:28:21.964872  5898 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 20:28:49.183874  5898 solver.cpp:237] Iteration 1070, loss = 0.00175926
I0204 20:28:49.183955  5898 solver.cpp:253]     Train net output #0: loss = 0.00175926 (* 1 = 0.00175926 loss)
I0204 20:28:49.183969  5898 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 20:29:16.498795  5898 solver.cpp:237] Iteration 1080, loss = 0.0125925
I0204 20:29:16.499025  5898 solver.cpp:253]     Train net output #0: loss = 0.0125925 (* 1 = 0.0125925 loss)
I0204 20:29:16.499042  5898 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 20:29:43.565795  5898 solver.cpp:237] Iteration 1090, loss = 0.0146841
I0204 20:29:43.565876  5898 solver.cpp:253]     Train net output #0: loss = 0.0146841 (* 1 = 0.0146841 loss)
I0204 20:29:43.565888  5898 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 20:30:08.030452  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1100.caffemodel
I0204 20:30:08.034324  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1100.solverstate
I0204 20:30:08.035729  5898 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 20:30:20.949568  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:30:20.949648  5898 solver.cpp:409]     Test net output #1: loss = 0.00368049 (* 1 = 0.00368049 loss)
I0204 20:30:23.688261  5898 solver.cpp:237] Iteration 1100, loss = 0.000579191
I0204 20:30:23.688339  5898 solver.cpp:253]     Train net output #0: loss = 0.000579198 (* 1 = 0.000579198 loss)
I0204 20:30:23.688351  5898 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 20:30:50.772478  5898 solver.cpp:237] Iteration 1110, loss = 0.00121154
I0204 20:30:50.772712  5898 solver.cpp:253]     Train net output #0: loss = 0.00121155 (* 1 = 0.00121155 loss)
I0204 20:30:50.772728  5898 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 20:31:17.943884  5898 solver.cpp:237] Iteration 1120, loss = 0.000215929
I0204 20:31:17.943964  5898 solver.cpp:253]     Train net output #0: loss = 0.000215936 (* 1 = 0.000215936 loss)
I0204 20:31:17.943977  5898 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 20:31:45.009188  5898 solver.cpp:237] Iteration 1130, loss = 0.0131678
I0204 20:31:45.009441  5898 solver.cpp:253]     Train net output #0: loss = 0.0131678 (* 1 = 0.0131678 loss)
I0204 20:31:45.009457  5898 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 20:32:12.080415  5898 solver.cpp:237] Iteration 1140, loss = 0.000968351
I0204 20:32:12.080498  5898 solver.cpp:253]     Train net output #0: loss = 0.000968362 (* 1 = 0.000968362 loss)
I0204 20:32:12.080512  5898 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 20:32:39.061929  5898 solver.cpp:237] Iteration 1150, loss = 0.00673902
I0204 20:32:39.062201  5898 solver.cpp:253]     Train net output #0: loss = 0.00673903 (* 1 = 0.00673903 loss)
I0204 20:32:39.062216  5898 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 20:33:05.931224  5898 solver.cpp:237] Iteration 1160, loss = 0.00635677
I0204 20:33:05.931311  5898 solver.cpp:253]     Train net output #0: loss = 0.00635679 (* 1 = 0.00635679 loss)
I0204 20:33:05.931324  5898 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 20:33:32.667955  5898 solver.cpp:237] Iteration 1170, loss = 0.000492888
I0204 20:33:32.676846  5898 solver.cpp:253]     Train net output #0: loss = 0.000492905 (* 1 = 0.000492905 loss)
I0204 20:33:32.676878  5898 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 20:33:59.609096  5898 solver.cpp:237] Iteration 1180, loss = 0.000602407
I0204 20:33:59.609179  5898 solver.cpp:253]     Train net output #0: loss = 0.000602422 (* 1 = 0.000602422 loss)
I0204 20:33:59.609191  5898 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 20:34:26.693434  5898 solver.cpp:237] Iteration 1190, loss = 0.0365154
I0204 20:34:26.693656  5898 solver.cpp:253]     Train net output #0: loss = 0.0365154 (* 1 = 0.0365154 loss)
I0204 20:34:26.693670  5898 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 20:34:50.912742  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1200.caffemodel
I0204 20:34:50.916468  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1200.solverstate
I0204 20:34:50.917876  5898 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 20:35:03.615118  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:35:03.615319  5898 solver.cpp:409]     Test net output #1: loss = 0.0061323 (* 1 = 0.0061323 loss)
I0204 20:35:06.281467  5898 solver.cpp:237] Iteration 1200, loss = 0.000644316
I0204 20:35:06.281536  5898 solver.cpp:253]     Train net output #0: loss = 0.000644332 (* 1 = 0.000644332 loss)
I0204 20:35:06.281548  5898 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 20:35:33.195616  5898 solver.cpp:237] Iteration 1210, loss = 0.039168
I0204 20:35:33.195695  5898 solver.cpp:253]     Train net output #0: loss = 0.039168 (* 1 = 0.039168 loss)
I0204 20:35:33.195708  5898 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 20:36:00.336737  5898 solver.cpp:237] Iteration 1220, loss = 0.032719
I0204 20:36:00.336940  5898 solver.cpp:253]     Train net output #0: loss = 0.032719 (* 1 = 0.032719 loss)
I0204 20:36:00.336953  5898 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 20:36:27.487994  5898 solver.cpp:237] Iteration 1230, loss = 0.0184407
I0204 20:36:27.488067  5898 solver.cpp:253]     Train net output #0: loss = 0.0184407 (* 1 = 0.0184407 loss)
I0204 20:36:27.488086  5898 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 20:36:54.824579  5898 solver.cpp:237] Iteration 1240, loss = 0.000514722
I0204 20:36:54.824828  5898 solver.cpp:253]     Train net output #0: loss = 0.00051473 (* 1 = 0.00051473 loss)
I0204 20:36:54.824853  5898 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 20:37:22.206728  5898 solver.cpp:237] Iteration 1250, loss = 0.0005444
I0204 20:37:22.206799  5898 solver.cpp:253]     Train net output #0: loss = 0.000544407 (* 1 = 0.000544407 loss)
I0204 20:37:22.206810  5898 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 20:37:49.514242  5898 solver.cpp:237] Iteration 1260, loss = 0.000350393
I0204 20:37:49.514464  5898 solver.cpp:253]     Train net output #0: loss = 0.000350402 (* 1 = 0.000350402 loss)
I0204 20:37:49.514478  5898 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 20:38:17.446568  5898 solver.cpp:237] Iteration 1270, loss = 0.00113644
I0204 20:38:17.446645  5898 solver.cpp:253]     Train net output #0: loss = 0.00113645 (* 1 = 0.00113645 loss)
I0204 20:38:17.446656  5898 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 20:38:45.366428  5898 solver.cpp:237] Iteration 1280, loss = 0.111559
I0204 20:38:45.366644  5898 solver.cpp:253]     Train net output #0: loss = 0.111559 (* 1 = 0.111559 loss)
I0204 20:38:45.366658  5898 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 20:39:13.257654  5898 solver.cpp:237] Iteration 1290, loss = 0.0032244
I0204 20:39:13.257727  5898 solver.cpp:253]     Train net output #0: loss = 0.0032244 (* 1 = 0.0032244 loss)
I0204 20:39:13.257740  5898 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 20:39:38.312618  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1300.caffemodel
I0204 20:39:38.316591  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1300.solverstate
I0204 20:39:38.317984  5898 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 20:39:51.656996  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:39:51.657075  5898 solver.cpp:409]     Test net output #1: loss = 0.00358774 (* 1 = 0.00358774 loss)
I0204 20:39:54.497181  5898 solver.cpp:237] Iteration 1300, loss = 0.000428149
I0204 20:39:54.497257  5898 solver.cpp:253]     Train net output #0: loss = 0.000428139 (* 1 = 0.000428139 loss)
I0204 20:39:54.497270  5898 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 20:40:22.276134  5898 solver.cpp:237] Iteration 1310, loss = 0.0685835
I0204 20:40:22.276357  5898 solver.cpp:253]     Train net output #0: loss = 0.0685835 (* 1 = 0.0685835 loss)
I0204 20:40:22.276372  5898 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 20:40:50.256701  5898 solver.cpp:237] Iteration 1320, loss = 0.000388036
I0204 20:40:50.256783  5898 solver.cpp:253]     Train net output #0: loss = 0.000388021 (* 1 = 0.000388021 loss)
I0204 20:40:50.256794  5898 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 20:41:18.137323  5898 solver.cpp:237] Iteration 1330, loss = 0.00132426
I0204 20:41:18.137542  5898 solver.cpp:253]     Train net output #0: loss = 0.00132424 (* 1 = 0.00132424 loss)
I0204 20:41:18.137557  5898 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 20:41:45.866670  5898 solver.cpp:237] Iteration 1340, loss = 0.00916538
I0204 20:41:45.866750  5898 solver.cpp:253]     Train net output #0: loss = 0.00916537 (* 1 = 0.00916537 loss)
I0204 20:41:45.866762  5898 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 20:42:13.842305  5898 solver.cpp:237] Iteration 1350, loss = 0.00244774
I0204 20:42:13.842530  5898 solver.cpp:253]     Train net output #0: loss = 0.00244772 (* 1 = 0.00244772 loss)
I0204 20:42:13.842545  5898 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 20:42:41.856498  5898 solver.cpp:237] Iteration 1360, loss = 0.000566509
I0204 20:42:41.856583  5898 solver.cpp:253]     Train net output #0: loss = 0.000566492 (* 1 = 0.000566492 loss)
I0204 20:42:41.856595  5898 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 20:43:09.679220  5898 solver.cpp:237] Iteration 1370, loss = 0.00339496
I0204 20:43:09.679481  5898 solver.cpp:253]     Train net output #0: loss = 0.00339494 (* 1 = 0.00339494 loss)
I0204 20:43:09.679505  5898 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 20:43:37.368039  5898 solver.cpp:237] Iteration 1380, loss = 0.00106934
I0204 20:43:37.368127  5898 solver.cpp:253]     Train net output #0: loss = 0.00106932 (* 1 = 0.00106932 loss)
I0204 20:43:37.368139  5898 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 20:44:04.976122  5898 solver.cpp:237] Iteration 1390, loss = 0.000848693
I0204 20:44:04.976361  5898 solver.cpp:253]     Train net output #0: loss = 0.000848675 (* 1 = 0.000848675 loss)
I0204 20:44:04.976375  5898 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 20:44:30.035078  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1400.caffemodel
I0204 20:44:30.038797  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1400.solverstate
I0204 20:44:30.040221  5898 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 20:44:43.305910  5898 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 20:44:43.306110  5898 solver.cpp:409]     Test net output #1: loss = 0.0010994 (* 1 = 0.0010994 loss)
I0204 20:44:46.053153  5898 solver.cpp:237] Iteration 1400, loss = 0.00105804
I0204 20:44:46.053227  5898 solver.cpp:253]     Train net output #0: loss = 0.00105803 (* 1 = 0.00105803 loss)
I0204 20:44:46.053241  5898 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 20:45:13.664994  5898 solver.cpp:237] Iteration 1410, loss = 0.00328113
I0204 20:45:13.665240  5898 solver.cpp:253]     Train net output #0: loss = 0.00328111 (* 1 = 0.00328111 loss)
I0204 20:45:13.665256  5898 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 20:45:41.378754  5898 solver.cpp:237] Iteration 1420, loss = 0.000414949
I0204 20:45:41.378820  5898 solver.cpp:253]     Train net output #0: loss = 0.000414934 (* 1 = 0.000414934 loss)
I0204 20:45:41.378831  5898 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 20:46:08.804460  5898 solver.cpp:237] Iteration 1430, loss = 0.00131432
I0204 20:46:08.804667  5898 solver.cpp:253]     Train net output #0: loss = 0.0013143 (* 1 = 0.0013143 loss)
I0204 20:46:08.804682  5898 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 20:46:36.042131  5898 solver.cpp:237] Iteration 1440, loss = 0.000221164
I0204 20:46:36.042212  5898 solver.cpp:253]     Train net output #0: loss = 0.00022115 (* 1 = 0.00022115 loss)
I0204 20:46:36.042222  5898 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 20:47:03.227761  5898 solver.cpp:237] Iteration 1450, loss = 0.000302255
I0204 20:47:03.227969  5898 solver.cpp:253]     Train net output #0: loss = 0.000302242 (* 1 = 0.000302242 loss)
I0204 20:47:03.227984  5898 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 20:47:30.493404  5898 solver.cpp:237] Iteration 1460, loss = 0.00866261
I0204 20:47:30.493479  5898 solver.cpp:253]     Train net output #0: loss = 0.00866259 (* 1 = 0.00866259 loss)
I0204 20:47:30.493491  5898 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 20:47:57.839129  5898 solver.cpp:237] Iteration 1470, loss = 0.00128446
I0204 20:47:57.839345  5898 solver.cpp:253]     Train net output #0: loss = 0.00128444 (* 1 = 0.00128444 loss)
I0204 20:47:57.839360  5898 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 20:48:25.598664  5898 solver.cpp:237] Iteration 1480, loss = 0.0110041
I0204 20:48:25.598742  5898 solver.cpp:253]     Train net output #0: loss = 0.0110041 (* 1 = 0.0110041 loss)
I0204 20:48:25.598753  5898 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 20:48:53.409623  5898 solver.cpp:237] Iteration 1490, loss = 0.000661224
I0204 20:48:53.409847  5898 solver.cpp:253]     Train net output #0: loss = 0.000661203 (* 1 = 0.000661203 loss)
I0204 20:48:53.409860  5898 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 20:49:18.577437  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1500.caffemodel
I0204 20:49:18.581078  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1500.solverstate
I0204 20:49:18.582466  5898 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 20:49:31.870537  5898 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 20:49:31.870756  5898 solver.cpp:409]     Test net output #1: loss = 0.0116153 (* 1 = 0.0116153 loss)
I0204 20:49:34.707166  5898 solver.cpp:237] Iteration 1500, loss = 0.00478884
I0204 20:49:34.707226  5898 solver.cpp:253]     Train net output #0: loss = 0.00478882 (* 1 = 0.00478882 loss)
I0204 20:49:34.707237  5898 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 20:50:03.156263  5898 solver.cpp:237] Iteration 1510, loss = 0.00135182
I0204 20:50:03.156467  5898 solver.cpp:253]     Train net output #0: loss = 0.0013518 (* 1 = 0.0013518 loss)
I0204 20:50:03.156481  5898 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 20:50:31.964179  5898 solver.cpp:237] Iteration 1520, loss = 0.0105628
I0204 20:50:31.964264  5898 solver.cpp:253]     Train net output #0: loss = 0.0105628 (* 1 = 0.0105628 loss)
I0204 20:50:31.964277  5898 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 20:50:59.985095  5898 solver.cpp:237] Iteration 1530, loss = 0.001914
I0204 20:50:59.985312  5898 solver.cpp:253]     Train net output #0: loss = 0.00191398 (* 1 = 0.00191398 loss)
I0204 20:50:59.985328  5898 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 20:51:27.996470  5898 solver.cpp:237] Iteration 1540, loss = 0.0193731
I0204 20:51:27.996551  5898 solver.cpp:253]     Train net output #0: loss = 0.019373 (* 1 = 0.019373 loss)
I0204 20:51:27.996564  5898 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 20:51:56.565668  5898 solver.cpp:237] Iteration 1550, loss = 0.00364299
I0204 20:51:56.565876  5898 solver.cpp:253]     Train net output #0: loss = 0.00364297 (* 1 = 0.00364297 loss)
I0204 20:51:56.565892  5898 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 20:52:24.688438  5898 solver.cpp:237] Iteration 1560, loss = 0.000360513
I0204 20:52:24.688519  5898 solver.cpp:253]     Train net output #0: loss = 0.000360493 (* 1 = 0.000360493 loss)
I0204 20:52:24.688532  5898 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 20:52:52.870256  5898 solver.cpp:237] Iteration 1570, loss = 0.0064262
I0204 20:52:52.870477  5898 solver.cpp:253]     Train net output #0: loss = 0.00642618 (* 1 = 0.00642618 loss)
I0204 20:52:52.870493  5898 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 20:53:20.956779  5898 solver.cpp:237] Iteration 1580, loss = 0.00177969
I0204 20:53:20.956857  5898 solver.cpp:253]     Train net output #0: loss = 0.00177967 (* 1 = 0.00177967 loss)
I0204 20:53:20.956869  5898 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 20:53:48.986106  5898 solver.cpp:237] Iteration 1590, loss = 0.000596108
I0204 20:53:48.986376  5898 solver.cpp:253]     Train net output #0: loss = 0.000596086 (* 1 = 0.000596086 loss)
I0204 20:53:48.986404  5898 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 20:54:14.278508  5898 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1600.caffemodel
I0204 20:54:14.282147  5898 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed12/snaps/snap__iter_1600.solverstate
I0204 20:54:15.628419  5898 solver.cpp:321] Iteration 1600, loss = 0.00758555
I0204 20:54:15.628479  5898 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 20:54:29.034582  5898 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 20:54:29.034821  5898 solver.cpp:409]     Test net output #1: loss = 0.00149003 (* 1 = 0.00149003 loss)
I0204 20:54:29.034832  5898 solver.cpp:326] Optimization Done.
I0204 20:54:29.034847  5898 caffe.cpp:215] Optimization Done.
