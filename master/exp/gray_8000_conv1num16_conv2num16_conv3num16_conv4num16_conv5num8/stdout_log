I0204 08:47:10.344633 31922 caffe.cpp:177] Use CPU.
I0204 08:47:10.345417 31922 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap_"
solver_mode: CPU
random_seed: 0
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/train_val.prototxt"
I0204 08:47:10.345630 31922 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/train_val.prototxt
I0204 08:47:10.346364 31922 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 08:47:10.346398 31922 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 08:47:10.346673 31922 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.346828 31922 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.347049 31922 net.cpp:106] Creating Layer data
I0204 08:47:10.347067 31922 net.cpp:411] data -> data
I0204 08:47:10.347167 31922 net.cpp:411] data -> label
I0204 08:47:10.347192 31922 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 08:47:10.347383 31928 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 08:47:10.348165 31922 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.377708 31922 net.cpp:150] Setting up data
I0204 08:47:10.377791 31922 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.377802 31922 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.377810 31922 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.377835 31922 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.377866 31922 net.cpp:106] Creating Layer conv1
I0204 08:47:10.377876 31922 net.cpp:454] conv1 <- data
I0204 08:47:10.377899 31922 net.cpp:411] conv1 -> conv1
I0204 08:47:10.378028 31922 net.cpp:150] Setting up conv1
I0204 08:47:10.378042 31922 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.378049 31922 net.cpp:165] Memory required for data: 39972000
I0204 08:47:10.378070 31922 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.378084 31922 net.cpp:106] Creating Layer relu1
I0204 08:47:10.378100 31922 net.cpp:454] relu1 <- conv1
I0204 08:47:10.378111 31922 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.378126 31922 net.cpp:150] Setting up relu1
I0204 08:47:10.378134 31922 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.378141 31922 net.cpp:165] Memory required for data: 59332000
I0204 08:47:10.378147 31922 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.378160 31922 net.cpp:106] Creating Layer pool1
I0204 08:47:10.378167 31922 net.cpp:454] pool1 <- conv1
I0204 08:47:10.378176 31922 net.cpp:411] pool1 -> pool1
I0204 08:47:10.378207 31922 net.cpp:150] Setting up pool1
I0204 08:47:10.378216 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.378222 31922 net.cpp:165] Memory required for data: 63997600
I0204 08:47:10.378229 31922 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.378253 31922 net.cpp:106] Creating Layer norm1
I0204 08:47:10.378271 31922 net.cpp:454] norm1 <- pool1
I0204 08:47:10.378283 31922 net.cpp:411] norm1 -> norm1
I0204 08:47:10.378303 31922 net.cpp:150] Setting up norm1
I0204 08:47:10.378312 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.378319 31922 net.cpp:165] Memory required for data: 68663200
I0204 08:47:10.378324 31922 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.378336 31922 net.cpp:106] Creating Layer conv2
I0204 08:47:10.378342 31922 net.cpp:454] conv2 <- norm1
I0204 08:47:10.378352 31922 net.cpp:411] conv2 -> conv2
I0204 08:47:10.378414 31922 net.cpp:150] Setting up conv2
I0204 08:47:10.378424 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.378430 31922 net.cpp:165] Memory required for data: 73328800
I0204 08:47:10.378443 31922 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.378453 31922 net.cpp:106] Creating Layer relu2
I0204 08:47:10.378461 31922 net.cpp:454] relu2 <- conv2
I0204 08:47:10.378471 31922 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.378481 31922 net.cpp:150] Setting up relu2
I0204 08:47:10.378489 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.378494 31922 net.cpp:165] Memory required for data: 77994400
I0204 08:47:10.378501 31922 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.378510 31922 net.cpp:106] Creating Layer pool2
I0204 08:47:10.378516 31922 net.cpp:454] pool2 <- conv2
I0204 08:47:10.378525 31922 net.cpp:411] pool2 -> pool2
I0204 08:47:10.378537 31922 net.cpp:150] Setting up pool2
I0204 08:47:10.378545 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378553 31922 net.cpp:165] Memory required for data: 79076000
I0204 08:47:10.378561 31922 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.378571 31922 net.cpp:106] Creating Layer norm2
I0204 08:47:10.378577 31922 net.cpp:454] norm2 <- pool2
I0204 08:47:10.378585 31922 net.cpp:411] norm2 -> norm2
I0204 08:47:10.378597 31922 net.cpp:150] Setting up norm2
I0204 08:47:10.378604 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378609 31922 net.cpp:165] Memory required for data: 80157600
I0204 08:47:10.378615 31922 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.378628 31922 net.cpp:106] Creating Layer conv3
I0204 08:47:10.378633 31922 net.cpp:454] conv3 <- norm2
I0204 08:47:10.378645 31922 net.cpp:411] conv3 -> conv3
I0204 08:47:10.378692 31922 net.cpp:150] Setting up conv3
I0204 08:47:10.378701 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378707 31922 net.cpp:165] Memory required for data: 81239200
I0204 08:47:10.378720 31922 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.378729 31922 net.cpp:106] Creating Layer relu3
I0204 08:47:10.378738 31922 net.cpp:454] relu3 <- conv3
I0204 08:47:10.378747 31922 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.378756 31922 net.cpp:150] Setting up relu3
I0204 08:47:10.378763 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378769 31922 net.cpp:165] Memory required for data: 82320800
I0204 08:47:10.378775 31922 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.378787 31922 net.cpp:106] Creating Layer conv4
I0204 08:47:10.378793 31922 net.cpp:454] conv4 <- conv3
I0204 08:47:10.378803 31922 net.cpp:411] conv4 -> conv4
I0204 08:47:10.378839 31922 net.cpp:150] Setting up conv4
I0204 08:47:10.378847 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378854 31922 net.cpp:165] Memory required for data: 83402400
I0204 08:47:10.378865 31922 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.378873 31922 net.cpp:106] Creating Layer relu4
I0204 08:47:10.378880 31922 net.cpp:454] relu4 <- conv4
I0204 08:47:10.378887 31922 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.378896 31922 net.cpp:150] Setting up relu4
I0204 08:47:10.378904 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.378912 31922 net.cpp:165] Memory required for data: 84484000
I0204 08:47:10.378919 31922 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.378937 31922 net.cpp:106] Creating Layer conv5
I0204 08:47:10.378954 31922 net.cpp:454] conv5 <- conv4
I0204 08:47:10.378964 31922 net.cpp:411] conv5 -> conv5
I0204 08:47:10.378993 31922 net.cpp:150] Setting up conv5
I0204 08:47:10.379004 31922 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.379010 31922 net.cpp:165] Memory required for data: 85024800
I0204 08:47:10.379024 31922 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.379034 31922 net.cpp:106] Creating Layer relu5
I0204 08:47:10.379040 31922 net.cpp:454] relu5 <- conv5
I0204 08:47:10.379057 31922 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.379068 31922 net.cpp:150] Setting up relu5
I0204 08:47:10.379076 31922 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.379083 31922 net.cpp:165] Memory required for data: 85565600
I0204 08:47:10.379096 31922 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.379106 31922 net.cpp:106] Creating Layer pool5
I0204 08:47:10.379115 31922 net.cpp:454] pool5 <- conv5
I0204 08:47:10.379124 31922 net.cpp:411] pool5 -> pool5
I0204 08:47:10.379137 31922 net.cpp:150] Setting up pool5
I0204 08:47:10.379145 31922 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.379151 31922 net.cpp:165] Memory required for data: 85680800
I0204 08:47:10.379158 31922 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.379174 31922 net.cpp:106] Creating Layer fc6
I0204 08:47:10.379181 31922 net.cpp:454] fc6 <- pool5
I0204 08:47:10.379194 31922 net.cpp:411] fc6 -> fc6
I0204 08:47:10.380144 31922 net.cpp:150] Setting up fc6
I0204 08:47:10.380161 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.380167 31922 net.cpp:165] Memory required for data: 85783200
I0204 08:47:10.380178 31922 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.380188 31922 net.cpp:106] Creating Layer relu6
I0204 08:47:10.380195 31922 net.cpp:454] relu6 <- fc6
I0204 08:47:10.380208 31922 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.380218 31922 net.cpp:150] Setting up relu6
I0204 08:47:10.380225 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.380231 31922 net.cpp:165] Memory required for data: 85885600
I0204 08:47:10.380237 31922 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.380249 31922 net.cpp:106] Creating Layer drop6
I0204 08:47:10.380255 31922 net.cpp:454] drop6 <- fc6
I0204 08:47:10.380264 31922 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.380286 31922 net.cpp:150] Setting up drop6
I0204 08:47:10.380295 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.380300 31922 net.cpp:165] Memory required for data: 85988000
I0204 08:47:10.380306 31922 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.380317 31922 net.cpp:106] Creating Layer fc7
I0204 08:47:10.380323 31922 net.cpp:454] fc7 <- fc6
I0204 08:47:10.380332 31922 net.cpp:411] fc7 -> fc7
I0204 08:47:10.381171 31922 net.cpp:150] Setting up fc7
I0204 08:47:10.381186 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.381191 31922 net.cpp:165] Memory required for data: 86090400
I0204 08:47:10.381201 31922 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.381211 31922 net.cpp:106] Creating Layer relu7
I0204 08:47:10.381217 31922 net.cpp:454] relu7 <- fc7
I0204 08:47:10.381227 31922 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.381237 31922 net.cpp:150] Setting up relu7
I0204 08:47:10.381245 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.381250 31922 net.cpp:165] Memory required for data: 86192800
I0204 08:47:10.381258 31922 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.381269 31922 net.cpp:106] Creating Layer drop7
I0204 08:47:10.381276 31922 net.cpp:454] drop7 <- fc7
I0204 08:47:10.381284 31922 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.381297 31922 net.cpp:150] Setting up drop7
I0204 08:47:10.381305 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.381311 31922 net.cpp:165] Memory required for data: 86295200
I0204 08:47:10.381317 31922 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.381335 31922 net.cpp:106] Creating Layer fc8
I0204 08:47:10.381361 31922 net.cpp:454] fc8 <- fc7
I0204 08:47:10.381371 31922 net.cpp:411] fc8 -> fc8
I0204 08:47:10.381399 31922 net.cpp:150] Setting up fc8
I0204 08:47:10.381409 31922 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.381415 31922 net.cpp:165] Memory required for data: 86296000
I0204 08:47:10.381427 31922 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.381439 31922 net.cpp:106] Creating Layer loss
I0204 08:47:10.381446 31922 net.cpp:454] loss <- fc8
I0204 08:47:10.381454 31922 net.cpp:454] loss <- label
I0204 08:47:10.381467 31922 net.cpp:411] loss -> loss
I0204 08:47:10.381484 31922 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.381510 31922 net.cpp:150] Setting up loss
I0204 08:47:10.381520 31922 net.cpp:157] Top shape: (1)
I0204 08:47:10.381525 31922 net.cpp:160]     with loss weight 1
I0204 08:47:10.381567 31922 net.cpp:165] Memory required for data: 86296004
I0204 08:47:10.381577 31922 net.cpp:226] loss needs backward computation.
I0204 08:47:10.381585 31922 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.381592 31922 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.381598 31922 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.381604 31922 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.381611 31922 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.381618 31922 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.381626 31922 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.381633 31922 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.381644 31922 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.381649 31922 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.381656 31922 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.381664 31922 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.381669 31922 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.381676 31922 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.381687 31922 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.381695 31922 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.381701 31922 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.381708 31922 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.381716 31922 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.381724 31922 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.381731 31922 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.381738 31922 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.381745 31922 net.cpp:228] data does not need backward computation.
I0204 08:47:10.381752 31922 net.cpp:270] This network produces output loss
I0204 08:47:10.381783 31922 net.cpp:283] Network initialization done.
I0204 08:47:10.382701 31922 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/train_val.prototxt
I0204 08:47:10.382768 31922 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 08:47:10.383131 31922 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.383381 31922 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.383570 31922 net.cpp:106] Creating Layer data
I0204 08:47:10.383587 31922 net.cpp:411] data -> data
I0204 08:47:10.383605 31922 net.cpp:411] data -> label
I0204 08:47:10.383618 31922 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 08:47:10.383896 31938 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 08:47:10.389816 31922 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.447734 31922 net.cpp:150] Setting up data
I0204 08:47:10.447796 31922 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.447811 31922 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.447821 31922 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.447837 31922 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 08:47:10.447868 31922 net.cpp:106] Creating Layer label_data_1_split
I0204 08:47:10.447881 31922 net.cpp:454] label_data_1_split <- label
I0204 08:47:10.447901 31922 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 08:47:10.447929 31922 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 08:47:10.447952 31922 net.cpp:150] Setting up label_data_1_split
I0204 08:47:10.447967 31922 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.447981 31922 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.447991 31922 net.cpp:165] Memory required for data: 20612800
I0204 08:47:10.448004 31922 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.448030 31922 net.cpp:106] Creating Layer conv1
I0204 08:47:10.448040 31922 net.cpp:454] conv1 <- data
I0204 08:47:10.448057 31922 net.cpp:411] conv1 -> conv1
I0204 08:47:10.448166 31922 net.cpp:150] Setting up conv1
I0204 08:47:10.448186 31922 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.448196 31922 net.cpp:165] Memory required for data: 39972800
I0204 08:47:10.448221 31922 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.448237 31922 net.cpp:106] Creating Layer relu1
I0204 08:47:10.448248 31922 net.cpp:454] relu1 <- conv1
I0204 08:47:10.448268 31922 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.448285 31922 net.cpp:150] Setting up relu1
I0204 08:47:10.448298 31922 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.448307 31922 net.cpp:165] Memory required for data: 59332800
I0204 08:47:10.448318 31922 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.448335 31922 net.cpp:106] Creating Layer pool1
I0204 08:47:10.448344 31922 net.cpp:454] pool1 <- conv1
I0204 08:47:10.448364 31922 net.cpp:411] pool1 -> pool1
I0204 08:47:10.448390 31922 net.cpp:150] Setting up pool1
I0204 08:47:10.448403 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.448412 31922 net.cpp:165] Memory required for data: 63998400
I0204 08:47:10.448421 31922 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.448438 31922 net.cpp:106] Creating Layer norm1
I0204 08:47:10.448451 31922 net.cpp:454] norm1 <- pool1
I0204 08:47:10.448465 31922 net.cpp:411] norm1 -> norm1
I0204 08:47:10.448483 31922 net.cpp:150] Setting up norm1
I0204 08:47:10.448498 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.448508 31922 net.cpp:165] Memory required for data: 68664000
I0204 08:47:10.448518 31922 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.448536 31922 net.cpp:106] Creating Layer conv2
I0204 08:47:10.448545 31922 net.cpp:454] conv2 <- norm1
I0204 08:47:10.448560 31922 net.cpp:411] conv2 -> conv2
I0204 08:47:10.448658 31922 net.cpp:150] Setting up conv2
I0204 08:47:10.448676 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.448686 31922 net.cpp:165] Memory required for data: 73329600
I0204 08:47:10.448705 31922 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.448719 31922 net.cpp:106] Creating Layer relu2
I0204 08:47:10.448734 31922 net.cpp:454] relu2 <- conv2
I0204 08:47:10.448746 31922 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.448778 31922 net.cpp:150] Setting up relu2
I0204 08:47:10.448807 31922 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.448817 31922 net.cpp:165] Memory required for data: 77995200
I0204 08:47:10.448828 31922 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.448845 31922 net.cpp:106] Creating Layer pool2
I0204 08:47:10.448856 31922 net.cpp:454] pool2 <- conv2
I0204 08:47:10.448873 31922 net.cpp:411] pool2 -> pool2
I0204 08:47:10.448894 31922 net.cpp:150] Setting up pool2
I0204 08:47:10.448907 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.448916 31922 net.cpp:165] Memory required for data: 79076800
I0204 08:47:10.448925 31922 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.448940 31922 net.cpp:106] Creating Layer norm2
I0204 08:47:10.448950 31922 net.cpp:454] norm2 <- pool2
I0204 08:47:10.448963 31922 net.cpp:411] norm2 -> norm2
I0204 08:47:10.448979 31922 net.cpp:150] Setting up norm2
I0204 08:47:10.448992 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.449000 31922 net.cpp:165] Memory required for data: 80158400
I0204 08:47:10.449010 31922 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.449026 31922 net.cpp:106] Creating Layer conv3
I0204 08:47:10.449036 31922 net.cpp:454] conv3 <- norm2
I0204 08:47:10.449051 31922 net.cpp:411] conv3 -> conv3
I0204 08:47:10.449127 31922 net.cpp:150] Setting up conv3
I0204 08:47:10.449149 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.449158 31922 net.cpp:165] Memory required for data: 81240000
I0204 08:47:10.449178 31922 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.449193 31922 net.cpp:106] Creating Layer relu3
I0204 08:47:10.449203 31922 net.cpp:454] relu3 <- conv3
I0204 08:47:10.449215 31922 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.449230 31922 net.cpp:150] Setting up relu3
I0204 08:47:10.449242 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.449250 31922 net.cpp:165] Memory required for data: 82321600
I0204 08:47:10.449260 31922 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.449276 31922 net.cpp:106] Creating Layer conv4
I0204 08:47:10.449286 31922 net.cpp:454] conv4 <- conv3
I0204 08:47:10.449306 31922 net.cpp:411] conv4 -> conv4
I0204 08:47:10.449362 31922 net.cpp:150] Setting up conv4
I0204 08:47:10.449375 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.449384 31922 net.cpp:165] Memory required for data: 83403200
I0204 08:47:10.449398 31922 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.449411 31922 net.cpp:106] Creating Layer relu4
I0204 08:47:10.449421 31922 net.cpp:454] relu4 <- conv4
I0204 08:47:10.449434 31922 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.449448 31922 net.cpp:150] Setting up relu4
I0204 08:47:10.449460 31922 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.449470 31922 net.cpp:165] Memory required for data: 84484800
I0204 08:47:10.449479 31922 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.449496 31922 net.cpp:106] Creating Layer conv5
I0204 08:47:10.449506 31922 net.cpp:454] conv5 <- conv4
I0204 08:47:10.449519 31922 net.cpp:411] conv5 -> conv5
I0204 08:47:10.449563 31922 net.cpp:150] Setting up conv5
I0204 08:47:10.449575 31922 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.449584 31922 net.cpp:165] Memory required for data: 85025600
I0204 08:47:10.449604 31922 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.449617 31922 net.cpp:106] Creating Layer relu5
I0204 08:47:10.449627 31922 net.cpp:454] relu5 <- conv5
I0204 08:47:10.449640 31922 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.449653 31922 net.cpp:150] Setting up relu5
I0204 08:47:10.449666 31922 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.449674 31922 net.cpp:165] Memory required for data: 85566400
I0204 08:47:10.449683 31922 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.449700 31922 net.cpp:106] Creating Layer pool5
I0204 08:47:10.449710 31922 net.cpp:454] pool5 <- conv5
I0204 08:47:10.449723 31922 net.cpp:411] pool5 -> pool5
I0204 08:47:10.449748 31922 net.cpp:150] Setting up pool5
I0204 08:47:10.449772 31922 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.449781 31922 net.cpp:165] Memory required for data: 85681600
I0204 08:47:10.449791 31922 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.449808 31922 net.cpp:106] Creating Layer fc6
I0204 08:47:10.449818 31922 net.cpp:454] fc6 <- pool5
I0204 08:47:10.449832 31922 net.cpp:411] fc6 -> fc6
I0204 08:47:10.452955 31922 net.cpp:150] Setting up fc6
I0204 08:47:10.453002 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.453012 31922 net.cpp:165] Memory required for data: 85784000
I0204 08:47:10.453030 31922 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.453049 31922 net.cpp:106] Creating Layer relu6
I0204 08:47:10.453061 31922 net.cpp:454] relu6 <- fc6
I0204 08:47:10.453078 31922 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.453097 31922 net.cpp:150] Setting up relu6
I0204 08:47:10.453110 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.453119 31922 net.cpp:165] Memory required for data: 85886400
I0204 08:47:10.453130 31922 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.453155 31922 net.cpp:106] Creating Layer drop6
I0204 08:47:10.453168 31922 net.cpp:454] drop6 <- fc6
I0204 08:47:10.453186 31922 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.453208 31922 net.cpp:150] Setting up drop6
I0204 08:47:10.453222 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.453232 31922 net.cpp:165] Memory required for data: 85988800
I0204 08:47:10.453244 31922 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.453268 31922 net.cpp:106] Creating Layer fc7
I0204 08:47:10.453279 31922 net.cpp:454] fc7 <- fc6
I0204 08:47:10.453297 31922 net.cpp:411] fc7 -> fc7
I0204 08:47:10.454571 31922 net.cpp:150] Setting up fc7
I0204 08:47:10.454592 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.454602 31922 net.cpp:165] Memory required for data: 86091200
I0204 08:47:10.454617 31922 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.454630 31922 net.cpp:106] Creating Layer relu7
I0204 08:47:10.454641 31922 net.cpp:454] relu7 <- fc7
I0204 08:47:10.454658 31922 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.454674 31922 net.cpp:150] Setting up relu7
I0204 08:47:10.454685 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.454695 31922 net.cpp:165] Memory required for data: 86193600
I0204 08:47:10.454704 31922 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.454717 31922 net.cpp:106] Creating Layer drop7
I0204 08:47:10.454728 31922 net.cpp:454] drop7 <- fc7
I0204 08:47:10.454741 31922 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.454758 31922 net.cpp:150] Setting up drop7
I0204 08:47:10.454771 31922 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.454780 31922 net.cpp:165] Memory required for data: 86296000
I0204 08:47:10.454792 31922 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.454813 31922 net.cpp:106] Creating Layer fc8
I0204 08:47:10.454823 31922 net.cpp:454] fc8 <- fc7
I0204 08:47:10.454843 31922 net.cpp:411] fc8 -> fc8
I0204 08:47:10.454893 31922 net.cpp:150] Setting up fc8
I0204 08:47:10.454913 31922 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.454923 31922 net.cpp:165] Memory required for data: 86296800
I0204 08:47:10.454937 31922 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 08:47:10.454953 31922 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 08:47:10.454964 31922 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 08:47:10.454978 31922 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 08:47:10.454994 31922 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 08:47:10.455011 31922 net.cpp:150] Setting up fc8_fc8_0_split
I0204 08:47:10.455024 31922 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.455035 31922 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.455044 31922 net.cpp:165] Memory required for data: 86298400
I0204 08:47:10.455054 31922 layer_factory.hpp:77] Creating layer accuracy
I0204 08:47:10.455129 31922 net.cpp:106] Creating Layer accuracy
I0204 08:47:10.455174 31922 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 08:47:10.455201 31922 net.cpp:454] accuracy <- label_data_1_split_0
I0204 08:47:10.455220 31922 net.cpp:411] accuracy -> accuracy
I0204 08:47:10.455245 31922 net.cpp:150] Setting up accuracy
I0204 08:47:10.455261 31922 net.cpp:157] Top shape: (1)
I0204 08:47:10.455271 31922 net.cpp:165] Memory required for data: 86298404
I0204 08:47:10.455281 31922 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.455296 31922 net.cpp:106] Creating Layer loss
I0204 08:47:10.455306 31922 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 08:47:10.455318 31922 net.cpp:454] loss <- label_data_1_split_1
I0204 08:47:10.455335 31922 net.cpp:411] loss -> loss
I0204 08:47:10.455356 31922 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.455391 31922 net.cpp:150] Setting up loss
I0204 08:47:10.455404 31922 net.cpp:157] Top shape: (1)
I0204 08:47:10.455413 31922 net.cpp:160]     with loss weight 1
I0204 08:47:10.455445 31922 net.cpp:165] Memory required for data: 86298408
I0204 08:47:10.455459 31922 net.cpp:226] loss needs backward computation.
I0204 08:47:10.455471 31922 net.cpp:228] accuracy does not need backward computation.
I0204 08:47:10.455484 31922 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 08:47:10.455494 31922 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.455505 31922 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.455516 31922 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.455529 31922 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.455539 31922 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.455549 31922 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.455560 31922 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.455571 31922 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.455585 31922 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.455596 31922 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.455608 31922 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.455621 31922 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.455631 31922 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.455643 31922 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.455657 31922 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.455668 31922 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.455680 31922 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.455693 31922 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.455704 31922 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.455716 31922 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.455727 31922 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.455742 31922 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.455754 31922 net.cpp:228] label_data_1_split does not need backward computation.
I0204 08:47:10.455768 31922 net.cpp:228] data does not need backward computation.
I0204 08:47:10.455777 31922 net.cpp:270] This network produces output accuracy
I0204 08:47:10.455790 31922 net.cpp:270] This network produces output loss
I0204 08:47:10.455849 31922 net.cpp:283] Network initialization done.
I0204 08:47:10.456049 31922 solver.cpp:60] Solver scaffolding done.
I0204 08:47:10.456156 31922 caffe.cpp:212] Starting Optimization
I0204 08:47:10.456169 31922 solver.cpp:288] Solving CaffeNet
I0204 08:47:10.456178 31922 solver.cpp:289] Learning Rate Policy: step
I0204 08:47:10.457747 31922 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 08:47:10.457924 31922 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 08:47:15.359968 31922 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:47:15.360047 31922 solver.cpp:409]     Test net output #1: loss = 4.88642 (* 1 = 4.88642 loss)
I0204 08:47:16.390779 31922 solver.cpp:237] Iteration 0, loss = 6.17857
I0204 08:47:16.390837 31922 solver.cpp:253]     Train net output #0: loss = 6.17857 (* 1 = 6.17857 loss)
I0204 08:47:16.390872 31922 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 08:47:26.128435 31922 solver.cpp:237] Iteration 10, loss = 1.34655
I0204 08:47:26.128495 31922 solver.cpp:253]     Train net output #0: loss = 1.34655 (* 1 = 1.34655 loss)
I0204 08:47:26.128507 31922 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 08:47:35.816083 31922 solver.cpp:237] Iteration 20, loss = 0.96357
I0204 08:47:35.816149 31922 solver.cpp:253]     Train net output #0: loss = 0.96357 (* 1 = 0.96357 loss)
I0204 08:47:35.816160 31922 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 08:47:45.658006 31922 solver.cpp:237] Iteration 30, loss = 0.782934
I0204 08:47:45.658133 31922 solver.cpp:253]     Train net output #0: loss = 0.782934 (* 1 = 0.782934 loss)
I0204 08:47:45.658146 31922 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 08:47:55.392096 31922 solver.cpp:237] Iteration 40, loss = 0.929976
I0204 08:47:55.392169 31922 solver.cpp:253]     Train net output #0: loss = 0.929976 (* 1 = 0.929976 loss)
I0204 08:47:55.392181 31922 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 08:48:05.023237 31922 solver.cpp:237] Iteration 50, loss = 0.742096
I0204 08:48:05.023310 31922 solver.cpp:253]     Train net output #0: loss = 0.742096 (* 1 = 0.742096 loss)
I0204 08:48:05.023355 31922 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 08:48:14.690057 31922 solver.cpp:237] Iteration 60, loss = 0.716862
I0204 08:48:14.690125 31922 solver.cpp:253]     Train net output #0: loss = 0.716862 (* 1 = 0.716862 loss)
I0204 08:48:14.690137 31922 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 08:48:24.365048 31922 solver.cpp:237] Iteration 70, loss = 0.769077
I0204 08:48:24.365226 31922 solver.cpp:253]     Train net output #0: loss = 0.769077 (* 1 = 0.769077 loss)
I0204 08:48:24.365239 31922 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 08:48:34.043820 31922 solver.cpp:237] Iteration 80, loss = 0.794714
I0204 08:48:34.043881 31922 solver.cpp:253]     Train net output #0: loss = 0.794714 (* 1 = 0.794714 loss)
I0204 08:48:34.043894 31922 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 08:48:43.730249 31922 solver.cpp:237] Iteration 90, loss = 0.803374
I0204 08:48:43.730312 31922 solver.cpp:253]     Train net output #0: loss = 0.803374 (* 1 = 0.803374 loss)
I0204 08:48:43.730324 31922 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 08:48:52.480828 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_100.caffemodel
I0204 08:48:52.483345 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_100.solverstate
I0204 08:48:52.484436 31922 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 08:48:57.098330 31922 solver.cpp:409]     Test net output #0: accuracy = 0.504
I0204 08:48:57.098520 31922 solver.cpp:409]     Test net output #1: loss = 0.690656 (* 1 = 0.690656 loss)
I0204 08:48:58.062932 31922 solver.cpp:237] Iteration 100, loss = 0.733115
I0204 08:48:58.062989 31922 solver.cpp:253]     Train net output #0: loss = 0.733115 (* 1 = 0.733115 loss)
I0204 08:48:58.063004 31922 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 08:49:07.768335 31922 solver.cpp:237] Iteration 110, loss = 0.774817
I0204 08:49:07.768404 31922 solver.cpp:253]     Train net output #0: loss = 0.774817 (* 1 = 0.774817 loss)
I0204 08:49:07.768416 31922 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 08:49:17.442369 31922 solver.cpp:237] Iteration 120, loss = 0.788204
I0204 08:49:17.442435 31922 solver.cpp:253]     Train net output #0: loss = 0.788204 (* 1 = 0.788204 loss)
I0204 08:49:17.442447 31922 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 08:49:27.120051 31922 solver.cpp:237] Iteration 130, loss = 0.742476
I0204 08:49:27.120281 31922 solver.cpp:253]     Train net output #0: loss = 0.742476 (* 1 = 0.742476 loss)
I0204 08:49:27.120296 31922 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 08:49:36.825366 31922 solver.cpp:237] Iteration 140, loss = 0.742757
I0204 08:49:36.825433 31922 solver.cpp:253]     Train net output #0: loss = 0.742757 (* 1 = 0.742757 loss)
I0204 08:49:36.825444 31922 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 08:49:46.463070 31922 solver.cpp:237] Iteration 150, loss = 0.688521
I0204 08:49:46.463132 31922 solver.cpp:253]     Train net output #0: loss = 0.688521 (* 1 = 0.688521 loss)
I0204 08:49:46.463143 31922 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 08:49:56.164635 31922 solver.cpp:237] Iteration 160, loss = 0.742027
I0204 08:49:56.164696 31922 solver.cpp:253]     Train net output #0: loss = 0.742027 (* 1 = 0.742027 loss)
I0204 08:49:56.164707 31922 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 08:50:05.804810 31922 solver.cpp:237] Iteration 170, loss = 0.738134
I0204 08:50:05.807263 31922 solver.cpp:253]     Train net output #0: loss = 0.738134 (* 1 = 0.738134 loss)
I0204 08:50:05.807292 31922 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 08:50:15.500953 31922 solver.cpp:237] Iteration 180, loss = 0.726899
I0204 08:50:15.501021 31922 solver.cpp:253]     Train net output #0: loss = 0.726899 (* 1 = 0.726899 loss)
I0204 08:50:15.501039 31922 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 08:50:25.200752 31922 solver.cpp:237] Iteration 190, loss = 0.704854
I0204 08:50:25.200812 31922 solver.cpp:253]     Train net output #0: loss = 0.704854 (* 1 = 0.704854 loss)
I0204 08:50:25.200824 31922 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 08:50:33.994848 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_200.caffemodel
I0204 08:50:33.997119 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_200.solverstate
I0204 08:50:33.998071 31922 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 08:50:38.638888 31922 solver.cpp:409]     Test net output #0: accuracy = 0.558
I0204 08:50:38.639053 31922 solver.cpp:409]     Test net output #1: loss = 0.65033 (* 1 = 0.65033 loss)
I0204 08:50:39.612547 31922 solver.cpp:237] Iteration 200, loss = 0.652648
I0204 08:50:39.612596 31922 solver.cpp:253]     Train net output #0: loss = 0.652648 (* 1 = 0.652648 loss)
I0204 08:50:39.612609 31922 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 08:50:49.444270 31922 solver.cpp:237] Iteration 210, loss = 0.689816
I0204 08:50:49.444329 31922 solver.cpp:253]     Train net output #0: loss = 0.689816 (* 1 = 0.689816 loss)
I0204 08:50:49.444341 31922 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 08:50:59.281441 31922 solver.cpp:237] Iteration 220, loss = 0.705934
I0204 08:50:59.281496 31922 solver.cpp:253]     Train net output #0: loss = 0.705934 (* 1 = 0.705934 loss)
I0204 08:50:59.281507 31922 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 08:51:09.136117 31922 solver.cpp:237] Iteration 230, loss = 0.686631
I0204 08:51:09.136291 31922 solver.cpp:253]     Train net output #0: loss = 0.686631 (* 1 = 0.686631 loss)
I0204 08:51:09.136304 31922 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 08:51:18.874583 31922 solver.cpp:237] Iteration 240, loss = 0.568363
I0204 08:51:18.874645 31922 solver.cpp:253]     Train net output #0: loss = 0.568363 (* 1 = 0.568363 loss)
I0204 08:51:18.874657 31922 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 08:51:28.523785 31922 solver.cpp:237] Iteration 250, loss = 0.556128
I0204 08:51:28.523847 31922 solver.cpp:253]     Train net output #0: loss = 0.556128 (* 1 = 0.556128 loss)
I0204 08:51:28.523859 31922 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 08:51:38.275235 31922 solver.cpp:237] Iteration 260, loss = 0.56671
I0204 08:51:38.275301 31922 solver.cpp:253]     Train net output #0: loss = 0.56671 (* 1 = 0.56671 loss)
I0204 08:51:38.275313 31922 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 08:51:47.970170 31922 solver.cpp:237] Iteration 270, loss = 0.490512
I0204 08:51:47.970392 31922 solver.cpp:253]     Train net output #0: loss = 0.490512 (* 1 = 0.490512 loss)
I0204 08:51:47.970407 31922 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 08:51:57.678613 31922 solver.cpp:237] Iteration 280, loss = 0.407859
I0204 08:51:57.678678 31922 solver.cpp:253]     Train net output #0: loss = 0.407859 (* 1 = 0.407859 loss)
I0204 08:51:57.678689 31922 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 08:52:07.448212 31922 solver.cpp:237] Iteration 290, loss = 0.468844
I0204 08:52:07.448261 31922 solver.cpp:253]     Train net output #0: loss = 0.468844 (* 1 = 0.468844 loss)
I0204 08:52:07.448271 31922 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 08:52:16.339579 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_300.caffemodel
I0204 08:52:16.342013 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_300.solverstate
I0204 08:52:16.343056 31922 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 08:52:21.033327 31922 solver.cpp:409]     Test net output #0: accuracy = 0.967
I0204 08:52:21.033499 31922 solver.cpp:409]     Test net output #1: loss = 0.126882 (* 1 = 0.126882 loss)
I0204 08:52:22.020576 31922 solver.cpp:237] Iteration 300, loss = 0.212428
I0204 08:52:22.020637 31922 solver.cpp:253]     Train net output #0: loss = 0.212428 (* 1 = 0.212428 loss)
I0204 08:52:22.020649 31922 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 08:52:31.982100 31922 solver.cpp:237] Iteration 310, loss = 0.236782
I0204 08:52:31.982172 31922 solver.cpp:253]     Train net output #0: loss = 0.236782 (* 1 = 0.236782 loss)
I0204 08:52:31.984189 31922 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 08:52:42.049386 31922 solver.cpp:237] Iteration 320, loss = 0.176527
I0204 08:52:42.049439 31922 solver.cpp:253]     Train net output #0: loss = 0.176527 (* 1 = 0.176527 loss)
I0204 08:52:42.049453 31922 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 08:52:52.158720 31922 solver.cpp:237] Iteration 330, loss = 0.0774752
I0204 08:52:52.158840 31922 solver.cpp:253]     Train net output #0: loss = 0.0774752 (* 1 = 0.0774752 loss)
I0204 08:52:52.158854 31922 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 08:53:02.350548 31922 solver.cpp:237] Iteration 340, loss = 0.198838
I0204 08:53:02.350608 31922 solver.cpp:253]     Train net output #0: loss = 0.198838 (* 1 = 0.198838 loss)
I0204 08:53:02.350622 31922 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 08:53:12.401789 31922 solver.cpp:237] Iteration 350, loss = 0.263045
I0204 08:53:12.401861 31922 solver.cpp:253]     Train net output #0: loss = 0.263045 (* 1 = 0.263045 loss)
I0204 08:53:12.401875 31922 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 08:53:22.456477 31922 solver.cpp:237] Iteration 360, loss = 0.0664132
I0204 08:53:22.456650 31922 solver.cpp:253]     Train net output #0: loss = 0.0664133 (* 1 = 0.0664133 loss)
I0204 08:53:22.456665 31922 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 08:53:32.458346 31922 solver.cpp:237] Iteration 370, loss = 0.0622529
I0204 08:53:32.458415 31922 solver.cpp:253]     Train net output #0: loss = 0.0622529 (* 1 = 0.0622529 loss)
I0204 08:53:32.458433 31922 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 08:53:42.599414 31922 solver.cpp:237] Iteration 380, loss = 0.0636396
I0204 08:53:42.599484 31922 solver.cpp:253]     Train net output #0: loss = 0.0636396 (* 1 = 0.0636396 loss)
I0204 08:53:42.599498 31922 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 08:53:52.645860 31922 solver.cpp:237] Iteration 390, loss = 0.0575028
I0204 08:53:52.646054 31922 solver.cpp:253]     Train net output #0: loss = 0.0575029 (* 1 = 0.0575029 loss)
I0204 08:53:52.646070 31922 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 08:54:01.787029 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_400.caffemodel
I0204 08:54:01.789300 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_400.solverstate
I0204 08:54:01.790293 31922 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 08:54:06.610888 31922 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 08:54:06.610944 31922 solver.cpp:409]     Test net output #1: loss = 0.0279333 (* 1 = 0.0279333 loss)
I0204 08:54:07.626785 31922 solver.cpp:237] Iteration 400, loss = 0.0460471
I0204 08:54:07.626838 31922 solver.cpp:253]     Train net output #0: loss = 0.0460471 (* 1 = 0.0460471 loss)
I0204 08:54:07.626852 31922 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 08:54:17.747700 31922 solver.cpp:237] Iteration 410, loss = 0.0391318
I0204 08:54:17.747762 31922 solver.cpp:253]     Train net output #0: loss = 0.0391318 (* 1 = 0.0391318 loss)
I0204 08:54:17.747776 31922 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 08:54:27.803884 31922 solver.cpp:237] Iteration 420, loss = 0.0301924
I0204 08:54:27.804075 31922 solver.cpp:253]     Train net output #0: loss = 0.0301925 (* 1 = 0.0301925 loss)
I0204 08:54:27.804090 31922 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 08:54:37.826627 31922 solver.cpp:237] Iteration 430, loss = 0.0913461
I0204 08:54:37.826688 31922 solver.cpp:253]     Train net output #0: loss = 0.0913462 (* 1 = 0.0913462 loss)
I0204 08:54:37.828433 31922 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 08:54:47.941573 31922 solver.cpp:237] Iteration 440, loss = 0.0618234
I0204 08:54:47.941630 31922 solver.cpp:253]     Train net output #0: loss = 0.0618235 (* 1 = 0.0618235 loss)
I0204 08:54:47.941643 31922 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 08:54:57.946516 31922 solver.cpp:237] Iteration 450, loss = 0.240171
I0204 08:54:57.946683 31922 solver.cpp:253]     Train net output #0: loss = 0.240171 (* 1 = 0.240171 loss)
I0204 08:54:57.946698 31922 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 08:55:07.965850 31922 solver.cpp:237] Iteration 460, loss = 0.177284
I0204 08:55:07.965909 31922 solver.cpp:253]     Train net output #0: loss = 0.177284 (* 1 = 0.177284 loss)
I0204 08:55:07.965929 31922 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 08:55:17.970459 31922 solver.cpp:237] Iteration 470, loss = 0.0288861
I0204 08:55:17.970517 31922 solver.cpp:253]     Train net output #0: loss = 0.0288862 (* 1 = 0.0288862 loss)
I0204 08:55:17.970530 31922 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 08:55:28.148196 31922 solver.cpp:237] Iteration 480, loss = 0.0306695
I0204 08:55:28.148358 31922 solver.cpp:253]     Train net output #0: loss = 0.0306696 (* 1 = 0.0306696 loss)
I0204 08:55:28.148371 31922 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 08:55:38.163475 31922 solver.cpp:237] Iteration 490, loss = 0.0126059
I0204 08:55:38.163534 31922 solver.cpp:253]     Train net output #0: loss = 0.012606 (* 1 = 0.012606 loss)
I0204 08:55:38.163547 31922 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 08:55:47.198926 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_500.caffemodel
I0204 08:55:47.201212 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_500.solverstate
I0204 08:55:47.202244 31922 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 08:55:51.931110 31922 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 08:55:51.931166 31922 solver.cpp:409]     Test net output #1: loss = 0.0161915 (* 1 = 0.0161915 loss)
I0204 08:55:52.933609 31922 solver.cpp:237] Iteration 500, loss = 0.0275565
I0204 08:55:52.933667 31922 solver.cpp:253]     Train net output #0: loss = 0.0275566 (* 1 = 0.0275566 loss)
I0204 08:55:52.933691 31922 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 08:56:02.989693 31922 solver.cpp:237] Iteration 510, loss = 0.217123
I0204 08:56:02.989904 31922 solver.cpp:253]     Train net output #0: loss = 0.217123 (* 1 = 0.217123 loss)
I0204 08:56:02.989918 31922 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 08:56:13.047421 31922 solver.cpp:237] Iteration 520, loss = 0.0254052
I0204 08:56:13.047477 31922 solver.cpp:253]     Train net output #0: loss = 0.0254053 (* 1 = 0.0254053 loss)
I0204 08:56:13.047489 31922 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 08:56:23.103579 31922 solver.cpp:237] Iteration 530, loss = 0.0441483
I0204 08:56:23.103639 31922 solver.cpp:253]     Train net output #0: loss = 0.0441483 (* 1 = 0.0441483 loss)
I0204 08:56:23.103654 31922 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 08:56:33.154919 31922 solver.cpp:237] Iteration 540, loss = 0.00860941
I0204 08:56:33.155076 31922 solver.cpp:253]     Train net output #0: loss = 0.00860949 (* 1 = 0.00860949 loss)
I0204 08:56:33.155089 31922 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 08:56:43.178287 31922 solver.cpp:237] Iteration 550, loss = 0.0536843
I0204 08:56:43.178359 31922 solver.cpp:253]     Train net output #0: loss = 0.0536844 (* 1 = 0.0536844 loss)
I0204 08:56:43.178374 31922 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 08:56:53.132156 31922 solver.cpp:237] Iteration 560, loss = 0.0458632
I0204 08:56:53.132226 31922 solver.cpp:253]     Train net output #0: loss = 0.0458633 (* 1 = 0.0458633 loss)
I0204 08:56:53.132239 31922 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 08:57:03.066949 31922 solver.cpp:237] Iteration 570, loss = 0.0222961
I0204 08:57:03.067021 31922 solver.cpp:253]     Train net output #0: loss = 0.0222962 (* 1 = 0.0222962 loss)
I0204 08:57:03.067034 31922 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 08:57:13.027868 31922 solver.cpp:237] Iteration 580, loss = 0.0594957
I0204 08:57:13.028053 31922 solver.cpp:253]     Train net output #0: loss = 0.0594958 (* 1 = 0.0594958 loss)
I0204 08:57:13.028069 31922 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 08:57:23.072341 31922 solver.cpp:237] Iteration 590, loss = 0.0676872
I0204 08:57:23.072412 31922 solver.cpp:253]     Train net output #0: loss = 0.0676873 (* 1 = 0.0676873 loss)
I0204 08:57:23.072425 31922 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 08:57:32.003062 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_600.caffemodel
I0204 08:57:32.005333 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_600.solverstate
I0204 08:57:32.006283 31922 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 08:57:36.713680 31922 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 08:57:36.713748 31922 solver.cpp:409]     Test net output #1: loss = 0.0109557 (* 1 = 0.0109557 loss)
I0204 08:57:37.705510 31922 solver.cpp:237] Iteration 600, loss = 0.02848
I0204 08:57:37.705577 31922 solver.cpp:253]     Train net output #0: loss = 0.0284801 (* 1 = 0.0284801 loss)
I0204 08:57:37.705590 31922 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 08:57:47.772223 31922 solver.cpp:237] Iteration 610, loss = 0.0859265
I0204 08:57:47.772398 31922 solver.cpp:253]     Train net output #0: loss = 0.0859266 (* 1 = 0.0859266 loss)
I0204 08:57:47.772411 31922 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 08:57:57.959781 31922 solver.cpp:237] Iteration 620, loss = 0.0290617
I0204 08:57:57.959851 31922 solver.cpp:253]     Train net output #0: loss = 0.0290618 (* 1 = 0.0290618 loss)
I0204 08:57:57.959863 31922 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 08:58:07.966240 31922 solver.cpp:237] Iteration 630, loss = 0.0217497
I0204 08:58:07.966311 31922 solver.cpp:253]     Train net output #0: loss = 0.0217497 (* 1 = 0.0217497 loss)
I0204 08:58:07.966325 31922 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 08:58:17.938392 31922 solver.cpp:237] Iteration 640, loss = 0.0297283
I0204 08:58:17.938601 31922 solver.cpp:253]     Train net output #0: loss = 0.0297284 (* 1 = 0.0297284 loss)
I0204 08:58:17.938614 31922 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 08:58:27.893223 31922 solver.cpp:237] Iteration 650, loss = 0.0413478
I0204 08:58:27.893286 31922 solver.cpp:253]     Train net output #0: loss = 0.0413479 (* 1 = 0.0413479 loss)
I0204 08:58:27.893298 31922 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 08:58:37.844538 31922 solver.cpp:237] Iteration 660, loss = 0.0311851
I0204 08:58:37.844601 31922 solver.cpp:253]     Train net output #0: loss = 0.0311852 (* 1 = 0.0311852 loss)
I0204 08:58:37.844612 31922 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 08:58:47.782306 31922 solver.cpp:237] Iteration 670, loss = 0.0338275
I0204 08:58:47.782371 31922 solver.cpp:253]     Train net output #0: loss = 0.0338276 (* 1 = 0.0338276 loss)
I0204 08:58:47.782382 31922 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 08:58:57.765947 31922 solver.cpp:237] Iteration 680, loss = 0.0133335
I0204 08:58:57.766101 31922 solver.cpp:253]     Train net output #0: loss = 0.0133336 (* 1 = 0.0133336 loss)
I0204 08:58:57.766115 31922 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 08:59:07.714176 31922 solver.cpp:237] Iteration 690, loss = 0.0019001
I0204 08:59:07.714244 31922 solver.cpp:253]     Train net output #0: loss = 0.00190018 (* 1 = 0.00190018 loss)
I0204 08:59:07.714257 31922 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 08:59:16.634702 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_700.caffemodel
I0204 08:59:16.637357 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_700.solverstate
I0204 08:59:16.638494 31922 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 08:59:21.331887 31922 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 08:59:21.331956 31922 solver.cpp:409]     Test net output #1: loss = 0.00940603 (* 1 = 0.00940603 loss)
I0204 08:59:22.303496 31922 solver.cpp:237] Iteration 700, loss = 0.0151541
I0204 08:59:22.303561 31922 solver.cpp:253]     Train net output #0: loss = 0.0151542 (* 1 = 0.0151542 loss)
I0204 08:59:22.303575 31922 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 08:59:32.030756 31922 solver.cpp:237] Iteration 710, loss = 0.00185123
I0204 08:59:32.030941 31922 solver.cpp:253]     Train net output #0: loss = 0.00185131 (* 1 = 0.00185131 loss)
I0204 08:59:32.030954 31922 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 08:59:41.687379 31922 solver.cpp:237] Iteration 720, loss = 0.00132378
I0204 08:59:41.687453 31922 solver.cpp:253]     Train net output #0: loss = 0.00132387 (* 1 = 0.00132387 loss)
I0204 08:59:41.687465 31922 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 08:59:51.700001 31922 solver.cpp:237] Iteration 730, loss = 0.0956639
I0204 08:59:51.700067 31922 solver.cpp:253]     Train net output #0: loss = 0.095664 (* 1 = 0.095664 loss)
I0204 08:59:51.700079 31922 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 09:00:01.805753 31922 solver.cpp:237] Iteration 740, loss = 0.0224759
I0204 09:00:01.805811 31922 solver.cpp:253]     Train net output #0: loss = 0.022476 (* 1 = 0.022476 loss)
I0204 09:00:01.805825 31922 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 09:00:11.873183 31922 solver.cpp:237] Iteration 750, loss = 0.00598275
I0204 09:00:11.873299 31922 solver.cpp:253]     Train net output #0: loss = 0.00598283 (* 1 = 0.00598283 loss)
I0204 09:00:11.873312 31922 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 09:00:21.952859 31922 solver.cpp:237] Iteration 760, loss = 0.00778897
I0204 09:00:21.952915 31922 solver.cpp:253]     Train net output #0: loss = 0.00778905 (* 1 = 0.00778905 loss)
I0204 09:00:21.952927 31922 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 09:00:32.023805 31922 solver.cpp:237] Iteration 770, loss = 0.00191321
I0204 09:00:32.023861 31922 solver.cpp:253]     Train net output #0: loss = 0.00191329 (* 1 = 0.00191329 loss)
I0204 09:00:32.023874 31922 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 09:00:42.088501 31922 solver.cpp:237] Iteration 780, loss = 0.00222937
I0204 09:00:42.088707 31922 solver.cpp:253]     Train net output #0: loss = 0.00222944 (* 1 = 0.00222944 loss)
I0204 09:00:42.088721 31922 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 09:00:52.128690 31922 solver.cpp:237] Iteration 790, loss = 0.0315567
I0204 09:00:52.128751 31922 solver.cpp:253]     Train net output #0: loss = 0.0315568 (* 1 = 0.0315568 loss)
I0204 09:00:52.128762 31922 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 09:01:01.186591 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_800.caffemodel
I0204 09:01:01.189175 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_800.solverstate
I0204 09:01:01.190295 31922 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 09:01:06.010205 31922 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 09:01:06.010260 31922 solver.cpp:409]     Test net output #1: loss = 0.00233217 (* 1 = 0.00233217 loss)
I0204 09:01:07.021311 31922 solver.cpp:237] Iteration 800, loss = 0.00356341
I0204 09:01:07.021365 31922 solver.cpp:253]     Train net output #0: loss = 0.00356348 (* 1 = 0.00356348 loss)
I0204 09:01:07.021378 31922 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 09:01:17.063436 31922 solver.cpp:237] Iteration 810, loss = 0.0580154
I0204 09:01:17.063594 31922 solver.cpp:253]     Train net output #0: loss = 0.0580154 (* 1 = 0.0580154 loss)
I0204 09:01:17.063607 31922 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 09:01:27.074515 31922 solver.cpp:237] Iteration 820, loss = 0.133967
I0204 09:01:27.074571 31922 solver.cpp:253]     Train net output #0: loss = 0.133967 (* 1 = 0.133967 loss)
I0204 09:01:27.074584 31922 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 09:01:37.096519 31922 solver.cpp:237] Iteration 830, loss = 0.00372453
I0204 09:01:37.096575 31922 solver.cpp:253]     Train net output #0: loss = 0.0037246 (* 1 = 0.0037246 loss)
I0204 09:01:37.096585 31922 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 09:01:47.221452 31922 solver.cpp:237] Iteration 840, loss = 0.0039745
I0204 09:01:47.221637 31922 solver.cpp:253]     Train net output #0: loss = 0.00397458 (* 1 = 0.00397458 loss)
I0204 09:01:47.221649 31922 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 09:01:57.235261 31922 solver.cpp:237] Iteration 850, loss = 0.0262977
I0204 09:01:57.235322 31922 solver.cpp:253]     Train net output #0: loss = 0.0262977 (* 1 = 0.0262977 loss)
I0204 09:01:57.235333 31922 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 09:02:06.968153 31922 solver.cpp:237] Iteration 860, loss = 0.0175334
I0204 09:02:06.968211 31922 solver.cpp:253]     Train net output #0: loss = 0.0175334 (* 1 = 0.0175334 loss)
I0204 09:02:06.968224 31922 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 09:02:16.757033 31922 solver.cpp:237] Iteration 870, loss = 0.0155293
I0204 09:02:16.757087 31922 solver.cpp:253]     Train net output #0: loss = 0.0155294 (* 1 = 0.0155294 loss)
I0204 09:02:16.757099 31922 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 09:02:26.581851 31922 solver.cpp:237] Iteration 880, loss = 0.014654
I0204 09:02:26.582026 31922 solver.cpp:253]     Train net output #0: loss = 0.014654 (* 1 = 0.014654 loss)
I0204 09:02:26.582039 31922 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 09:02:36.724606 31922 solver.cpp:237] Iteration 890, loss = 0.118249
I0204 09:02:36.725165 31922 solver.cpp:253]     Train net output #0: loss = 0.118249 (* 1 = 0.118249 loss)
I0204 09:02:36.725183 31922 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 09:02:45.834728 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_900.caffemodel
I0204 09:02:45.837112 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_900.solverstate
I0204 09:02:45.838173 31922 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 09:02:50.720494 31922 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 09:02:50.720548 31922 solver.cpp:409]     Test net output #1: loss = 0.00192955 (* 1 = 0.00192955 loss)
I0204 09:02:51.705528 31922 solver.cpp:237] Iteration 900, loss = 0.013689
I0204 09:02:51.705586 31922 solver.cpp:253]     Train net output #0: loss = 0.013689 (* 1 = 0.013689 loss)
I0204 09:02:51.705598 31922 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 09:03:01.646697 31922 solver.cpp:237] Iteration 910, loss = 0.0113805
I0204 09:03:01.646920 31922 solver.cpp:253]     Train net output #0: loss = 0.0113806 (* 1 = 0.0113806 loss)
I0204 09:03:01.646935 31922 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 09:03:11.614583 31922 solver.cpp:237] Iteration 920, loss = 0.00718097
I0204 09:03:11.614651 31922 solver.cpp:253]     Train net output #0: loss = 0.00718103 (* 1 = 0.00718103 loss)
I0204 09:03:11.614663 31922 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 09:03:21.653699 31922 solver.cpp:237] Iteration 930, loss = 0.0221829
I0204 09:03:21.653758 31922 solver.cpp:253]     Train net output #0: loss = 0.022183 (* 1 = 0.022183 loss)
I0204 09:03:21.653769 31922 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 09:03:31.694561 31922 solver.cpp:237] Iteration 940, loss = 0.00374291
I0204 09:03:31.694728 31922 solver.cpp:253]     Train net output #0: loss = 0.00374297 (* 1 = 0.00374297 loss)
I0204 09:03:31.694741 31922 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 09:03:41.773612 31922 solver.cpp:237] Iteration 950, loss = 0.00203438
I0204 09:03:41.773669 31922 solver.cpp:253]     Train net output #0: loss = 0.00203444 (* 1 = 0.00203444 loss)
I0204 09:03:41.773679 31922 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 09:03:51.805099 31922 solver.cpp:237] Iteration 960, loss = 0.0129996
I0204 09:03:51.805160 31922 solver.cpp:253]     Train net output #0: loss = 0.0129997 (* 1 = 0.0129997 loss)
I0204 09:03:51.805172 31922 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 09:04:01.802043 31922 solver.cpp:237] Iteration 970, loss = 0.089945
I0204 09:04:01.802240 31922 solver.cpp:253]     Train net output #0: loss = 0.0899451 (* 1 = 0.0899451 loss)
I0204 09:04:01.802253 31922 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 09:04:11.852527 31922 solver.cpp:237] Iteration 980, loss = 0.00153251
I0204 09:04:11.852591 31922 solver.cpp:253]     Train net output #0: loss = 0.00153258 (* 1 = 0.00153258 loss)
I0204 09:04:11.852602 31922 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 09:04:21.827239 31922 solver.cpp:237] Iteration 990, loss = 0.00422268
I0204 09:04:21.827308 31922 solver.cpp:253]     Train net output #0: loss = 0.00422275 (* 1 = 0.00422275 loss)
I0204 09:04:21.827319 31922 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 09:04:30.831081 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1000.caffemodel
I0204 09:04:30.833417 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1000.solverstate
I0204 09:04:30.834414 31922 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 09:04:35.564846 31922 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 09:04:35.565014 31922 solver.cpp:409]     Test net output #1: loss = 0.00855534 (* 1 = 0.00855534 loss)
I0204 09:04:36.561297 31922 solver.cpp:237] Iteration 1000, loss = 0.0275769
I0204 09:04:36.561373 31922 solver.cpp:253]     Train net output #0: loss = 0.027577 (* 1 = 0.027577 loss)
I0204 09:04:36.561385 31922 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 09:04:46.495728 31922 solver.cpp:237] Iteration 1010, loss = 0.020403
I0204 09:04:46.495793 31922 solver.cpp:253]     Train net output #0: loss = 0.0204031 (* 1 = 0.0204031 loss)
I0204 09:04:46.495805 31922 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 09:04:56.380638 31922 solver.cpp:237] Iteration 1020, loss = 0.0347342
I0204 09:04:56.380709 31922 solver.cpp:253]     Train net output #0: loss = 0.0347343 (* 1 = 0.0347343 loss)
I0204 09:04:56.380722 31922 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 09:05:06.295308 31922 solver.cpp:237] Iteration 1030, loss = 0.00556246
I0204 09:05:06.295524 31922 solver.cpp:253]     Train net output #0: loss = 0.00556253 (* 1 = 0.00556253 loss)
I0204 09:05:06.295538 31922 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 09:05:16.220362 31922 solver.cpp:237] Iteration 1040, loss = 0.00500302
I0204 09:05:16.220429 31922 solver.cpp:253]     Train net output #0: loss = 0.00500309 (* 1 = 0.00500309 loss)
I0204 09:05:16.220441 31922 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 09:05:26.126402 31922 solver.cpp:237] Iteration 1050, loss = 0.00204191
I0204 09:05:26.126471 31922 solver.cpp:253]     Train net output #0: loss = 0.00204199 (* 1 = 0.00204199 loss)
I0204 09:05:26.126483 31922 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 09:05:36.226014 31922 solver.cpp:237] Iteration 1060, loss = 0.0126723
I0204 09:05:36.226096 31922 solver.cpp:253]     Train net output #0: loss = 0.0126724 (* 1 = 0.0126724 loss)
I0204 09:05:36.226109 31922 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 09:05:46.144266 31922 solver.cpp:237] Iteration 1070, loss = 0.00186673
I0204 09:05:46.144461 31922 solver.cpp:253]     Train net output #0: loss = 0.00186681 (* 1 = 0.00186681 loss)
I0204 09:05:46.144475 31922 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 09:05:56.189883 31922 solver.cpp:237] Iteration 1080, loss = 0.0149731
I0204 09:05:56.189954 31922 solver.cpp:253]     Train net output #0: loss = 0.0149732 (* 1 = 0.0149732 loss)
I0204 09:05:56.189970 31922 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 09:06:06.316854 31922 solver.cpp:237] Iteration 1090, loss = 0.00323307
I0204 09:06:06.316911 31922 solver.cpp:253]     Train net output #0: loss = 0.00323315 (* 1 = 0.00323315 loss)
I0204 09:06:06.316928 31922 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 09:06:15.486601 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1100.caffemodel
I0204 09:06:15.488905 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1100.solverstate
I0204 09:06:15.489898 31922 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 09:06:20.370451 31922 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 09:06:20.372056 31922 solver.cpp:409]     Test net output #1: loss = 0.00119442 (* 1 = 0.00119442 loss)
I0204 09:06:21.381505 31922 solver.cpp:237] Iteration 1100, loss = 0.00128336
I0204 09:06:21.381558 31922 solver.cpp:253]     Train net output #0: loss = 0.00128344 (* 1 = 0.00128344 loss)
I0204 09:06:21.381570 31922 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 09:06:31.477504 31922 solver.cpp:237] Iteration 1110, loss = 0.00814056
I0204 09:06:31.477555 31922 solver.cpp:253]     Train net output #0: loss = 0.00814064 (* 1 = 0.00814064 loss)
I0204 09:06:31.477567 31922 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 09:06:41.568104 31922 solver.cpp:237] Iteration 1120, loss = 0.036315
I0204 09:06:41.568171 31922 solver.cpp:253]     Train net output #0: loss = 0.0363151 (* 1 = 0.0363151 loss)
I0204 09:06:41.568225 31922 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 09:06:51.727156 31922 solver.cpp:237] Iteration 1130, loss = 0.00428677
I0204 09:06:51.727362 31922 solver.cpp:253]     Train net output #0: loss = 0.00428684 (* 1 = 0.00428684 loss)
I0204 09:06:51.727376 31922 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 09:07:01.727573 31922 solver.cpp:237] Iteration 1140, loss = 0.0202599
I0204 09:07:01.727632 31922 solver.cpp:253]     Train net output #0: loss = 0.02026 (* 1 = 0.02026 loss)
I0204 09:07:01.727643 31922 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 09:07:11.574882 31922 solver.cpp:237] Iteration 1150, loss = 0.116869
I0204 09:07:11.574950 31922 solver.cpp:253]     Train net output #0: loss = 0.116869 (* 1 = 0.116869 loss)
I0204 09:07:11.574962 31922 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 09:07:21.408278 31922 solver.cpp:237] Iteration 1160, loss = 0.0169149
I0204 09:07:21.408336 31922 solver.cpp:253]     Train net output #0: loss = 0.016915 (* 1 = 0.016915 loss)
I0204 09:07:21.408349 31922 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 09:07:31.287281 31922 solver.cpp:237] Iteration 1170, loss = 0.104555
I0204 09:07:31.287418 31922 solver.cpp:253]     Train net output #0: loss = 0.104556 (* 1 = 0.104556 loss)
I0204 09:07:31.287431 31922 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 09:07:41.111639 31922 solver.cpp:237] Iteration 1180, loss = 0.0426763
I0204 09:07:41.111695 31922 solver.cpp:253]     Train net output #0: loss = 0.0426763 (* 1 = 0.0426763 loss)
I0204 09:07:41.111706 31922 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 09:07:50.950179 31922 solver.cpp:237] Iteration 1190, loss = 0.0159929
I0204 09:07:50.950235 31922 solver.cpp:253]     Train net output #0: loss = 0.015993 (* 1 = 0.015993 loss)
I0204 09:07:50.950248 31922 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 09:07:59.786547 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1200.caffemodel
I0204 09:07:59.788830 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1200.solverstate
I0204 09:07:59.789835 31922 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 09:08:04.421727 31922 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 09:08:04.421900 31922 solver.cpp:409]     Test net output #1: loss = 0.00587701 (* 1 = 0.00587701 loss)
I0204 09:08:05.408999 31922 solver.cpp:237] Iteration 1200, loss = 0.00954622
I0204 09:08:05.409052 31922 solver.cpp:253]     Train net output #0: loss = 0.00954629 (* 1 = 0.00954629 loss)
I0204 09:08:05.409065 31922 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 09:08:15.282510 31922 solver.cpp:237] Iteration 1210, loss = 0.000737157
I0204 09:08:15.282565 31922 solver.cpp:253]     Train net output #0: loss = 0.000737224 (* 1 = 0.000737224 loss)
I0204 09:08:15.282577 31922 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 09:08:25.226541 31922 solver.cpp:237] Iteration 1220, loss = 0.00208725
I0204 09:08:25.226598 31922 solver.cpp:253]     Train net output #0: loss = 0.00208732 (* 1 = 0.00208732 loss)
I0204 09:08:25.226610 31922 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 09:08:35.110484 31922 solver.cpp:237] Iteration 1230, loss = 0.0144217
I0204 09:08:35.110623 31922 solver.cpp:253]     Train net output #0: loss = 0.0144217 (* 1 = 0.0144217 loss)
I0204 09:08:35.110636 31922 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 09:08:45.004566 31922 solver.cpp:237] Iteration 1240, loss = 0.00204227
I0204 09:08:45.004631 31922 solver.cpp:253]     Train net output #0: loss = 0.00204234 (* 1 = 0.00204234 loss)
I0204 09:08:45.004642 31922 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 09:08:54.856305 31922 solver.cpp:237] Iteration 1250, loss = 0.00320707
I0204 09:08:54.856364 31922 solver.cpp:253]     Train net output #0: loss = 0.00320713 (* 1 = 0.00320713 loss)
I0204 09:08:54.856375 31922 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 09:09:04.969627 31922 solver.cpp:237] Iteration 1260, loss = 0.000611552
I0204 09:09:04.969717 31922 solver.cpp:253]     Train net output #0: loss = 0.000611607 (* 1 = 0.000611607 loss)
I0204 09:09:04.969729 31922 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 09:09:14.980039 31922 solver.cpp:237] Iteration 1270, loss = 0.000749279
I0204 09:09:14.980712 31922 solver.cpp:253]     Train net output #0: loss = 0.000749333 (* 1 = 0.000749333 loss)
I0204 09:09:14.980726 31922 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 09:09:25.070720 31922 solver.cpp:237] Iteration 1280, loss = 0.00808569
I0204 09:09:25.070782 31922 solver.cpp:253]     Train net output #0: loss = 0.00808574 (* 1 = 0.00808574 loss)
I0204 09:09:25.070793 31922 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 09:09:35.047325 31922 solver.cpp:237] Iteration 1290, loss = 0.00583717
I0204 09:09:35.047389 31922 solver.cpp:253]     Train net output #0: loss = 0.00583723 (* 1 = 0.00583723 loss)
I0204 09:09:35.047401 31922 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 09:09:43.952780 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1300.caffemodel
I0204 09:09:43.955045 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1300.solverstate
I0204 09:09:43.956022 31922 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 09:09:48.649580 31922 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 09:09:48.649749 31922 solver.cpp:409]     Test net output #1: loss = 0.0042239 (* 1 = 0.0042239 loss)
I0204 09:09:49.624984 31922 solver.cpp:237] Iteration 1300, loss = 0.000828769
I0204 09:09:49.625046 31922 solver.cpp:253]     Train net output #0: loss = 0.000828827 (* 1 = 0.000828827 loss)
I0204 09:09:49.625058 31922 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 09:09:59.370019 31922 solver.cpp:237] Iteration 1310, loss = 0.00864471
I0204 09:09:59.370085 31922 solver.cpp:253]     Train net output #0: loss = 0.00864477 (* 1 = 0.00864477 loss)
I0204 09:09:59.370095 31922 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 09:10:09.233242 31922 solver.cpp:237] Iteration 1320, loss = 0.0634582
I0204 09:10:09.233314 31922 solver.cpp:253]     Train net output #0: loss = 0.0634582 (* 1 = 0.0634582 loss)
I0204 09:10:09.233366 31922 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 09:10:19.401495 31922 solver.cpp:237] Iteration 1330, loss = 0.0368508
I0204 09:10:19.401676 31922 solver.cpp:253]     Train net output #0: loss = 0.0368508 (* 1 = 0.0368508 loss)
I0204 09:10:19.401690 31922 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 09:10:29.483808 31922 solver.cpp:237] Iteration 1340, loss = 0.00168519
I0204 09:10:29.483872 31922 solver.cpp:253]     Train net output #0: loss = 0.00168525 (* 1 = 0.00168525 loss)
I0204 09:10:29.483885 31922 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 09:10:39.479347 31922 solver.cpp:237] Iteration 1350, loss = 0.00902337
I0204 09:10:39.479413 31922 solver.cpp:253]     Train net output #0: loss = 0.00902344 (* 1 = 0.00902344 loss)
I0204 09:10:39.479425 31922 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 09:10:49.393743 31922 solver.cpp:237] Iteration 1360, loss = 0.0064123
I0204 09:10:49.393807 31922 solver.cpp:253]     Train net output #0: loss = 0.00641236 (* 1 = 0.00641236 loss)
I0204 09:10:49.393820 31922 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 09:10:59.302587 31922 solver.cpp:237] Iteration 1370, loss = 0.0106999
I0204 09:10:59.302777 31922 solver.cpp:253]     Train net output #0: loss = 0.0106999 (* 1 = 0.0106999 loss)
I0204 09:10:59.302790 31922 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 09:11:09.192909 31922 solver.cpp:237] Iteration 1380, loss = 0.0108874
I0204 09:11:09.192973 31922 solver.cpp:253]     Train net output #0: loss = 0.0108874 (* 1 = 0.0108874 loss)
I0204 09:11:09.192996 31922 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 09:11:18.978400 31922 solver.cpp:237] Iteration 1390, loss = 0.0261197
I0204 09:11:18.978456 31922 solver.cpp:253]     Train net output #0: loss = 0.0261197 (* 1 = 0.0261197 loss)
I0204 09:11:18.978468 31922 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 09:11:27.777770 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1400.caffemodel
I0204 09:11:27.780113 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1400.solverstate
I0204 09:11:27.781128 31922 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 09:11:32.400594 31922 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 09:11:32.400805 31922 solver.cpp:409]     Test net output #1: loss = 0.00368491 (* 1 = 0.00368491 loss)
I0204 09:11:33.384332 31922 solver.cpp:237] Iteration 1400, loss = 0.0119928
I0204 09:11:33.384384 31922 solver.cpp:253]     Train net output #0: loss = 0.0119929 (* 1 = 0.0119929 loss)
I0204 09:11:33.384397 31922 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 09:11:43.336731 31922 solver.cpp:237] Iteration 1410, loss = 0.000375193
I0204 09:11:43.336791 31922 solver.cpp:253]     Train net output #0: loss = 0.000375247 (* 1 = 0.000375247 loss)
I0204 09:11:43.336803 31922 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 09:11:53.423941 31922 solver.cpp:237] Iteration 1420, loss = 0.001245
I0204 09:11:53.424000 31922 solver.cpp:253]     Train net output #0: loss = 0.00124505 (* 1 = 0.00124505 loss)
I0204 09:11:53.424011 31922 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 09:12:03.175671 31922 solver.cpp:237] Iteration 1430, loss = 0.000931025
I0204 09:12:03.175858 31922 solver.cpp:253]     Train net output #0: loss = 0.00093108 (* 1 = 0.00093108 loss)
I0204 09:12:03.175871 31922 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 09:12:13.056478 31922 solver.cpp:237] Iteration 1440, loss = 0.0058085
I0204 09:12:13.056532 31922 solver.cpp:253]     Train net output #0: loss = 0.00580856 (* 1 = 0.00580856 loss)
I0204 09:12:13.056545 31922 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 09:12:22.938148 31922 solver.cpp:237] Iteration 1450, loss = 0.000354807
I0204 09:12:22.938204 31922 solver.cpp:253]     Train net output #0: loss = 0.000354863 (* 1 = 0.000354863 loss)
I0204 09:12:22.938215 31922 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 09:12:32.759590 31922 solver.cpp:237] Iteration 1460, loss = 0.00188134
I0204 09:12:32.759660 31922 solver.cpp:253]     Train net output #0: loss = 0.00188139 (* 1 = 0.00188139 loss)
I0204 09:12:32.759671 31922 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 09:12:42.674221 31922 solver.cpp:237] Iteration 1470, loss = 0.050144
I0204 09:12:42.674402 31922 solver.cpp:253]     Train net output #0: loss = 0.0501441 (* 1 = 0.0501441 loss)
I0204 09:12:42.674415 31922 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 09:12:52.603590 31922 solver.cpp:237] Iteration 1480, loss = 0.00074053
I0204 09:12:52.603658 31922 solver.cpp:253]     Train net output #0: loss = 0.000740588 (* 1 = 0.000740588 loss)
I0204 09:12:52.603672 31922 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 09:13:02.601569 31922 solver.cpp:237] Iteration 1490, loss = 0.00476663
I0204 09:13:02.601624 31922 solver.cpp:253]     Train net output #0: loss = 0.00476669 (* 1 = 0.00476669 loss)
I0204 09:13:02.601634 31922 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 09:13:11.616050 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1500.caffemodel
I0204 09:13:11.618396 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1500.solverstate
I0204 09:13:11.619464 31922 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 09:13:16.359040 31922 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 09:13:16.360215 31922 solver.cpp:409]     Test net output #1: loss = 0.00463613 (* 1 = 0.00463613 loss)
I0204 09:13:17.338299 31922 solver.cpp:237] Iteration 1500, loss = 0.00053155
I0204 09:13:17.338354 31922 solver.cpp:253]     Train net output #0: loss = 0.000531611 (* 1 = 0.000531611 loss)
I0204 09:13:17.338366 31922 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 09:13:27.067749 31922 solver.cpp:237] Iteration 1510, loss = 0.00105546
I0204 09:13:27.067802 31922 solver.cpp:253]     Train net output #0: loss = 0.00105552 (* 1 = 0.00105552 loss)
I0204 09:13:27.067813 31922 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 09:13:36.845263 31922 solver.cpp:237] Iteration 1520, loss = 0.000391353
I0204 09:13:36.845324 31922 solver.cpp:253]     Train net output #0: loss = 0.000391411 (* 1 = 0.000391411 loss)
I0204 09:13:36.845336 31922 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 09:13:46.446892 31922 solver.cpp:237] Iteration 1530, loss = 0.00131187
I0204 09:13:46.447077 31922 solver.cpp:253]     Train net output #0: loss = 0.00131193 (* 1 = 0.00131193 loss)
I0204 09:13:46.447089 31922 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 09:13:56.038426 31922 solver.cpp:237] Iteration 1540, loss = 0.00344254
I0204 09:13:56.038481 31922 solver.cpp:253]     Train net output #0: loss = 0.0034426 (* 1 = 0.0034426 loss)
I0204 09:13:56.038492 31922 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 09:14:05.527305 31922 solver.cpp:237] Iteration 1550, loss = 0.00113957
I0204 09:14:05.527361 31922 solver.cpp:253]     Train net output #0: loss = 0.00113963 (* 1 = 0.00113963 loss)
I0204 09:14:05.527374 31922 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 09:14:14.733261 31922 solver.cpp:237] Iteration 1560, loss = 0.000806244
I0204 09:14:14.733311 31922 solver.cpp:253]     Train net output #0: loss = 0.000806304 (* 1 = 0.000806304 loss)
I0204 09:14:14.733324 31922 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 09:14:23.899847 31922 solver.cpp:237] Iteration 1570, loss = 0.000434491
I0204 09:14:23.900033 31922 solver.cpp:253]     Train net output #0: loss = 0.00043455 (* 1 = 0.00043455 loss)
I0204 09:14:23.900045 31922 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 09:14:33.062942 31922 solver.cpp:237] Iteration 1580, loss = 0.00126062
I0204 09:14:33.063010 31922 solver.cpp:253]     Train net output #0: loss = 0.00126068 (* 1 = 0.00126068 loss)
I0204 09:14:33.063084 31922 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 09:14:42.199867 31922 solver.cpp:237] Iteration 1590, loss = 0.00351633
I0204 09:14:42.199923 31922 solver.cpp:253]     Train net output #0: loss = 0.00351638 (* 1 = 0.00351638 loss)
I0204 09:14:42.199935 31922 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 09:14:50.389519 31922 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1600.caffemodel
I0204 09:14:50.391638 31922 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num16_conv4num16_conv5num8/snaps/snap__iter_1600.solverstate
I0204 09:14:50.821792 31922 solver.cpp:321] Iteration 1600, loss = 0.00386822
I0204 09:14:50.821837 31922 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 09:14:55.117529 31922 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 09:14:55.117708 31922 solver.cpp:409]     Test net output #1: loss = 0.000435481 (* 1 = 0.000435481 loss)
I0204 09:14:55.117718 31922 solver.cpp:326] Optimization Done.
I0204 09:14:55.117724 31922 caffe.cpp:215] Optimization Done.
