I0204 16:28:13.641911  3298 caffe.cpp:177] Use CPU.
I0204 16:28:13.642434  3298 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap_"
solver_mode: CPU
random_seed: 2
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/train_val.prototxt"
I0204 16:28:13.642590  3298 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/train_val.prototxt
I0204 16:28:13.643193  3298 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:28:13.643225  3298 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:28:13.643468  3298 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.643613  3298 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.643797  3298 net.cpp:106] Creating Layer data
I0204 16:28:13.643817  3298 net.cpp:411] data -> data
I0204 16:28:13.643896  3298 net.cpp:411] data -> label
I0204 16:28:13.643920  3298 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:28:13.644012  3302 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:28:13.645067  3298 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.675799  3298 net.cpp:150] Setting up data
I0204 16:28:13.675923  3298 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.675935  3298 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.675966  3298 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.675988  3298 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.676017  3298 net.cpp:106] Creating Layer conv1
I0204 16:28:13.676026  3298 net.cpp:454] conv1 <- data
I0204 16:28:13.676046  3298 net.cpp:411] conv1 -> conv1
I0204 16:28:13.676182  3298 net.cpp:150] Setting up conv1
I0204 16:28:13.676194  3298 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.676200  3298 net.cpp:165] Memory required for data: 59332000
I0204 16:28:13.676219  3298 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.676234  3298 net.cpp:106] Creating Layer relu1
I0204 16:28:13.676239  3298 net.cpp:454] relu1 <- conv1
I0204 16:28:13.676249  3298 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.676262  3298 net.cpp:150] Setting up relu1
I0204 16:28:13.676270  3298 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.676275  3298 net.cpp:165] Memory required for data: 98052000
I0204 16:28:13.676280  3298 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.676291  3298 net.cpp:106] Creating Layer pool1
I0204 16:28:13.676297  3298 net.cpp:454] pool1 <- conv1
I0204 16:28:13.676306  3298 net.cpp:411] pool1 -> pool1
I0204 16:28:13.676329  3298 net.cpp:150] Setting up pool1
I0204 16:28:13.676337  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.676343  3298 net.cpp:165] Memory required for data: 107383200
I0204 16:28:13.676352  3298 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.676383  3298 net.cpp:106] Creating Layer norm1
I0204 16:28:13.676389  3298 net.cpp:454] norm1 <- pool1
I0204 16:28:13.676398  3298 net.cpp:411] norm1 -> norm1
I0204 16:28:13.676416  3298 net.cpp:150] Setting up norm1
I0204 16:28:13.676424  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.676429  3298 net.cpp:165] Memory required for data: 116714400
I0204 16:28:13.676434  3298 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.676447  3298 net.cpp:106] Creating Layer conv2
I0204 16:28:13.676452  3298 net.cpp:454] conv2 <- norm1
I0204 16:28:13.676462  3298 net.cpp:411] conv2 -> conv2
I0204 16:28:13.676595  3298 net.cpp:150] Setting up conv2
I0204 16:28:13.676606  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.676612  3298 net.cpp:165] Memory required for data: 126045600
I0204 16:28:13.676623  3298 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.676652  3298 net.cpp:106] Creating Layer relu2
I0204 16:28:13.676661  3298 net.cpp:454] relu2 <- conv2
I0204 16:28:13.676668  3298 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.676679  3298 net.cpp:150] Setting up relu2
I0204 16:28:13.676687  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.676692  3298 net.cpp:165] Memory required for data: 135376800
I0204 16:28:13.676697  3298 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.676707  3298 net.cpp:106] Creating Layer pool2
I0204 16:28:13.676712  3298 net.cpp:454] pool2 <- conv2
I0204 16:28:13.676720  3298 net.cpp:411] pool2 -> pool2
I0204 16:28:13.676731  3298 net.cpp:150] Setting up pool2
I0204 16:28:13.676738  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.676743  3298 net.cpp:165] Memory required for data: 137540000
I0204 16:28:13.676749  3298 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.676764  3298 net.cpp:106] Creating Layer norm2
I0204 16:28:13.676771  3298 net.cpp:454] norm2 <- pool2
I0204 16:28:13.676780  3298 net.cpp:411] norm2 -> norm2
I0204 16:28:13.676790  3298 net.cpp:150] Setting up norm2
I0204 16:28:13.676797  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.676803  3298 net.cpp:165] Memory required for data: 139703200
I0204 16:28:13.676810  3298 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.676820  3298 net.cpp:106] Creating Layer conv3
I0204 16:28:13.676826  3298 net.cpp:454] conv3 <- norm2
I0204 16:28:13.676837  3298 net.cpp:411] conv3 -> conv3
I0204 16:28:13.676956  3298 net.cpp:150] Setting up conv3
I0204 16:28:13.676967  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.676972  3298 net.cpp:165] Memory required for data: 141866400
I0204 16:28:13.676983  3298 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.676992  3298 net.cpp:106] Creating Layer relu3
I0204 16:28:13.676998  3298 net.cpp:454] relu3 <- conv3
I0204 16:28:13.677011  3298 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.677021  3298 net.cpp:150] Setting up relu3
I0204 16:28:13.677028  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.677033  3298 net.cpp:165] Memory required for data: 144029600
I0204 16:28:13.677039  3298 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.677050  3298 net.cpp:106] Creating Layer conv4
I0204 16:28:13.677055  3298 net.cpp:454] conv4 <- conv3
I0204 16:28:13.677067  3298 net.cpp:411] conv4 -> conv4
I0204 16:28:13.677145  3298 net.cpp:150] Setting up conv4
I0204 16:28:13.677155  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.677161  3298 net.cpp:165] Memory required for data: 146192800
I0204 16:28:13.677170  3298 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.677180  3298 net.cpp:106] Creating Layer relu4
I0204 16:28:13.677184  3298 net.cpp:454] relu4 <- conv4
I0204 16:28:13.677192  3298 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.677201  3298 net.cpp:150] Setting up relu4
I0204 16:28:13.677209  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.677216  3298 net.cpp:165] Memory required for data: 148356000
I0204 16:28:13.677227  3298 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.677245  3298 net.cpp:106] Creating Layer conv5
I0204 16:28:13.677253  3298 net.cpp:454] conv5 <- conv4
I0204 16:28:13.677260  3298 net.cpp:411] conv5 -> conv5
I0204 16:28:13.677310  3298 net.cpp:150] Setting up conv5
I0204 16:28:13.677320  3298 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.677325  3298 net.cpp:165] Memory required for data: 149437600
I0204 16:28:13.677336  3298 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.677347  3298 net.cpp:106] Creating Layer relu5
I0204 16:28:13.677353  3298 net.cpp:454] relu5 <- conv5
I0204 16:28:13.677361  3298 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.677371  3298 net.cpp:150] Setting up relu5
I0204 16:28:13.677377  3298 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.677383  3298 net.cpp:165] Memory required for data: 150519200
I0204 16:28:13.677388  3298 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.677397  3298 net.cpp:106] Creating Layer pool5
I0204 16:28:13.677402  3298 net.cpp:454] pool5 <- conv5
I0204 16:28:13.677414  3298 net.cpp:411] pool5 -> pool5
I0204 16:28:13.677428  3298 net.cpp:150] Setting up pool5
I0204 16:28:13.677434  3298 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.677439  3298 net.cpp:165] Memory required for data: 150749600
I0204 16:28:13.677444  3298 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.677464  3298 net.cpp:106] Creating Layer fc6
I0204 16:28:13.677470  3298 net.cpp:454] fc6 <- pool5
I0204 16:28:13.677479  3298 net.cpp:411] fc6 -> fc6
I0204 16:28:13.679116  3298 net.cpp:150] Setting up fc6
I0204 16:28:13.679129  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.679134  3298 net.cpp:165] Memory required for data: 150852000
I0204 16:28:13.679143  3298 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.679155  3298 net.cpp:106] Creating Layer relu6
I0204 16:28:13.679162  3298 net.cpp:454] relu6 <- fc6
I0204 16:28:13.679168  3298 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.679178  3298 net.cpp:150] Setting up relu6
I0204 16:28:13.679184  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.679190  3298 net.cpp:165] Memory required for data: 150954400
I0204 16:28:13.679195  3298 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.679205  3298 net.cpp:106] Creating Layer drop6
I0204 16:28:13.679214  3298 net.cpp:454] drop6 <- fc6
I0204 16:28:13.679220  3298 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.679237  3298 net.cpp:150] Setting up drop6
I0204 16:28:13.679244  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.679250  3298 net.cpp:165] Memory required for data: 151056800
I0204 16:28:13.679255  3298 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.679265  3298 net.cpp:106] Creating Layer fc7
I0204 16:28:13.679270  3298 net.cpp:454] fc7 <- fc6
I0204 16:28:13.679280  3298 net.cpp:411] fc7 -> fc7
I0204 16:28:13.680001  3298 net.cpp:150] Setting up fc7
I0204 16:28:13.680013  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.680018  3298 net.cpp:165] Memory required for data: 151159200
I0204 16:28:13.680029  3298 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.680037  3298 net.cpp:106] Creating Layer relu7
I0204 16:28:13.680044  3298 net.cpp:454] relu7 <- fc7
I0204 16:28:13.680055  3298 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.680064  3298 net.cpp:150] Setting up relu7
I0204 16:28:13.680071  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.680078  3298 net.cpp:165] Memory required for data: 151261600
I0204 16:28:13.680083  3298 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.680091  3298 net.cpp:106] Creating Layer drop7
I0204 16:28:13.680097  3298 net.cpp:454] drop7 <- fc7
I0204 16:28:13.680107  3298 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.680119  3298 net.cpp:150] Setting up drop7
I0204 16:28:13.680125  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.680130  3298 net.cpp:165] Memory required for data: 151364000
I0204 16:28:13.680136  3298 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.680150  3298 net.cpp:106] Creating Layer fc8
I0204 16:28:13.680163  3298 net.cpp:454] fc8 <- fc7
I0204 16:28:13.680177  3298 net.cpp:411] fc8 -> fc8
I0204 16:28:13.680200  3298 net.cpp:150] Setting up fc8
I0204 16:28:13.680208  3298 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.680213  3298 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.680222  3298 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.680233  3298 net.cpp:106] Creating Layer loss
I0204 16:28:13.680239  3298 net.cpp:454] loss <- fc8
I0204 16:28:13.680245  3298 net.cpp:454] loss <- label
I0204 16:28:13.680254  3298 net.cpp:411] loss -> loss
I0204 16:28:13.680269  3298 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.680294  3298 net.cpp:150] Setting up loss
I0204 16:28:13.680305  3298 net.cpp:157] Top shape: (1)
I0204 16:28:13.680310  3298 net.cpp:160]     with loss weight 1
I0204 16:28:13.680337  3298 net.cpp:165] Memory required for data: 151364804
I0204 16:28:13.680346  3298 net.cpp:226] loss needs backward computation.
I0204 16:28:13.680352  3298 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.680357  3298 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.680363  3298 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.680368  3298 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.680374  3298 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.680380  3298 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.680385  3298 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.680392  3298 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.680397  3298 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.680402  3298 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.680408  3298 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.680414  3298 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.680419  3298 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.680425  3298 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.680436  3298 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.680443  3298 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.680449  3298 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.680454  3298 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.680461  3298 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.680467  3298 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.680474  3298 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.680480  3298 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.680486  3298 net.cpp:228] data does not need backward computation.
I0204 16:28:13.680492  3298 net.cpp:270] This network produces output loss
I0204 16:28:13.680519  3298 net.cpp:283] Network initialization done.
I0204 16:28:13.681291  3298 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/train_val.prototxt
I0204 16:28:13.681350  3298 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:28:13.681646  3298 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.681818  3298 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.681983  3298 net.cpp:106] Creating Layer data
I0204 16:28:13.682016  3298 net.cpp:411] data -> data
I0204 16:28:13.682031  3298 net.cpp:411] data -> label
I0204 16:28:13.682042  3298 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:28:13.682184  3316 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:28:13.682968  3298 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.729454  3298 net.cpp:150] Setting up data
I0204 16:28:13.729490  3298 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.729501  3298 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.729507  3298 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.729528  3298 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:28:13.729549  3298 net.cpp:106] Creating Layer label_data_1_split
I0204 16:28:13.729558  3298 net.cpp:454] label_data_1_split <- label
I0204 16:28:13.729570  3298 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:28:13.729588  3298 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:28:13.729604  3298 net.cpp:150] Setting up label_data_1_split
I0204 16:28:13.729614  3298 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.729621  3298 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.729629  3298 net.cpp:165] Memory required for data: 20612800
I0204 16:28:13.729636  3298 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.729655  3298 net.cpp:106] Creating Layer conv1
I0204 16:28:13.729663  3298 net.cpp:454] conv1 <- data
I0204 16:28:13.729673  3298 net.cpp:411] conv1 -> conv1
I0204 16:28:13.729751  3298 net.cpp:150] Setting up conv1
I0204 16:28:13.729765  3298 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.730132  3298 net.cpp:165] Memory required for data: 59332800
I0204 16:28:13.730154  3298 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.730167  3298 net.cpp:106] Creating Layer relu1
I0204 16:28:13.730176  3298 net.cpp:454] relu1 <- conv1
I0204 16:28:13.730187  3298 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.730200  3298 net.cpp:150] Setting up relu1
I0204 16:28:13.730208  3298 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.730216  3298 net.cpp:165] Memory required for data: 98052800
I0204 16:28:13.730222  3298 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.730234  3298 net.cpp:106] Creating Layer pool1
I0204 16:28:13.730240  3298 net.cpp:454] pool1 <- conv1
I0204 16:28:13.730249  3298 net.cpp:411] pool1 -> pool1
I0204 16:28:13.730265  3298 net.cpp:150] Setting up pool1
I0204 16:28:13.730275  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.730281  3298 net.cpp:165] Memory required for data: 107384000
I0204 16:28:13.730288  3298 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.730300  3298 net.cpp:106] Creating Layer norm1
I0204 16:28:13.730307  3298 net.cpp:454] norm1 <- pool1
I0204 16:28:13.730316  3298 net.cpp:411] norm1 -> norm1
I0204 16:28:13.730329  3298 net.cpp:150] Setting up norm1
I0204 16:28:13.730336  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.730341  3298 net.cpp:165] Memory required for data: 116715200
I0204 16:28:13.730348  3298 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.730360  3298 net.cpp:106] Creating Layer conv2
I0204 16:28:13.730367  3298 net.cpp:454] conv2 <- norm1
I0204 16:28:13.730377  3298 net.cpp:411] conv2 -> conv2
I0204 16:28:13.730525  3298 net.cpp:150] Setting up conv2
I0204 16:28:13.730535  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.730541  3298 net.cpp:165] Memory required for data: 126046400
I0204 16:28:13.730553  3298 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.730563  3298 net.cpp:106] Creating Layer relu2
I0204 16:28:13.730571  3298 net.cpp:454] relu2 <- conv2
I0204 16:28:13.730587  3298 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.730608  3298 net.cpp:150] Setting up relu2
I0204 16:28:13.741447  3298 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.741504  3298 net.cpp:165] Memory required for data: 135377600
I0204 16:28:13.741520  3298 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.741554  3298 net.cpp:106] Creating Layer pool2
I0204 16:28:13.741564  3298 net.cpp:454] pool2 <- conv2
I0204 16:28:13.741580  3298 net.cpp:411] pool2 -> pool2
I0204 16:28:13.741608  3298 net.cpp:150] Setting up pool2
I0204 16:28:13.741618  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.741623  3298 net.cpp:165] Memory required for data: 137540800
I0204 16:28:13.741629  3298 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.741641  3298 net.cpp:106] Creating Layer norm2
I0204 16:28:13.741647  3298 net.cpp:454] norm2 <- pool2
I0204 16:28:13.741657  3298 net.cpp:411] norm2 -> norm2
I0204 16:28:13.741668  3298 net.cpp:150] Setting up norm2
I0204 16:28:13.741677  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.741682  3298 net.cpp:165] Memory required for data: 139704000
I0204 16:28:13.741688  3298 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.741714  3298 net.cpp:106] Creating Layer conv3
I0204 16:28:13.741722  3298 net.cpp:454] conv3 <- norm2
I0204 16:28:13.741734  3298 net.cpp:411] conv3 -> conv3
I0204 16:28:13.741848  3298 net.cpp:150] Setting up conv3
I0204 16:28:13.741859  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.741864  3298 net.cpp:165] Memory required for data: 141867200
I0204 16:28:13.741878  3298 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.741889  3298 net.cpp:106] Creating Layer relu3
I0204 16:28:13.741896  3298 net.cpp:454] relu3 <- conv3
I0204 16:28:13.741904  3298 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.741915  3298 net.cpp:150] Setting up relu3
I0204 16:28:13.741931  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.741936  3298 net.cpp:165] Memory required for data: 144030400
I0204 16:28:13.741943  3298 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.741955  3298 net.cpp:106] Creating Layer conv4
I0204 16:28:13.741961  3298 net.cpp:454] conv4 <- conv3
I0204 16:28:13.741971  3298 net.cpp:411] conv4 -> conv4
I0204 16:28:13.742033  3298 net.cpp:150] Setting up conv4
I0204 16:28:13.742043  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.742048  3298 net.cpp:165] Memory required for data: 146193600
I0204 16:28:13.742058  3298 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.742066  3298 net.cpp:106] Creating Layer relu4
I0204 16:28:13.742074  3298 net.cpp:454] relu4 <- conv4
I0204 16:28:13.742081  3298 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.742090  3298 net.cpp:150] Setting up relu4
I0204 16:28:13.742099  3298 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.742103  3298 net.cpp:165] Memory required for data: 148356800
I0204 16:28:13.742110  3298 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.742121  3298 net.cpp:106] Creating Layer conv5
I0204 16:28:13.742127  3298 net.cpp:454] conv5 <- conv4
I0204 16:28:13.742137  3298 net.cpp:411] conv5 -> conv5
I0204 16:28:13.742178  3298 net.cpp:150] Setting up conv5
I0204 16:28:13.742188  3298 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.742193  3298 net.cpp:165] Memory required for data: 149438400
I0204 16:28:13.742233  3298 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.742245  3298 net.cpp:106] Creating Layer relu5
I0204 16:28:13.742252  3298 net.cpp:454] relu5 <- conv5
I0204 16:28:13.742260  3298 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.742270  3298 net.cpp:150] Setting up relu5
I0204 16:28:13.742277  3298 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.742283  3298 net.cpp:165] Memory required for data: 150520000
I0204 16:28:13.742288  3298 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.742300  3298 net.cpp:106] Creating Layer pool5
I0204 16:28:13.742306  3298 net.cpp:454] pool5 <- conv5
I0204 16:28:13.742336  3298 net.cpp:411] pool5 -> pool5
I0204 16:28:13.742349  3298 net.cpp:150] Setting up pool5
I0204 16:28:13.742357  3298 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.742362  3298 net.cpp:165] Memory required for data: 150750400
I0204 16:28:13.742367  3298 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.742380  3298 net.cpp:106] Creating Layer fc6
I0204 16:28:13.742386  3298 net.cpp:454] fc6 <- pool5
I0204 16:28:13.742403  3298 net.cpp:411] fc6 -> fc6
I0204 16:28:13.744403  3298 net.cpp:150] Setting up fc6
I0204 16:28:13.744431  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.744437  3298 net.cpp:165] Memory required for data: 150852800
I0204 16:28:13.744449  3298 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.744463  3298 net.cpp:106] Creating Layer relu6
I0204 16:28:13.744472  3298 net.cpp:454] relu6 <- fc6
I0204 16:28:13.744482  3298 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.744493  3298 net.cpp:150] Setting up relu6
I0204 16:28:13.744500  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.744506  3298 net.cpp:165] Memory required for data: 150955200
I0204 16:28:13.744514  3298 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.744525  3298 net.cpp:106] Creating Layer drop6
I0204 16:28:13.744531  3298 net.cpp:454] drop6 <- fc6
I0204 16:28:13.744540  3298 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.744552  3298 net.cpp:150] Setting up drop6
I0204 16:28:13.744560  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.744565  3298 net.cpp:165] Memory required for data: 151057600
I0204 16:28:13.744572  3298 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.744585  3298 net.cpp:106] Creating Layer fc7
I0204 16:28:13.744592  3298 net.cpp:454] fc7 <- fc6
I0204 16:28:13.744601  3298 net.cpp:411] fc7 -> fc7
I0204 16:28:13.745920  3298 net.cpp:150] Setting up fc7
I0204 16:28:13.745939  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.745960  3298 net.cpp:165] Memory required for data: 151160000
I0204 16:28:13.745971  3298 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.745986  3298 net.cpp:106] Creating Layer relu7
I0204 16:28:13.745993  3298 net.cpp:454] relu7 <- fc7
I0204 16:28:13.746001  3298 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.746012  3298 net.cpp:150] Setting up relu7
I0204 16:28:13.746021  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.746026  3298 net.cpp:165] Memory required for data: 151262400
I0204 16:28:13.746031  3298 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.746040  3298 net.cpp:106] Creating Layer drop7
I0204 16:28:13.746047  3298 net.cpp:454] drop7 <- fc7
I0204 16:28:13.746057  3298 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.746073  3298 net.cpp:150] Setting up drop7
I0204 16:28:13.746079  3298 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.746084  3298 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.746091  3298 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.746103  3298 net.cpp:106] Creating Layer fc8
I0204 16:28:13.746109  3298 net.cpp:454] fc8 <- fc7
I0204 16:28:13.746119  3298 net.cpp:411] fc8 -> fc8
I0204 16:28:13.746148  3298 net.cpp:150] Setting up fc8
I0204 16:28:13.746160  3298 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.746167  3298 net.cpp:165] Memory required for data: 151365600
I0204 16:28:13.746176  3298 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:28:13.746186  3298 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:28:13.746191  3298 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:28:13.746198  3298 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:28:13.746207  3298 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:28:13.746220  3298 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:28:13.746227  3298 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.746234  3298 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.746239  3298 net.cpp:165] Memory required for data: 151367200
I0204 16:28:13.746244  3298 layer_factory.hpp:77] Creating layer accuracy
I0204 16:28:13.746280  3298 net.cpp:106] Creating Layer accuracy
I0204 16:28:13.746287  3298 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:28:13.746295  3298 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:28:13.746305  3298 net.cpp:411] accuracy -> accuracy
I0204 16:28:13.746318  3298 net.cpp:150] Setting up accuracy
I0204 16:28:13.746325  3298 net.cpp:157] Top shape: (1)
I0204 16:28:13.746330  3298 net.cpp:165] Memory required for data: 151367204
I0204 16:28:13.746336  3298 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.746346  3298 net.cpp:106] Creating Layer loss
I0204 16:28:13.746354  3298 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:28:13.746361  3298 net.cpp:454] loss <- label_data_1_split_1
I0204 16:28:13.746369  3298 net.cpp:411] loss -> loss
I0204 16:28:13.746381  3298 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.746402  3298 net.cpp:150] Setting up loss
I0204 16:28:13.746409  3298 net.cpp:157] Top shape: (1)
I0204 16:28:13.746414  3298 net.cpp:160]     with loss weight 1
I0204 16:28:13.746430  3298 net.cpp:165] Memory required for data: 151367208
I0204 16:28:13.746436  3298 net.cpp:226] loss needs backward computation.
I0204 16:28:13.746445  3298 net.cpp:228] accuracy does not need backward computation.
I0204 16:28:13.746453  3298 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:28:13.746459  3298 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.746466  3298 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.746472  3298 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.746477  3298 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.746484  3298 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.746490  3298 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.746495  3298 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.746500  3298 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.746506  3298 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.746513  3298 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.746518  3298 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.746526  3298 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.746531  3298 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.746539  3298 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.746546  3298 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.746553  3298 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.746559  3298 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.746565  3298 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.746572  3298 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.746578  3298 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.746584  3298 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.746590  3298 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.746598  3298 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:28:13.746605  3298 net.cpp:228] data does not need backward computation.
I0204 16:28:13.746610  3298 net.cpp:270] This network produces output accuracy
I0204 16:28:13.746618  3298 net.cpp:270] This network produces output loss
I0204 16:28:13.747380  3298 net.cpp:283] Network initialization done.
I0204 16:28:13.747501  3298 solver.cpp:60] Solver scaffolding done.
I0204 16:28:13.747562  3298 caffe.cpp:212] Starting Optimization
I0204 16:28:13.747570  3298 solver.cpp:288] Solving CaffeNet
I0204 16:28:13.747575  3298 solver.cpp:289] Learning Rate Policy: step
I0204 16:28:13.748356  3298 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:28:13.748491  3298 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:28:21.837189  3298 solver.cpp:409]     Test net output #0: accuracy = 0.501
I0204 16:28:21.837260  3298 solver.cpp:409]     Test net output #1: loss = 5.15947 (* 1 = 5.15947 loss)
I0204 16:28:23.624164  3298 solver.cpp:237] Iteration 0, loss = 6.68459
I0204 16:28:23.624239  3298 solver.cpp:253]     Train net output #0: loss = 6.68459 (* 1 = 6.68459 loss)
I0204 16:28:23.624266  3298 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:28:44.067625  3298 solver.cpp:237] Iteration 10, loss = 1.30724
I0204 16:28:44.067924  3298 solver.cpp:253]     Train net output #0: loss = 1.30724 (* 1 = 1.30724 loss)
I0204 16:28:44.067939  3298 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:29:07.855953  3298 solver.cpp:237] Iteration 20, loss = 1.02692
I0204 16:29:07.856027  3298 solver.cpp:253]     Train net output #0: loss = 1.02692 (* 1 = 1.02692 loss)
I0204 16:29:07.856041  3298 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:29:29.834238  3298 solver.cpp:237] Iteration 30, loss = 0.822663
I0204 16:29:29.834358  3298 solver.cpp:253]     Train net output #0: loss = 0.822663 (* 1 = 0.822663 loss)
I0204 16:29:29.834373  3298 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:29:51.641574  3298 solver.cpp:237] Iteration 40, loss = 0.850336
I0204 16:29:51.641650  3298 solver.cpp:253]     Train net output #0: loss = 0.850336 (* 1 = 0.850336 loss)
I0204 16:29:51.641664  3298 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:30:14.132733  3298 solver.cpp:237] Iteration 50, loss = 0.735921
I0204 16:30:14.132954  3298 solver.cpp:253]     Train net output #0: loss = 0.735921 (* 1 = 0.735921 loss)
I0204 16:30:14.132972  3298 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:30:37.062525  3298 solver.cpp:237] Iteration 60, loss = 0.875909
I0204 16:30:37.062580  3298 solver.cpp:253]     Train net output #0: loss = 0.875909 (* 1 = 0.875909 loss)
I0204 16:30:37.062593  3298 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:31:01.096004  3298 solver.cpp:237] Iteration 70, loss = 0.713104
I0204 16:31:01.096201  3298 solver.cpp:253]     Train net output #0: loss = 0.713104 (* 1 = 0.713104 loss)
I0204 16:31:01.096218  3298 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:31:25.008083  3298 solver.cpp:237] Iteration 80, loss = 0.653847
I0204 16:31:25.008134  3298 solver.cpp:253]     Train net output #0: loss = 0.653847 (* 1 = 0.653847 loss)
I0204 16:31:25.008147  3298 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:47.156147  3298 solver.cpp:237] Iteration 90, loss = 0.663505
I0204 16:31:47.156327  3298 solver.cpp:253]     Train net output #0: loss = 0.663505 (* 1 = 0.663505 loss)
I0204 16:31:47.156342  3298 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:32:06.997382  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_100.caffemodel
I0204 16:32:07.001194  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_100.solverstate
I0204 16:32:07.002926  3298 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:32:17.424794  3298 solver.cpp:409]     Test net output #0: accuracy = 0.821
I0204 16:32:17.424976  3298 solver.cpp:409]     Test net output #1: loss = 0.416475 (* 1 = 0.416475 loss)
I0204 16:32:19.659452  3298 solver.cpp:237] Iteration 100, loss = 0.447003
I0204 16:32:19.659512  3298 solver.cpp:253]     Train net output #0: loss = 0.447003 (* 1 = 0.447003 loss)
I0204 16:32:19.659523  3298 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:42.824983  3298 solver.cpp:237] Iteration 110, loss = 0.420021
I0204 16:32:42.825042  3298 solver.cpp:253]     Train net output #0: loss = 0.420021 (* 1 = 0.420021 loss)
I0204 16:32:42.825053  3298 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:33:06.991478  3298 solver.cpp:237] Iteration 120, loss = 0.344578
I0204 16:33:06.995029  3298 solver.cpp:253]     Train net output #0: loss = 0.344578 (* 1 = 0.344578 loss)
I0204 16:33:06.995048  3298 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:33:31.940837  3298 solver.cpp:237] Iteration 130, loss = 0.264868
I0204 16:33:31.940892  3298 solver.cpp:253]     Train net output #0: loss = 0.264868 (* 1 = 0.264868 loss)
I0204 16:33:31.940915  3298 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:33:58.388586  3298 solver.cpp:237] Iteration 140, loss = 0.280322
I0204 16:33:58.388761  3298 solver.cpp:253]     Train net output #0: loss = 0.280322 (* 1 = 0.280322 loss)
I0204 16:33:58.388775  3298 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:34:25.579190  3298 solver.cpp:237] Iteration 150, loss = 0.198433
I0204 16:34:25.579244  3298 solver.cpp:253]     Train net output #0: loss = 0.198433 (* 1 = 0.198433 loss)
I0204 16:34:25.579257  3298 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:34:53.134230  3298 solver.cpp:237] Iteration 160, loss = 0.170304
I0204 16:34:53.134351  3298 solver.cpp:253]     Train net output #0: loss = 0.170304 (* 1 = 0.170304 loss)
I0204 16:34:53.134366  3298 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:35:20.840068  3298 solver.cpp:237] Iteration 170, loss = 0.137693
I0204 16:35:20.840118  3298 solver.cpp:253]     Train net output #0: loss = 0.137693 (* 1 = 0.137693 loss)
I0204 16:35:20.840129  3298 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:35:48.670418  3298 solver.cpp:237] Iteration 180, loss = 0.0976735
I0204 16:35:48.670578  3298 solver.cpp:253]     Train net output #0: loss = 0.0976735 (* 1 = 0.0976735 loss)
I0204 16:35:48.670593  3298 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:36:16.213832  3298 solver.cpp:237] Iteration 190, loss = 0.122075
I0204 16:36:16.213886  3298 solver.cpp:253]     Train net output #0: loss = 0.122075 (* 1 = 0.122075 loss)
I0204 16:36:16.213909  3298 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:36:41.343010  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_200.caffemodel
I0204 16:36:41.346912  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_200.solverstate
I0204 16:36:41.348438  3298 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:36:54.038395  3298 solver.cpp:409]     Test net output #0: accuracy = 0.986
I0204 16:36:54.038461  3298 solver.cpp:409]     Test net output #1: loss = 0.0460825 (* 1 = 0.0460825 loss)
I0204 16:36:56.721570  3298 solver.cpp:237] Iteration 200, loss = 0.0522892
I0204 16:36:56.721642  3298 solver.cpp:253]     Train net output #0: loss = 0.0522892 (* 1 = 0.0522892 loss)
I0204 16:36:56.721667  3298 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:37:23.701306  3298 solver.cpp:237] Iteration 210, loss = 0.0564867
I0204 16:37:23.701499  3298 solver.cpp:253]     Train net output #0: loss = 0.0564867 (* 1 = 0.0564867 loss)
I0204 16:37:23.701514  3298 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:37:51.013212  3298 solver.cpp:237] Iteration 220, loss = 0.101439
I0204 16:37:51.013286  3298 solver.cpp:253]     Train net output #0: loss = 0.101439 (* 1 = 0.101439 loss)
I0204 16:37:51.013300  3298 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:38:17.834935  3298 solver.cpp:237] Iteration 230, loss = 0.0357119
I0204 16:38:17.835098  3298 solver.cpp:253]     Train net output #0: loss = 0.0357118 (* 1 = 0.0357118 loss)
I0204 16:38:17.835113  3298 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:38:44.259620  3298 solver.cpp:237] Iteration 240, loss = 0.0680169
I0204 16:38:44.259680  3298 solver.cpp:253]     Train net output #0: loss = 0.0680168 (* 1 = 0.0680168 loss)
I0204 16:38:44.259692  3298 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:39:10.943944  3298 solver.cpp:237] Iteration 250, loss = 0.113678
I0204 16:39:10.944109  3298 solver.cpp:253]     Train net output #0: loss = 0.113678 (* 1 = 0.113678 loss)
I0204 16:39:10.944123  3298 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:39:37.500478  3298 solver.cpp:237] Iteration 260, loss = 0.0752589
I0204 16:39:37.500532  3298 solver.cpp:253]     Train net output #0: loss = 0.0752588 (* 1 = 0.0752588 loss)
I0204 16:39:37.500556  3298 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:40:03.656349  3298 solver.cpp:237] Iteration 270, loss = 0.0604069
I0204 16:40:03.664258  3298 solver.cpp:253]     Train net output #0: loss = 0.0604068 (* 1 = 0.0604068 loss)
I0204 16:40:03.664291  3298 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:40:29.887490  3298 solver.cpp:237] Iteration 280, loss = 0.0279788
I0204 16:40:29.887548  3298 solver.cpp:253]     Train net output #0: loss = 0.0279788 (* 1 = 0.0279788 loss)
I0204 16:40:29.887562  3298 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:40:56.056447  3298 solver.cpp:237] Iteration 290, loss = 0.0100783
I0204 16:40:56.056622  3298 solver.cpp:253]     Train net output #0: loss = 0.0100783 (* 1 = 0.0100783 loss)
I0204 16:40:56.056637  3298 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:41:19.249398  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_300.caffemodel
I0204 16:41:19.253206  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_300.solverstate
I0204 16:41:19.254761  3298 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:41:31.421787  3298 solver.cpp:409]     Test net output #0: accuracy = 0.984
I0204 16:41:31.421960  3298 solver.cpp:409]     Test net output #1: loss = 0.0362923 (* 1 = 0.0362923 loss)
I0204 16:41:34.069393  3298 solver.cpp:237] Iteration 300, loss = 0.0228959
I0204 16:41:34.069449  3298 solver.cpp:253]     Train net output #0: loss = 0.0228959 (* 1 = 0.0228959 loss)
I0204 16:41:34.069460  3298 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:42:00.277902  3298 solver.cpp:237] Iteration 310, loss = 0.0120092
I0204 16:42:00.277957  3298 solver.cpp:253]     Train net output #0: loss = 0.0120092 (* 1 = 0.0120092 loss)
I0204 16:42:00.277969  3298 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:42:26.122786  3298 solver.cpp:237] Iteration 320, loss = 0.00952276
I0204 16:42:26.122937  3298 solver.cpp:253]     Train net output #0: loss = 0.00952274 (* 1 = 0.00952274 loss)
I0204 16:42:26.122951  3298 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:42:52.057683  3298 solver.cpp:237] Iteration 330, loss = 0.0098951
I0204 16:42:52.057741  3298 solver.cpp:253]     Train net output #0: loss = 0.00989508 (* 1 = 0.00989508 loss)
I0204 16:42:52.057754  3298 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:43:18.219262  3298 solver.cpp:237] Iteration 340, loss = 0.00431345
I0204 16:43:18.219437  3298 solver.cpp:253]     Train net output #0: loss = 0.00431343 (* 1 = 0.00431343 loss)
I0204 16:43:18.219451  3298 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:43:44.180438  3298 solver.cpp:237] Iteration 350, loss = 0.0240672
I0204 16:43:44.180493  3298 solver.cpp:253]     Train net output #0: loss = 0.0240672 (* 1 = 0.0240672 loss)
I0204 16:43:44.180505  3298 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:44:09.888053  3298 solver.cpp:237] Iteration 360, loss = 0.050101
I0204 16:44:09.888224  3298 solver.cpp:253]     Train net output #0: loss = 0.050101 (* 1 = 0.050101 loss)
I0204 16:44:09.888237  3298 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:44:35.451700  3298 solver.cpp:237] Iteration 370, loss = 0.0873947
I0204 16:44:35.451756  3298 solver.cpp:253]     Train net output #0: loss = 0.0873946 (* 1 = 0.0873946 loss)
I0204 16:44:35.451767  3298 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:45:00.804019  3298 solver.cpp:237] Iteration 380, loss = 0.00569221
I0204 16:45:00.804185  3298 solver.cpp:253]     Train net output #0: loss = 0.00569219 (* 1 = 0.00569219 loss)
I0204 16:45:00.804199  3298 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:45:26.324363  3298 solver.cpp:237] Iteration 390, loss = 0.00599843
I0204 16:45:26.324419  3298 solver.cpp:253]     Train net output #0: loss = 0.00599841 (* 1 = 0.00599841 loss)
I0204 16:45:26.324442  3298 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:45:49.194078  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_400.caffemodel
I0204 16:45:49.198523  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_400.solverstate
I0204 16:45:49.200248  3298 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:46:01.044811  3298 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 16:46:01.044867  3298 solver.cpp:409]     Test net output #1: loss = 0.00985064 (* 1 = 0.00985064 loss)
I0204 16:46:03.557940  3298 solver.cpp:237] Iteration 400, loss = 0.0305289
I0204 16:46:03.557989  3298 solver.cpp:253]     Train net output #0: loss = 0.0305289 (* 1 = 0.0305289 loss)
I0204 16:46:03.558001  3298 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:46:28.855142  3298 solver.cpp:237] Iteration 410, loss = 0.0102916
I0204 16:46:28.855289  3298 solver.cpp:253]     Train net output #0: loss = 0.0102916 (* 1 = 0.0102916 loss)
I0204 16:46:28.855303  3298 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:46:54.210150  3298 solver.cpp:237] Iteration 420, loss = 0.00273589
I0204 16:46:54.210202  3298 solver.cpp:253]     Train net output #0: loss = 0.00273589 (* 1 = 0.00273589 loss)
I0204 16:46:54.210214  3298 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:47:18.438673  3298 solver.cpp:237] Iteration 430, loss = 0.0025235
I0204 16:47:18.438815  3298 solver.cpp:253]     Train net output #0: loss = 0.00252349 (* 1 = 0.00252349 loss)
I0204 16:47:18.438828  3298 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:47:42.535295  3298 solver.cpp:237] Iteration 440, loss = 0.000996531
I0204 16:47:42.535349  3298 solver.cpp:253]     Train net output #0: loss = 0.000996518 (* 1 = 0.000996518 loss)
I0204 16:47:42.535362  3298 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:48:06.136057  3298 solver.cpp:237] Iteration 450, loss = 0.00552968
I0204 16:48:06.136227  3298 solver.cpp:253]     Train net output #0: loss = 0.00552967 (* 1 = 0.00552967 loss)
I0204 16:48:06.136240  3298 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:48:29.624116  3298 solver.cpp:237] Iteration 460, loss = 0.00394164
I0204 16:48:29.624166  3298 solver.cpp:253]     Train net output #0: loss = 0.00394163 (* 1 = 0.00394163 loss)
I0204 16:48:29.624177  3298 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:48:53.160861  3298 solver.cpp:237] Iteration 470, loss = 0.00428945
I0204 16:48:53.161032  3298 solver.cpp:253]     Train net output #0: loss = 0.00428944 (* 1 = 0.00428944 loss)
I0204 16:48:53.161046  3298 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:49:17.003770  3298 solver.cpp:237] Iteration 480, loss = 0.0042498
I0204 16:49:17.003823  3298 solver.cpp:253]     Train net output #0: loss = 0.00424978 (* 1 = 0.00424978 loss)
I0204 16:49:17.003834  3298 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:49:40.705854  3298 solver.cpp:237] Iteration 490, loss = 0.0330635
I0204 16:49:40.706004  3298 solver.cpp:253]     Train net output #0: loss = 0.0330635 (* 1 = 0.0330635 loss)
I0204 16:49:40.706028  3298 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:50:02.131582  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_500.caffemodel
I0204 16:50:02.135217  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_500.solverstate
I0204 16:50:02.136708  3298 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:50:13.124459  3298 solver.cpp:409]     Test net output #0: accuracy = 0.99
I0204 16:50:13.124663  3298 solver.cpp:409]     Test net output #1: loss = 0.0257139 (* 1 = 0.0257139 loss)
I0204 16:50:15.464558  3298 solver.cpp:237] Iteration 500, loss = 0.120722
I0204 16:50:15.464609  3298 solver.cpp:253]     Train net output #0: loss = 0.120722 (* 1 = 0.120722 loss)
I0204 16:50:15.464622  3298 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:50:39.524368  3298 solver.cpp:237] Iteration 510, loss = 0.104384
I0204 16:50:39.524421  3298 solver.cpp:253]     Train net output #0: loss = 0.104384 (* 1 = 0.104384 loss)
I0204 16:50:39.524435  3298 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:51:03.619439  3298 solver.cpp:237] Iteration 520, loss = 0.0361359
I0204 16:51:03.619626  3298 solver.cpp:253]     Train net output #0: loss = 0.0361359 (* 1 = 0.0361359 loss)
I0204 16:51:03.619639  3298 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:51:26.840091  3298 solver.cpp:237] Iteration 530, loss = 0.00720822
I0204 16:51:26.840157  3298 solver.cpp:253]     Train net output #0: loss = 0.00720817 (* 1 = 0.00720817 loss)
I0204 16:51:26.840172  3298 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:51:50.073243  3298 solver.cpp:237] Iteration 540, loss = 0.0124506
I0204 16:51:50.073415  3298 solver.cpp:253]     Train net output #0: loss = 0.0124506 (* 1 = 0.0124506 loss)
I0204 16:51:50.073427  3298 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:52:13.566815  3298 solver.cpp:237] Iteration 550, loss = 0.00196543
I0204 16:52:13.566867  3298 solver.cpp:253]     Train net output #0: loss = 0.00196538 (* 1 = 0.00196538 loss)
I0204 16:52:13.566879  3298 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:52:36.948837  3298 solver.cpp:237] Iteration 560, loss = 0.00319902
I0204 16:52:36.949017  3298 solver.cpp:253]     Train net output #0: loss = 0.00319898 (* 1 = 0.00319898 loss)
I0204 16:52:36.949030  3298 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:53:00.207361  3298 solver.cpp:237] Iteration 570, loss = 0.00264413
I0204 16:53:00.207429  3298 solver.cpp:253]     Train net output #0: loss = 0.00264409 (* 1 = 0.00264409 loss)
I0204 16:53:00.207442  3298 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:53:23.748805  3298 solver.cpp:237] Iteration 580, loss = 0.00193162
I0204 16:53:23.748994  3298 solver.cpp:253]     Train net output #0: loss = 0.00193158 (* 1 = 0.00193158 loss)
I0204 16:53:23.749007  3298 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:53:47.040762  3298 solver.cpp:237] Iteration 590, loss = 0.0783478
I0204 16:53:47.040815  3298 solver.cpp:253]     Train net output #0: loss = 0.0783477 (* 1 = 0.0783477 loss)
I0204 16:53:47.040827  3298 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:54:07.978549  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_600.caffemodel
I0204 16:54:07.982352  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_600.solverstate
I0204 16:54:07.983882  3298 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:54:18.925528  3298 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 16:54:18.925575  3298 solver.cpp:409]     Test net output #1: loss = 0.00110218 (* 1 = 0.00110218 loss)
I0204 16:54:21.242054  3298 solver.cpp:237] Iteration 600, loss = 0.00740987
I0204 16:54:21.242100  3298 solver.cpp:253]     Train net output #0: loss = 0.00740982 (* 1 = 0.00740982 loss)
I0204 16:54:21.242110  3298 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:54:44.601631  3298 solver.cpp:237] Iteration 610, loss = 0.00751521
I0204 16:54:44.601809  3298 solver.cpp:253]     Train net output #0: loss = 0.00751517 (* 1 = 0.00751517 loss)
I0204 16:54:44.601822  3298 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:55:07.968955  3298 solver.cpp:237] Iteration 620, loss = 0.00108787
I0204 16:55:07.969007  3298 solver.cpp:253]     Train net output #0: loss = 0.00108782 (* 1 = 0.00108782 loss)
I0204 16:55:07.969018  3298 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:55:31.229943  3298 solver.cpp:237] Iteration 630, loss = 0.00705441
I0204 16:55:31.230159  3298 solver.cpp:253]     Train net output #0: loss = 0.00705436 (* 1 = 0.00705436 loss)
I0204 16:55:31.230173  3298 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:55:54.394804  3298 solver.cpp:237] Iteration 640, loss = 0.0600637
I0204 16:55:54.394856  3298 solver.cpp:253]     Train net output #0: loss = 0.0600636 (* 1 = 0.0600636 loss)
I0204 16:55:54.394867  3298 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:56:17.025779  3298 solver.cpp:237] Iteration 650, loss = 0.00289173
I0204 16:56:17.025938  3298 solver.cpp:253]     Train net output #0: loss = 0.00289168 (* 1 = 0.00289168 loss)
I0204 16:56:17.025964  3298 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:56:39.784780  3298 solver.cpp:237] Iteration 660, loss = 0.0178198
I0204 16:56:39.784834  3298 solver.cpp:253]     Train net output #0: loss = 0.0178197 (* 1 = 0.0178197 loss)
I0204 16:56:39.784845  3298 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:57:02.316716  3298 solver.cpp:237] Iteration 670, loss = 0.00380005
I0204 16:57:02.316911  3298 solver.cpp:253]     Train net output #0: loss = 0.00379999 (* 1 = 0.00379999 loss)
I0204 16:57:02.316923  3298 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:57:24.772614  3298 solver.cpp:237] Iteration 680, loss = 0.00178765
I0204 16:57:24.772680  3298 solver.cpp:253]     Train net output #0: loss = 0.00178759 (* 1 = 0.00178759 loss)
I0204 16:57:24.772691  3298 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:57:47.319634  3298 solver.cpp:237] Iteration 690, loss = 0.0234202
I0204 16:57:47.319795  3298 solver.cpp:253]     Train net output #0: loss = 0.0234201 (* 1 = 0.0234201 loss)
I0204 16:57:47.319808  3298 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:58:07.424615  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_700.caffemodel
I0204 16:58:07.428346  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_700.solverstate
I0204 16:58:07.429746  3298 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:58:17.841033  3298 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:58:17.841190  3298 solver.cpp:409]     Test net output #1: loss = 0.00388147 (* 1 = 0.00388147 loss)
I0204 16:58:20.130393  3298 solver.cpp:237] Iteration 700, loss = 0.000838459
I0204 16:58:20.130446  3298 solver.cpp:253]     Train net output #0: loss = 0.000838403 (* 1 = 0.000838403 loss)
I0204 16:58:20.130457  3298 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:58:42.551453  3298 solver.cpp:237] Iteration 710, loss = 0.0211134
I0204 16:58:42.551503  3298 solver.cpp:253]     Train net output #0: loss = 0.0211134 (* 1 = 0.0211134 loss)
I0204 16:58:42.551514  3298 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:59:04.952839  3298 solver.cpp:237] Iteration 720, loss = 0.00158885
I0204 16:59:04.953014  3298 solver.cpp:253]     Train net output #0: loss = 0.0015888 (* 1 = 0.0015888 loss)
I0204 16:59:04.953027  3298 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:59:27.451828  3298 solver.cpp:237] Iteration 730, loss = 0.084872
I0204 16:59:27.451877  3298 solver.cpp:253]     Train net output #0: loss = 0.084872 (* 1 = 0.084872 loss)
I0204 16:59:27.451889  3298 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:59:49.877959  3298 solver.cpp:237] Iteration 740, loss = 0.114001
I0204 16:59:49.878129  3298 solver.cpp:253]     Train net output #0: loss = 0.114001 (* 1 = 0.114001 loss)
I0204 16:59:49.878141  3298 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 17:00:12.259959  3298 solver.cpp:237] Iteration 750, loss = 0.01086
I0204 17:00:12.260011  3298 solver.cpp:253]     Train net output #0: loss = 0.0108599 (* 1 = 0.0108599 loss)
I0204 17:00:12.260022  3298 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 17:00:34.549702  3298 solver.cpp:237] Iteration 760, loss = 0.0501204
I0204 17:00:34.549917  3298 solver.cpp:253]     Train net output #0: loss = 0.0501203 (* 1 = 0.0501203 loss)
I0204 17:00:34.549933  3298 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 17:00:56.642120  3298 solver.cpp:237] Iteration 770, loss = 0.00477523
I0204 17:00:56.642158  3298 solver.cpp:253]     Train net output #0: loss = 0.00477516 (* 1 = 0.00477516 loss)
I0204 17:00:56.642168  3298 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 17:01:19.124261  3298 solver.cpp:237] Iteration 780, loss = 0.0052857
I0204 17:01:19.124444  3298 solver.cpp:253]     Train net output #0: loss = 0.00528562 (* 1 = 0.00528562 loss)
I0204 17:01:19.124459  3298 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 17:01:41.725836  3298 solver.cpp:237] Iteration 790, loss = 0.00751125
I0204 17:01:41.725888  3298 solver.cpp:253]     Train net output #0: loss = 0.00751117 (* 1 = 0.00751117 loss)
I0204 17:01:41.725899  3298 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 17:02:02.140846  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_800.caffemodel
I0204 17:02:02.144670  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_800.solverstate
I0204 17:02:02.146172  3298 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 17:02:12.662967  3298 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:02:12.663018  3298 solver.cpp:409]     Test net output #1: loss = 0.00446222 (* 1 = 0.00446222 loss)
I0204 17:02:14.919332  3298 solver.cpp:237] Iteration 800, loss = 0.00103993
I0204 17:02:15.031394  3298 solver.cpp:253]     Train net output #0: loss = 0.00103986 (* 1 = 0.00103986 loss)
I0204 17:02:15.031438  3298 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 17:02:37.918807  3298 solver.cpp:237] Iteration 810, loss = 0.000713816
I0204 17:02:37.918994  3298 solver.cpp:253]     Train net output #0: loss = 0.000713742 (* 1 = 0.000713742 loss)
I0204 17:02:37.919011  3298 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 17:03:00.567466  3298 solver.cpp:237] Iteration 820, loss = 0.00086682
I0204 17:03:00.567531  3298 solver.cpp:253]     Train net output #0: loss = 0.000866746 (* 1 = 0.000866746 loss)
I0204 17:03:00.567589  3298 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 17:03:22.708137  3298 solver.cpp:237] Iteration 830, loss = 0.00487158
I0204 17:03:22.708302  3298 solver.cpp:253]     Train net output #0: loss = 0.00487151 (* 1 = 0.00487151 loss)
I0204 17:03:22.708314  3298 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 17:03:46.008765  3298 solver.cpp:237] Iteration 840, loss = 0.0042776
I0204 17:03:46.008822  3298 solver.cpp:253]     Train net output #0: loss = 0.00427753 (* 1 = 0.00427753 loss)
I0204 17:03:46.008833  3298 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 17:04:09.215036  3298 solver.cpp:237] Iteration 850, loss = 0.00396761
I0204 17:04:09.215216  3298 solver.cpp:253]     Train net output #0: loss = 0.00396753 (* 1 = 0.00396753 loss)
I0204 17:04:09.215229  3298 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 17:04:32.347903  3298 solver.cpp:237] Iteration 860, loss = 0.0018258
I0204 17:04:32.347957  3298 solver.cpp:253]     Train net output #0: loss = 0.00182573 (* 1 = 0.00182573 loss)
I0204 17:04:32.347968  3298 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 17:04:55.571933  3298 solver.cpp:237] Iteration 870, loss = 0.000730521
I0204 17:04:55.572118  3298 solver.cpp:253]     Train net output #0: loss = 0.000730446 (* 1 = 0.000730446 loss)
I0204 17:04:55.572130  3298 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 17:05:18.759138  3298 solver.cpp:237] Iteration 880, loss = 0.000599787
I0204 17:05:18.759191  3298 solver.cpp:253]     Train net output #0: loss = 0.000599712 (* 1 = 0.000599712 loss)
I0204 17:05:18.759219  3298 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 17:05:41.971498  3298 solver.cpp:237] Iteration 890, loss = 0.00116124
I0204 17:05:41.971705  3298 solver.cpp:253]     Train net output #0: loss = 0.00116117 (* 1 = 0.00116117 loss)
I0204 17:05:41.971719  3298 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 17:06:02.863077  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_900.caffemodel
I0204 17:06:02.867025  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_900.solverstate
I0204 17:06:02.868713  3298 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 17:06:13.801498  3298 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:06:13.801686  3298 solver.cpp:409]     Test net output #1: loss = 0.00237037 (* 1 = 0.00237037 loss)
I0204 17:06:16.109145  3298 solver.cpp:237] Iteration 900, loss = 0.00556386
I0204 17:06:16.109197  3298 solver.cpp:253]     Train net output #0: loss = 0.00556378 (* 1 = 0.00556378 loss)
I0204 17:06:16.109208  3298 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 17:06:39.106238  3298 solver.cpp:237] Iteration 910, loss = 0.00205722
I0204 17:06:39.106292  3298 solver.cpp:253]     Train net output #0: loss = 0.00205715 (* 1 = 0.00205715 loss)
I0204 17:06:39.106302  3298 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 17:07:02.055126  3298 solver.cpp:237] Iteration 920, loss = 0.000666482
I0204 17:07:02.055299  3298 solver.cpp:253]     Train net output #0: loss = 0.000666405 (* 1 = 0.000666405 loss)
I0204 17:07:02.055313  3298 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 17:07:24.925362  3298 solver.cpp:237] Iteration 930, loss = 0.00233032
I0204 17:07:24.925415  3298 solver.cpp:253]     Train net output #0: loss = 0.00233024 (* 1 = 0.00233024 loss)
I0204 17:07:24.925426  3298 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 17:07:47.608492  3298 solver.cpp:237] Iteration 940, loss = 0.000663275
I0204 17:07:47.608687  3298 solver.cpp:253]     Train net output #0: loss = 0.000663198 (* 1 = 0.000663198 loss)
I0204 17:07:47.608700  3298 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 17:08:10.714610  3298 solver.cpp:237] Iteration 950, loss = 0.0111205
I0204 17:08:10.714661  3298 solver.cpp:253]     Train net output #0: loss = 0.0111205 (* 1 = 0.0111205 loss)
I0204 17:08:10.714673  3298 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 17:08:33.881875  3298 solver.cpp:237] Iteration 960, loss = 0.00329463
I0204 17:08:33.882053  3298 solver.cpp:253]     Train net output #0: loss = 0.00329455 (* 1 = 0.00329455 loss)
I0204 17:08:33.882066  3298 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 17:08:57.027642  3298 solver.cpp:237] Iteration 970, loss = 0.0079819
I0204 17:08:57.027693  3298 solver.cpp:253]     Train net output #0: loss = 0.00798183 (* 1 = 0.00798183 loss)
I0204 17:08:57.027704  3298 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 17:09:19.467995  3298 solver.cpp:237] Iteration 980, loss = 0.00425516
I0204 17:09:19.468171  3298 solver.cpp:253]     Train net output #0: loss = 0.00425508 (* 1 = 0.00425508 loss)
I0204 17:09:19.468183  3298 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 17:09:42.062145  3298 solver.cpp:237] Iteration 990, loss = 0.00155692
I0204 17:09:42.062198  3298 solver.cpp:253]     Train net output #0: loss = 0.00155684 (* 1 = 0.00155684 loss)
I0204 17:09:42.062209  3298 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 17:10:01.927533  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1000.caffemodel
I0204 17:10:01.931759  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1000.solverstate
I0204 17:10:01.933555  3298 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 17:10:12.300670  3298 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:10:12.300715  3298 solver.cpp:409]     Test net output #1: loss = 0.00139268 (* 1 = 0.00139268 loss)
I0204 17:10:14.504195  3298 solver.cpp:237] Iteration 1000, loss = 0.00148282
I0204 17:10:14.504240  3298 solver.cpp:253]     Train net output #0: loss = 0.00148273 (* 1 = 0.00148273 loss)
I0204 17:10:14.504250  3298 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 17:10:36.311822  3298 solver.cpp:237] Iteration 1010, loss = 0.00404074
I0204 17:10:36.312033  3298 solver.cpp:253]     Train net output #0: loss = 0.00404066 (* 1 = 0.00404066 loss)
I0204 17:10:36.312047  3298 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 17:10:59.016667  3298 solver.cpp:237] Iteration 1020, loss = 0.000773438
I0204 17:10:59.016721  3298 solver.cpp:253]     Train net output #0: loss = 0.000773357 (* 1 = 0.000773357 loss)
I0204 17:10:59.016732  3298 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 17:11:21.652108  3298 solver.cpp:237] Iteration 1030, loss = 0.000945527
I0204 17:11:21.652293  3298 solver.cpp:253]     Train net output #0: loss = 0.000945446 (* 1 = 0.000945446 loss)
I0204 17:11:21.652305  3298 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 17:11:44.806762  3298 solver.cpp:237] Iteration 1040, loss = 0.000473563
I0204 17:11:44.806813  3298 solver.cpp:253]     Train net output #0: loss = 0.000473481 (* 1 = 0.000473481 loss)
I0204 17:11:44.806823  3298 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 17:12:07.006685  3298 solver.cpp:237] Iteration 1050, loss = 0.0753822
I0204 17:12:07.006870  3298 solver.cpp:253]     Train net output #0: loss = 0.0753821 (* 1 = 0.0753821 loss)
I0204 17:12:07.006883  3298 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 17:12:28.726908  3298 solver.cpp:237] Iteration 1060, loss = 0.00136335
I0204 17:12:28.726954  3298 solver.cpp:253]     Train net output #0: loss = 0.00136327 (* 1 = 0.00136327 loss)
I0204 17:12:28.726971  3298 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 17:12:50.479159  3298 solver.cpp:237] Iteration 1070, loss = 0.00303405
I0204 17:12:50.479341  3298 solver.cpp:253]     Train net output #0: loss = 0.00303397 (* 1 = 0.00303397 loss)
I0204 17:12:50.479353  3298 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 17:13:12.239388  3298 solver.cpp:237] Iteration 1080, loss = 0.00044879
I0204 17:13:12.239440  3298 solver.cpp:253]     Train net output #0: loss = 0.000448708 (* 1 = 0.000448708 loss)
I0204 17:13:12.239450  3298 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 17:13:33.796675  3298 solver.cpp:237] Iteration 1090, loss = 0.00338418
I0204 17:13:33.796860  3298 solver.cpp:253]     Train net output #0: loss = 0.0033841 (* 1 = 0.0033841 loss)
I0204 17:13:33.796874  3298 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 17:13:53.282677  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1100.caffemodel
I0204 17:13:53.286391  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1100.solverstate
I0204 17:13:53.287920  3298 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 17:14:03.768023  3298 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 17:14:03.768070  3298 solver.cpp:409]     Test net output #1: loss = 0.00114557 (* 1 = 0.00114557 loss)
I0204 17:14:05.943625  3298 solver.cpp:237] Iteration 1100, loss = 0.000369161
I0204 17:14:05.943799  3298 solver.cpp:253]     Train net output #0: loss = 0.00036908 (* 1 = 0.00036908 loss)
I0204 17:14:05.943812  3298 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 17:14:27.547729  3298 solver.cpp:237] Iteration 1110, loss = 0.000654561
I0204 17:14:27.547777  3298 solver.cpp:253]     Train net output #0: loss = 0.00065448 (* 1 = 0.00065448 loss)
I0204 17:14:27.547799  3298 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 17:14:49.066370  3298 solver.cpp:237] Iteration 1120, loss = 0.00140446
I0204 17:14:49.066576  3298 solver.cpp:253]     Train net output #0: loss = 0.00140438 (* 1 = 0.00140438 loss)
I0204 17:14:49.066589  3298 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 17:15:12.084369  3298 solver.cpp:237] Iteration 1130, loss = 0.049941
I0204 17:15:12.084419  3298 solver.cpp:253]     Train net output #0: loss = 0.0499409 (* 1 = 0.0499409 loss)
I0204 17:15:12.084429  3298 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 17:15:35.332406  3298 solver.cpp:237] Iteration 1140, loss = 0.000353128
I0204 17:15:35.332610  3298 solver.cpp:253]     Train net output #0: loss = 0.000353048 (* 1 = 0.000353048 loss)
I0204 17:15:35.332623  3298 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 17:15:58.799978  3298 solver.cpp:237] Iteration 1150, loss = 0.0227949
I0204 17:15:58.800042  3298 solver.cpp:253]     Train net output #0: loss = 0.0227949 (* 1 = 0.0227949 loss)
I0204 17:15:58.800055  3298 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 17:16:22.193133  3298 solver.cpp:237] Iteration 1160, loss = 0.00382522
I0204 17:16:22.193330  3298 solver.cpp:253]     Train net output #0: loss = 0.00382515 (* 1 = 0.00382515 loss)
I0204 17:16:22.193342  3298 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 17:16:45.706766  3298 solver.cpp:237] Iteration 1170, loss = 0.000324683
I0204 17:16:45.706818  3298 solver.cpp:253]     Train net output #0: loss = 0.000324606 (* 1 = 0.000324606 loss)
I0204 17:16:45.706828  3298 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 17:17:09.199251  3298 solver.cpp:237] Iteration 1180, loss = 0.000303963
I0204 17:17:09.199441  3298 solver.cpp:253]     Train net output #0: loss = 0.000303886 (* 1 = 0.000303886 loss)
I0204 17:17:09.199453  3298 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 17:17:32.557446  3298 solver.cpp:237] Iteration 1190, loss = 0.00241693
I0204 17:17:32.557497  3298 solver.cpp:253]     Train net output #0: loss = 0.00241685 (* 1 = 0.00241685 loss)
I0204 17:17:32.557507  3298 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 17:17:53.835942  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1200.caffemodel
I0204 17:17:53.839843  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1200.solverstate
I0204 17:17:53.841356  3298 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 17:18:04.888363  3298 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:18:04.888411  3298 solver.cpp:409]     Test net output #1: loss = 0.000926955 (* 1 = 0.000926955 loss)
I0204 17:18:07.262367  3298 solver.cpp:237] Iteration 1200, loss = 0.0040422
I0204 17:18:07.262414  3298 solver.cpp:253]     Train net output #0: loss = 0.00404212 (* 1 = 0.00404212 loss)
I0204 17:18:07.262425  3298 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 17:18:30.691102  3298 solver.cpp:237] Iteration 1210, loss = 0.00145822
I0204 17:18:30.691296  3298 solver.cpp:253]     Train net output #0: loss = 0.00145814 (* 1 = 0.00145814 loss)
I0204 17:18:30.691308  3298 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 17:18:54.256314  3298 solver.cpp:237] Iteration 1220, loss = 0.0016763
I0204 17:18:54.256366  3298 solver.cpp:253]     Train net output #0: loss = 0.00167623 (* 1 = 0.00167623 loss)
I0204 17:18:54.256376  3298 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 17:19:17.753468  3298 solver.cpp:237] Iteration 1230, loss = 0.00189068
I0204 17:19:17.753657  3298 solver.cpp:253]     Train net output #0: loss = 0.0018906 (* 1 = 0.0018906 loss)
I0204 17:19:17.753669  3298 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 17:19:41.105348  3298 solver.cpp:237] Iteration 1240, loss = 0.000601544
I0204 17:19:41.105417  3298 solver.cpp:253]     Train net output #0: loss = 0.000601467 (* 1 = 0.000601467 loss)
I0204 17:19:41.105427  3298 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 17:20:04.544780  3298 solver.cpp:237] Iteration 1250, loss = 0.000116155
I0204 17:20:04.544996  3298 solver.cpp:253]     Train net output #0: loss = 0.000116077 (* 1 = 0.000116077 loss)
I0204 17:20:04.545008  3298 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 17:20:27.975672  3298 solver.cpp:237] Iteration 1260, loss = 0.0012259
I0204 17:20:27.975724  3298 solver.cpp:253]     Train net output #0: loss = 0.00122583 (* 1 = 0.00122583 loss)
I0204 17:20:27.975736  3298 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 17:20:51.422150  3298 solver.cpp:237] Iteration 1270, loss = 0.000473238
I0204 17:20:51.422333  3298 solver.cpp:253]     Train net output #0: loss = 0.000473159 (* 1 = 0.000473159 loss)
I0204 17:20:51.422345  3298 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 17:21:15.082846  3298 solver.cpp:237] Iteration 1280, loss = 0.000589177
I0204 17:21:15.082897  3298 solver.cpp:253]     Train net output #0: loss = 0.000589097 (* 1 = 0.000589097 loss)
I0204 17:21:15.082907  3298 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 17:21:38.254750  3298 solver.cpp:237] Iteration 1290, loss = 0.000838362
I0204 17:21:38.254910  3298 solver.cpp:253]     Train net output #0: loss = 0.000838281 (* 1 = 0.000838281 loss)
I0204 17:21:38.254923  3298 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 17:21:59.800729  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1300.caffemodel
I0204 17:21:59.804464  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1300.solverstate
I0204 17:21:59.805982  3298 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 17:22:10.930465  3298 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:22:10.930670  3298 solver.cpp:409]     Test net output #1: loss = 0.00140156 (* 1 = 0.00140156 loss)
I0204 17:22:13.320143  3298 solver.cpp:237] Iteration 1300, loss = 0.00114207
I0204 17:22:13.320191  3298 solver.cpp:253]     Train net output #0: loss = 0.00114199 (* 1 = 0.00114199 loss)
I0204 17:22:13.320202  3298 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 17:22:37.126504  3298 solver.cpp:237] Iteration 1310, loss = 0.0035561
I0204 17:22:37.126554  3298 solver.cpp:253]     Train net output #0: loss = 0.00355601 (* 1 = 0.00355601 loss)
I0204 17:22:37.126564  3298 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 17:23:00.610131  3298 solver.cpp:237] Iteration 1320, loss = 0.000465887
I0204 17:23:00.610306  3298 solver.cpp:253]     Train net output #0: loss = 0.000465802 (* 1 = 0.000465802 loss)
I0204 17:23:00.610317  3298 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 17:23:24.152458  3298 solver.cpp:237] Iteration 1330, loss = 0.00187712
I0204 17:23:24.152513  3298 solver.cpp:253]     Train net output #0: loss = 0.00187703 (* 1 = 0.00187703 loss)
I0204 17:23:24.152524  3298 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 17:23:47.424157  3298 solver.cpp:237] Iteration 1340, loss = 0.000477891
I0204 17:23:47.424350  3298 solver.cpp:253]     Train net output #0: loss = 0.0004778 (* 1 = 0.0004778 loss)
I0204 17:23:47.424361  3298 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 17:24:10.837795  3298 solver.cpp:237] Iteration 1350, loss = 0.00280603
I0204 17:24:10.837846  3298 solver.cpp:253]     Train net output #0: loss = 0.00280594 (* 1 = 0.00280594 loss)
I0204 17:24:10.837857  3298 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 17:24:33.979830  3298 solver.cpp:237] Iteration 1360, loss = 0.0495742
I0204 17:24:33.979995  3298 solver.cpp:253]     Train net output #0: loss = 0.0495742 (* 1 = 0.0495742 loss)
I0204 17:24:33.980006  3298 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 17:24:56.039849  3298 solver.cpp:237] Iteration 1370, loss = 0.0101932
I0204 17:24:56.039911  3298 solver.cpp:253]     Train net output #0: loss = 0.0101931 (* 1 = 0.0101931 loss)
I0204 17:24:56.039921  3298 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 17:25:17.962252  3298 solver.cpp:237] Iteration 1380, loss = 0.00115029
I0204 17:25:17.962477  3298 solver.cpp:253]     Train net output #0: loss = 0.0011502 (* 1 = 0.0011502 loss)
I0204 17:25:17.962491  3298 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 17:25:39.735860  3298 solver.cpp:237] Iteration 1390, loss = 0.000780636
I0204 17:25:39.735909  3298 solver.cpp:253]     Train net output #0: loss = 0.000780549 (* 1 = 0.000780549 loss)
I0204 17:25:39.735920  3298 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 17:25:59.331287  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1400.caffemodel
I0204 17:25:59.334924  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1400.solverstate
I0204 17:25:59.336308  3298 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 17:26:09.696377  3298 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:26:09.696422  3298 solver.cpp:409]     Test net output #1: loss = 0.00254233 (* 1 = 0.00254233 loss)
I0204 17:26:11.846379  3298 solver.cpp:237] Iteration 1400, loss = 0.00205087
I0204 17:26:11.846434  3298 solver.cpp:253]     Train net output #0: loss = 0.00205079 (* 1 = 0.00205079 loss)
I0204 17:26:11.846446  3298 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 17:26:33.668308  3298 solver.cpp:237] Iteration 1410, loss = 0.00010284
I0204 17:26:33.668488  3298 solver.cpp:253]     Train net output #0: loss = 0.000102755 (* 1 = 0.000102755 loss)
I0204 17:26:33.668499  3298 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 17:26:55.468288  3298 solver.cpp:237] Iteration 1420, loss = 0.000227852
I0204 17:26:55.468336  3298 solver.cpp:253]     Train net output #0: loss = 0.000227767 (* 1 = 0.000227767 loss)
I0204 17:26:55.468346  3298 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 17:27:17.574749  3298 solver.cpp:237] Iteration 1430, loss = 0.000794403
I0204 17:27:17.574928  3298 solver.cpp:253]     Train net output #0: loss = 0.000794317 (* 1 = 0.000794317 loss)
I0204 17:27:17.574941  3298 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 17:27:39.834733  3298 solver.cpp:237] Iteration 1440, loss = 0.000133965
I0204 17:27:39.834796  3298 solver.cpp:253]     Train net output #0: loss = 0.000133882 (* 1 = 0.000133882 loss)
I0204 17:27:39.834821  3298 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 17:28:01.579107  3298 solver.cpp:237] Iteration 1450, loss = 0.00246075
I0204 17:28:01.579288  3298 solver.cpp:253]     Train net output #0: loss = 0.00246067 (* 1 = 0.00246067 loss)
I0204 17:28:01.579300  3298 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 17:28:23.103723  3298 solver.cpp:237] Iteration 1460, loss = 0.000296655
I0204 17:28:23.103771  3298 solver.cpp:253]     Train net output #0: loss = 0.000296572 (* 1 = 0.000296572 loss)
I0204 17:28:23.103781  3298 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 17:28:44.558183  3298 solver.cpp:237] Iteration 1470, loss = 0.000609802
I0204 17:28:44.558336  3298 solver.cpp:253]     Train net output #0: loss = 0.000609718 (* 1 = 0.000609718 loss)
I0204 17:28:44.558349  3298 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 17:29:06.013845  3298 solver.cpp:237] Iteration 1480, loss = 0.000292337
I0204 17:29:06.013897  3298 solver.cpp:253]     Train net output #0: loss = 0.000292252 (* 1 = 0.000292252 loss)
I0204 17:29:06.013908  3298 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 17:29:27.411603  3298 solver.cpp:237] Iteration 1490, loss = 0.000290337
I0204 17:29:27.411806  3298 solver.cpp:253]     Train net output #0: loss = 0.000290252 (* 1 = 0.000290252 loss)
I0204 17:29:27.411823  3298 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 17:29:46.593854  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1500.caffemodel
I0204 17:29:46.597228  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1500.solverstate
I0204 17:29:46.598574  3298 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 17:29:56.650926  3298 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 17:29:56.650974  3298 solver.cpp:409]     Test net output #1: loss = 0.000364226 (* 1 = 0.000364226 loss)
I0204 17:29:58.827733  3298 solver.cpp:237] Iteration 1500, loss = 0.000280661
I0204 17:29:58.827903  3298 solver.cpp:253]     Train net output #0: loss = 0.000280576 (* 1 = 0.000280576 loss)
I0204 17:29:58.827915  3298 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 17:30:20.383148  3298 solver.cpp:237] Iteration 1510, loss = 0.00138167
I0204 17:30:20.383198  3298 solver.cpp:253]     Train net output #0: loss = 0.00138159 (* 1 = 0.00138159 loss)
I0204 17:30:20.383208  3298 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 17:30:42.057873  3298 solver.cpp:237] Iteration 1520, loss = 0.0216172
I0204 17:30:42.058038  3298 solver.cpp:253]     Train net output #0: loss = 0.0216171 (* 1 = 0.0216171 loss)
I0204 17:30:42.058051  3298 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 17:31:03.601399  3298 solver.cpp:237] Iteration 1530, loss = 0.00131793
I0204 17:31:03.601452  3298 solver.cpp:253]     Train net output #0: loss = 0.00131785 (* 1 = 0.00131785 loss)
I0204 17:31:03.601464  3298 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 17:31:25.065795  3298 solver.cpp:237] Iteration 1540, loss = 0.130834
I0204 17:31:25.065979  3298 solver.cpp:253]     Train net output #0: loss = 0.130834 (* 1 = 0.130834 loss)
I0204 17:31:25.065991  3298 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 17:31:46.586736  3298 solver.cpp:237] Iteration 1550, loss = 0.00203807
I0204 17:31:46.586787  3298 solver.cpp:253]     Train net output #0: loss = 0.00203798 (* 1 = 0.00203798 loss)
I0204 17:31:46.586798  3298 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 17:32:08.112566  3298 solver.cpp:237] Iteration 1560, loss = 0.00771908
I0204 17:32:08.112736  3298 solver.cpp:253]     Train net output #0: loss = 0.007719 (* 1 = 0.007719 loss)
I0204 17:32:08.112749  3298 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 17:32:29.273139  3298 solver.cpp:237] Iteration 1570, loss = 0.0235524
I0204 17:32:29.273190  3298 solver.cpp:253]     Train net output #0: loss = 0.0235523 (* 1 = 0.0235523 loss)
I0204 17:32:29.273200  3298 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 17:32:50.509742  3298 solver.cpp:237] Iteration 1580, loss = 0.0374481
I0204 17:32:50.509894  3298 solver.cpp:253]     Train net output #0: loss = 0.037448 (* 1 = 0.037448 loss)
I0204 17:32:50.509907  3298 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 17:33:11.799041  3298 solver.cpp:237] Iteration 1590, loss = 0.00616248
I0204 17:33:11.799089  3298 solver.cpp:253]     Train net output #0: loss = 0.0061624 (* 1 = 0.0061624 loss)
I0204 17:33:11.799100  3298 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 17:33:30.906708  3298 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1600.caffemodel
I0204 17:33:30.910385  3298 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed2/snaps/snap__iter_1600.solverstate
I0204 17:33:31.914120  3298 solver.cpp:321] Iteration 1600, loss = 0.000549333
I0204 17:33:31.914154  3298 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 17:33:41.804064  3298 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:33:41.804124  3298 solver.cpp:409]     Test net output #1: loss = 0.00223189 (* 1 = 0.00223189 loss)
I0204 17:33:41.804131  3298 solver.cpp:326] Optimization Done.
I0204 17:33:41.804136  3298 caffe.cpp:215] Optimization Done.
