Log file created at: 2016/02/04 16:28:13
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 16:28:13.600556  3286 caffe.cpp:177] Use CPU.
I0204 16:28:13.601155  3286 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap_"
solver_mode: CPU
random_seed: 1
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/train_val.prototxt"
I0204 16:28:13.601332  3286 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/train_val.prototxt
I0204 16:28:13.601955  3286 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:28:13.601999  3286 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:28:13.602252  3286 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.602391  3286 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.602589  3286 net.cpp:106] Creating Layer data
I0204 16:28:13.602607  3286 net.cpp:411] data -> data
I0204 16:28:13.602697  3286 net.cpp:411] data -> label
I0204 16:28:13.602722  3286 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:28:13.602886  3291 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:28:13.603804  3286 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.633755  3286 net.cpp:150] Setting up data
I0204 16:28:13.633826  3286 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.633844  3286 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.633852  3286 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.633879  3286 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.633908  3286 net.cpp:106] Creating Layer conv1
I0204 16:28:13.633921  3286 net.cpp:454] conv1 <- data
I0204 16:28:13.633941  3286 net.cpp:411] conv1 -> conv1
I0204 16:28:13.634079  3286 net.cpp:150] Setting up conv1
I0204 16:28:13.634091  3286 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.634098  3286 net.cpp:165] Memory required for data: 59332000
I0204 16:28:13.634115  3286 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.634130  3286 net.cpp:106] Creating Layer relu1
I0204 16:28:13.634136  3286 net.cpp:454] relu1 <- conv1
I0204 16:28:13.634146  3286 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.634160  3286 net.cpp:150] Setting up relu1
I0204 16:28:13.634166  3286 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.634172  3286 net.cpp:165] Memory required for data: 98052000
I0204 16:28:13.634177  3286 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.634188  3286 net.cpp:106] Creating Layer pool1
I0204 16:28:13.634194  3286 net.cpp:454] pool1 <- conv1
I0204 16:28:13.634203  3286 net.cpp:411] pool1 -> pool1
I0204 16:28:13.634227  3286 net.cpp:150] Setting up pool1
I0204 16:28:13.634235  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.634240  3286 net.cpp:165] Memory required for data: 107383200
I0204 16:28:13.634246  3286 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.634292  3286 net.cpp:106] Creating Layer norm1
I0204 16:28:13.634300  3286 net.cpp:454] norm1 <- pool1
I0204 16:28:13.634310  3286 net.cpp:411] norm1 -> norm1
I0204 16:28:13.634327  3286 net.cpp:150] Setting up norm1
I0204 16:28:13.634336  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.634341  3286 net.cpp:165] Memory required for data: 116714400
I0204 16:28:13.634346  3286 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.634359  3286 net.cpp:106] Creating Layer conv2
I0204 16:28:13.634364  3286 net.cpp:454] conv2 <- norm1
I0204 16:28:13.634373  3286 net.cpp:411] conv2 -> conv2
I0204 16:28:13.634506  3286 net.cpp:150] Setting up conv2
I0204 16:28:13.634516  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.634521  3286 net.cpp:165] Memory required for data: 126045600
I0204 16:28:13.634532  3286 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.634552  3286 net.cpp:106] Creating Layer relu2
I0204 16:28:13.634559  3286 net.cpp:454] relu2 <- conv2
I0204 16:28:13.634568  3286 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.634579  3286 net.cpp:150] Setting up relu2
I0204 16:28:13.634585  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.634590  3286 net.cpp:165] Memory required for data: 135376800
I0204 16:28:13.634596  3286 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.634604  3286 net.cpp:106] Creating Layer pool2
I0204 16:28:13.634610  3286 net.cpp:454] pool2 <- conv2
I0204 16:28:13.634618  3286 net.cpp:411] pool2 -> pool2
I0204 16:28:13.634629  3286 net.cpp:150] Setting up pool2
I0204 16:28:13.634635  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.634640  3286 net.cpp:165] Memory required for data: 137540000
I0204 16:28:13.634645  3286 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.634659  3286 net.cpp:106] Creating Layer norm2
I0204 16:28:13.634663  3286 net.cpp:454] norm2 <- pool2
I0204 16:28:13.634672  3286 net.cpp:411] norm2 -> norm2
I0204 16:28:13.634681  3286 net.cpp:150] Setting up norm2
I0204 16:28:13.634688  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.634693  3286 net.cpp:165] Memory required for data: 139703200
I0204 16:28:13.634698  3286 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.634712  3286 net.cpp:106] Creating Layer conv3
I0204 16:28:13.634717  3286 net.cpp:454] conv3 <- norm2
I0204 16:28:13.634729  3286 net.cpp:411] conv3 -> conv3
I0204 16:28:13.634837  3286 net.cpp:150] Setting up conv3
I0204 16:28:13.634847  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.634851  3286 net.cpp:165] Memory required for data: 141866400
I0204 16:28:13.634861  3286 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.634871  3286 net.cpp:106] Creating Layer relu3
I0204 16:28:13.634876  3286 net.cpp:454] relu3 <- conv3
I0204 16:28:13.634886  3286 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.634894  3286 net.cpp:150] Setting up relu3
I0204 16:28:13.634901  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.634905  3286 net.cpp:165] Memory required for data: 144029600
I0204 16:28:13.634910  3286 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.634920  3286 net.cpp:106] Creating Layer conv4
I0204 16:28:13.634927  3286 net.cpp:454] conv4 <- conv3
I0204 16:28:13.634937  3286 net.cpp:411] conv4 -> conv4
I0204 16:28:13.635030  3286 net.cpp:150] Setting up conv4
I0204 16:28:13.635042  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.635047  3286 net.cpp:165] Memory required for data: 146192800
I0204 16:28:13.635056  3286 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.635066  3286 net.cpp:106] Creating Layer relu4
I0204 16:28:13.635073  3286 net.cpp:454] relu4 <- conv4
I0204 16:28:13.635081  3286 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.635089  3286 net.cpp:150] Setting up relu4
I0204 16:28:13.635097  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.635102  3286 net.cpp:165] Memory required for data: 148356000
I0204 16:28:13.635112  3286 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.635131  3286 net.cpp:106] Creating Layer conv5
I0204 16:28:13.635139  3286 net.cpp:454] conv5 <- conv4
I0204 16:28:13.635148  3286 net.cpp:411] conv5 -> conv5
I0204 16:28:13.635193  3286 net.cpp:150] Setting up conv5
I0204 16:28:13.635201  3286 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.635206  3286 net.cpp:165] Memory required for data: 149437600
I0204 16:28:13.635216  3286 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.635227  3286 net.cpp:106] Creating Layer relu5
I0204 16:28:13.635232  3286 net.cpp:454] relu5 <- conv5
I0204 16:28:13.635239  3286 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.635247  3286 net.cpp:150] Setting up relu5
I0204 16:28:13.635253  3286 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.635258  3286 net.cpp:165] Memory required for data: 150519200
I0204 16:28:13.635264  3286 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.635274  3286 net.cpp:106] Creating Layer pool5
I0204 16:28:13.635280  3286 net.cpp:454] pool5 <- conv5
I0204 16:28:13.635289  3286 net.cpp:411] pool5 -> pool5
I0204 16:28:13.635300  3286 net.cpp:150] Setting up pool5
I0204 16:28:13.635308  3286 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.635313  3286 net.cpp:165] Memory required for data: 150749600
I0204 16:28:13.635318  3286 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.635335  3286 net.cpp:106] Creating Layer fc6
I0204 16:28:13.635341  3286 net.cpp:454] fc6 <- pool5
I0204 16:28:13.635349  3286 net.cpp:411] fc6 -> fc6
I0204 16:28:13.636952  3286 net.cpp:150] Setting up fc6
I0204 16:28:13.636971  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.636976  3286 net.cpp:165] Memory required for data: 150852000
I0204 16:28:13.636986  3286 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.636997  3286 net.cpp:106] Creating Layer relu6
I0204 16:28:13.637002  3286 net.cpp:454] relu6 <- fc6
I0204 16:28:13.637011  3286 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.637022  3286 net.cpp:150] Setting up relu6
I0204 16:28:13.637028  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.637033  3286 net.cpp:165] Memory required for data: 150954400
I0204 16:28:13.637038  3286 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.637048  3286 net.cpp:106] Creating Layer drop6
I0204 16:28:13.637054  3286 net.cpp:454] drop6 <- fc6
I0204 16:28:13.637061  3286 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.637078  3286 net.cpp:150] Setting up drop6
I0204 16:28:13.637085  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.637091  3286 net.cpp:165] Memory required for data: 151056800
I0204 16:28:13.637096  3286 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.637106  3286 net.cpp:106] Creating Layer fc7
I0204 16:28:13.637111  3286 net.cpp:454] fc7 <- fc6
I0204 16:28:13.637121  3286 net.cpp:411] fc7 -> fc7
I0204 16:28:13.637838  3286 net.cpp:150] Setting up fc7
I0204 16:28:13.637850  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.637855  3286 net.cpp:165] Memory required for data: 151159200
I0204 16:28:13.637863  3286 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.637873  3286 net.cpp:106] Creating Layer relu7
I0204 16:28:13.637879  3286 net.cpp:454] relu7 <- fc7
I0204 16:28:13.637887  3286 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.637895  3286 net.cpp:150] Setting up relu7
I0204 16:28:13.637902  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.637907  3286 net.cpp:165] Memory required for data: 151261600
I0204 16:28:13.637912  3286 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.637923  3286 net.cpp:106] Creating Layer drop7
I0204 16:28:13.637928  3286 net.cpp:454] drop7 <- fc7
I0204 16:28:13.637934  3286 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.637943  3286 net.cpp:150] Setting up drop7
I0204 16:28:13.637950  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.637956  3286 net.cpp:165] Memory required for data: 151364000
I0204 16:28:13.637962  3286 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.637982  3286 net.cpp:106] Creating Layer fc8
I0204 16:28:13.637995  3286 net.cpp:454] fc8 <- fc7
I0204 16:28:13.638005  3286 net.cpp:411] fc8 -> fc8
I0204 16:28:13.638031  3286 net.cpp:150] Setting up fc8
I0204 16:28:13.638037  3286 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.638042  3286 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.638051  3286 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.638061  3286 net.cpp:106] Creating Layer loss
I0204 16:28:13.638065  3286 net.cpp:454] loss <- fc8
I0204 16:28:13.638072  3286 net.cpp:454] loss <- label
I0204 16:28:13.638085  3286 net.cpp:411] loss -> loss
I0204 16:28:13.638103  3286 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.638124  3286 net.cpp:150] Setting up loss
I0204 16:28:13.638133  3286 net.cpp:157] Top shape: (1)
I0204 16:28:13.638137  3286 net.cpp:160]     with loss weight 1
I0204 16:28:13.638164  3286 net.cpp:165] Memory required for data: 151364804
I0204 16:28:13.638171  3286 net.cpp:226] loss needs backward computation.
I0204 16:28:13.638178  3286 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.638183  3286 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.638190  3286 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.638195  3286 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.638200  3286 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.638206  3286 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.638211  3286 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.638216  3286 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.638223  3286 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.638228  3286 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.638234  3286 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.638239  3286 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.638244  3286 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.638250  3286 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.638258  3286 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.638264  3286 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.638269  3286 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.638274  3286 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.638280  3286 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.638286  3286 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.638291  3286 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.638298  3286 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.638303  3286 net.cpp:228] data does not need backward computation.
I0204 16:28:13.638309  3286 net.cpp:270] This network produces output loss
I0204 16:28:13.638334  3286 net.cpp:283] Network initialization done.
I0204 16:28:13.639104  3286 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/train_val.prototxt
I0204 16:28:13.639163  3286 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:28:13.639456  3286 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.639626  3286 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.639777  3286 net.cpp:106] Creating Layer data
I0204 16:28:13.639793  3286 net.cpp:411] data -> data
I0204 16:28:13.639808  3286 net.cpp:411] data -> label
I0204 16:28:13.639819  3286 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:28:13.640043  3301 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:28:13.640820  3286 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.676832  3286 net.cpp:150] Setting up data
I0204 16:28:13.676863  3286 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.676874  3286 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.676883  3286 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.676894  3286 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:28:13.676915  3286 net.cpp:106] Creating Layer label_data_1_split
I0204 16:28:13.676924  3286 net.cpp:454] label_data_1_split <- label
I0204 16:28:13.676937  3286 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:28:13.676952  3286 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:28:13.676972  3286 net.cpp:150] Setting up label_data_1_split
I0204 16:28:13.676982  3286 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.676990  3286 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.676997  3286 net.cpp:165] Memory required for data: 20612800
I0204 16:28:13.677005  3286 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.677021  3286 net.cpp:106] Creating Layer conv1
I0204 16:28:13.677029  3286 net.cpp:454] conv1 <- data
I0204 16:28:13.677042  3286 net.cpp:411] conv1 -> conv1
I0204 16:28:13.677127  3286 net.cpp:150] Setting up conv1
I0204 16:28:13.677140  3286 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.677146  3286 net.cpp:165] Memory required for data: 59332800
I0204 16:28:13.677163  3286 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.677175  3286 net.cpp:106] Creating Layer relu1
I0204 16:28:13.677183  3286 net.cpp:454] relu1 <- conv1
I0204 16:28:13.677193  3286 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.677206  3286 net.cpp:150] Setting up relu1
I0204 16:28:13.677214  3286 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.677222  3286 net.cpp:165] Memory required for data: 98052800
I0204 16:28:13.677230  3286 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.677244  3286 net.cpp:106] Creating Layer pool1
I0204 16:28:13.677251  3286 net.cpp:454] pool1 <- conv1
I0204 16:28:13.677265  3286 net.cpp:411] pool1 -> pool1
I0204 16:28:13.677281  3286 net.cpp:150] Setting up pool1
I0204 16:28:13.677290  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.677296  3286 net.cpp:165] Memory required for data: 107384000
I0204 16:28:13.677304  3286 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.677315  3286 net.cpp:106] Creating Layer norm1
I0204 16:28:13.677322  3286 net.cpp:454] norm1 <- pool1
I0204 16:28:13.677332  3286 net.cpp:411] norm1 -> norm1
I0204 16:28:13.677345  3286 net.cpp:150] Setting up norm1
I0204 16:28:13.677355  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.677361  3286 net.cpp:165] Memory required for data: 116715200
I0204 16:28:13.677367  3286 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.677381  3286 net.cpp:106] Creating Layer conv2
I0204 16:28:13.677391  3286 net.cpp:454] conv2 <- norm1
I0204 16:28:13.677402  3286 net.cpp:411] conv2 -> conv2
I0204 16:28:13.677574  3286 net.cpp:150] Setting up conv2
I0204 16:28:13.677588  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.677594  3286 net.cpp:165] Memory required for data: 126046400
I0204 16:28:13.677608  3286 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.677618  3286 net.cpp:106] Creating Layer relu2
I0204 16:28:13.677626  3286 net.cpp:454] relu2 <- conv2
I0204 16:28:13.677642  3286 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.677667  3286 net.cpp:150] Setting up relu2
I0204 16:28:13.677675  3286 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.677682  3286 net.cpp:165] Memory required for data: 135377600
I0204 16:28:13.677688  3286 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.677700  3286 net.cpp:106] Creating Layer pool2
I0204 16:28:13.677709  3286 net.cpp:454] pool2 <- conv2
I0204 16:28:13.677721  3286 net.cpp:411] pool2 -> pool2
I0204 16:28:13.677736  3286 net.cpp:150] Setting up pool2
I0204 16:28:13.677745  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.677752  3286 net.cpp:165] Memory required for data: 137540800
I0204 16:28:13.677758  3286 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.677772  3286 net.cpp:106] Creating Layer norm2
I0204 16:28:13.677779  3286 net.cpp:454] norm2 <- pool2
I0204 16:28:13.677788  3286 net.cpp:411] norm2 -> norm2
I0204 16:28:13.677801  3286 net.cpp:150] Setting up norm2
I0204 16:28:13.677809  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.677815  3286 net.cpp:165] Memory required for data: 139704000
I0204 16:28:13.677822  3286 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.677835  3286 net.cpp:106] Creating Layer conv3
I0204 16:28:13.677842  3286 net.cpp:454] conv3 <- norm2
I0204 16:28:13.677852  3286 net.cpp:411] conv3 -> conv3
I0204 16:28:13.677990  3286 net.cpp:150] Setting up conv3
I0204 16:28:13.678004  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.678009  3286 net.cpp:165] Memory required for data: 141867200
I0204 16:28:13.678022  3286 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.678032  3286 net.cpp:106] Creating Layer relu3
I0204 16:28:13.678040  3286 net.cpp:454] relu3 <- conv3
I0204 16:28:13.678051  3286 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.678063  3286 net.cpp:150] Setting up relu3
I0204 16:28:13.678071  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.678077  3286 net.cpp:165] Memory required for data: 144030400
I0204 16:28:13.678084  3286 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.678097  3286 net.cpp:106] Creating Layer conv4
I0204 16:28:13.678107  3286 net.cpp:454] conv4 <- conv3
I0204 16:28:13.678117  3286 net.cpp:411] conv4 -> conv4
I0204 16:28:13.678192  3286 net.cpp:150] Setting up conv4
I0204 16:28:13.678202  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.678208  3286 net.cpp:165] Memory required for data: 146193600
I0204 16:28:13.678220  3286 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.678231  3286 net.cpp:106] Creating Layer relu4
I0204 16:28:13.678238  3286 net.cpp:454] relu4 <- conv4
I0204 16:28:13.678247  3286 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.678257  3286 net.cpp:150] Setting up relu4
I0204 16:28:13.678267  3286 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.678272  3286 net.cpp:165] Memory required for data: 148356800
I0204 16:28:13.678280  3286 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.678294  3286 net.cpp:106] Creating Layer conv5
I0204 16:28:13.678303  3286 net.cpp:454] conv5 <- conv4
I0204 16:28:13.678313  3286 net.cpp:411] conv5 -> conv5
I0204 16:28:13.678362  3286 net.cpp:150] Setting up conv5
I0204 16:28:13.678371  3286 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.678377  3286 net.cpp:165] Memory required for data: 149438400
I0204 16:28:13.678390  3286 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.678402  3286 net.cpp:106] Creating Layer relu5
I0204 16:28:13.678411  3286 net.cpp:454] relu5 <- conv5
I0204 16:28:13.678421  3286 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.678431  3286 net.cpp:150] Setting up relu5
I0204 16:28:13.678438  3286 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.678444  3286 net.cpp:165] Memory required for data: 150520000
I0204 16:28:13.678452  3286 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.678463  3286 net.cpp:106] Creating Layer pool5
I0204 16:28:13.678472  3286 net.cpp:454] pool5 <- conv5
I0204 16:28:13.678498  3286 net.cpp:411] pool5 -> pool5
I0204 16:28:13.678513  3286 net.cpp:150] Setting up pool5
I0204 16:28:13.678522  3286 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.678529  3286 net.cpp:165] Memory required for data: 150750400
I0204 16:28:13.678535  3286 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.678549  3286 net.cpp:106] Creating Layer fc6
I0204 16:28:13.678555  3286 net.cpp:454] fc6 <- pool5
I0204 16:28:13.678568  3286 net.cpp:411] fc6 -> fc6
I0204 16:28:13.681236  3286 net.cpp:150] Setting up fc6
I0204 16:28:13.681255  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.681264  3286 net.cpp:165] Memory required for data: 150852800
I0204 16:28:13.681277  3286 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.681288  3286 net.cpp:106] Creating Layer relu6
I0204 16:28:13.681295  3286 net.cpp:454] relu6 <- fc6
I0204 16:28:13.681306  3286 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.681321  3286 net.cpp:150] Setting up relu6
I0204 16:28:13.681330  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.681336  3286 net.cpp:165] Memory required for data: 150955200
I0204 16:28:13.681344  3286 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.681359  3286 net.cpp:106] Creating Layer drop6
I0204 16:28:13.681366  3286 net.cpp:454] drop6 <- fc6
I0204 16:28:13.681376  3286 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.681388  3286 net.cpp:150] Setting up drop6
I0204 16:28:13.681397  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.681403  3286 net.cpp:165] Memory required for data: 151057600
I0204 16:28:13.681411  3286 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.681422  3286 net.cpp:106] Creating Layer fc7
I0204 16:28:13.681429  3286 net.cpp:454] fc7 <- fc6
I0204 16:28:13.681440  3286 net.cpp:411] fc7 -> fc7
I0204 16:28:13.682389  3286 net.cpp:150] Setting up fc7
I0204 16:28:13.682404  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.682410  3286 net.cpp:165] Memory required for data: 151160000
I0204 16:28:13.682421  3286 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.682431  3286 net.cpp:106] Creating Layer relu7
I0204 16:28:13.682438  3286 net.cpp:454] relu7 <- fc7
I0204 16:28:13.682448  3286 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.682462  3286 net.cpp:150] Setting up relu7
I0204 16:28:13.682471  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.682477  3286 net.cpp:165] Memory required for data: 151262400
I0204 16:28:13.682484  3286 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.682498  3286 net.cpp:106] Creating Layer drop7
I0204 16:28:13.682505  3286 net.cpp:454] drop7 <- fc7
I0204 16:28:13.682514  3286 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.682526  3286 net.cpp:150] Setting up drop7
I0204 16:28:13.682536  3286 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.682543  3286 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.682549  3286 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.682565  3286 net.cpp:106] Creating Layer fc8
I0204 16:28:13.682574  3286 net.cpp:454] fc8 <- fc7
I0204 16:28:13.682582  3286 net.cpp:411] fc8 -> fc8
I0204 16:28:13.682621  3286 net.cpp:150] Setting up fc8
I0204 16:28:13.682631  3286 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.682641  3286 net.cpp:165] Memory required for data: 151365600
I0204 16:28:13.682652  3286 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:28:13.682667  3286 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:28:13.682674  3286 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:28:13.682683  3286 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:28:13.682694  3286 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:28:13.682706  3286 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:28:13.682719  3286 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.682728  3286 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.682734  3286 net.cpp:165] Memory required for data: 151367200
I0204 16:28:13.682741  3286 layer_factory.hpp:77] Creating layer accuracy
I0204 16:28:13.682771  3286 net.cpp:106] Creating Layer accuracy
I0204 16:28:13.682780  3286 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:28:13.682787  3286 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:28:13.682797  3286 net.cpp:411] accuracy -> accuracy
I0204 16:28:13.682814  3286 net.cpp:150] Setting up accuracy
I0204 16:28:13.682823  3286 net.cpp:157] Top shape: (1)
I0204 16:28:13.682831  3286 net.cpp:165] Memory required for data: 151367204
I0204 16:28:13.682837  3286 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.682850  3286 net.cpp:106] Creating Layer loss
I0204 16:28:13.682858  3286 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:28:13.682867  3286 net.cpp:454] loss <- label_data_1_split_1
I0204 16:28:13.682875  3286 net.cpp:411] loss -> loss
I0204 16:28:13.682890  3286 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.682915  3286 net.cpp:150] Setting up loss
I0204 16:28:13.682924  3286 net.cpp:157] Top shape: (1)
I0204 16:28:13.682930  3286 net.cpp:160]     with loss weight 1
I0204 16:28:13.682941  3286 net.cpp:165] Memory required for data: 151367208
I0204 16:28:13.682950  3286 net.cpp:226] loss needs backward computation.
I0204 16:28:13.682956  3286 net.cpp:228] accuracy does not need backward computation.
I0204 16:28:13.682971  3286 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:28:13.682981  3286 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.682993  3286 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.682999  3286 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.683007  3286 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.683014  3286 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.683020  3286 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.683028  3286 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.683037  3286 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.683043  3286 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.683050  3286 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.683059  3286 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.683068  3286 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.683074  3286 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.683081  3286 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.683089  3286 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.683095  3286 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.683104  3286 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.683109  3286 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.683116  3286 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.683125  3286 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.683131  3286 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.683140  3286 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.683148  3286 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:28:13.683157  3286 net.cpp:228] data does not need backward computation.
I0204 16:28:13.683163  3286 net.cpp:270] This network produces output accuracy
I0204 16:28:13.683172  3286 net.cpp:270] This network produces output loss
I0204 16:28:13.683231  3286 net.cpp:283] Network initialization done.
I0204 16:28:13.683363  3286 solver.cpp:60] Solver scaffolding done.
I0204 16:28:13.683439  3286 caffe.cpp:212] Starting Optimization
I0204 16:28:13.683449  3286 solver.cpp:288] Solving CaffeNet
I0204 16:28:13.683455  3286 solver.cpp:289] Learning Rate Policy: step
I0204 16:28:13.684631  3286 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:28:13.684804  3286 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:28:21.256999  3286 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:28:21.257050  3286 solver.cpp:409]     Test net output #1: loss = 6.91523 (* 1 = 6.91523 loss)
I0204 16:28:22.887689  3286 solver.cpp:237] Iteration 0, loss = 9.80365
I0204 16:28:22.887747  3286 solver.cpp:253]     Train net output #0: loss = 9.80365 (* 1 = 9.80365 loss)
I0204 16:28:22.887768  3286 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:28:39.343629  3286 solver.cpp:237] Iteration 10, loss = 1.1213
I0204 16:28:39.343672  3286 solver.cpp:253]     Train net output #0: loss = 1.1213 (* 1 = 1.1213 loss)
I0204 16:28:39.343683  3286 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:28:56.440683  3286 solver.cpp:237] Iteration 20, loss = 0.915261
I0204 16:28:56.440783  3286 solver.cpp:253]     Train net output #0: loss = 0.915261 (* 1 = 0.915261 loss)
I0204 16:28:56.440793  3286 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:29:14.476950  3286 solver.cpp:237] Iteration 30, loss = 0.803171
I0204 16:29:14.477006  3286 solver.cpp:253]     Train net output #0: loss = 0.803171 (* 1 = 0.803171 loss)
I0204 16:29:14.477018  3286 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:29:33.161514  3286 solver.cpp:237] Iteration 40, loss = 0.751369
I0204 16:29:33.161702  3286 solver.cpp:253]     Train net output #0: loss = 0.751369 (* 1 = 0.751369 loss)
I0204 16:29:33.161715  3286 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:29:51.583195  3286 solver.cpp:237] Iteration 50, loss = 0.596409
I0204 16:29:51.583245  3286 solver.cpp:253]     Train net output #0: loss = 0.596409 (* 1 = 0.596409 loss)
I0204 16:29:51.583255  3286 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:30:09.800081  3286 solver.cpp:237] Iteration 60, loss = 0.46919
I0204 16:30:09.800256  3286 solver.cpp:253]     Train net output #0: loss = 0.46919 (* 1 = 0.46919 loss)
I0204 16:30:09.800268  3286 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:30:27.902457  3286 solver.cpp:237] Iteration 70, loss = 0.546709
I0204 16:30:27.902508  3286 solver.cpp:253]     Train net output #0: loss = 0.546709 (* 1 = 0.546709 loss)
I0204 16:30:27.902518  3286 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:30:45.972712  3286 solver.cpp:237] Iteration 80, loss = 0.326209
I0204 16:30:45.972888  3286 solver.cpp:253]     Train net output #0: loss = 0.326209 (* 1 = 0.326209 loss)
I0204 16:30:45.972900  3286 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:06.740607  3286 solver.cpp:237] Iteration 90, loss = 0.279299
I0204 16:31:06.740661  3286 solver.cpp:253]     Train net output #0: loss = 0.279299 (* 1 = 0.279299 loss)
I0204 16:31:06.740674  3286 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:31:26.131399  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_100.caffemodel
I0204 16:31:26.135083  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_100.solverstate
I0204 16:31:26.136721  3286 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:31:36.169751  3286 solver.cpp:409]     Test net output #0: accuracy = 0.944
I0204 16:31:36.169801  3286 solver.cpp:409]     Test net output #1: loss = 0.142489 (* 1 = 0.142489 loss)
I0204 16:31:38.331177  3286 solver.cpp:237] Iteration 100, loss = 0.274044
I0204 16:31:38.331239  3286 solver.cpp:253]     Train net output #0: loss = 0.274044 (* 1 = 0.274044 loss)
I0204 16:31:38.331251  3286 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:00.153820  3286 solver.cpp:237] Iteration 110, loss = 0.192592
I0204 16:32:00.153992  3286 solver.cpp:253]     Train net output #0: loss = 0.192592 (* 1 = 0.192592 loss)
I0204 16:32:00.154006  3286 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:32:22.269678  3286 solver.cpp:237] Iteration 120, loss = 0.129566
I0204 16:32:22.269732  3286 solver.cpp:253]     Train net output #0: loss = 0.129566 (* 1 = 0.129566 loss)
I0204 16:32:22.269744  3286 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:32:44.417392  3286 solver.cpp:237] Iteration 130, loss = 0.186358
I0204 16:32:44.417567  3286 solver.cpp:253]     Train net output #0: loss = 0.186358 (* 1 = 0.186358 loss)
I0204 16:32:44.417583  3286 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:33:06.149894  3286 solver.cpp:237] Iteration 140, loss = 0.192799
I0204 16:33:06.149942  3286 solver.cpp:253]     Train net output #0: loss = 0.192799 (* 1 = 0.192799 loss)
I0204 16:33:06.149955  3286 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:33:28.035789  3286 solver.cpp:237] Iteration 150, loss = 0.102954
I0204 16:33:28.035958  3286 solver.cpp:253]     Train net output #0: loss = 0.102954 (* 1 = 0.102954 loss)
I0204 16:33:28.035971  3286 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:33:50.177973  3286 solver.cpp:237] Iteration 160, loss = 0.136358
I0204 16:33:50.178051  3286 solver.cpp:253]     Train net output #0: loss = 0.136358 (* 1 = 0.136358 loss)
I0204 16:33:50.178066  3286 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:34:12.407467  3286 solver.cpp:237] Iteration 170, loss = 0.0622601
I0204 16:34:12.408227  3286 solver.cpp:253]     Train net output #0: loss = 0.06226 (* 1 = 0.06226 loss)
I0204 16:34:12.408242  3286 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:34:34.571522  3286 solver.cpp:237] Iteration 180, loss = 0.156035
I0204 16:34:34.571588  3286 solver.cpp:253]     Train net output #0: loss = 0.156035 (* 1 = 0.156035 loss)
I0204 16:34:34.571600  3286 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:34:56.421813  3286 solver.cpp:237] Iteration 190, loss = 0.194718
I0204 16:34:56.421947  3286 solver.cpp:253]     Train net output #0: loss = 0.194718 (* 1 = 0.194718 loss)
I0204 16:34:56.421960  3286 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:35:15.795651  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_200.caffemodel
I0204 16:35:15.799486  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_200.solverstate
I0204 16:35:15.801023  3286 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:35:25.761533  3286 solver.cpp:409]     Test net output #0: accuracy = 0.983
I0204 16:35:25.761595  3286 solver.cpp:409]     Test net output #1: loss = 0.054553 (* 1 = 0.054553 loss)
I0204 16:35:27.886688  3286 solver.cpp:237] Iteration 200, loss = 0.0909768
I0204 16:35:27.886868  3286 solver.cpp:253]     Train net output #0: loss = 0.0909767 (* 1 = 0.0909767 loss)
I0204 16:35:27.886883  3286 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:35:49.358819  3286 solver.cpp:237] Iteration 210, loss = 0.118721
I0204 16:35:49.358886  3286 solver.cpp:253]     Train net output #0: loss = 0.11872 (* 1 = 0.11872 loss)
I0204 16:35:49.358899  3286 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:36:11.124555  3286 solver.cpp:237] Iteration 220, loss = 0.0175084
I0204 16:36:11.124737  3286 solver.cpp:253]     Train net output #0: loss = 0.0175083 (* 1 = 0.0175083 loss)
I0204 16:36:11.124750  3286 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:36:33.005631  3286 solver.cpp:237] Iteration 230, loss = 0.0392646
I0204 16:36:33.005707  3286 solver.cpp:253]     Train net output #0: loss = 0.0392646 (* 1 = 0.0392646 loss)
I0204 16:36:33.005722  3286 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:36:54.740175  3286 solver.cpp:237] Iteration 240, loss = 0.145923
I0204 16:36:54.740358  3286 solver.cpp:253]     Train net output #0: loss = 0.145923 (* 1 = 0.145923 loss)
I0204 16:36:54.740373  3286 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:37:16.384320  3286 solver.cpp:237] Iteration 250, loss = 0.091576
I0204 16:37:16.384387  3286 solver.cpp:253]     Train net output #0: loss = 0.0915759 (* 1 = 0.0915759 loss)
I0204 16:37:16.384402  3286 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:37:38.122099  3286 solver.cpp:237] Iteration 260, loss = 0.0886489
I0204 16:37:38.122313  3286 solver.cpp:253]     Train net output #0: loss = 0.0886488 (* 1 = 0.0886488 loss)
I0204 16:37:38.122334  3286 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:37:59.719745  3286 solver.cpp:237] Iteration 270, loss = 0.0504784
I0204 16:37:59.719817  3286 solver.cpp:253]     Train net output #0: loss = 0.0504783 (* 1 = 0.0504783 loss)
I0204 16:37:59.719831  3286 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:38:21.523221  3286 solver.cpp:237] Iteration 280, loss = 0.0379144
I0204 16:38:21.526015  3286 solver.cpp:253]     Train net output #0: loss = 0.0379143 (* 1 = 0.0379143 loss)
I0204 16:38:21.526031  3286 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:38:43.081051  3286 solver.cpp:237] Iteration 290, loss = 0.0841712
I0204 16:38:43.081132  3286 solver.cpp:253]     Train net output #0: loss = 0.0841711 (* 1 = 0.0841711 loss)
I0204 16:38:43.081146  3286 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:39:02.366834  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_300.caffemodel
I0204 16:39:02.370898  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_300.solverstate
I0204 16:39:02.372551  3286 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:39:12.637864  3286 solver.cpp:409]     Test net output #0: accuracy = 0.979
I0204 16:39:12.637934  3286 solver.cpp:409]     Test net output #1: loss = 0.0656767 (* 1 = 0.0656767 loss)
I0204 16:39:14.789240  3286 solver.cpp:237] Iteration 300, loss = 0.0662302
I0204 16:39:14.789305  3286 solver.cpp:253]     Train net output #0: loss = 0.0662301 (* 1 = 0.0662301 loss)
I0204 16:39:14.789319  3286 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:39:36.310134  3286 solver.cpp:237] Iteration 310, loss = 0.105423
I0204 16:39:36.310299  3286 solver.cpp:253]     Train net output #0: loss = 0.105423 (* 1 = 0.105423 loss)
I0204 16:39:36.310313  3286 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:39:58.539973  3286 solver.cpp:237] Iteration 320, loss = 0.0530838
I0204 16:39:58.540045  3286 solver.cpp:253]     Train net output #0: loss = 0.0530837 (* 1 = 0.0530837 loss)
I0204 16:39:58.540057  3286 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:40:20.884198  3286 solver.cpp:237] Iteration 330, loss = 0.111541
I0204 16:40:20.884392  3286 solver.cpp:253]     Train net output #0: loss = 0.111541 (* 1 = 0.111541 loss)
I0204 16:40:20.884407  3286 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:40:43.301031  3286 solver.cpp:237] Iteration 340, loss = 0.0747204
I0204 16:40:43.301116  3286 solver.cpp:253]     Train net output #0: loss = 0.0747203 (* 1 = 0.0747203 loss)
I0204 16:40:43.301131  3286 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:41:05.950736  3286 solver.cpp:237] Iteration 350, loss = 0.0534095
I0204 16:41:05.950877  3286 solver.cpp:253]     Train net output #0: loss = 0.0534093 (* 1 = 0.0534093 loss)
I0204 16:41:05.950891  3286 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:41:28.206032  3286 solver.cpp:237] Iteration 360, loss = 0.074711
I0204 16:41:28.206087  3286 solver.cpp:253]     Train net output #0: loss = 0.0747109 (* 1 = 0.0747109 loss)
I0204 16:41:28.206100  3286 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:41:50.649766  3286 solver.cpp:237] Iteration 370, loss = 0.0512607
I0204 16:41:50.649895  3286 solver.cpp:253]     Train net output #0: loss = 0.0512606 (* 1 = 0.0512606 loss)
I0204 16:41:50.649907  3286 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:42:13.273444  3286 solver.cpp:237] Iteration 380, loss = 0.0166276
I0204 16:42:13.273505  3286 solver.cpp:253]     Train net output #0: loss = 0.0166275 (* 1 = 0.0166275 loss)
I0204 16:42:13.273517  3286 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:42:36.039460  3286 solver.cpp:237] Iteration 390, loss = 0.010819
I0204 16:42:36.039666  3286 solver.cpp:253]     Train net output #0: loss = 0.0108188 (* 1 = 0.0108188 loss)
I0204 16:42:36.039685  3286 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:42:56.365118  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_400.caffemodel
I0204 16:42:56.369010  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_400.solverstate
I0204 16:42:56.370693  3286 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:43:06.720414  3286 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:43:06.720530  3286 solver.cpp:409]     Test net output #1: loss = 0.00918652 (* 1 = 0.00918652 loss)
I0204 16:43:08.952277  3286 solver.cpp:237] Iteration 400, loss = 0.0107008
I0204 16:43:08.952330  3286 solver.cpp:253]     Train net output #0: loss = 0.0107007 (* 1 = 0.0107007 loss)
I0204 16:43:08.952342  3286 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:43:30.881763  3286 solver.cpp:237] Iteration 410, loss = 0.00252509
I0204 16:43:30.881817  3286 solver.cpp:253]     Train net output #0: loss = 0.00252498 (* 1 = 0.00252498 loss)
I0204 16:43:30.881829  3286 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:43:52.577569  3286 solver.cpp:237] Iteration 420, loss = 0.0270022
I0204 16:43:52.577719  3286 solver.cpp:253]     Train net output #0: loss = 0.0270021 (* 1 = 0.0270021 loss)
I0204 16:43:52.577731  3286 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:44:14.426066  3286 solver.cpp:237] Iteration 430, loss = 0.0523693
I0204 16:44:14.426127  3286 solver.cpp:253]     Train net output #0: loss = 0.0523692 (* 1 = 0.0523692 loss)
I0204 16:44:14.426139  3286 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:44:36.436218  3286 solver.cpp:237] Iteration 440, loss = 0.00945573
I0204 16:44:36.436363  3286 solver.cpp:253]     Train net output #0: loss = 0.00945562 (* 1 = 0.00945562 loss)
I0204 16:44:36.436377  3286 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:44:58.378155  3286 solver.cpp:237] Iteration 450, loss = 0.0559899
I0204 16:44:58.378209  3286 solver.cpp:253]     Train net output #0: loss = 0.0559898 (* 1 = 0.0559898 loss)
I0204 16:44:58.378221  3286 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:45:20.453395  3286 solver.cpp:237] Iteration 460, loss = 0.00682588
I0204 16:45:20.453574  3286 solver.cpp:253]     Train net output #0: loss = 0.00682577 (* 1 = 0.00682577 loss)
I0204 16:45:20.453589  3286 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:45:42.374970  3286 solver.cpp:237] Iteration 470, loss = 0.0031693
I0204 16:45:42.375041  3286 solver.cpp:253]     Train net output #0: loss = 0.00316919 (* 1 = 0.00316919 loss)
I0204 16:45:42.375056  3286 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:46:04.288457  3286 solver.cpp:237] Iteration 480, loss = 0.0236772
I0204 16:46:04.295356  3286 solver.cpp:253]     Train net output #0: loss = 0.0236771 (* 1 = 0.0236771 loss)
I0204 16:46:04.295379  3286 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:46:26.474436  3286 solver.cpp:237] Iteration 490, loss = 0.00556733
I0204 16:46:26.474514  3286 solver.cpp:253]     Train net output #0: loss = 0.00556723 (* 1 = 0.00556723 loss)
I0204 16:46:26.474529  3286 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:46:46.216049  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_500.caffemodel
I0204 16:46:46.220369  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_500.solverstate
I0204 16:46:46.222144  3286 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:46:56.550492  3286 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 16:46:56.550567  3286 solver.cpp:409]     Test net output #1: loss = 0.00639117 (* 1 = 0.00639117 loss)
I0204 16:46:58.806421  3286 solver.cpp:237] Iteration 500, loss = 0.0124193
I0204 16:46:58.806480  3286 solver.cpp:253]     Train net output #0: loss = 0.0124192 (* 1 = 0.0124192 loss)
I0204 16:46:58.806493  3286 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:47:20.121755  3286 solver.cpp:237] Iteration 510, loss = 0.0268103
I0204 16:47:20.121986  3286 solver.cpp:253]     Train net output #0: loss = 0.0268102 (* 1 = 0.0268102 loss)
I0204 16:47:20.122000  3286 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:47:41.342284  3286 solver.cpp:237] Iteration 520, loss = 0.00353093
I0204 16:47:41.342352  3286 solver.cpp:253]     Train net output #0: loss = 0.00353082 (* 1 = 0.00353082 loss)
I0204 16:47:41.342365  3286 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:48:02.675057  3286 solver.cpp:237] Iteration 530, loss = 0.0183709
I0204 16:48:02.675278  3286 solver.cpp:253]     Train net output #0: loss = 0.0183708 (* 1 = 0.0183708 loss)
I0204 16:48:02.675293  3286 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:48:23.954695  3286 solver.cpp:237] Iteration 540, loss = 0.00232484
I0204 16:48:23.954762  3286 solver.cpp:253]     Train net output #0: loss = 0.00232473 (* 1 = 0.00232473 loss)
I0204 16:48:23.954776  3286 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:48:45.230198  3286 solver.cpp:237] Iteration 550, loss = 0.00289738
I0204 16:48:45.230450  3286 solver.cpp:253]     Train net output #0: loss = 0.00289726 (* 1 = 0.00289726 loss)
I0204 16:48:45.230463  3286 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:49:06.401195  3286 solver.cpp:237] Iteration 560, loss = 0.00137578
I0204 16:49:06.401257  3286 solver.cpp:253]     Train net output #0: loss = 0.00137566 (* 1 = 0.00137566 loss)
I0204 16:49:06.401268  3286 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:49:27.449784  3286 solver.cpp:237] Iteration 570, loss = 0.0564085
I0204 16:49:27.449991  3286 solver.cpp:253]     Train net output #0: loss = 0.0564083 (* 1 = 0.0564083 loss)
I0204 16:49:27.450006  3286 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:49:48.505409  3286 solver.cpp:237] Iteration 580, loss = 0.00326657
I0204 16:49:48.505471  3286 solver.cpp:253]     Train net output #0: loss = 0.00326645 (* 1 = 0.00326645 loss)
I0204 16:49:48.505484  3286 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:50:09.420881  3286 solver.cpp:237] Iteration 590, loss = 0.00549334
I0204 16:50:09.421071  3286 solver.cpp:253]     Train net output #0: loss = 0.00549323 (* 1 = 0.00549323 loss)
I0204 16:50:09.421085  3286 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:50:28.255784  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_600.caffemodel
I0204 16:50:28.260036  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_600.solverstate
I0204 16:50:28.261874  3286 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:50:37.976300  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 16:50:37.976361  3286 solver.cpp:409]     Test net output #1: loss = 0.00572756 (* 1 = 0.00572756 loss)
I0204 16:50:40.060686  3286 solver.cpp:237] Iteration 600, loss = 0.00956011
I0204 16:50:40.060871  3286 solver.cpp:253]     Train net output #0: loss = 0.00956 (* 1 = 0.00956 loss)
I0204 16:50:40.060886  3286 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:51:00.769764  3286 solver.cpp:237] Iteration 610, loss = 0.00129817
I0204 16:51:00.769830  3286 solver.cpp:253]     Train net output #0: loss = 0.00129806 (* 1 = 0.00129806 loss)
I0204 16:51:00.769842  3286 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:51:21.110816  3286 solver.cpp:237] Iteration 620, loss = 0.00121455
I0204 16:51:21.111037  3286 solver.cpp:253]     Train net output #0: loss = 0.00121444 (* 1 = 0.00121444 loss)
I0204 16:51:21.111052  3286 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:51:41.478225  3286 solver.cpp:237] Iteration 630, loss = 0.00131645
I0204 16:51:41.478287  3286 solver.cpp:253]     Train net output #0: loss = 0.00131634 (* 1 = 0.00131634 loss)
I0204 16:51:41.478301  3286 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:52:01.822697  3286 solver.cpp:237] Iteration 640, loss = 0.0338018
I0204 16:52:01.822898  3286 solver.cpp:253]     Train net output #0: loss = 0.0338017 (* 1 = 0.0338017 loss)
I0204 16:52:01.822911  3286 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:52:22.006098  3286 solver.cpp:237] Iteration 650, loss = 0.00844572
I0204 16:52:22.006165  3286 solver.cpp:253]     Train net output #0: loss = 0.00844561 (* 1 = 0.00844561 loss)
I0204 16:52:22.006177  3286 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:52:42.164048  3286 solver.cpp:237] Iteration 660, loss = 0.0348232
I0204 16:52:42.164255  3286 solver.cpp:253]     Train net output #0: loss = 0.0348231 (* 1 = 0.0348231 loss)
I0204 16:52:42.164269  3286 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:53:01.937710  3286 solver.cpp:237] Iteration 670, loss = 0.024412
I0204 16:53:01.937772  3286 solver.cpp:253]     Train net output #0: loss = 0.0244119 (* 1 = 0.0244119 loss)
I0204 16:53:01.937783  3286 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:53:22.028417  3286 solver.cpp:237] Iteration 680, loss = 0.0290945
I0204 16:53:22.028630  3286 solver.cpp:253]     Train net output #0: loss = 0.0290944 (* 1 = 0.0290944 loss)
I0204 16:53:22.028643  3286 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:53:42.531410  3286 solver.cpp:237] Iteration 690, loss = 0.159128
I0204 16:53:42.531478  3286 solver.cpp:253]     Train net output #0: loss = 0.159128 (* 1 = 0.159128 loss)
I0204 16:53:42.531491  3286 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:54:01.293550  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_700.caffemodel
I0204 16:54:01.297435  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_700.solverstate
I0204 16:54:01.298935  3286 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:54:11.169945  3286 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 16:54:11.170004  3286 solver.cpp:409]     Test net output #1: loss = 0.0127921 (* 1 = 0.0127921 loss)
I0204 16:54:13.284474  3286 solver.cpp:237] Iteration 700, loss = 0.00375318
I0204 16:54:13.284535  3286 solver.cpp:253]     Train net output #0: loss = 0.00375308 (* 1 = 0.00375308 loss)
I0204 16:54:13.284548  3286 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:54:34.266876  3286 solver.cpp:237] Iteration 710, loss = 0.00525399
I0204 16:54:34.267084  3286 solver.cpp:253]     Train net output #0: loss = 0.00525389 (* 1 = 0.00525389 loss)
I0204 16:54:34.267099  3286 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:54:55.187520  3286 solver.cpp:237] Iteration 720, loss = 0.0142467
I0204 16:54:55.187587  3286 solver.cpp:253]     Train net output #0: loss = 0.0142466 (* 1 = 0.0142466 loss)
I0204 16:54:55.187598  3286 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:55:15.934845  3286 solver.cpp:237] Iteration 730, loss = 0.0298073
I0204 16:55:15.935048  3286 solver.cpp:253]     Train net output #0: loss = 0.0298072 (* 1 = 0.0298072 loss)
I0204 16:55:15.935061  3286 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:55:36.619043  3286 solver.cpp:237] Iteration 740, loss = 0.00597667
I0204 16:55:36.619107  3286 solver.cpp:253]     Train net output #0: loss = 0.00597657 (* 1 = 0.00597657 loss)
I0204 16:55:36.619119  3286 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 16:55:57.186902  3286 solver.cpp:237] Iteration 750, loss = 0.00459921
I0204 16:55:57.187172  3286 solver.cpp:253]     Train net output #0: loss = 0.00459911 (* 1 = 0.00459911 loss)
I0204 16:55:57.187187  3286 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 16:56:17.547027  3286 solver.cpp:237] Iteration 760, loss = 0.0194318
I0204 16:56:17.547093  3286 solver.cpp:253]     Train net output #0: loss = 0.0194317 (* 1 = 0.0194317 loss)
I0204 16:56:17.547106  3286 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 16:56:37.906998  3286 solver.cpp:237] Iteration 770, loss = 0.00104511
I0204 16:56:37.907201  3286 solver.cpp:253]     Train net output #0: loss = 0.001045 (* 1 = 0.001045 loss)
I0204 16:56:37.907214  3286 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 16:56:58.465117  3286 solver.cpp:237] Iteration 780, loss = 0.00522459
I0204 16:56:58.465188  3286 solver.cpp:253]     Train net output #0: loss = 0.00522448 (* 1 = 0.00522448 loss)
I0204 16:56:58.465200  3286 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 16:57:19.231676  3286 solver.cpp:237] Iteration 790, loss = 0.00171571
I0204 16:57:19.231870  3286 solver.cpp:253]     Train net output #0: loss = 0.0017156 (* 1 = 0.0017156 loss)
I0204 16:57:19.231885  3286 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 16:57:37.967175  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_800.caffemodel
I0204 16:57:37.970974  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_800.solverstate
I0204 16:57:37.972442  3286 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 16:57:47.678557  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 16:57:47.678616  3286 solver.cpp:409]     Test net output #1: loss = 0.00593736 (* 1 = 0.00593736 loss)
I0204 16:57:49.748621  3286 solver.cpp:237] Iteration 800, loss = 0.0036744
I0204 16:57:49.748807  3286 solver.cpp:253]     Train net output #0: loss = 0.00367429 (* 1 = 0.00367429 loss)
I0204 16:57:49.748821  3286 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 16:58:10.429600  3286 solver.cpp:237] Iteration 810, loss = 0.000866704
I0204 16:58:10.429663  3286 solver.cpp:253]     Train net output #0: loss = 0.000866595 (* 1 = 0.000866595 loss)
I0204 16:58:10.429675  3286 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 16:58:31.068802  3286 solver.cpp:237] Iteration 820, loss = 0.00175426
I0204 16:58:31.069001  3286 solver.cpp:253]     Train net output #0: loss = 0.00175415 (* 1 = 0.00175415 loss)
I0204 16:58:31.069015  3286 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 16:58:51.352987  3286 solver.cpp:237] Iteration 830, loss = 0.0237287
I0204 16:58:51.353052  3286 solver.cpp:253]     Train net output #0: loss = 0.0237285 (* 1 = 0.0237285 loss)
I0204 16:58:51.353065  3286 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 16:59:11.456709  3286 solver.cpp:237] Iteration 840, loss = 0.00637327
I0204 16:59:11.456912  3286 solver.cpp:253]     Train net output #0: loss = 0.00637315 (* 1 = 0.00637315 loss)
I0204 16:59:11.456926  3286 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 16:59:31.412052  3286 solver.cpp:237] Iteration 850, loss = 0.000566713
I0204 16:59:31.412122  3286 solver.cpp:253]     Train net output #0: loss = 0.000566602 (* 1 = 0.000566602 loss)
I0204 16:59:31.412134  3286 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 16:59:51.434900  3286 solver.cpp:237] Iteration 860, loss = 0.000541851
I0204 16:59:51.435077  3286 solver.cpp:253]     Train net output #0: loss = 0.00054174 (* 1 = 0.00054174 loss)
I0204 16:59:51.435091  3286 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 17:00:11.501190  3286 solver.cpp:237] Iteration 870, loss = 0.00329733
I0204 17:00:11.501260  3286 solver.cpp:253]     Train net output #0: loss = 0.00329722 (* 1 = 0.00329722 loss)
I0204 17:00:11.501273  3286 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 17:00:31.518090  3286 solver.cpp:237] Iteration 880, loss = 0.00244004
I0204 17:00:31.518332  3286 solver.cpp:253]     Train net output #0: loss = 0.00243993 (* 1 = 0.00243993 loss)
I0204 17:00:31.518347  3286 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 17:00:51.488598  3286 solver.cpp:237] Iteration 890, loss = 0.00636581
I0204 17:00:51.488663  3286 solver.cpp:253]     Train net output #0: loss = 0.0063657 (* 1 = 0.0063657 loss)
I0204 17:00:51.488675  3286 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 17:01:09.390661  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_900.caffemodel
I0204 17:01:09.394562  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_900.solverstate
I0204 17:01:09.396098  3286 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 17:01:18.665508  3286 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 17:01:18.665568  3286 solver.cpp:409]     Test net output #1: loss = 0.0133677 (* 1 = 0.0133677 loss)
I0204 17:01:20.653250  3286 solver.cpp:237] Iteration 900, loss = 0.061485
I0204 17:01:20.653309  3286 solver.cpp:253]     Train net output #0: loss = 0.0614849 (* 1 = 0.0614849 loss)
I0204 17:01:20.653321  3286 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 17:01:40.555946  3286 solver.cpp:237] Iteration 910, loss = 0.0522543
I0204 17:01:40.556200  3286 solver.cpp:253]     Train net output #0: loss = 0.0522542 (* 1 = 0.0522542 loss)
I0204 17:01:40.556213  3286 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 17:02:00.468466  3286 solver.cpp:237] Iteration 920, loss = 0.0503504
I0204 17:02:00.468534  3286 solver.cpp:253]     Train net output #0: loss = 0.0503503 (* 1 = 0.0503503 loss)
I0204 17:02:00.468546  3286 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 17:02:20.617271  3286 solver.cpp:237] Iteration 930, loss = 0.00707201
I0204 17:02:20.617483  3286 solver.cpp:253]     Train net output #0: loss = 0.0070719 (* 1 = 0.0070719 loss)
I0204 17:02:20.617496  3286 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 17:02:40.920375  3286 solver.cpp:237] Iteration 940, loss = 0.00152561
I0204 17:02:40.920450  3286 solver.cpp:253]     Train net output #0: loss = 0.0015255 (* 1 = 0.0015255 loss)
I0204 17:02:40.920462  3286 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 17:03:01.430480  3286 solver.cpp:237] Iteration 950, loss = 0.00276619
I0204 17:03:01.430676  3286 solver.cpp:253]     Train net output #0: loss = 0.00276608 (* 1 = 0.00276608 loss)
I0204 17:03:01.430690  3286 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 17:03:21.139156  3286 solver.cpp:237] Iteration 960, loss = 0.00775018
I0204 17:03:21.139222  3286 solver.cpp:253]     Train net output #0: loss = 0.00775007 (* 1 = 0.00775007 loss)
I0204 17:03:21.139235  3286 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 17:03:39.764108  3286 solver.cpp:237] Iteration 970, loss = 0.0144161
I0204 17:03:39.764325  3286 solver.cpp:253]     Train net output #0: loss = 0.014416 (* 1 = 0.014416 loss)
I0204 17:03:39.764339  3286 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 17:03:58.527793  3286 solver.cpp:237] Iteration 980, loss = 0.00119557
I0204 17:03:58.527865  3286 solver.cpp:253]     Train net output #0: loss = 0.00119546 (* 1 = 0.00119546 loss)
I0204 17:03:58.527878  3286 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 17:04:17.144428  3286 solver.cpp:237] Iteration 990, loss = 0.00179405
I0204 17:04:17.144613  3286 solver.cpp:253]     Train net output #0: loss = 0.00179394 (* 1 = 0.00179394 loss)
I0204 17:04:17.144628  3286 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 17:04:33.930425  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1000.caffemodel
I0204 17:04:33.933930  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1000.solverstate
I0204 17:04:33.935297  3286 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 17:04:42.689294  3286 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:04:42.689354  3286 solver.cpp:409]     Test net output #1: loss = 0.0101584 (* 1 = 0.0101584 loss)
I0204 17:04:44.554607  3286 solver.cpp:237] Iteration 1000, loss = 0.0681532
I0204 17:04:44.554675  3286 solver.cpp:253]     Train net output #0: loss = 0.0681531 (* 1 = 0.0681531 loss)
I0204 17:04:44.554692  3286 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 17:05:03.220330  3286 solver.cpp:237] Iteration 1010, loss = 0.00850864
I0204 17:05:03.220603  3286 solver.cpp:253]     Train net output #0: loss = 0.00850853 (* 1 = 0.00850853 loss)
I0204 17:05:03.220618  3286 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 17:05:21.883503  3286 solver.cpp:237] Iteration 1020, loss = 0.000766673
I0204 17:05:21.883563  3286 solver.cpp:253]     Train net output #0: loss = 0.000766565 (* 1 = 0.000766565 loss)
I0204 17:05:21.883574  3286 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 17:05:40.479200  3286 solver.cpp:237] Iteration 1030, loss = 0.00097033
I0204 17:05:40.479476  3286 solver.cpp:253]     Train net output #0: loss = 0.00097022 (* 1 = 0.00097022 loss)
I0204 17:05:40.479491  3286 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 17:05:58.856230  3286 solver.cpp:237] Iteration 1040, loss = 0.0018112
I0204 17:05:58.856289  3286 solver.cpp:253]     Train net output #0: loss = 0.00181109 (* 1 = 0.00181109 loss)
I0204 17:05:58.856302  3286 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 17:06:17.284598  3286 solver.cpp:237] Iteration 1050, loss = 0.00967263
I0204 17:06:17.284793  3286 solver.cpp:253]     Train net output #0: loss = 0.00967252 (* 1 = 0.00967252 loss)
I0204 17:06:17.284807  3286 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 17:06:35.812525  3286 solver.cpp:237] Iteration 1060, loss = 0.00616679
I0204 17:06:35.812587  3286 solver.cpp:253]     Train net output #0: loss = 0.00616668 (* 1 = 0.00616668 loss)
I0204 17:06:35.812598  3286 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 17:06:54.451634  3286 solver.cpp:237] Iteration 1070, loss = 0.0273604
I0204 17:06:54.451820  3286 solver.cpp:253]     Train net output #0: loss = 0.0273603 (* 1 = 0.0273603 loss)
I0204 17:06:54.451834  3286 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 17:07:13.278868  3286 solver.cpp:237] Iteration 1080, loss = 0.00202165
I0204 17:07:13.278936  3286 solver.cpp:253]     Train net output #0: loss = 0.00202154 (* 1 = 0.00202154 loss)
I0204 17:07:13.278949  3286 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 17:07:31.884660  3286 solver.cpp:237] Iteration 1090, loss = 0.000341678
I0204 17:07:31.884865  3286 solver.cpp:253]     Train net output #0: loss = 0.000341567 (* 1 = 0.000341567 loss)
I0204 17:07:31.884879  3286 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 17:07:49.075955  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1100.caffemodel
I0204 17:07:49.079371  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1100.solverstate
I0204 17:07:49.080749  3286 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 17:07:57.783995  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:07:57.784046  3286 solver.cpp:409]     Test net output #1: loss = 0.00611909 (* 1 = 0.00611909 loss)
I0204 17:07:59.647320  3286 solver.cpp:237] Iteration 1100, loss = 0.000862396
I0204 17:07:59.647380  3286 solver.cpp:253]     Train net output #0: loss = 0.000862286 (* 1 = 0.000862286 loss)
I0204 17:07:59.647392  3286 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 17:08:18.246788  3286 solver.cpp:237] Iteration 1110, loss = 0.00758275
I0204 17:08:18.247017  3286 solver.cpp:253]     Train net output #0: loss = 0.00758264 (* 1 = 0.00758264 loss)
I0204 17:08:18.247032  3286 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 17:08:36.568341  3286 solver.cpp:237] Iteration 1120, loss = 0.00116703
I0204 17:08:36.568405  3286 solver.cpp:253]     Train net output #0: loss = 0.00116693 (* 1 = 0.00116693 loss)
I0204 17:08:36.568416  3286 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 17:08:55.321223  3286 solver.cpp:237] Iteration 1130, loss = 0.0394194
I0204 17:08:55.321450  3286 solver.cpp:253]     Train net output #0: loss = 0.0394193 (* 1 = 0.0394193 loss)
I0204 17:08:55.321465  3286 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 17:09:14.627965  3286 solver.cpp:237] Iteration 1140, loss = 0.042098
I0204 17:09:14.628031  3286 solver.cpp:253]     Train net output #0: loss = 0.0420979 (* 1 = 0.0420979 loss)
I0204 17:09:14.628042  3286 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 17:09:34.252696  3286 solver.cpp:237] Iteration 1150, loss = 0.0130962
I0204 17:09:34.252888  3286 solver.cpp:253]     Train net output #0: loss = 0.0130961 (* 1 = 0.0130961 loss)
I0204 17:09:34.252902  3286 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 17:09:54.345170  3286 solver.cpp:237] Iteration 1160, loss = 0.000602067
I0204 17:09:54.345230  3286 solver.cpp:253]     Train net output #0: loss = 0.000601966 (* 1 = 0.000601966 loss)
I0204 17:09:54.345242  3286 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 17:10:14.386834  3286 solver.cpp:237] Iteration 1170, loss = 0.00284397
I0204 17:10:14.387040  3286 solver.cpp:253]     Train net output #0: loss = 0.00284387 (* 1 = 0.00284387 loss)
I0204 17:10:14.387054  3286 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 17:10:34.580394  3286 solver.cpp:237] Iteration 1180, loss = 0.000813499
I0204 17:10:34.580457  3286 solver.cpp:253]     Train net output #0: loss = 0.000813395 (* 1 = 0.000813395 loss)
I0204 17:10:34.580469  3286 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 17:10:54.157521  3286 solver.cpp:237] Iteration 1190, loss = 0.000865937
I0204 17:10:54.157716  3286 solver.cpp:253]     Train net output #0: loss = 0.000865833 (* 1 = 0.000865833 loss)
I0204 17:10:54.157728  3286 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 17:11:11.284171  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1200.caffemodel
I0204 17:11:11.287891  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1200.solverstate
I0204 17:11:11.289392  3286 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 17:11:20.350883  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:11:20.350947  3286 solver.cpp:409]     Test net output #1: loss = 0.00327383 (* 1 = 0.00327383 loss)
I0204 17:11:22.242017  3286 solver.cpp:237] Iteration 1200, loss = 0.000771318
I0204 17:11:22.242071  3286 solver.cpp:253]     Train net output #0: loss = 0.000771214 (* 1 = 0.000771214 loss)
I0204 17:11:22.242082  3286 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 17:11:40.744120  3286 solver.cpp:237] Iteration 1210, loss = 0.00608593
I0204 17:11:40.744307  3286 solver.cpp:253]     Train net output #0: loss = 0.00608582 (* 1 = 0.00608582 loss)
I0204 17:11:40.744321  3286 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 17:12:00.254591  3286 solver.cpp:237] Iteration 1220, loss = 0.00196847
I0204 17:12:00.254657  3286 solver.cpp:253]     Train net output #0: loss = 0.00196837 (* 1 = 0.00196837 loss)
I0204 17:12:00.254668  3286 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 17:12:20.315883  3286 solver.cpp:237] Iteration 1230, loss = 0.0014837
I0204 17:12:20.316071  3286 solver.cpp:253]     Train net output #0: loss = 0.0014836 (* 1 = 0.0014836 loss)
I0204 17:12:20.316084  3286 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 17:12:40.377162  3286 solver.cpp:237] Iteration 1240, loss = 0.00798996
I0204 17:12:40.377233  3286 solver.cpp:253]     Train net output #0: loss = 0.00798986 (* 1 = 0.00798986 loss)
I0204 17:12:40.377264  3286 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 17:13:00.513458  3286 solver.cpp:237] Iteration 1250, loss = 0.00340919
I0204 17:13:00.513694  3286 solver.cpp:253]     Train net output #0: loss = 0.00340909 (* 1 = 0.00340909 loss)
I0204 17:13:00.513707  3286 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 17:13:20.686877  3286 solver.cpp:237] Iteration 1260, loss = 0.00749683
I0204 17:13:20.686940  3286 solver.cpp:253]     Train net output #0: loss = 0.00749674 (* 1 = 0.00749674 loss)
I0204 17:13:20.686952  3286 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 17:13:40.742389  3286 solver.cpp:237] Iteration 1270, loss = 0.000441277
I0204 17:13:40.742597  3286 solver.cpp:253]     Train net output #0: loss = 0.000441184 (* 1 = 0.000441184 loss)
I0204 17:13:40.742610  3286 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 17:14:00.315495  3286 solver.cpp:237] Iteration 1280, loss = 0.000781924
I0204 17:14:00.315557  3286 solver.cpp:253]     Train net output #0: loss = 0.000781832 (* 1 = 0.000781832 loss)
I0204 17:14:00.315568  3286 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 17:14:20.118836  3286 solver.cpp:237] Iteration 1290, loss = 0.00267369
I0204 17:14:20.119035  3286 solver.cpp:253]     Train net output #0: loss = 0.0026736 (* 1 = 0.0026736 loss)
I0204 17:14:20.119048  3286 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 17:14:38.017315  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1300.caffemodel
I0204 17:14:38.021143  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1300.solverstate
I0204 17:14:38.022665  3286 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 17:14:47.291323  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:14:47.291388  3286 solver.cpp:409]     Test net output #1: loss = 0.00204019 (* 1 = 0.00204019 loss)
I0204 17:14:49.271462  3286 solver.cpp:237] Iteration 1300, loss = 0.000303697
I0204 17:14:49.271518  3286 solver.cpp:253]     Train net output #0: loss = 0.000303606 (* 1 = 0.000303606 loss)
I0204 17:14:49.271529  3286 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 17:15:08.393378  3286 solver.cpp:237] Iteration 1310, loss = 0.00532736
I0204 17:15:08.393604  3286 solver.cpp:253]     Train net output #0: loss = 0.00532726 (* 1 = 0.00532726 loss)
I0204 17:15:08.393620  3286 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 17:15:26.973752  3286 solver.cpp:237] Iteration 1320, loss = 0.00101651
I0204 17:15:26.973810  3286 solver.cpp:253]     Train net output #0: loss = 0.00101643 (* 1 = 0.00101643 loss)
I0204 17:15:26.973822  3286 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 17:15:45.521746  3286 solver.cpp:237] Iteration 1330, loss = 8.52197e-05
I0204 17:15:45.521940  3286 solver.cpp:253]     Train net output #0: loss = 8.51304e-05 (* 1 = 8.51304e-05 loss)
I0204 17:15:45.521955  3286 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 17:16:04.247985  3286 solver.cpp:237] Iteration 1340, loss = 0.000791029
I0204 17:16:04.248049  3286 solver.cpp:253]     Train net output #0: loss = 0.000790939 (* 1 = 0.000790939 loss)
I0204 17:16:04.248060  3286 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 17:16:22.800237  3286 solver.cpp:237] Iteration 1350, loss = 0.00100111
I0204 17:16:22.800417  3286 solver.cpp:253]     Train net output #0: loss = 0.00100102 (* 1 = 0.00100102 loss)
I0204 17:16:22.800431  3286 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 17:16:41.220749  3286 solver.cpp:237] Iteration 1360, loss = 0.0321074
I0204 17:16:41.220815  3286 solver.cpp:253]     Train net output #0: loss = 0.0321073 (* 1 = 0.0321073 loss)
I0204 17:16:41.220826  3286 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 17:16:59.690274  3286 solver.cpp:237] Iteration 1370, loss = 0.000172519
I0204 17:16:59.690531  3286 solver.cpp:253]     Train net output #0: loss = 0.000172428 (* 1 = 0.000172428 loss)
I0204 17:16:59.690546  3286 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 17:17:18.238162  3286 solver.cpp:237] Iteration 1380, loss = 0.00887249
I0204 17:17:18.238224  3286 solver.cpp:253]     Train net output #0: loss = 0.0088724 (* 1 = 0.0088724 loss)
I0204 17:17:18.238235  3286 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 17:17:36.753350  3286 solver.cpp:237] Iteration 1390, loss = 0.00480021
I0204 17:17:36.753538  3286 solver.cpp:253]     Train net output #0: loss = 0.00480012 (* 1 = 0.00480012 loss)
I0204 17:17:36.753552  3286 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 17:17:53.561954  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1400.caffemodel
I0204 17:17:53.565387  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1400.solverstate
I0204 17:17:53.566736  3286 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 17:18:02.308364  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:18:02.308425  3286 solver.cpp:409]     Test net output #1: loss = 0.00593713 (* 1 = 0.00593713 loss)
I0204 17:18:04.164420  3286 solver.cpp:237] Iteration 1400, loss = 0.00109238
I0204 17:18:04.164479  3286 solver.cpp:253]     Train net output #0: loss = 0.00109229 (* 1 = 0.00109229 loss)
I0204 17:18:04.164491  3286 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 17:18:22.936489  3286 solver.cpp:237] Iteration 1410, loss = 0.000796686
I0204 17:18:22.936676  3286 solver.cpp:253]     Train net output #0: loss = 0.000796603 (* 1 = 0.000796603 loss)
I0204 17:18:22.936689  3286 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 17:18:41.781710  3286 solver.cpp:237] Iteration 1420, loss = 0.000947401
I0204 17:18:41.781766  3286 solver.cpp:253]     Train net output #0: loss = 0.000947318 (* 1 = 0.000947318 loss)
I0204 17:18:41.781779  3286 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 17:19:00.490988  3286 solver.cpp:237] Iteration 1430, loss = 0.00733194
I0204 17:19:00.491185  3286 solver.cpp:253]     Train net output #0: loss = 0.00733185 (* 1 = 0.00733185 loss)
I0204 17:19:00.491199  3286 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 17:19:19.173636  3286 solver.cpp:237] Iteration 1440, loss = 0.000216544
I0204 17:19:19.173698  3286 solver.cpp:253]     Train net output #0: loss = 0.00021646 (* 1 = 0.00021646 loss)
I0204 17:19:19.173709  3286 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 17:19:38.014569  3286 solver.cpp:237] Iteration 1450, loss = 0.0241859
I0204 17:19:38.014770  3286 solver.cpp:253]     Train net output #0: loss = 0.0241858 (* 1 = 0.0241858 loss)
I0204 17:19:38.014785  3286 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 17:19:57.102413  3286 solver.cpp:237] Iteration 1460, loss = 0.000617468
I0204 17:19:57.102473  3286 solver.cpp:253]     Train net output #0: loss = 0.000617379 (* 1 = 0.000617379 loss)
I0204 17:19:57.102484  3286 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 17:20:16.180907  3286 solver.cpp:237] Iteration 1470, loss = 0.00124441
I0204 17:20:16.181128  3286 solver.cpp:253]     Train net output #0: loss = 0.00124432 (* 1 = 0.00124432 loss)
I0204 17:20:16.181141  3286 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 17:20:35.106276  3286 solver.cpp:237] Iteration 1480, loss = 0.0038168
I0204 17:20:35.106336  3286 solver.cpp:253]     Train net output #0: loss = 0.00381671 (* 1 = 0.00381671 loss)
I0204 17:20:35.106360  3286 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 17:20:54.002910  3286 solver.cpp:237] Iteration 1490, loss = 0.000665828
I0204 17:20:54.003119  3286 solver.cpp:253]     Train net output #0: loss = 0.000665739 (* 1 = 0.000665739 loss)
I0204 17:20:54.003134  3286 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 17:21:11.065377  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1500.caffemodel
I0204 17:21:11.068965  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1500.solverstate
I0204 17:21:11.070466  3286 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 17:21:19.936879  3286 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 17:21:19.936939  3286 solver.cpp:409]     Test net output #1: loss = 0.0143017 (* 1 = 0.0143017 loss)
I0204 17:21:21.898067  3286 solver.cpp:237] Iteration 1500, loss = 0.00295026
I0204 17:21:21.898123  3286 solver.cpp:253]     Train net output #0: loss = 0.00295017 (* 1 = 0.00295017 loss)
I0204 17:21:21.898134  3286 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 17:21:40.854564  3286 solver.cpp:237] Iteration 1510, loss = 0.00167564
I0204 17:21:40.854825  3286 solver.cpp:253]     Train net output #0: loss = 0.00167556 (* 1 = 0.00167556 loss)
I0204 17:21:40.854840  3286 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 17:21:59.691659  3286 solver.cpp:237] Iteration 1520, loss = 0.000974964
I0204 17:21:59.691721  3286 solver.cpp:253]     Train net output #0: loss = 0.000974877 (* 1 = 0.000974877 loss)
I0204 17:21:59.691732  3286 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 17:22:18.421670  3286 solver.cpp:237] Iteration 1530, loss = 0.00191317
I0204 17:22:18.421905  3286 solver.cpp:253]     Train net output #0: loss = 0.00191308 (* 1 = 0.00191308 loss)
I0204 17:22:18.421919  3286 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 17:22:36.992441  3286 solver.cpp:237] Iteration 1540, loss = 0.000606852
I0204 17:22:36.992506  3286 solver.cpp:253]     Train net output #0: loss = 0.000606763 (* 1 = 0.000606763 loss)
I0204 17:22:36.992517  3286 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 17:22:55.582839  3286 solver.cpp:237] Iteration 1550, loss = 0.00180085
I0204 17:22:55.583031  3286 solver.cpp:253]     Train net output #0: loss = 0.00180076 (* 1 = 0.00180076 loss)
I0204 17:22:55.583045  3286 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 17:23:14.127547  3286 solver.cpp:237] Iteration 1560, loss = 0.000400494
I0204 17:23:14.127614  3286 solver.cpp:253]     Train net output #0: loss = 0.000400404 (* 1 = 0.000400404 loss)
I0204 17:23:14.127625  3286 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 17:23:32.741832  3286 solver.cpp:237] Iteration 1570, loss = 0.00136769
I0204 17:23:32.742024  3286 solver.cpp:253]     Train net output #0: loss = 0.0013676 (* 1 = 0.0013676 loss)
I0204 17:23:32.742038  3286 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 17:23:51.390715  3286 solver.cpp:237] Iteration 1580, loss = 0.000753675
I0204 17:23:51.390772  3286 solver.cpp:253]     Train net output #0: loss = 0.000753585 (* 1 = 0.000753585 loss)
I0204 17:23:51.390784  3286 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 17:24:10.119097  3286 solver.cpp:237] Iteration 1590, loss = 0.000158231
I0204 17:24:10.119295  3286 solver.cpp:253]     Train net output #0: loss = 0.000158142 (* 1 = 0.000158142 loss)
I0204 17:24:10.119309  3286 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 17:24:26.903942  3286 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1600.caffemodel
I0204 17:24:26.907440  3286 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed1/snaps/snap__iter_1600.solverstate
I0204 17:24:27.793627  3286 solver.cpp:321] Iteration 1600, loss = 0.00045964
I0204 17:24:27.793673  3286 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 17:24:36.587764  3286 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:24:36.587821  3286 solver.cpp:409]     Test net output #1: loss = 0.00412976 (* 1 = 0.00412976 loss)
I0204 17:24:36.587842  3286 solver.cpp:326] Optimization Done.
I0204 17:24:36.587849  3286 caffe.cpp:215] Optimization Done.
