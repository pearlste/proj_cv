I0204 18:49:43.995928  5458 caffe.cpp:177] Use CPU.
I0204 18:49:43.996748  5458 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap_"
solver_mode: CPU
random_seed: 11
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/train_val.prototxt"
I0204 18:49:43.997485  5458 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/train_val.prototxt
I0204 18:49:43.998105  5458 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 18:49:43.998138  5458 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 18:49:43.998386  5458 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 18:49:43.998522  5458 layer_factory.hpp:77] Creating layer data
I0204 18:49:43.998708  5458 net.cpp:106] Creating Layer data
I0204 18:49:43.998724  5458 net.cpp:411] data -> data
I0204 18:49:43.998817  5458 net.cpp:411] data -> label
I0204 18:49:43.998845  5458 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 18:49:43.999037  5459 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 18:49:44.000010  5458 data_layer.cpp:41] output data size: 100,1,227,227
I0204 18:49:44.027230  5458 net.cpp:150] Setting up data
I0204 18:49:44.027305  5458 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 18:49:44.027314  5458 net.cpp:157] Top shape: 100 (100)
I0204 18:49:44.027320  5458 net.cpp:165] Memory required for data: 20612000
I0204 18:49:44.027338  5458 layer_factory.hpp:77] Creating layer conv1
I0204 18:49:44.027361  5458 net.cpp:106] Creating Layer conv1
I0204 18:49:44.027370  5458 net.cpp:454] conv1 <- data
I0204 18:49:44.027390  5458 net.cpp:411] conv1 -> conv1
I0204 18:49:44.027518  5458 net.cpp:150] Setting up conv1
I0204 18:49:44.027530  5458 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 18:49:44.027535  5458 net.cpp:165] Memory required for data: 59332000
I0204 18:49:44.027556  5458 layer_factory.hpp:77] Creating layer relu1
I0204 18:49:44.027568  5458 net.cpp:106] Creating Layer relu1
I0204 18:49:44.027575  5458 net.cpp:454] relu1 <- conv1
I0204 18:49:44.027583  5458 net.cpp:397] relu1 -> conv1 (in-place)
I0204 18:49:44.027597  5458 net.cpp:150] Setting up relu1
I0204 18:49:44.027606  5458 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 18:49:44.027611  5458 net.cpp:165] Memory required for data: 98052000
I0204 18:49:44.027616  5458 layer_factory.hpp:77] Creating layer pool1
I0204 18:49:44.027626  5458 net.cpp:106] Creating Layer pool1
I0204 18:49:44.027631  5458 net.cpp:454] pool1 <- conv1
I0204 18:49:44.027640  5458 net.cpp:411] pool1 -> pool1
I0204 18:49:44.027668  5458 net.cpp:150] Setting up pool1
I0204 18:49:44.027676  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.027683  5458 net.cpp:165] Memory required for data: 107383200
I0204 18:49:44.027688  5458 layer_factory.hpp:77] Creating layer norm1
I0204 18:49:44.027714  5458 net.cpp:106] Creating Layer norm1
I0204 18:49:44.027719  5458 net.cpp:454] norm1 <- pool1
I0204 18:49:44.027729  5458 net.cpp:411] norm1 -> norm1
I0204 18:49:44.027750  5458 net.cpp:150] Setting up norm1
I0204 18:49:44.027758  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.027763  5458 net.cpp:165] Memory required for data: 116714400
I0204 18:49:44.027770  5458 layer_factory.hpp:77] Creating layer conv2
I0204 18:49:44.027778  5458 net.cpp:106] Creating Layer conv2
I0204 18:49:44.027784  5458 net.cpp:454] conv2 <- norm1
I0204 18:49:44.027792  5458 net.cpp:411] conv2 -> conv2
I0204 18:49:44.027921  5458 net.cpp:150] Setting up conv2
I0204 18:49:44.027931  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.027937  5458 net.cpp:165] Memory required for data: 126045600
I0204 18:49:44.027950  5458 layer_factory.hpp:77] Creating layer relu2
I0204 18:49:44.027957  5458 net.cpp:106] Creating Layer relu2
I0204 18:49:44.027963  5458 net.cpp:454] relu2 <- conv2
I0204 18:49:44.027981  5458 net.cpp:397] relu2 -> conv2 (in-place)
I0204 18:49:44.027992  5458 net.cpp:150] Setting up relu2
I0204 18:49:44.027998  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.028004  5458 net.cpp:165] Memory required for data: 135376800
I0204 18:49:44.028009  5458 layer_factory.hpp:77] Creating layer pool2
I0204 18:49:44.028020  5458 net.cpp:106] Creating Layer pool2
I0204 18:49:44.028026  5458 net.cpp:454] pool2 <- conv2
I0204 18:49:44.028033  5458 net.cpp:411] pool2 -> pool2
I0204 18:49:44.028045  5458 net.cpp:150] Setting up pool2
I0204 18:49:44.028053  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028059  5458 net.cpp:165] Memory required for data: 137540000
I0204 18:49:44.028064  5458 layer_factory.hpp:77] Creating layer norm2
I0204 18:49:44.028074  5458 net.cpp:106] Creating Layer norm2
I0204 18:49:44.028079  5458 net.cpp:454] norm2 <- pool2
I0204 18:49:44.028100  5458 net.cpp:411] norm2 -> norm2
I0204 18:49:44.028115  5458 net.cpp:150] Setting up norm2
I0204 18:49:44.028122  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028127  5458 net.cpp:165] Memory required for data: 139703200
I0204 18:49:44.028133  5458 layer_factory.hpp:77] Creating layer conv3
I0204 18:49:44.028142  5458 net.cpp:106] Creating Layer conv3
I0204 18:49:44.028147  5458 net.cpp:454] conv3 <- norm2
I0204 18:49:44.028158  5458 net.cpp:411] conv3 -> conv3
I0204 18:49:44.028269  5458 net.cpp:150] Setting up conv3
I0204 18:49:44.028278  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028286  5458 net.cpp:165] Memory required for data: 141866400
I0204 18:49:44.028297  5458 layer_factory.hpp:77] Creating layer relu3
I0204 18:49:44.028306  5458 net.cpp:106] Creating Layer relu3
I0204 18:49:44.028311  5458 net.cpp:454] relu3 <- conv3
I0204 18:49:44.028322  5458 net.cpp:397] relu3 -> conv3 (in-place)
I0204 18:49:44.028332  5458 net.cpp:150] Setting up relu3
I0204 18:49:44.028338  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028344  5458 net.cpp:165] Memory required for data: 144029600
I0204 18:49:44.028349  5458 layer_factory.hpp:77] Creating layer conv4
I0204 18:49:44.028357  5458 net.cpp:106] Creating Layer conv4
I0204 18:49:44.028363  5458 net.cpp:454] conv4 <- conv3
I0204 18:49:44.028376  5458 net.cpp:411] conv4 -> conv4
I0204 18:49:44.028456  5458 net.cpp:150] Setting up conv4
I0204 18:49:44.028468  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028473  5458 net.cpp:165] Memory required for data: 146192800
I0204 18:49:44.028481  5458 layer_factory.hpp:77] Creating layer relu4
I0204 18:49:44.028489  5458 net.cpp:106] Creating Layer relu4
I0204 18:49:44.028494  5458 net.cpp:454] relu4 <- conv4
I0204 18:49:44.028502  5458 net.cpp:397] relu4 -> conv4 (in-place)
I0204 18:49:44.028511  5458 net.cpp:150] Setting up relu4
I0204 18:49:44.028517  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.028522  5458 net.cpp:165] Memory required for data: 148356000
I0204 18:49:44.028533  5458 layer_factory.hpp:77] Creating layer conv5
I0204 18:49:44.028553  5458 net.cpp:106] Creating Layer conv5
I0204 18:49:44.028559  5458 net.cpp:454] conv5 <- conv4
I0204 18:49:44.028568  5458 net.cpp:411] conv5 -> conv5
I0204 18:49:44.028614  5458 net.cpp:150] Setting up conv5
I0204 18:49:44.028623  5458 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 18:49:44.028628  5458 net.cpp:165] Memory required for data: 149437600
I0204 18:49:44.028640  5458 layer_factory.hpp:77] Creating layer relu5
I0204 18:49:44.028652  5458 net.cpp:106] Creating Layer relu5
I0204 18:49:44.028658  5458 net.cpp:454] relu5 <- conv5
I0204 18:49:44.028666  5458 net.cpp:397] relu5 -> conv5 (in-place)
I0204 18:49:44.028676  5458 net.cpp:150] Setting up relu5
I0204 18:49:44.028682  5458 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 18:49:44.028687  5458 net.cpp:165] Memory required for data: 150519200
I0204 18:49:44.028693  5458 layer_factory.hpp:77] Creating layer pool5
I0204 18:49:44.028700  5458 net.cpp:106] Creating Layer pool5
I0204 18:49:44.028707  5458 net.cpp:454] pool5 <- conv5
I0204 18:49:44.028717  5458 net.cpp:411] pool5 -> pool5
I0204 18:49:44.028730  5458 net.cpp:150] Setting up pool5
I0204 18:49:44.028738  5458 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 18:49:44.028743  5458 net.cpp:165] Memory required for data: 150749600
I0204 18:49:44.028749  5458 layer_factory.hpp:77] Creating layer fc6
I0204 18:49:44.028767  5458 net.cpp:106] Creating Layer fc6
I0204 18:49:44.028774  5458 net.cpp:454] fc6 <- pool5
I0204 18:49:44.028781  5458 net.cpp:411] fc6 -> fc6
I0204 18:49:44.030470  5458 net.cpp:150] Setting up fc6
I0204 18:49:44.030483  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.030489  5458 net.cpp:165] Memory required for data: 150852000
I0204 18:49:44.030498  5458 layer_factory.hpp:77] Creating layer relu6
I0204 18:49:44.030509  5458 net.cpp:106] Creating Layer relu6
I0204 18:49:44.030515  5458 net.cpp:454] relu6 <- fc6
I0204 18:49:44.030524  5458 net.cpp:397] relu6 -> fc6 (in-place)
I0204 18:49:44.030534  5458 net.cpp:150] Setting up relu6
I0204 18:49:44.030540  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.030545  5458 net.cpp:165] Memory required for data: 150954400
I0204 18:49:44.030551  5458 layer_factory.hpp:77] Creating layer drop6
I0204 18:49:44.030562  5458 net.cpp:106] Creating Layer drop6
I0204 18:49:44.030570  5458 net.cpp:454] drop6 <- fc6
I0204 18:49:44.030576  5458 net.cpp:397] drop6 -> fc6 (in-place)
I0204 18:49:44.030596  5458 net.cpp:150] Setting up drop6
I0204 18:49:44.030602  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.030607  5458 net.cpp:165] Memory required for data: 151056800
I0204 18:49:44.030613  5458 layer_factory.hpp:77] Creating layer fc7
I0204 18:49:44.030622  5458 net.cpp:106] Creating Layer fc7
I0204 18:49:44.030628  5458 net.cpp:454] fc7 <- fc6
I0204 18:49:44.030639  5458 net.cpp:411] fc7 -> fc7
I0204 18:49:44.031364  5458 net.cpp:150] Setting up fc7
I0204 18:49:44.031376  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.031383  5458 net.cpp:165] Memory required for data: 151159200
I0204 18:49:44.031393  5458 layer_factory.hpp:77] Creating layer relu7
I0204 18:49:44.031400  5458 net.cpp:106] Creating Layer relu7
I0204 18:49:44.031406  5458 net.cpp:454] relu7 <- fc7
I0204 18:49:44.031417  5458 net.cpp:397] relu7 -> fc7 (in-place)
I0204 18:49:44.031426  5458 net.cpp:150] Setting up relu7
I0204 18:49:44.031433  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.031440  5458 net.cpp:165] Memory required for data: 151261600
I0204 18:49:44.031445  5458 layer_factory.hpp:77] Creating layer drop7
I0204 18:49:44.031452  5458 net.cpp:106] Creating Layer drop7
I0204 18:49:44.031458  5458 net.cpp:454] drop7 <- fc7
I0204 18:49:44.031468  5458 net.cpp:397] drop7 -> fc7 (in-place)
I0204 18:49:44.031481  5458 net.cpp:150] Setting up drop7
I0204 18:49:44.031487  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.031492  5458 net.cpp:165] Memory required for data: 151364000
I0204 18:49:44.031498  5458 layer_factory.hpp:77] Creating layer fc8
I0204 18:49:44.031512  5458 net.cpp:106] Creating Layer fc8
I0204 18:49:44.031524  5458 net.cpp:454] fc8 <- fc7
I0204 18:49:44.031535  5458 net.cpp:411] fc8 -> fc8
I0204 18:49:44.031558  5458 net.cpp:150] Setting up fc8
I0204 18:49:44.031569  5458 net.cpp:157] Top shape: 100 2 (200)
I0204 18:49:44.031574  5458 net.cpp:165] Memory required for data: 151364800
I0204 18:49:44.031582  5458 layer_factory.hpp:77] Creating layer loss
I0204 18:49:44.031594  5458 net.cpp:106] Creating Layer loss
I0204 18:49:44.031599  5458 net.cpp:454] loss <- fc8
I0204 18:49:44.031605  5458 net.cpp:454] loss <- label
I0204 18:49:44.031615  5458 net.cpp:411] loss -> loss
I0204 18:49:44.031630  5458 layer_factory.hpp:77] Creating layer loss
I0204 18:49:44.031661  5458 net.cpp:150] Setting up loss
I0204 18:49:44.031669  5458 net.cpp:157] Top shape: (1)
I0204 18:49:44.031674  5458 net.cpp:160]     with loss weight 1
I0204 18:49:44.031700  5458 net.cpp:165] Memory required for data: 151364804
I0204 18:49:44.031709  5458 net.cpp:226] loss needs backward computation.
I0204 18:49:44.031715  5458 net.cpp:226] fc8 needs backward computation.
I0204 18:49:44.031721  5458 net.cpp:226] drop7 needs backward computation.
I0204 18:49:44.031728  5458 net.cpp:226] relu7 needs backward computation.
I0204 18:49:44.031733  5458 net.cpp:226] fc7 needs backward computation.
I0204 18:49:44.031738  5458 net.cpp:226] drop6 needs backward computation.
I0204 18:49:44.031745  5458 net.cpp:226] relu6 needs backward computation.
I0204 18:49:44.031751  5458 net.cpp:226] fc6 needs backward computation.
I0204 18:49:44.031757  5458 net.cpp:226] pool5 needs backward computation.
I0204 18:49:44.031764  5458 net.cpp:226] relu5 needs backward computation.
I0204 18:49:44.031769  5458 net.cpp:226] conv5 needs backward computation.
I0204 18:49:44.031774  5458 net.cpp:226] relu4 needs backward computation.
I0204 18:49:44.031780  5458 net.cpp:226] conv4 needs backward computation.
I0204 18:49:44.031785  5458 net.cpp:226] relu3 needs backward computation.
I0204 18:49:44.031790  5458 net.cpp:226] conv3 needs backward computation.
I0204 18:49:44.031800  5458 net.cpp:226] norm2 needs backward computation.
I0204 18:49:44.031806  5458 net.cpp:226] pool2 needs backward computation.
I0204 18:49:44.031812  5458 net.cpp:226] relu2 needs backward computation.
I0204 18:49:44.031817  5458 net.cpp:226] conv2 needs backward computation.
I0204 18:49:44.031823  5458 net.cpp:226] norm1 needs backward computation.
I0204 18:49:44.031831  5458 net.cpp:226] pool1 needs backward computation.
I0204 18:49:44.031837  5458 net.cpp:226] relu1 needs backward computation.
I0204 18:49:44.031843  5458 net.cpp:226] conv1 needs backward computation.
I0204 18:49:44.031849  5458 net.cpp:228] data does not need backward computation.
I0204 18:49:44.031855  5458 net.cpp:270] This network produces output loss
I0204 18:49:44.031883  5458 net.cpp:283] Network initialization done.
I0204 18:49:44.035352  5458 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/train_val.prototxt
I0204 18:49:44.035413  5458 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 18:49:44.035748  5458 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 18:49:44.035934  5458 layer_factory.hpp:77] Creating layer data
I0204 18:49:44.036123  5458 net.cpp:106] Creating Layer data
I0204 18:49:44.036140  5458 net.cpp:411] data -> data
I0204 18:49:44.036155  5458 net.cpp:411] data -> label
I0204 18:49:44.036167  5458 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 18:49:44.036414  5463 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 18:49:44.037166  5458 data_layer.cpp:41] output data size: 100,1,227,227
I0204 18:49:44.065038  5458 net.cpp:150] Setting up data
I0204 18:49:44.065083  5458 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 18:49:44.065110  5458 net.cpp:157] Top shape: 100 (100)
I0204 18:49:44.065116  5458 net.cpp:165] Memory required for data: 20612000
I0204 18:49:44.065132  5458 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 18:49:44.065153  5458 net.cpp:106] Creating Layer label_data_1_split
I0204 18:49:44.065161  5458 net.cpp:454] label_data_1_split <- label
I0204 18:49:44.065174  5458 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 18:49:44.065193  5458 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 18:49:44.065207  5458 net.cpp:150] Setting up label_data_1_split
I0204 18:49:44.065218  5458 net.cpp:157] Top shape: 100 (100)
I0204 18:49:44.065224  5458 net.cpp:157] Top shape: 100 (100)
I0204 18:49:44.065230  5458 net.cpp:165] Memory required for data: 20612800
I0204 18:49:44.065237  5458 layer_factory.hpp:77] Creating layer conv1
I0204 18:49:44.065254  5458 net.cpp:106] Creating Layer conv1
I0204 18:49:44.065261  5458 net.cpp:454] conv1 <- data
I0204 18:49:44.065273  5458 net.cpp:411] conv1 -> conv1
I0204 18:49:44.065352  5458 net.cpp:150] Setting up conv1
I0204 18:49:44.065362  5458 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 18:49:44.065371  5458 net.cpp:165] Memory required for data: 59332800
I0204 18:49:44.065385  5458 layer_factory.hpp:77] Creating layer relu1
I0204 18:49:44.065397  5458 net.cpp:106] Creating Layer relu1
I0204 18:49:44.065402  5458 net.cpp:454] relu1 <- conv1
I0204 18:49:44.065412  5458 net.cpp:397] relu1 -> conv1 (in-place)
I0204 18:49:44.065421  5458 net.cpp:150] Setting up relu1
I0204 18:49:44.065431  5458 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 18:49:44.065438  5458 net.cpp:165] Memory required for data: 98052800
I0204 18:49:44.065444  5458 layer_factory.hpp:77] Creating layer pool1
I0204 18:49:44.065455  5458 net.cpp:106] Creating Layer pool1
I0204 18:49:44.065461  5458 net.cpp:454] pool1 <- conv1
I0204 18:49:44.065470  5458 net.cpp:411] pool1 -> pool1
I0204 18:49:44.065486  5458 net.cpp:150] Setting up pool1
I0204 18:49:44.065493  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.065500  5458 net.cpp:165] Memory required for data: 107384000
I0204 18:49:44.065505  5458 layer_factory.hpp:77] Creating layer norm1
I0204 18:49:44.065516  5458 net.cpp:106] Creating Layer norm1
I0204 18:49:44.065522  5458 net.cpp:454] norm1 <- pool1
I0204 18:49:44.065533  5458 net.cpp:411] norm1 -> norm1
I0204 18:49:44.065546  5458 net.cpp:150] Setting up norm1
I0204 18:49:44.065553  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.065558  5458 net.cpp:165] Memory required for data: 116715200
I0204 18:49:44.065564  5458 layer_factory.hpp:77] Creating layer conv2
I0204 18:49:44.065577  5458 net.cpp:106] Creating Layer conv2
I0204 18:49:44.065584  5458 net.cpp:454] conv2 <- norm1
I0204 18:49:44.065594  5458 net.cpp:411] conv2 -> conv2
I0204 18:49:44.065726  5458 net.cpp:150] Setting up conv2
I0204 18:49:44.065737  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.065742  5458 net.cpp:165] Memory required for data: 126046400
I0204 18:49:44.065753  5458 layer_factory.hpp:77] Creating layer relu2
I0204 18:49:44.065762  5458 net.cpp:106] Creating Layer relu2
I0204 18:49:44.065768  5458 net.cpp:454] relu2 <- conv2
I0204 18:49:44.065788  5458 net.cpp:397] relu2 -> conv2 (in-place)
I0204 18:49:44.065811  5458 net.cpp:150] Setting up relu2
I0204 18:49:44.065819  5458 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 18:49:44.065824  5458 net.cpp:165] Memory required for data: 135377600
I0204 18:49:44.065830  5458 layer_factory.hpp:77] Creating layer pool2
I0204 18:49:44.065840  5458 net.cpp:106] Creating Layer pool2
I0204 18:49:44.065846  5458 net.cpp:454] pool2 <- conv2
I0204 18:49:44.065855  5458 net.cpp:411] pool2 -> pool2
I0204 18:49:44.065866  5458 net.cpp:150] Setting up pool2
I0204 18:49:44.065877  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.065882  5458 net.cpp:165] Memory required for data: 137540800
I0204 18:49:44.065888  5458 layer_factory.hpp:77] Creating layer norm2
I0204 18:49:44.065897  5458 net.cpp:106] Creating Layer norm2
I0204 18:49:44.065903  5458 net.cpp:454] norm2 <- pool2
I0204 18:49:44.065912  5458 net.cpp:411] norm2 -> norm2
I0204 18:49:44.065922  5458 net.cpp:150] Setting up norm2
I0204 18:49:44.065929  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.065934  5458 net.cpp:165] Memory required for data: 139704000
I0204 18:49:44.065940  5458 layer_factory.hpp:77] Creating layer conv3
I0204 18:49:44.065953  5458 net.cpp:106] Creating Layer conv3
I0204 18:49:44.065959  5458 net.cpp:454] conv3 <- norm2
I0204 18:49:44.065970  5458 net.cpp:411] conv3 -> conv3
I0204 18:49:44.066071  5458 net.cpp:150] Setting up conv3
I0204 18:49:44.066081  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.066085  5458 net.cpp:165] Memory required for data: 141867200
I0204 18:49:44.066102  5458 layer_factory.hpp:77] Creating layer relu3
I0204 18:49:44.066112  5458 net.cpp:106] Creating Layer relu3
I0204 18:49:44.066120  5458 net.cpp:454] relu3 <- conv3
I0204 18:49:44.066129  5458 net.cpp:397] relu3 -> conv3 (in-place)
I0204 18:49:44.066140  5458 net.cpp:150] Setting up relu3
I0204 18:49:44.066148  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.066153  5458 net.cpp:165] Memory required for data: 144030400
I0204 18:49:44.066159  5458 layer_factory.hpp:77] Creating layer conv4
I0204 18:49:44.066169  5458 net.cpp:106] Creating Layer conv4
I0204 18:49:44.066177  5458 net.cpp:454] conv4 <- conv3
I0204 18:49:44.066187  5458 net.cpp:411] conv4 -> conv4
I0204 18:49:44.066247  5458 net.cpp:150] Setting up conv4
I0204 18:49:44.066256  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.066262  5458 net.cpp:165] Memory required for data: 146193600
I0204 18:49:44.066272  5458 layer_factory.hpp:77] Creating layer relu4
I0204 18:49:44.066280  5458 net.cpp:106] Creating Layer relu4
I0204 18:49:44.066287  5458 net.cpp:454] relu4 <- conv4
I0204 18:49:44.066295  5458 net.cpp:397] relu4 -> conv4 (in-place)
I0204 18:49:44.066304  5458 net.cpp:150] Setting up relu4
I0204 18:49:44.066310  5458 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 18:49:44.066316  5458 net.cpp:165] Memory required for data: 148356800
I0204 18:49:44.066323  5458 layer_factory.hpp:77] Creating layer conv5
I0204 18:49:44.066336  5458 net.cpp:106] Creating Layer conv5
I0204 18:49:44.066341  5458 net.cpp:454] conv5 <- conv4
I0204 18:49:44.066350  5458 net.cpp:411] conv5 -> conv5
I0204 18:49:44.066391  5458 net.cpp:150] Setting up conv5
I0204 18:49:44.066400  5458 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 18:49:44.066406  5458 net.cpp:165] Memory required for data: 149438400
I0204 18:49:44.066416  5458 layer_factory.hpp:77] Creating layer relu5
I0204 18:49:44.066427  5458 net.cpp:106] Creating Layer relu5
I0204 18:49:44.066433  5458 net.cpp:454] relu5 <- conv5
I0204 18:49:44.066442  5458 net.cpp:397] relu5 -> conv5 (in-place)
I0204 18:49:44.066452  5458 net.cpp:150] Setting up relu5
I0204 18:49:44.066458  5458 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 18:49:44.066463  5458 net.cpp:165] Memory required for data: 150520000
I0204 18:49:44.066471  5458 layer_factory.hpp:77] Creating layer pool5
I0204 18:49:44.066483  5458 net.cpp:106] Creating Layer pool5
I0204 18:49:44.066493  5458 net.cpp:454] pool5 <- conv5
I0204 18:49:44.066512  5458 net.cpp:411] pool5 -> pool5
I0204 18:49:44.066524  5458 net.cpp:150] Setting up pool5
I0204 18:49:44.066532  5458 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 18:49:44.066537  5458 net.cpp:165] Memory required for data: 150750400
I0204 18:49:44.066543  5458 layer_factory.hpp:77] Creating layer fc6
I0204 18:49:44.066555  5458 net.cpp:106] Creating Layer fc6
I0204 18:49:44.066561  5458 net.cpp:454] fc6 <- pool5
I0204 18:49:44.066573  5458 net.cpp:411] fc6 -> fc6
I0204 18:49:44.068197  5458 net.cpp:150] Setting up fc6
I0204 18:49:44.068209  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.068214  5458 net.cpp:165] Memory required for data: 150852800
I0204 18:49:44.068223  5458 layer_factory.hpp:77] Creating layer relu6
I0204 18:49:44.068233  5458 net.cpp:106] Creating Layer relu6
I0204 18:49:44.068239  5458 net.cpp:454] relu6 <- fc6
I0204 18:49:44.068248  5458 net.cpp:397] relu6 -> fc6 (in-place)
I0204 18:49:44.068258  5458 net.cpp:150] Setting up relu6
I0204 18:49:44.068265  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.068271  5458 net.cpp:165] Memory required for data: 150955200
I0204 18:49:44.068276  5458 layer_factory.hpp:77] Creating layer drop6
I0204 18:49:44.068287  5458 net.cpp:106] Creating Layer drop6
I0204 18:49:44.068294  5458 net.cpp:454] drop6 <- fc6
I0204 18:49:44.068305  5458 net.cpp:397] drop6 -> fc6 (in-place)
I0204 18:49:44.068320  5458 net.cpp:150] Setting up drop6
I0204 18:49:44.068326  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.068331  5458 net.cpp:165] Memory required for data: 151057600
I0204 18:49:44.068337  5458 layer_factory.hpp:77] Creating layer fc7
I0204 18:49:44.068347  5458 net.cpp:106] Creating Layer fc7
I0204 18:49:44.068353  5458 net.cpp:454] fc7 <- fc6
I0204 18:49:44.068362  5458 net.cpp:411] fc7 -> fc7
I0204 18:49:44.069078  5458 net.cpp:150] Setting up fc7
I0204 18:49:44.069095  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.069103  5458 net.cpp:165] Memory required for data: 151160000
I0204 18:49:44.069114  5458 layer_factory.hpp:77] Creating layer relu7
I0204 18:49:44.069123  5458 net.cpp:106] Creating Layer relu7
I0204 18:49:44.069129  5458 net.cpp:454] relu7 <- fc7
I0204 18:49:44.069139  5458 net.cpp:397] relu7 -> fc7 (in-place)
I0204 18:49:44.069149  5458 net.cpp:150] Setting up relu7
I0204 18:49:44.069156  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.069161  5458 net.cpp:165] Memory required for data: 151262400
I0204 18:49:44.069167  5458 layer_factory.hpp:77] Creating layer drop7
I0204 18:49:44.069175  5458 net.cpp:106] Creating Layer drop7
I0204 18:49:44.069181  5458 net.cpp:454] drop7 <- fc7
I0204 18:49:44.069188  5458 net.cpp:397] drop7 -> fc7 (in-place)
I0204 18:49:44.069201  5458 net.cpp:150] Setting up drop7
I0204 18:49:44.069208  5458 net.cpp:157] Top shape: 100 256 (25600)
I0204 18:49:44.069213  5458 net.cpp:165] Memory required for data: 151364800
I0204 18:49:44.069219  5458 layer_factory.hpp:77] Creating layer fc8
I0204 18:49:44.069228  5458 net.cpp:106] Creating Layer fc8
I0204 18:49:44.069234  5458 net.cpp:454] fc8 <- fc7
I0204 18:49:44.069242  5458 net.cpp:411] fc8 -> fc8
I0204 18:49:44.069283  5458 net.cpp:150] Setting up fc8
I0204 18:49:44.069291  5458 net.cpp:157] Top shape: 100 2 (200)
I0204 18:49:44.069298  5458 net.cpp:165] Memory required for data: 151365600
I0204 18:49:44.069305  5458 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 18:49:44.069316  5458 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 18:49:44.069322  5458 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 18:49:44.069330  5458 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 18:49:44.069341  5458 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 18:49:44.069351  5458 net.cpp:150] Setting up fc8_fc8_0_split
I0204 18:49:44.069358  5458 net.cpp:157] Top shape: 100 2 (200)
I0204 18:49:44.069365  5458 net.cpp:157] Top shape: 100 2 (200)
I0204 18:49:44.069370  5458 net.cpp:165] Memory required for data: 151367200
I0204 18:49:44.069375  5458 layer_factory.hpp:77] Creating layer accuracy
I0204 18:49:44.069402  5458 net.cpp:106] Creating Layer accuracy
I0204 18:49:44.069411  5458 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 18:49:44.069419  5458 net.cpp:454] accuracy <- label_data_1_split_0
I0204 18:49:44.069428  5458 net.cpp:411] accuracy -> accuracy
I0204 18:49:44.069443  5458 net.cpp:150] Setting up accuracy
I0204 18:49:44.069450  5458 net.cpp:157] Top shape: (1)
I0204 18:49:44.069456  5458 net.cpp:165] Memory required for data: 151367204
I0204 18:49:44.069463  5458 layer_factory.hpp:77] Creating layer loss
I0204 18:49:44.069473  5458 net.cpp:106] Creating Layer loss
I0204 18:49:44.069479  5458 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 18:49:44.069486  5458 net.cpp:454] loss <- label_data_1_split_1
I0204 18:49:44.069494  5458 net.cpp:411] loss -> loss
I0204 18:49:44.069506  5458 layer_factory.hpp:77] Creating layer loss
I0204 18:49:44.069526  5458 net.cpp:150] Setting up loss
I0204 18:49:44.069533  5458 net.cpp:157] Top shape: (1)
I0204 18:49:44.069538  5458 net.cpp:160]     with loss weight 1
I0204 18:49:44.069556  5458 net.cpp:165] Memory required for data: 151367208
I0204 18:49:44.069563  5458 net.cpp:226] loss needs backward computation.
I0204 18:49:44.069572  5458 net.cpp:228] accuracy does not need backward computation.
I0204 18:49:44.069579  5458 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 18:49:44.069586  5458 net.cpp:226] fc8 needs backward computation.
I0204 18:49:44.069593  5458 net.cpp:226] drop7 needs backward computation.
I0204 18:49:44.069599  5458 net.cpp:226] relu7 needs backward computation.
I0204 18:49:44.069604  5458 net.cpp:226] fc7 needs backward computation.
I0204 18:49:44.069612  5458 net.cpp:226] drop6 needs backward computation.
I0204 18:49:44.069618  5458 net.cpp:226] relu6 needs backward computation.
I0204 18:49:44.069623  5458 net.cpp:226] fc6 needs backward computation.
I0204 18:49:44.069629  5458 net.cpp:226] pool5 needs backward computation.
I0204 18:49:44.069635  5458 net.cpp:226] relu5 needs backward computation.
I0204 18:49:44.069640  5458 net.cpp:226] conv5 needs backward computation.
I0204 18:49:44.069646  5458 net.cpp:226] relu4 needs backward computation.
I0204 18:49:44.069653  5458 net.cpp:226] conv4 needs backward computation.
I0204 18:49:44.069658  5458 net.cpp:226] relu3 needs backward computation.
I0204 18:49:44.069664  5458 net.cpp:226] conv3 needs backward computation.
I0204 18:49:44.069669  5458 net.cpp:226] norm2 needs backward computation.
I0204 18:49:44.069675  5458 net.cpp:226] pool2 needs backward computation.
I0204 18:49:44.069681  5458 net.cpp:226] relu2 needs backward computation.
I0204 18:49:44.069686  5458 net.cpp:226] conv2 needs backward computation.
I0204 18:49:44.069694  5458 net.cpp:226] norm1 needs backward computation.
I0204 18:49:44.069700  5458 net.cpp:226] pool1 needs backward computation.
I0204 18:49:44.069705  5458 net.cpp:226] relu1 needs backward computation.
I0204 18:49:44.069711  5458 net.cpp:226] conv1 needs backward computation.
I0204 18:49:44.069720  5458 net.cpp:228] label_data_1_split does not need backward computation.
I0204 18:49:44.069727  5458 net.cpp:228] data does not need backward computation.
I0204 18:49:44.069732  5458 net.cpp:270] This network produces output accuracy
I0204 18:49:44.069739  5458 net.cpp:270] This network produces output loss
I0204 18:49:44.069782  5458 net.cpp:283] Network initialization done.
I0204 18:49:44.069897  5458 solver.cpp:60] Solver scaffolding done.
I0204 18:49:44.069955  5458 caffe.cpp:212] Starting Optimization
I0204 18:49:44.069962  5458 solver.cpp:288] Solving CaffeNet
I0204 18:49:44.069968  5458 solver.cpp:289] Learning Rate Policy: step
I0204 18:49:44.070839  5458 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 18:49:44.070966  5458 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 18:49:51.487632  5458 solver.cpp:409]     Test net output #0: accuracy = 0.491
I0204 18:49:51.487697  5458 solver.cpp:409]     Test net output #1: loss = 2.12571 (* 1 = 2.12571 loss)
I0204 18:49:53.138310  5458 solver.cpp:237] Iteration 0, loss = 7.83438
I0204 18:49:53.138401  5458 solver.cpp:253]     Train net output #0: loss = 7.83438 (* 1 = 7.83438 loss)
I0204 18:49:53.138416  5458 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 18:50:11.436203  5458 solver.cpp:237] Iteration 10, loss = 1.31726
I0204 18:50:11.436272  5458 solver.cpp:253]     Train net output #0: loss = 1.31726 (* 1 = 1.31726 loss)
I0204 18:50:11.436285  5458 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 18:50:29.814868  5458 solver.cpp:237] Iteration 20, loss = 0.943556
I0204 18:50:29.815022  5458 solver.cpp:253]     Train net output #0: loss = 0.943556 (* 1 = 0.943556 loss)
I0204 18:50:29.815037  5458 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 18:50:46.978549  5458 solver.cpp:237] Iteration 30, loss = 0.908891
I0204 18:50:46.978622  5458 solver.cpp:253]     Train net output #0: loss = 0.908891 (* 1 = 0.908891 loss)
I0204 18:50:46.978636  5458 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 18:51:03.873370  5458 solver.cpp:237] Iteration 40, loss = 0.838483
I0204 18:51:03.873579  5458 solver.cpp:253]     Train net output #0: loss = 0.838483 (* 1 = 0.838483 loss)
I0204 18:51:03.873594  5458 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 18:51:20.708869  5458 solver.cpp:237] Iteration 50, loss = 0.76809
I0204 18:51:20.708940  5458 solver.cpp:253]     Train net output #0: loss = 0.76809 (* 1 = 0.76809 loss)
I0204 18:51:20.708952  5458 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 18:51:37.566239  5458 solver.cpp:237] Iteration 60, loss = 0.768647
I0204 18:51:37.566437  5458 solver.cpp:253]     Train net output #0: loss = 0.768647 (* 1 = 0.768647 loss)
I0204 18:51:37.566452  5458 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 18:51:54.497776  5458 solver.cpp:237] Iteration 70, loss = 0.649096
I0204 18:51:54.497853  5458 solver.cpp:253]     Train net output #0: loss = 0.649096 (* 1 = 0.649096 loss)
I0204 18:51:54.497865  5458 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 18:52:11.484850  5458 solver.cpp:237] Iteration 80, loss = 0.557022
I0204 18:52:11.485062  5458 solver.cpp:253]     Train net output #0: loss = 0.557022 (* 1 = 0.557022 loss)
I0204 18:52:11.485077  5458 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 18:52:28.614926  5458 solver.cpp:237] Iteration 90, loss = 0.649313
I0204 18:52:28.614997  5458 solver.cpp:253]     Train net output #0: loss = 0.649313 (* 1 = 0.649313 loss)
I0204 18:52:28.615011  5458 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 18:52:44.123530  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_100.caffemodel
I0204 18:52:44.128063  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_100.solverstate
I0204 18:52:44.129467  5458 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 18:52:52.090834  5458 solver.cpp:409]     Test net output #0: accuracy = 0.897
I0204 18:52:52.090903  5458 solver.cpp:409]     Test net output #1: loss = 0.371154 (* 1 = 0.371154 loss)
I0204 18:52:53.812928  5458 solver.cpp:237] Iteration 100, loss = 0.45263
I0204 18:52:53.812996  5458 solver.cpp:253]     Train net output #0: loss = 0.45263 (* 1 = 0.45263 loss)
I0204 18:52:53.813010  5458 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 18:53:11.092861  5458 solver.cpp:237] Iteration 110, loss = 0.429217
I0204 18:53:11.092933  5458 solver.cpp:253]     Train net output #0: loss = 0.429217 (* 1 = 0.429217 loss)
I0204 18:53:11.092947  5458 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 18:53:28.414885  5458 solver.cpp:237] Iteration 120, loss = 0.377453
I0204 18:53:28.415125  5458 solver.cpp:253]     Train net output #0: loss = 0.377453 (* 1 = 0.377453 loss)
I0204 18:53:28.415140  5458 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 18:53:45.755558  5458 solver.cpp:237] Iteration 130, loss = 0.281586
I0204 18:53:45.755631  5458 solver.cpp:253]     Train net output #0: loss = 0.281586 (* 1 = 0.281586 loss)
I0204 18:53:45.755657  5458 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 18:54:03.092320  5458 solver.cpp:237] Iteration 140, loss = 0.359588
I0204 18:54:03.092562  5458 solver.cpp:253]     Train net output #0: loss = 0.359588 (* 1 = 0.359588 loss)
I0204 18:54:03.092577  5458 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 18:54:20.560843  5458 solver.cpp:237] Iteration 150, loss = 0.165859
I0204 18:54:20.560920  5458 solver.cpp:253]     Train net output #0: loss = 0.165859 (* 1 = 0.165859 loss)
I0204 18:54:20.560933  5458 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 18:54:38.135048  5458 solver.cpp:237] Iteration 160, loss = 0.190807
I0204 18:54:38.135284  5458 solver.cpp:253]     Train net output #0: loss = 0.190807 (* 1 = 0.190807 loss)
I0204 18:54:38.135298  5458 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 18:54:55.743640  5458 solver.cpp:237] Iteration 170, loss = 0.114175
I0204 18:54:55.743710  5458 solver.cpp:253]     Train net output #0: loss = 0.114175 (* 1 = 0.114175 loss)
I0204 18:54:55.743723  5458 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 18:55:13.238040  5458 solver.cpp:237] Iteration 180, loss = 0.193415
I0204 18:55:13.238243  5458 solver.cpp:253]     Train net output #0: loss = 0.193415 (* 1 = 0.193415 loss)
I0204 18:55:13.238258  5458 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 18:55:30.723711  5458 solver.cpp:237] Iteration 190, loss = 0.166468
I0204 18:55:30.723791  5458 solver.cpp:253]     Train net output #0: loss = 0.166468 (* 1 = 0.166468 loss)
I0204 18:55:30.723805  5458 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 18:55:46.592824  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_200.caffemodel
I0204 18:55:46.596709  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_200.solverstate
I0204 18:55:46.598053  5458 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 18:55:54.800787  5458 solver.cpp:409]     Test net output #0: accuracy = 0.974
I0204 18:55:54.800855  5458 solver.cpp:409]     Test net output #1: loss = 0.0742526 (* 1 = 0.0742526 loss)
I0204 18:55:56.565548  5458 solver.cpp:237] Iteration 200, loss = 0.177794
I0204 18:55:56.565614  5458 solver.cpp:253]     Train net output #0: loss = 0.177794 (* 1 = 0.177794 loss)
I0204 18:55:56.565626  5458 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 18:56:14.360313  5458 solver.cpp:237] Iteration 210, loss = 0.163583
I0204 18:56:14.360388  5458 solver.cpp:253]     Train net output #0: loss = 0.163583 (* 1 = 0.163583 loss)
I0204 18:56:14.360401  5458 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 18:56:32.402894  5458 solver.cpp:237] Iteration 220, loss = 0.0960428
I0204 18:56:32.403084  5458 solver.cpp:253]     Train net output #0: loss = 0.0960428 (* 1 = 0.0960428 loss)
I0204 18:56:32.403098  5458 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 18:56:50.334437  5458 solver.cpp:237] Iteration 230, loss = 0.126127
I0204 18:56:50.334532  5458 solver.cpp:253]     Train net output #0: loss = 0.126127 (* 1 = 0.126127 loss)
I0204 18:56:50.334547  5458 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 18:57:08.112479  5458 solver.cpp:237] Iteration 240, loss = 0.0444348
I0204 18:57:08.112694  5458 solver.cpp:253]     Train net output #0: loss = 0.0444348 (* 1 = 0.0444348 loss)
I0204 18:57:08.112710  5458 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 18:57:25.862443  5458 solver.cpp:237] Iteration 250, loss = 0.0296159
I0204 18:57:25.862520  5458 solver.cpp:253]     Train net output #0: loss = 0.0296159 (* 1 = 0.0296159 loss)
I0204 18:57:25.862534  5458 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 18:57:43.736449  5458 solver.cpp:237] Iteration 260, loss = 0.0494531
I0204 18:57:43.736728  5458 solver.cpp:253]     Train net output #0: loss = 0.0494531 (* 1 = 0.0494531 loss)
I0204 18:57:43.736748  5458 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 18:58:01.661314  5458 solver.cpp:237] Iteration 270, loss = 0.0597645
I0204 18:58:01.661396  5458 solver.cpp:253]     Train net output #0: loss = 0.0597645 (* 1 = 0.0597645 loss)
I0204 18:58:01.661408  5458 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 18:58:19.651623  5458 solver.cpp:237] Iteration 280, loss = 0.0204824
I0204 18:58:19.651857  5458 solver.cpp:253]     Train net output #0: loss = 0.0204824 (* 1 = 0.0204824 loss)
I0204 18:58:19.651873  5458 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 18:58:37.527704  5458 solver.cpp:237] Iteration 290, loss = 0.0729277
I0204 18:58:37.527783  5458 solver.cpp:253]     Train net output #0: loss = 0.0729277 (* 1 = 0.0729277 loss)
I0204 18:58:37.527797  5458 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 18:58:53.554448  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_300.caffemodel
I0204 18:58:53.558349  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_300.solverstate
I0204 18:58:53.559736  5458 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 18:59:01.837618  5458 solver.cpp:409]     Test net output #0: accuracy = 0.993
I0204 18:59:01.837697  5458 solver.cpp:409]     Test net output #1: loss = 0.0180907 (* 1 = 0.0180907 loss)
I0204 18:59:03.621026  5458 solver.cpp:237] Iteration 300, loss = 0.0152845
I0204 18:59:03.621109  5458 solver.cpp:253]     Train net output #0: loss = 0.0152844 (* 1 = 0.0152844 loss)
I0204 18:59:03.621122  5458 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 18:59:21.450558  5458 solver.cpp:237] Iteration 310, loss = 0.00583755
I0204 18:59:21.450650  5458 solver.cpp:253]     Train net output #0: loss = 0.00583752 (* 1 = 0.00583752 loss)
I0204 18:59:21.450665  5458 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 18:59:39.326422  5458 solver.cpp:237] Iteration 320, loss = 0.0892743
I0204 18:59:39.326643  5458 solver.cpp:253]     Train net output #0: loss = 0.0892743 (* 1 = 0.0892743 loss)
I0204 18:59:39.326658  5458 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 18:59:57.164680  5458 solver.cpp:237] Iteration 330, loss = 0.0176008
I0204 18:59:57.164762  5458 solver.cpp:253]     Train net output #0: loss = 0.0176008 (* 1 = 0.0176008 loss)
I0204 18:59:57.164775  5458 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 19:00:14.998126  5458 solver.cpp:237] Iteration 340, loss = 0.0542686
I0204 19:00:14.998348  5458 solver.cpp:253]     Train net output #0: loss = 0.0542685 (* 1 = 0.0542685 loss)
I0204 19:00:14.998364  5458 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 19:00:32.900251  5458 solver.cpp:237] Iteration 350, loss = 0.0242006
I0204 19:00:32.900334  5458 solver.cpp:253]     Train net output #0: loss = 0.0242006 (* 1 = 0.0242006 loss)
I0204 19:00:32.900347  5458 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 19:00:50.797462  5458 solver.cpp:237] Iteration 360, loss = 0.0504205
I0204 19:00:50.797683  5458 solver.cpp:253]     Train net output #0: loss = 0.0504205 (* 1 = 0.0504205 loss)
I0204 19:00:50.797698  5458 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 19:01:08.814185  5458 solver.cpp:237] Iteration 370, loss = 0.00949085
I0204 19:01:08.814266  5458 solver.cpp:253]     Train net output #0: loss = 0.0094908 (* 1 = 0.0094908 loss)
I0204 19:01:08.814280  5458 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 19:01:26.699347  5458 solver.cpp:237] Iteration 380, loss = 0.0423926
I0204 19:01:26.699553  5458 solver.cpp:253]     Train net output #0: loss = 0.0423925 (* 1 = 0.0423925 loss)
I0204 19:01:26.699570  5458 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 19:01:44.522932  5458 solver.cpp:237] Iteration 390, loss = 0.00647749
I0204 19:01:44.523017  5458 solver.cpp:253]     Train net output #0: loss = 0.00647744 (* 1 = 0.00647744 loss)
I0204 19:01:44.523044  5458 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 19:02:00.701231  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_400.caffemodel
I0204 19:02:00.705046  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_400.solverstate
I0204 19:02:00.706475  5458 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 19:02:08.996062  5458 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 19:02:08.996135  5458 solver.cpp:409]     Test net output #1: loss = 0.013054 (* 1 = 0.013054 loss)
I0204 19:02:10.783434  5458 solver.cpp:237] Iteration 400, loss = 0.0509967
I0204 19:02:10.783510  5458 solver.cpp:253]     Train net output #0: loss = 0.0509967 (* 1 = 0.0509967 loss)
I0204 19:02:10.783524  5458 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 19:02:28.815316  5458 solver.cpp:237] Iteration 410, loss = 0.0041815
I0204 19:02:28.815402  5458 solver.cpp:253]     Train net output #0: loss = 0.00418145 (* 1 = 0.00418145 loss)
I0204 19:02:28.815415  5458 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 19:02:47.055866  5458 solver.cpp:237] Iteration 420, loss = 0.0130884
I0204 19:02:47.056087  5458 solver.cpp:253]     Train net output #0: loss = 0.0130883 (* 1 = 0.0130883 loss)
I0204 19:02:47.056102  5458 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 19:03:05.297950  5458 solver.cpp:237] Iteration 430, loss = 0.0380395
I0204 19:03:05.298037  5458 solver.cpp:253]     Train net output #0: loss = 0.0380394 (* 1 = 0.0380394 loss)
I0204 19:03:05.298054  5458 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 19:03:23.454203  5458 solver.cpp:237] Iteration 440, loss = 0.00687412
I0204 19:03:23.454411  5458 solver.cpp:253]     Train net output #0: loss = 0.00687407 (* 1 = 0.00687407 loss)
I0204 19:03:23.454426  5458 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 19:03:41.541432  5458 solver.cpp:237] Iteration 450, loss = 0.0763346
I0204 19:03:41.541514  5458 solver.cpp:253]     Train net output #0: loss = 0.0763345 (* 1 = 0.0763345 loss)
I0204 19:03:41.541527  5458 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 19:03:59.569267  5458 solver.cpp:237] Iteration 460, loss = 0.0259949
I0204 19:03:59.569497  5458 solver.cpp:253]     Train net output #0: loss = 0.0259949 (* 1 = 0.0259949 loss)
I0204 19:03:59.569514  5458 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 19:04:17.640697  5458 solver.cpp:237] Iteration 470, loss = 0.0179929
I0204 19:04:17.640774  5458 solver.cpp:253]     Train net output #0: loss = 0.0179929 (* 1 = 0.0179929 loss)
I0204 19:04:17.640787  5458 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 19:04:35.739171  5458 solver.cpp:237] Iteration 480, loss = 0.00197898
I0204 19:04:35.739377  5458 solver.cpp:253]     Train net output #0: loss = 0.00197892 (* 1 = 0.00197892 loss)
I0204 19:04:35.739392  5458 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 19:04:53.783570  5458 solver.cpp:237] Iteration 490, loss = 0.0130354
I0204 19:04:53.783649  5458 solver.cpp:253]     Train net output #0: loss = 0.0130353 (* 1 = 0.0130353 loss)
I0204 19:04:53.783663  5458 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 19:05:10.042304  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_500.caffemodel
I0204 19:05:10.046140  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_500.solverstate
I0204 19:05:10.047518  5458 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 19:05:18.387517  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:05:18.387590  5458 solver.cpp:409]     Test net output #1: loss = 0.0126331 (* 1 = 0.0126331 loss)
I0204 19:05:20.184387  5458 solver.cpp:237] Iteration 500, loss = 0.0101112
I0204 19:05:20.184463  5458 solver.cpp:253]     Train net output #0: loss = 0.0101111 (* 1 = 0.0101111 loss)
I0204 19:05:20.184474  5458 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 19:05:38.354270  5458 solver.cpp:237] Iteration 510, loss = 0.0359945
I0204 19:05:38.354343  5458 solver.cpp:253]     Train net output #0: loss = 0.0359944 (* 1 = 0.0359944 loss)
I0204 19:05:38.354356  5458 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 19:05:56.432126  5458 solver.cpp:237] Iteration 520, loss = 0.0135341
I0204 19:05:56.432400  5458 solver.cpp:253]     Train net output #0: loss = 0.013534 (* 1 = 0.013534 loss)
I0204 19:05:56.432416  5458 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 19:06:14.443564  5458 solver.cpp:237] Iteration 530, loss = 0.00822628
I0204 19:06:14.443648  5458 solver.cpp:253]     Train net output #0: loss = 0.00822621 (* 1 = 0.00822621 loss)
I0204 19:06:14.443661  5458 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 19:06:32.408043  5458 solver.cpp:237] Iteration 540, loss = 0.0020336
I0204 19:06:32.408285  5458 solver.cpp:253]     Train net output #0: loss = 0.00203354 (* 1 = 0.00203354 loss)
I0204 19:06:32.408301  5458 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 19:06:50.352725  5458 solver.cpp:237] Iteration 550, loss = 0.0182624
I0204 19:06:50.352808  5458 solver.cpp:253]     Train net output #0: loss = 0.0182624 (* 1 = 0.0182624 loss)
I0204 19:06:50.352821  5458 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 19:07:08.395887  5458 solver.cpp:237] Iteration 560, loss = 0.00175187
I0204 19:07:08.396100  5458 solver.cpp:253]     Train net output #0: loss = 0.00175181 (* 1 = 0.00175181 loss)
I0204 19:07:08.396116  5458 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 19:07:26.402204  5458 solver.cpp:237] Iteration 570, loss = 0.0183902
I0204 19:07:26.402279  5458 solver.cpp:253]     Train net output #0: loss = 0.0183901 (* 1 = 0.0183901 loss)
I0204 19:07:26.402292  5458 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 19:07:44.592972  5458 solver.cpp:237] Iteration 580, loss = 0.0118254
I0204 19:07:44.593210  5458 solver.cpp:253]     Train net output #0: loss = 0.0118253 (* 1 = 0.0118253 loss)
I0204 19:07:44.593226  5458 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 19:08:02.777581  5458 solver.cpp:237] Iteration 590, loss = 0.00641547
I0204 19:08:02.777663  5458 solver.cpp:253]     Train net output #0: loss = 0.00641541 (* 1 = 0.00641541 loss)
I0204 19:08:02.777676  5458 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 19:08:19.140178  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_600.caffemodel
I0204 19:08:19.144116  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_600.solverstate
I0204 19:08:19.145519  5458 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 19:08:27.548725  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:08:27.548795  5458 solver.cpp:409]     Test net output #1: loss = 0.0078797 (* 1 = 0.0078797 loss)
I0204 19:08:29.364821  5458 solver.cpp:237] Iteration 600, loss = 0.0153675
I0204 19:08:29.364897  5458 solver.cpp:253]     Train net output #0: loss = 0.0153674 (* 1 = 0.0153674 loss)
I0204 19:08:29.364912  5458 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 19:08:47.468809  5458 solver.cpp:237] Iteration 610, loss = 0.00242102
I0204 19:08:47.468893  5458 solver.cpp:253]     Train net output #0: loss = 0.00242096 (* 1 = 0.00242096 loss)
I0204 19:08:47.468905  5458 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 19:09:05.874847  5458 solver.cpp:237] Iteration 620, loss = 0.00128628
I0204 19:09:05.875083  5458 solver.cpp:253]     Train net output #0: loss = 0.00128622 (* 1 = 0.00128622 loss)
I0204 19:09:05.875099  5458 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 19:09:24.164613  5458 solver.cpp:237] Iteration 630, loss = 0.00623859
I0204 19:09:24.164676  5458 solver.cpp:253]     Train net output #0: loss = 0.00623853 (* 1 = 0.00623853 loss)
I0204 19:09:24.164688  5458 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 19:09:42.462707  5458 solver.cpp:237] Iteration 640, loss = 0.00786174
I0204 19:09:42.462896  5458 solver.cpp:253]     Train net output #0: loss = 0.00786168 (* 1 = 0.00786168 loss)
I0204 19:09:42.462913  5458 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 19:10:00.760756  5458 solver.cpp:237] Iteration 650, loss = 0.0835693
I0204 19:10:00.760821  5458 solver.cpp:253]     Train net output #0: loss = 0.0835692 (* 1 = 0.0835692 loss)
I0204 19:10:00.760833  5458 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 19:10:19.204715  5458 solver.cpp:237] Iteration 660, loss = 0.0607578
I0204 19:10:19.204893  5458 solver.cpp:253]     Train net output #0: loss = 0.0607578 (* 1 = 0.0607578 loss)
I0204 19:10:19.204907  5458 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 19:10:37.617524  5458 solver.cpp:237] Iteration 670, loss = 0.0653507
I0204 19:10:37.617586  5458 solver.cpp:253]     Train net output #0: loss = 0.0653507 (* 1 = 0.0653507 loss)
I0204 19:10:37.617599  5458 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 19:10:55.874248  5458 solver.cpp:237] Iteration 680, loss = 0.00591767
I0204 19:10:55.874691  5458 solver.cpp:253]     Train net output #0: loss = 0.00591761 (* 1 = 0.00591761 loss)
I0204 19:10:55.874719  5458 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 19:11:14.190829  5458 solver.cpp:237] Iteration 690, loss = 0.0515607
I0204 19:11:14.190909  5458 solver.cpp:253]     Train net output #0: loss = 0.0515607 (* 1 = 0.0515607 loss)
I0204 19:11:14.190922  5458 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 19:11:30.888203  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_700.caffemodel
I0204 19:11:30.892343  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_700.solverstate
I0204 19:11:30.893765  5458 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 19:11:39.510535  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:11:39.510593  5458 solver.cpp:409]     Test net output #1: loss = 0.0110738 (* 1 = 0.0110738 loss)
I0204 19:11:41.364727  5458 solver.cpp:237] Iteration 700, loss = 0.00515189
I0204 19:11:41.364784  5458 solver.cpp:253]     Train net output #0: loss = 0.00515183 (* 1 = 0.00515183 loss)
I0204 19:11:41.364795  5458 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 19:11:59.916824  5458 solver.cpp:237] Iteration 710, loss = 0.00357353
I0204 19:11:59.916887  5458 solver.cpp:253]     Train net output #0: loss = 0.00357347 (* 1 = 0.00357347 loss)
I0204 19:11:59.916898  5458 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 19:12:18.425359  5458 solver.cpp:237] Iteration 720, loss = 0.000559248
I0204 19:12:18.425534  5458 solver.cpp:253]     Train net output #0: loss = 0.000559191 (* 1 = 0.000559191 loss)
I0204 19:12:18.425549  5458 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 19:12:36.850692  5458 solver.cpp:237] Iteration 730, loss = 0.0388691
I0204 19:12:36.850754  5458 solver.cpp:253]     Train net output #0: loss = 0.038869 (* 1 = 0.038869 loss)
I0204 19:12:36.850767  5458 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 19:12:55.313544  5458 solver.cpp:237] Iteration 740, loss = 0.00742785
I0204 19:12:55.313745  5458 solver.cpp:253]     Train net output #0: loss = 0.0074278 (* 1 = 0.0074278 loss)
I0204 19:12:55.313761  5458 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 19:13:13.816182  5458 solver.cpp:237] Iteration 750, loss = 0.0268236
I0204 19:13:13.816242  5458 solver.cpp:253]     Train net output #0: loss = 0.0268236 (* 1 = 0.0268236 loss)
I0204 19:13:13.816256  5458 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 19:13:32.497898  5458 solver.cpp:237] Iteration 760, loss = 0.00134593
I0204 19:13:32.498160  5458 solver.cpp:253]     Train net output #0: loss = 0.00134587 (* 1 = 0.00134587 loss)
I0204 19:13:32.498175  5458 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 19:13:51.225703  5458 solver.cpp:237] Iteration 770, loss = 0.00981921
I0204 19:13:51.225766  5458 solver.cpp:253]     Train net output #0: loss = 0.00981915 (* 1 = 0.00981915 loss)
I0204 19:13:51.225778  5458 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 19:14:09.710440  5458 solver.cpp:237] Iteration 780, loss = 0.0017556
I0204 19:14:09.710640  5458 solver.cpp:253]     Train net output #0: loss = 0.00175553 (* 1 = 0.00175553 loss)
I0204 19:14:09.710656  5458 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 19:14:28.139253  5458 solver.cpp:237] Iteration 790, loss = 0.00145282
I0204 19:14:28.139318  5458 solver.cpp:253]     Train net output #0: loss = 0.00145275 (* 1 = 0.00145275 loss)
I0204 19:14:28.139330  5458 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 19:14:44.693390  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_800.caffemodel
I0204 19:14:44.697269  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_800.solverstate
I0204 19:14:44.698674  5458 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 19:14:53.218768  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:14:53.218824  5458 solver.cpp:409]     Test net output #1: loss = 0.00457359 (* 1 = 0.00457359 loss)
I0204 19:14:55.062249  5458 solver.cpp:237] Iteration 800, loss = 0.00508502
I0204 19:14:55.062306  5458 solver.cpp:253]     Train net output #0: loss = 0.00508496 (* 1 = 0.00508496 loss)
I0204 19:14:55.062319  5458 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 19:15:13.410466  5458 solver.cpp:237] Iteration 810, loss = 0.0010811
I0204 19:15:13.410532  5458 solver.cpp:253]     Train net output #0: loss = 0.00108104 (* 1 = 0.00108104 loss)
I0204 19:15:13.410544  5458 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 19:15:31.774546  5458 solver.cpp:237] Iteration 820, loss = 0.0148644
I0204 19:15:31.782142  5458 solver.cpp:253]     Train net output #0: loss = 0.0148643 (* 1 = 0.0148643 loss)
I0204 19:15:31.782157  5458 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 19:15:50.213644  5458 solver.cpp:237] Iteration 830, loss = 0.0457846
I0204 19:15:50.213706  5458 solver.cpp:253]     Train net output #0: loss = 0.0457845 (* 1 = 0.0457845 loss)
I0204 19:15:50.213719  5458 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 19:16:08.594503  5458 solver.cpp:237] Iteration 840, loss = 0.00368823
I0204 19:16:08.594686  5458 solver.cpp:253]     Train net output #0: loss = 0.00368815 (* 1 = 0.00368815 loss)
I0204 19:16:08.594699  5458 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 19:16:26.986218  5458 solver.cpp:237] Iteration 850, loss = 0.00209469
I0204 19:16:26.986280  5458 solver.cpp:253]     Train net output #0: loss = 0.00209461 (* 1 = 0.00209461 loss)
I0204 19:16:26.986294  5458 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 19:16:45.360489  5458 solver.cpp:237] Iteration 860, loss = 0.00755327
I0204 19:16:45.360713  5458 solver.cpp:253]     Train net output #0: loss = 0.00755319 (* 1 = 0.00755319 loss)
I0204 19:16:45.360730  5458 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 19:17:03.666009  5458 solver.cpp:237] Iteration 870, loss = 0.000806939
I0204 19:17:03.666090  5458 solver.cpp:253]     Train net output #0: loss = 0.000806862 (* 1 = 0.000806862 loss)
I0204 19:17:03.666105  5458 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 19:17:22.124613  5458 solver.cpp:237] Iteration 880, loss = 0.00695879
I0204 19:17:22.124842  5458 solver.cpp:253]     Train net output #0: loss = 0.00695871 (* 1 = 0.00695871 loss)
I0204 19:17:22.124864  5458 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 19:17:40.634637  5458 solver.cpp:237] Iteration 890, loss = 0.00052508
I0204 19:17:40.634696  5458 solver.cpp:253]     Train net output #0: loss = 0.000525006 (* 1 = 0.000525006 loss)
I0204 19:17:40.634709  5458 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 19:17:57.351971  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_900.caffemodel
I0204 19:17:57.355736  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_900.solverstate
I0204 19:17:57.357141  5458 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 19:18:05.937903  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:18:05.937968  5458 solver.cpp:409]     Test net output #1: loss = 0.0107721 (* 1 = 0.0107721 loss)
I0204 19:18:07.781659  5458 solver.cpp:237] Iteration 900, loss = 0.00618914
I0204 19:18:07.781719  5458 solver.cpp:253]     Train net output #0: loss = 0.00618906 (* 1 = 0.00618906 loss)
I0204 19:18:07.781733  5458 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 19:18:26.316548  5458 solver.cpp:237] Iteration 910, loss = 0.010491
I0204 19:18:26.316613  5458 solver.cpp:253]     Train net output #0: loss = 0.0104909 (* 1 = 0.0104909 loss)
I0204 19:18:26.316627  5458 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 19:18:44.907863  5458 solver.cpp:237] Iteration 920, loss = 0.000315329
I0204 19:18:44.908068  5458 solver.cpp:253]     Train net output #0: loss = 0.000315252 (* 1 = 0.000315252 loss)
I0204 19:18:44.908083  5458 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 19:19:03.506659  5458 solver.cpp:237] Iteration 930, loss = 0.000270214
I0204 19:19:03.506721  5458 solver.cpp:253]     Train net output #0: loss = 0.000270133 (* 1 = 0.000270133 loss)
I0204 19:19:03.506734  5458 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 19:19:22.160975  5458 solver.cpp:237] Iteration 940, loss = 0.00318276
I0204 19:19:22.161186  5458 solver.cpp:253]     Train net output #0: loss = 0.00318268 (* 1 = 0.00318268 loss)
I0204 19:19:22.161201  5458 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 19:19:40.723489  5458 solver.cpp:237] Iteration 950, loss = 0.000692351
I0204 19:19:40.723554  5458 solver.cpp:253]     Train net output #0: loss = 0.000692267 (* 1 = 0.000692267 loss)
I0204 19:19:40.723567  5458 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 19:19:59.296257  5458 solver.cpp:237] Iteration 960, loss = 0.00177064
I0204 19:19:59.296461  5458 solver.cpp:253]     Train net output #0: loss = 0.00177055 (* 1 = 0.00177055 loss)
I0204 19:19:59.296476  5458 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 19:20:17.851866  5458 solver.cpp:237] Iteration 970, loss = 0.00414369
I0204 19:20:17.851936  5458 solver.cpp:253]     Train net output #0: loss = 0.00414361 (* 1 = 0.00414361 loss)
I0204 19:20:17.851950  5458 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 19:20:36.436146  5458 solver.cpp:237] Iteration 980, loss = 0.0038298
I0204 19:20:36.436332  5458 solver.cpp:253]     Train net output #0: loss = 0.00382972 (* 1 = 0.00382972 loss)
I0204 19:20:36.436347  5458 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 19:20:54.936764  5458 solver.cpp:237] Iteration 990, loss = 0.00963639
I0204 19:20:54.936828  5458 solver.cpp:253]     Train net output #0: loss = 0.00963631 (* 1 = 0.00963631 loss)
I0204 19:20:54.936842  5458 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 19:21:11.631456  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1000.caffemodel
I0204 19:21:11.635781  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1000.solverstate
I0204 19:21:11.637199  5458 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 19:21:20.238710  5458 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 19:21:20.238765  5458 solver.cpp:409]     Test net output #1: loss = 0.00320324 (* 1 = 0.00320324 loss)
I0204 19:21:22.091900  5458 solver.cpp:237] Iteration 1000, loss = 0.0117826
I0204 19:21:22.091964  5458 solver.cpp:253]     Train net output #0: loss = 0.0117825 (* 1 = 0.0117825 loss)
I0204 19:21:22.091975  5458 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 19:21:40.609998  5458 solver.cpp:237] Iteration 1010, loss = 0.000830982
I0204 19:21:40.610064  5458 solver.cpp:253]     Train net output #0: loss = 0.0008309 (* 1 = 0.0008309 loss)
I0204 19:21:40.610076  5458 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 19:21:59.089543  5458 solver.cpp:237] Iteration 1020, loss = 0.000591144
I0204 19:21:59.089758  5458 solver.cpp:253]     Train net output #0: loss = 0.000591063 (* 1 = 0.000591063 loss)
I0204 19:21:59.089773  5458 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 19:22:17.642004  5458 solver.cpp:237] Iteration 1030, loss = 0.000809543
I0204 19:22:17.642069  5458 solver.cpp:253]     Train net output #0: loss = 0.000809463 (* 1 = 0.000809463 loss)
I0204 19:22:17.642081  5458 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 19:22:36.277616  5458 solver.cpp:237] Iteration 1040, loss = 0.000504793
I0204 19:22:36.277808  5458 solver.cpp:253]     Train net output #0: loss = 0.000504713 (* 1 = 0.000504713 loss)
I0204 19:22:36.277823  5458 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 19:22:54.997265  5458 solver.cpp:237] Iteration 1050, loss = 0.00371994
I0204 19:22:54.997333  5458 solver.cpp:253]     Train net output #0: loss = 0.00371986 (* 1 = 0.00371986 loss)
I0204 19:22:54.997345  5458 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 19:23:13.799865  5458 solver.cpp:237] Iteration 1060, loss = 0.000523159
I0204 19:23:13.808150  5458 solver.cpp:253]     Train net output #0: loss = 0.000523081 (* 1 = 0.000523081 loss)
I0204 19:23:13.808178  5458 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 19:23:32.430995  5458 solver.cpp:237] Iteration 1070, loss = 0.0115549
I0204 19:23:32.431063  5458 solver.cpp:253]     Train net output #0: loss = 0.0115548 (* 1 = 0.0115548 loss)
I0204 19:23:32.431077  5458 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 19:23:51.058765  5458 solver.cpp:237] Iteration 1080, loss = 0.00165794
I0204 19:23:51.058964  5458 solver.cpp:253]     Train net output #0: loss = 0.00165786 (* 1 = 0.00165786 loss)
I0204 19:23:51.058979  5458 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 19:24:09.584012  5458 solver.cpp:237] Iteration 1090, loss = 0.011653
I0204 19:24:09.584074  5458 solver.cpp:253]     Train net output #0: loss = 0.0116529 (* 1 = 0.0116529 loss)
I0204 19:24:09.584087  5458 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 19:24:26.256264  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1100.caffemodel
I0204 19:24:26.260151  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1100.solverstate
I0204 19:24:26.261517  5458 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 19:24:34.861382  5458 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 19:24:34.861439  5458 solver.cpp:409]     Test net output #1: loss = 0.00715501 (* 1 = 0.00715501 loss)
I0204 19:24:36.732539  5458 solver.cpp:237] Iteration 1100, loss = 0.000343436
I0204 19:24:36.732599  5458 solver.cpp:253]     Train net output #0: loss = 0.000343355 (* 1 = 0.000343355 loss)
I0204 19:24:36.732610  5458 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 19:24:55.250236  5458 solver.cpp:237] Iteration 1110, loss = 0.000406969
I0204 19:24:55.250303  5458 solver.cpp:253]     Train net output #0: loss = 0.000406887 (* 1 = 0.000406887 loss)
I0204 19:24:55.250326  5458 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 19:25:13.845870  5458 solver.cpp:237] Iteration 1120, loss = 0.0021667
I0204 19:25:13.846104  5458 solver.cpp:253]     Train net output #0: loss = 0.00216662 (* 1 = 0.00216662 loss)
I0204 19:25:13.846119  5458 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 19:25:32.394084  5458 solver.cpp:237] Iteration 1130, loss = 0.00562284
I0204 19:25:32.394155  5458 solver.cpp:253]     Train net output #0: loss = 0.00562276 (* 1 = 0.00562276 loss)
I0204 19:25:32.394168  5458 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 19:25:50.997972  5458 solver.cpp:237] Iteration 1140, loss = 0.00111425
I0204 19:25:50.998203  5458 solver.cpp:253]     Train net output #0: loss = 0.00111417 (* 1 = 0.00111417 loss)
I0204 19:25:50.998217  5458 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 19:26:09.477166  5458 solver.cpp:237] Iteration 1150, loss = 0.0898907
I0204 19:26:09.477232  5458 solver.cpp:253]     Train net output #0: loss = 0.0898906 (* 1 = 0.0898906 loss)
I0204 19:26:09.477244  5458 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 19:26:27.958412  5458 solver.cpp:237] Iteration 1160, loss = 0.00563367
I0204 19:26:27.958590  5458 solver.cpp:253]     Train net output #0: loss = 0.00563358 (* 1 = 0.00563358 loss)
I0204 19:26:27.958605  5458 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 19:26:46.340436  5458 solver.cpp:237] Iteration 1170, loss = 0.0167689
I0204 19:26:46.340502  5458 solver.cpp:253]     Train net output #0: loss = 0.0167688 (* 1 = 0.0167688 loss)
I0204 19:26:46.340515  5458 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 19:27:04.790470  5458 solver.cpp:237] Iteration 1180, loss = 0.00189303
I0204 19:27:04.790659  5458 solver.cpp:253]     Train net output #0: loss = 0.00189296 (* 1 = 0.00189296 loss)
I0204 19:27:04.790674  5458 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 19:27:23.268275  5458 solver.cpp:237] Iteration 1190, loss = 0.000801535
I0204 19:27:23.268340  5458 solver.cpp:253]     Train net output #0: loss = 0.000801458 (* 1 = 0.000801458 loss)
I0204 19:27:23.268352  5458 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 19:27:39.999146  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1200.caffemodel
I0204 19:27:40.002939  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1200.solverstate
I0204 19:27:40.004310  5458 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 19:27:48.629200  5458 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 19:27:48.629256  5458 solver.cpp:409]     Test net output #1: loss = 0.00364202 (* 1 = 0.00364202 loss)
I0204 19:27:50.496150  5458 solver.cpp:237] Iteration 1200, loss = 0.00068241
I0204 19:27:50.496206  5458 solver.cpp:253]     Train net output #0: loss = 0.000682335 (* 1 = 0.000682335 loss)
I0204 19:27:50.496218  5458 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 19:28:09.086905  5458 solver.cpp:237] Iteration 1210, loss = 0.00457028
I0204 19:28:09.086997  5458 solver.cpp:253]     Train net output #0: loss = 0.0045702 (* 1 = 0.0045702 loss)
I0204 19:28:09.087009  5458 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 19:28:27.387632  5458 solver.cpp:237] Iteration 1220, loss = 0.00333759
I0204 19:28:27.387858  5458 solver.cpp:253]     Train net output #0: loss = 0.00333751 (* 1 = 0.00333751 loss)
I0204 19:28:27.387874  5458 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 19:28:45.639227  5458 solver.cpp:237] Iteration 1230, loss = 0.0223268
I0204 19:28:45.639308  5458 solver.cpp:253]     Train net output #0: loss = 0.0223267 (* 1 = 0.0223267 loss)
I0204 19:28:45.639322  5458 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 19:29:03.969521  5458 solver.cpp:237] Iteration 1240, loss = 0.000313926
I0204 19:29:03.969789  5458 solver.cpp:253]     Train net output #0: loss = 0.000313848 (* 1 = 0.000313848 loss)
I0204 19:29:03.969805  5458 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 19:29:22.332222  5458 solver.cpp:237] Iteration 1250, loss = 0.043054
I0204 19:29:22.332298  5458 solver.cpp:253]     Train net output #0: loss = 0.0430539 (* 1 = 0.0430539 loss)
I0204 19:29:22.332311  5458 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 19:29:40.685700  5458 solver.cpp:237] Iteration 1260, loss = 0.00157039
I0204 19:29:40.685928  5458 solver.cpp:253]     Train net output #0: loss = 0.00157031 (* 1 = 0.00157031 loss)
I0204 19:29:40.685945  5458 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 19:29:59.042145  5458 solver.cpp:237] Iteration 1270, loss = 0.000720677
I0204 19:29:59.042227  5458 solver.cpp:253]     Train net output #0: loss = 0.000720603 (* 1 = 0.000720603 loss)
I0204 19:29:59.042238  5458 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 19:30:17.306336  5458 solver.cpp:237] Iteration 1280, loss = 0.00720483
I0204 19:30:17.306555  5458 solver.cpp:253]     Train net output #0: loss = 0.00720475 (* 1 = 0.00720475 loss)
I0204 19:30:17.306571  5458 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 19:30:35.542330  5458 solver.cpp:237] Iteration 1290, loss = 0.00148532
I0204 19:30:35.542412  5458 solver.cpp:253]     Train net output #0: loss = 0.00148524 (* 1 = 0.00148524 loss)
I0204 19:30:35.542424  5458 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 19:30:52.075409  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1300.caffemodel
I0204 19:30:52.079277  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1300.solverstate
I0204 19:30:52.080673  5458 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 19:31:00.634296  5458 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 19:31:00.634371  5458 solver.cpp:409]     Test net output #1: loss = 0.00610468 (* 1 = 0.00610468 loss)
I0204 19:31:02.479086  5458 solver.cpp:237] Iteration 1300, loss = 0.00081291
I0204 19:31:02.479161  5458 solver.cpp:253]     Train net output #0: loss = 0.000812825 (* 1 = 0.000812825 loss)
I0204 19:31:02.479174  5458 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 19:31:20.846325  5458 solver.cpp:237] Iteration 1310, loss = 0.0081882
I0204 19:31:20.846411  5458 solver.cpp:253]     Train net output #0: loss = 0.00818811 (* 1 = 0.00818811 loss)
I0204 19:31:20.846424  5458 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 19:31:39.253999  5458 solver.cpp:237] Iteration 1320, loss = 0.000485577
I0204 19:31:39.263015  5458 solver.cpp:253]     Train net output #0: loss = 0.000485492 (* 1 = 0.000485492 loss)
I0204 19:31:39.263048  5458 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 19:31:57.674502  5458 solver.cpp:237] Iteration 1330, loss = 0.00275803
I0204 19:31:57.674577  5458 solver.cpp:253]     Train net output #0: loss = 0.00275794 (* 1 = 0.00275794 loss)
I0204 19:31:57.674589  5458 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 19:32:16.044453  5458 solver.cpp:237] Iteration 1340, loss = 0.000237601
I0204 19:32:16.044680  5458 solver.cpp:253]     Train net output #0: loss = 0.000237517 (* 1 = 0.000237517 loss)
I0204 19:32:16.044694  5458 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 19:32:34.418470  5458 solver.cpp:237] Iteration 1350, loss = 0.00124842
I0204 19:32:34.418545  5458 solver.cpp:253]     Train net output #0: loss = 0.00124834 (* 1 = 0.00124834 loss)
I0204 19:32:34.418557  5458 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 19:32:52.806485  5458 solver.cpp:237] Iteration 1360, loss = 0.00260421
I0204 19:32:52.806710  5458 solver.cpp:253]     Train net output #0: loss = 0.00260413 (* 1 = 0.00260413 loss)
I0204 19:32:52.806725  5458 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 19:33:11.188369  5458 solver.cpp:237] Iteration 1370, loss = 0.0023401
I0204 19:33:11.188462  5458 solver.cpp:253]     Train net output #0: loss = 0.00234001 (* 1 = 0.00234001 loss)
I0204 19:33:11.188474  5458 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 19:33:29.560683  5458 solver.cpp:237] Iteration 1380, loss = 0.00249584
I0204 19:33:29.560940  5458 solver.cpp:253]     Train net output #0: loss = 0.00249575 (* 1 = 0.00249575 loss)
I0204 19:33:29.560955  5458 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 19:33:47.946967  5458 solver.cpp:237] Iteration 1390, loss = 0.00166492
I0204 19:33:47.947041  5458 solver.cpp:253]     Train net output #0: loss = 0.00166483 (* 1 = 0.00166483 loss)
I0204 19:33:47.947052  5458 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 19:34:04.542536  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1400.caffemodel
I0204 19:34:04.547235  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1400.solverstate
I0204 19:34:04.548625  5458 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 19:34:13.088251  5458 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 19:34:13.088320  5458 solver.cpp:409]     Test net output #1: loss = 0.00206934 (* 1 = 0.00206934 loss)
I0204 19:34:14.929298  5458 solver.cpp:237] Iteration 1400, loss = 0.000271409
I0204 19:34:14.929364  5458 solver.cpp:253]     Train net output #0: loss = 0.000271325 (* 1 = 0.000271325 loss)
I0204 19:34:14.929376  5458 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 19:34:33.304863  5458 solver.cpp:237] Iteration 1410, loss = 0.00101491
I0204 19:34:33.304937  5458 solver.cpp:253]     Train net output #0: loss = 0.00101483 (* 1 = 0.00101483 loss)
I0204 19:34:33.304949  5458 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 19:34:51.697229  5458 solver.cpp:237] Iteration 1420, loss = 0.000522474
I0204 19:34:51.697440  5458 solver.cpp:253]     Train net output #0: loss = 0.00052239 (* 1 = 0.00052239 loss)
I0204 19:34:51.697455  5458 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 19:35:10.032901  5458 solver.cpp:237] Iteration 1430, loss = 0.000244722
I0204 19:35:10.032973  5458 solver.cpp:253]     Train net output #0: loss = 0.000244637 (* 1 = 0.000244637 loss)
I0204 19:35:10.032985  5458 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 19:35:28.389436  5458 solver.cpp:237] Iteration 1440, loss = 0.00147201
I0204 19:35:28.389649  5458 solver.cpp:253]     Train net output #0: loss = 0.00147192 (* 1 = 0.00147192 loss)
I0204 19:35:28.389664  5458 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 19:35:46.662737  5458 solver.cpp:237] Iteration 1450, loss = 0.0712605
I0204 19:35:46.662808  5458 solver.cpp:253]     Train net output #0: loss = 0.0712605 (* 1 = 0.0712605 loss)
I0204 19:35:46.662822  5458 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 19:36:04.972347  5458 solver.cpp:237] Iteration 1460, loss = 0.00135392
I0204 19:36:04.972550  5458 solver.cpp:253]     Train net output #0: loss = 0.00135382 (* 1 = 0.00135382 loss)
I0204 19:36:04.972566  5458 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 19:36:23.236591  5458 solver.cpp:237] Iteration 1470, loss = 0.10742
I0204 19:36:23.236666  5458 solver.cpp:253]     Train net output #0: loss = 0.10742 (* 1 = 0.10742 loss)
I0204 19:36:23.236680  5458 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 19:36:41.608041  5458 solver.cpp:237] Iteration 1480, loss = 0.0374031
I0204 19:36:41.608268  5458 solver.cpp:253]     Train net output #0: loss = 0.037403 (* 1 = 0.037403 loss)
I0204 19:36:41.608283  5458 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 19:37:00.028040  5458 solver.cpp:237] Iteration 1490, loss = 0.00155672
I0204 19:37:00.028118  5458 solver.cpp:253]     Train net output #0: loss = 0.00155661 (* 1 = 0.00155661 loss)
I0204 19:37:00.028131  5458 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 19:37:16.618829  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1500.caffemodel
I0204 19:37:16.959347  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1500.solverstate
I0204 19:37:16.960985  5458 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 19:37:25.557538  5458 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 19:37:25.557605  5458 solver.cpp:409]     Test net output #1: loss = 0.00696728 (* 1 = 0.00696728 loss)
I0204 19:37:27.412324  5458 solver.cpp:237] Iteration 1500, loss = 0.000976499
I0204 19:37:27.412390  5458 solver.cpp:253]     Train net output #0: loss = 0.000976388 (* 1 = 0.000976388 loss)
I0204 19:37:27.412403  5458 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 19:37:45.988831  5458 solver.cpp:237] Iteration 1510, loss = 0.000408435
I0204 19:37:45.988903  5458 solver.cpp:253]     Train net output #0: loss = 0.000408323 (* 1 = 0.000408323 loss)
I0204 19:37:45.988915  5458 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 19:38:04.460000  5458 solver.cpp:237] Iteration 1520, loss = 0.000880573
I0204 19:38:04.460234  5458 solver.cpp:253]     Train net output #0: loss = 0.000880461 (* 1 = 0.000880461 loss)
I0204 19:38:04.460249  5458 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 19:38:22.881614  5458 solver.cpp:237] Iteration 1530, loss = 0.0526754
I0204 19:38:22.881685  5458 solver.cpp:253]     Train net output #0: loss = 0.0526753 (* 1 = 0.0526753 loss)
I0204 19:38:22.881698  5458 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 19:38:41.252930  5458 solver.cpp:237] Iteration 1540, loss = 0.0111501
I0204 19:38:41.253149  5458 solver.cpp:253]     Train net output #0: loss = 0.01115 (* 1 = 0.01115 loss)
I0204 19:38:41.253165  5458 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 19:38:59.661286  5458 solver.cpp:237] Iteration 1550, loss = 0.000599424
I0204 19:38:59.661365  5458 solver.cpp:253]     Train net output #0: loss = 0.000599313 (* 1 = 0.000599313 loss)
I0204 19:38:59.661376  5458 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 19:39:18.078117  5458 solver.cpp:237] Iteration 1560, loss = 0.000298105
I0204 19:39:18.078327  5458 solver.cpp:253]     Train net output #0: loss = 0.00029799 (* 1 = 0.00029799 loss)
I0204 19:39:18.078342  5458 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 19:39:36.488997  5458 solver.cpp:237] Iteration 1570, loss = 0.000371779
I0204 19:39:36.489063  5458 solver.cpp:253]     Train net output #0: loss = 0.000371665 (* 1 = 0.000371665 loss)
I0204 19:39:36.489081  5458 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 19:39:54.845295  5458 solver.cpp:237] Iteration 1580, loss = 0.00210751
I0204 19:39:54.845504  5458 solver.cpp:253]     Train net output #0: loss = 0.0021074 (* 1 = 0.0021074 loss)
I0204 19:39:54.845520  5458 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 19:40:13.183760  5458 solver.cpp:237] Iteration 1590, loss = 0.000608876
I0204 19:40:13.183832  5458 solver.cpp:253]     Train net output #0: loss = 0.000608763 (* 1 = 0.000608763 loss)
I0204 19:40:13.183845  5458 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 19:40:29.886318  5458 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1600.caffemodel
I0204 19:40:29.890022  5458 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed11/snaps/snap__iter_1600.solverstate
I0204 19:40:30.755978  5458 solver.cpp:321] Iteration 1600, loss = 0.00141358
I0204 19:40:30.756038  5458 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 19:40:39.385426  5458 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 19:40:39.385498  5458 solver.cpp:409]     Test net output #1: loss = 0.00148936 (* 1 = 0.00148936 loss)
I0204 19:40:39.385506  5458 solver.cpp:326] Optimization Done.
I0204 19:40:39.385512  5458 caffe.cpp:215] Optimization Done.
