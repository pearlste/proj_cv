I0205 07:15:44.029124 12957 caffe.cpp:177] Use CPU.
I0205 07:15:44.029980 12957 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap_"
solver_mode: CPU
random_seed: 242
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/train_val.prototxt"
I0205 07:15:44.030153 12957 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/train_val.prototxt
I0205 07:15:44.030764 12957 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0205 07:15:44.030798 12957 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0205 07:15:44.031049 12957 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 07:15:44.031206 12957 layer_factory.hpp:77] Creating layer data
I0205 07:15:44.031395 12957 net.cpp:106] Creating Layer data
I0205 07:15:44.031414 12957 net.cpp:411] data -> data
I0205 07:15:44.031496 12957 net.cpp:411] data -> label
I0205 07:15:44.031519 12957 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0205 07:15:44.031674 12958 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0205 07:15:44.032601 12957 data_layer.cpp:41] output data size: 100,1,227,227
I0205 07:15:44.063905 12957 net.cpp:150] Setting up data
I0205 07:15:44.063974 12957 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 07:15:44.063984 12957 net.cpp:157] Top shape: 100 (100)
I0205 07:15:44.063992 12957 net.cpp:165] Memory required for data: 20612000
I0205 07:15:44.064010 12957 layer_factory.hpp:77] Creating layer conv1
I0205 07:15:44.064046 12957 net.cpp:106] Creating Layer conv1
I0205 07:15:44.064056 12957 net.cpp:454] conv1 <- data
I0205 07:15:44.064080 12957 net.cpp:411] conv1 -> conv1
I0205 07:15:44.064204 12957 net.cpp:150] Setting up conv1
I0205 07:15:44.064218 12957 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0205 07:15:44.064224 12957 net.cpp:165] Memory required for data: 30292000
I0205 07:15:44.064242 12957 layer_factory.hpp:77] Creating layer relu1
I0205 07:15:44.064256 12957 net.cpp:106] Creating Layer relu1
I0205 07:15:44.064263 12957 net.cpp:454] relu1 <- conv1
I0205 07:15:44.064272 12957 net.cpp:397] relu1 -> conv1 (in-place)
I0205 07:15:44.064286 12957 net.cpp:150] Setting up relu1
I0205 07:15:44.064294 12957 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0205 07:15:44.064299 12957 net.cpp:165] Memory required for data: 39972000
I0205 07:15:44.064306 12957 layer_factory.hpp:77] Creating layer pool1
I0205 07:15:44.064317 12957 net.cpp:106] Creating Layer pool1
I0205 07:15:44.064323 12957 net.cpp:454] pool1 <- conv1
I0205 07:15:44.064332 12957 net.cpp:411] pool1 -> pool1
I0205 07:15:44.064358 12957 net.cpp:150] Setting up pool1
I0205 07:15:44.064368 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.064373 12957 net.cpp:165] Memory required for data: 42304800
I0205 07:15:44.064380 12957 layer_factory.hpp:77] Creating layer norm1
I0205 07:15:44.064404 12957 net.cpp:106] Creating Layer norm1
I0205 07:15:44.064419 12957 net.cpp:454] norm1 <- pool1
I0205 07:15:44.064429 12957 net.cpp:411] norm1 -> norm1
I0205 07:15:44.064447 12957 net.cpp:150] Setting up norm1
I0205 07:15:44.064455 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.064460 12957 net.cpp:165] Memory required for data: 44637600
I0205 07:15:44.064466 12957 layer_factory.hpp:77] Creating layer conv2
I0205 07:15:44.064478 12957 net.cpp:106] Creating Layer conv2
I0205 07:15:44.064484 12957 net.cpp:454] conv2 <- norm1
I0205 07:15:44.064492 12957 net.cpp:411] conv2 -> conv2
I0205 07:15:44.064527 12957 net.cpp:150] Setting up conv2
I0205 07:15:44.064535 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.064540 12957 net.cpp:165] Memory required for data: 46970400
I0205 07:15:44.064551 12957 layer_factory.hpp:77] Creating layer relu2
I0205 07:15:44.064559 12957 net.cpp:106] Creating Layer relu2
I0205 07:15:44.064565 12957 net.cpp:454] relu2 <- conv2
I0205 07:15:44.064573 12957 net.cpp:397] relu2 -> conv2 (in-place)
I0205 07:15:44.064581 12957 net.cpp:150] Setting up relu2
I0205 07:15:44.064589 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.064594 12957 net.cpp:165] Memory required for data: 49303200
I0205 07:15:44.064599 12957 layer_factory.hpp:77] Creating layer pool2
I0205 07:15:44.064606 12957 net.cpp:106] Creating Layer pool2
I0205 07:15:44.064612 12957 net.cpp:454] pool2 <- conv2
I0205 07:15:44.064620 12957 net.cpp:411] pool2 -> pool2
I0205 07:15:44.064630 12957 net.cpp:150] Setting up pool2
I0205 07:15:44.064636 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064645 12957 net.cpp:165] Memory required for data: 49844000
I0205 07:15:44.064651 12957 layer_factory.hpp:77] Creating layer norm2
I0205 07:15:44.064661 12957 net.cpp:106] Creating Layer norm2
I0205 07:15:44.064666 12957 net.cpp:454] norm2 <- pool2
I0205 07:15:44.064676 12957 net.cpp:411] norm2 -> norm2
I0205 07:15:44.064684 12957 net.cpp:150] Setting up norm2
I0205 07:15:44.064692 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064697 12957 net.cpp:165] Memory required for data: 50384800
I0205 07:15:44.064702 12957 layer_factory.hpp:77] Creating layer conv3
I0205 07:15:44.064713 12957 net.cpp:106] Creating Layer conv3
I0205 07:15:44.064718 12957 net.cpp:454] conv3 <- norm2
I0205 07:15:44.064726 12957 net.cpp:411] conv3 -> conv3
I0205 07:15:44.064754 12957 net.cpp:150] Setting up conv3
I0205 07:15:44.064761 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064766 12957 net.cpp:165] Memory required for data: 50925600
I0205 07:15:44.064779 12957 layer_factory.hpp:77] Creating layer relu3
I0205 07:15:44.064788 12957 net.cpp:106] Creating Layer relu3
I0205 07:15:44.064795 12957 net.cpp:454] relu3 <- conv3
I0205 07:15:44.064802 12957 net.cpp:397] relu3 -> conv3 (in-place)
I0205 07:15:44.064810 12957 net.cpp:150] Setting up relu3
I0205 07:15:44.064816 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064822 12957 net.cpp:165] Memory required for data: 51466400
I0205 07:15:44.064827 12957 layer_factory.hpp:77] Creating layer conv4
I0205 07:15:44.064838 12957 net.cpp:106] Creating Layer conv4
I0205 07:15:44.064844 12957 net.cpp:454] conv4 <- conv3
I0205 07:15:44.064851 12957 net.cpp:411] conv4 -> conv4
I0205 07:15:44.064874 12957 net.cpp:150] Setting up conv4
I0205 07:15:44.064882 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064888 12957 net.cpp:165] Memory required for data: 52007200
I0205 07:15:44.064895 12957 layer_factory.hpp:77] Creating layer relu4
I0205 07:15:44.064905 12957 net.cpp:106] Creating Layer relu4
I0205 07:15:44.064911 12957 net.cpp:454] relu4 <- conv4
I0205 07:15:44.064919 12957 net.cpp:397] relu4 -> conv4 (in-place)
I0205 07:15:44.064927 12957 net.cpp:150] Setting up relu4
I0205 07:15:44.064935 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.064940 12957 net.cpp:165] Memory required for data: 52548000
I0205 07:15:44.064946 12957 layer_factory.hpp:77] Creating layer conv5
I0205 07:15:44.064961 12957 net.cpp:106] Creating Layer conv5
I0205 07:15:44.064975 12957 net.cpp:454] conv5 <- conv4
I0205 07:15:44.064982 12957 net.cpp:411] conv5 -> conv5
I0205 07:15:44.065003 12957 net.cpp:150] Setting up conv5
I0205 07:15:44.065011 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.065016 12957 net.cpp:165] Memory required for data: 53088800
I0205 07:15:44.065029 12957 layer_factory.hpp:77] Creating layer relu5
I0205 07:15:44.065038 12957 net.cpp:106] Creating Layer relu5
I0205 07:15:44.065044 12957 net.cpp:454] relu5 <- conv5
I0205 07:15:44.065052 12957 net.cpp:397] relu5 -> conv5 (in-place)
I0205 07:15:44.065059 12957 net.cpp:150] Setting up relu5
I0205 07:15:44.065067 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.065071 12957 net.cpp:165] Memory required for data: 53629600
I0205 07:15:44.065078 12957 layer_factory.hpp:77] Creating layer pool5
I0205 07:15:44.065084 12957 net.cpp:106] Creating Layer pool5
I0205 07:15:44.065105 12957 net.cpp:454] pool5 <- conv5
I0205 07:15:44.065114 12957 net.cpp:411] pool5 -> pool5
I0205 07:15:44.065125 12957 net.cpp:150] Setting up pool5
I0205 07:15:44.065134 12957 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0205 07:15:44.065138 12957 net.cpp:165] Memory required for data: 53744800
I0205 07:15:44.065145 12957 layer_factory.hpp:77] Creating layer fc6
I0205 07:15:44.065161 12957 net.cpp:106] Creating Layer fc6
I0205 07:15:44.065167 12957 net.cpp:454] fc6 <- pool5
I0205 07:15:44.065176 12957 net.cpp:411] fc6 -> fc6
I0205 07:15:44.065980 12957 net.cpp:150] Setting up fc6
I0205 07:15:44.065995 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066000 12957 net.cpp:165] Memory required for data: 53847200
I0205 07:15:44.066009 12957 layer_factory.hpp:77] Creating layer relu6
I0205 07:15:44.066018 12957 net.cpp:106] Creating Layer relu6
I0205 07:15:44.066025 12957 net.cpp:454] relu6 <- fc6
I0205 07:15:44.066033 12957 net.cpp:397] relu6 -> fc6 (in-place)
I0205 07:15:44.066041 12957 net.cpp:150] Setting up relu6
I0205 07:15:44.066048 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066054 12957 net.cpp:165] Memory required for data: 53949600
I0205 07:15:44.066059 12957 layer_factory.hpp:77] Creating layer drop6
I0205 07:15:44.066071 12957 net.cpp:106] Creating Layer drop6
I0205 07:15:44.066076 12957 net.cpp:454] drop6 <- fc6
I0205 07:15:44.066083 12957 net.cpp:397] drop6 -> fc6 (in-place)
I0205 07:15:44.066108 12957 net.cpp:150] Setting up drop6
I0205 07:15:44.066117 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066123 12957 net.cpp:165] Memory required for data: 54052000
I0205 07:15:44.066129 12957 layer_factory.hpp:77] Creating layer fc7
I0205 07:15:44.066139 12957 net.cpp:106] Creating Layer fc7
I0205 07:15:44.066145 12957 net.cpp:454] fc7 <- fc6
I0205 07:15:44.066154 12957 net.cpp:411] fc7 -> fc7
I0205 07:15:44.066853 12957 net.cpp:150] Setting up fc7
I0205 07:15:44.066864 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066869 12957 net.cpp:165] Memory required for data: 54154400
I0205 07:15:44.066877 12957 layer_factory.hpp:77] Creating layer relu7
I0205 07:15:44.066885 12957 net.cpp:106] Creating Layer relu7
I0205 07:15:44.066891 12957 net.cpp:454] relu7 <- fc7
I0205 07:15:44.066900 12957 net.cpp:397] relu7 -> fc7 (in-place)
I0205 07:15:44.066907 12957 net.cpp:150] Setting up relu7
I0205 07:15:44.066915 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066920 12957 net.cpp:165] Memory required for data: 54256800
I0205 07:15:44.066926 12957 layer_factory.hpp:77] Creating layer drop7
I0205 07:15:44.066937 12957 net.cpp:106] Creating Layer drop7
I0205 07:15:44.066946 12957 net.cpp:454] drop7 <- fc7
I0205 07:15:44.066953 12957 net.cpp:397] drop7 -> fc7 (in-place)
I0205 07:15:44.066963 12957 net.cpp:150] Setting up drop7
I0205 07:15:44.066970 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.066975 12957 net.cpp:165] Memory required for data: 54359200
I0205 07:15:44.066982 12957 layer_factory.hpp:77] Creating layer fc8
I0205 07:15:44.066993 12957 net.cpp:106] Creating Layer fc8
I0205 07:15:44.067003 12957 net.cpp:454] fc8 <- fc7
I0205 07:15:44.067018 12957 net.cpp:411] fc8 -> fc8
I0205 07:15:44.067042 12957 net.cpp:150] Setting up fc8
I0205 07:15:44.067050 12957 net.cpp:157] Top shape: 100 2 (200)
I0205 07:15:44.067055 12957 net.cpp:165] Memory required for data: 54360000
I0205 07:15:44.067064 12957 layer_factory.hpp:77] Creating layer loss
I0205 07:15:44.067075 12957 net.cpp:106] Creating Layer loss
I0205 07:15:44.067080 12957 net.cpp:454] loss <- fc8
I0205 07:15:44.067087 12957 net.cpp:454] loss <- label
I0205 07:15:44.067104 12957 net.cpp:411] loss -> loss
I0205 07:15:44.067121 12957 layer_factory.hpp:77] Creating layer loss
I0205 07:15:44.067145 12957 net.cpp:150] Setting up loss
I0205 07:15:44.067153 12957 net.cpp:157] Top shape: (1)
I0205 07:15:44.067158 12957 net.cpp:160]     with loss weight 1
I0205 07:15:44.067191 12957 net.cpp:165] Memory required for data: 54360004
I0205 07:15:44.067199 12957 net.cpp:226] loss needs backward computation.
I0205 07:15:44.067206 12957 net.cpp:226] fc8 needs backward computation.
I0205 07:15:44.067215 12957 net.cpp:226] drop7 needs backward computation.
I0205 07:15:44.067220 12957 net.cpp:226] relu7 needs backward computation.
I0205 07:15:44.067225 12957 net.cpp:226] fc7 needs backward computation.
I0205 07:15:44.067231 12957 net.cpp:226] drop6 needs backward computation.
I0205 07:15:44.067236 12957 net.cpp:226] relu6 needs backward computation.
I0205 07:15:44.067242 12957 net.cpp:226] fc6 needs backward computation.
I0205 07:15:44.067247 12957 net.cpp:226] pool5 needs backward computation.
I0205 07:15:44.067256 12957 net.cpp:226] relu5 needs backward computation.
I0205 07:15:44.067262 12957 net.cpp:226] conv5 needs backward computation.
I0205 07:15:44.067267 12957 net.cpp:226] relu4 needs backward computation.
I0205 07:15:44.067273 12957 net.cpp:226] conv4 needs backward computation.
I0205 07:15:44.067278 12957 net.cpp:226] relu3 needs backward computation.
I0205 07:15:44.067284 12957 net.cpp:226] conv3 needs backward computation.
I0205 07:15:44.067294 12957 net.cpp:226] norm2 needs backward computation.
I0205 07:15:44.067299 12957 net.cpp:226] pool2 needs backward computation.
I0205 07:15:44.067306 12957 net.cpp:226] relu2 needs backward computation.
I0205 07:15:44.067312 12957 net.cpp:226] conv2 needs backward computation.
I0205 07:15:44.067317 12957 net.cpp:226] norm1 needs backward computation.
I0205 07:15:44.067322 12957 net.cpp:226] pool1 needs backward computation.
I0205 07:15:44.067328 12957 net.cpp:226] relu1 needs backward computation.
I0205 07:15:44.067333 12957 net.cpp:226] conv1 needs backward computation.
I0205 07:15:44.067342 12957 net.cpp:228] data does not need backward computation.
I0205 07:15:44.067348 12957 net.cpp:270] This network produces output loss
I0205 07:15:44.067375 12957 net.cpp:283] Network initialization done.
I0205 07:15:44.068146 12957 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/train_val.prototxt
I0205 07:15:44.068203 12957 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0205 07:15:44.068503 12957 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 07:15:44.068683 12957 layer_factory.hpp:77] Creating layer data
I0205 07:15:44.068850 12957 net.cpp:106] Creating Layer data
I0205 07:15:44.068864 12957 net.cpp:411] data -> data
I0205 07:15:44.068878 12957 net.cpp:411] data -> label
I0205 07:15:44.068889 12957 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0205 07:15:44.069118 12961 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0205 07:15:44.069829 12957 data_layer.cpp:41] output data size: 100,1,227,227
I0205 07:15:44.099052 12957 net.cpp:150] Setting up data
I0205 07:15:44.099102 12957 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 07:15:44.099112 12957 net.cpp:157] Top shape: 100 (100)
I0205 07:15:44.099119 12957 net.cpp:165] Memory required for data: 20612000
I0205 07:15:44.099131 12957 layer_factory.hpp:77] Creating layer label_data_1_split
I0205 07:15:44.099153 12957 net.cpp:106] Creating Layer label_data_1_split
I0205 07:15:44.099161 12957 net.cpp:454] label_data_1_split <- label
I0205 07:15:44.099174 12957 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0205 07:15:44.099190 12957 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0205 07:15:44.099205 12957 net.cpp:150] Setting up label_data_1_split
I0205 07:15:44.099215 12957 net.cpp:157] Top shape: 100 (100)
I0205 07:15:44.099220 12957 net.cpp:157] Top shape: 100 (100)
I0205 07:15:44.099225 12957 net.cpp:165] Memory required for data: 20612800
I0205 07:15:44.099231 12957 layer_factory.hpp:77] Creating layer conv1
I0205 07:15:44.099248 12957 net.cpp:106] Creating Layer conv1
I0205 07:15:44.099254 12957 net.cpp:454] conv1 <- data
I0205 07:15:44.099264 12957 net.cpp:411] conv1 -> conv1
I0205 07:15:44.099319 12957 net.cpp:150] Setting up conv1
I0205 07:15:44.099329 12957 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0205 07:15:44.099335 12957 net.cpp:165] Memory required for data: 30292800
I0205 07:15:44.099349 12957 layer_factory.hpp:77] Creating layer relu1
I0205 07:15:44.099361 12957 net.cpp:106] Creating Layer relu1
I0205 07:15:44.099369 12957 net.cpp:454] relu1 <- conv1
I0205 07:15:44.099377 12957 net.cpp:397] relu1 -> conv1 (in-place)
I0205 07:15:44.099386 12957 net.cpp:150] Setting up relu1
I0205 07:15:44.099393 12957 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0205 07:15:44.099400 12957 net.cpp:165] Memory required for data: 39972800
I0205 07:15:44.099406 12957 layer_factory.hpp:77] Creating layer pool1
I0205 07:15:44.099416 12957 net.cpp:106] Creating Layer pool1
I0205 07:15:44.099422 12957 net.cpp:454] pool1 <- conv1
I0205 07:15:44.099431 12957 net.cpp:411] pool1 -> pool1
I0205 07:15:44.099445 12957 net.cpp:150] Setting up pool1
I0205 07:15:44.099452 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.099459 12957 net.cpp:165] Memory required for data: 42305600
I0205 07:15:44.099467 12957 layer_factory.hpp:77] Creating layer norm1
I0205 07:15:44.099478 12957 net.cpp:106] Creating Layer norm1
I0205 07:15:44.099483 12957 net.cpp:454] norm1 <- pool1
I0205 07:15:44.099491 12957 net.cpp:411] norm1 -> norm1
I0205 07:15:44.099504 12957 net.cpp:150] Setting up norm1
I0205 07:15:44.099512 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.099517 12957 net.cpp:165] Memory required for data: 44638400
I0205 07:15:44.099524 12957 layer_factory.hpp:77] Creating layer conv2
I0205 07:15:44.099534 12957 net.cpp:106] Creating Layer conv2
I0205 07:15:44.099539 12957 net.cpp:454] conv2 <- norm1
I0205 07:15:44.099550 12957 net.cpp:411] conv2 -> conv2
I0205 07:15:44.099580 12957 net.cpp:150] Setting up conv2
I0205 07:15:44.099587 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.099592 12957 net.cpp:165] Memory required for data: 46971200
I0205 07:15:44.099606 12957 layer_factory.hpp:77] Creating layer relu2
I0205 07:15:44.099616 12957 net.cpp:106] Creating Layer relu2
I0205 07:15:44.099622 12957 net.cpp:454] relu2 <- conv2
I0205 07:15:44.099629 12957 net.cpp:397] relu2 -> conv2 (in-place)
I0205 07:15:44.099649 12957 net.cpp:150] Setting up relu2
I0205 07:15:44.099668 12957 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0205 07:15:44.099673 12957 net.cpp:165] Memory required for data: 49304000
I0205 07:15:44.099679 12957 layer_factory.hpp:77] Creating layer pool2
I0205 07:15:44.099689 12957 net.cpp:106] Creating Layer pool2
I0205 07:15:44.099695 12957 net.cpp:454] pool2 <- conv2
I0205 07:15:44.099704 12957 net.cpp:411] pool2 -> pool2
I0205 07:15:44.099716 12957 net.cpp:150] Setting up pool2
I0205 07:15:44.099723 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.099728 12957 net.cpp:165] Memory required for data: 49844800
I0205 07:15:44.099735 12957 layer_factory.hpp:77] Creating layer norm2
I0205 07:15:44.099743 12957 net.cpp:106] Creating Layer norm2
I0205 07:15:44.099751 12957 net.cpp:454] norm2 <- pool2
I0205 07:15:44.099761 12957 net.cpp:411] norm2 -> norm2
I0205 07:15:44.099771 12957 net.cpp:150] Setting up norm2
I0205 07:15:44.099777 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.099782 12957 net.cpp:165] Memory required for data: 50385600
I0205 07:15:44.099788 12957 layer_factory.hpp:77] Creating layer conv3
I0205 07:15:44.099802 12957 net.cpp:106] Creating Layer conv3
I0205 07:15:44.099807 12957 net.cpp:454] conv3 <- norm2
I0205 07:15:44.099817 12957 net.cpp:411] conv3 -> conv3
I0205 07:15:44.099843 12957 net.cpp:150] Setting up conv3
I0205 07:15:44.099851 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.099856 12957 net.cpp:165] Memory required for data: 50926400
I0205 07:15:44.099866 12957 layer_factory.hpp:77] Creating layer relu3
I0205 07:15:44.099875 12957 net.cpp:106] Creating Layer relu3
I0205 07:15:44.099881 12957 net.cpp:454] relu3 <- conv3
I0205 07:15:44.099889 12957 net.cpp:397] relu3 -> conv3 (in-place)
I0205 07:15:44.099900 12957 net.cpp:150] Setting up relu3
I0205 07:15:44.099906 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.099911 12957 net.cpp:165] Memory required for data: 51467200
I0205 07:15:44.099916 12957 layer_factory.hpp:77] Creating layer conv4
I0205 07:15:44.099927 12957 net.cpp:106] Creating Layer conv4
I0205 07:15:44.099932 12957 net.cpp:454] conv4 <- conv3
I0205 07:15:44.099941 12957 net.cpp:411] conv4 -> conv4
I0205 07:15:44.099964 12957 net.cpp:150] Setting up conv4
I0205 07:15:44.099974 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.099979 12957 net.cpp:165] Memory required for data: 52008000
I0205 07:15:44.099988 12957 layer_factory.hpp:77] Creating layer relu4
I0205 07:15:44.099997 12957 net.cpp:106] Creating Layer relu4
I0205 07:15:44.100003 12957 net.cpp:454] relu4 <- conv4
I0205 07:15:44.100009 12957 net.cpp:397] relu4 -> conv4 (in-place)
I0205 07:15:44.100018 12957 net.cpp:150] Setting up relu4
I0205 07:15:44.100025 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.100033 12957 net.cpp:165] Memory required for data: 52548800
I0205 07:15:44.100039 12957 layer_factory.hpp:77] Creating layer conv5
I0205 07:15:44.100051 12957 net.cpp:106] Creating Layer conv5
I0205 07:15:44.100057 12957 net.cpp:454] conv5 <- conv4
I0205 07:15:44.100066 12957 net.cpp:411] conv5 -> conv5
I0205 07:15:44.100087 12957 net.cpp:150] Setting up conv5
I0205 07:15:44.100100 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.100106 12957 net.cpp:165] Memory required for data: 53089600
I0205 07:15:44.100116 12957 layer_factory.hpp:77] Creating layer relu5
I0205 07:15:44.100124 12957 net.cpp:106] Creating Layer relu5
I0205 07:15:44.100132 12957 net.cpp:454] relu5 <- conv5
I0205 07:15:44.100142 12957 net.cpp:397] relu5 -> conv5 (in-place)
I0205 07:15:44.100149 12957 net.cpp:150] Setting up relu5
I0205 07:15:44.100157 12957 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0205 07:15:44.100162 12957 net.cpp:165] Memory required for data: 53630400
I0205 07:15:44.100167 12957 layer_factory.hpp:77] Creating layer pool5
I0205 07:15:44.100178 12957 net.cpp:106] Creating Layer pool5
I0205 07:15:44.100183 12957 net.cpp:454] pool5 <- conv5
I0205 07:15:44.100193 12957 net.cpp:411] pool5 -> pool5
I0205 07:15:44.100210 12957 net.cpp:150] Setting up pool5
I0205 07:15:44.100227 12957 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0205 07:15:44.100234 12957 net.cpp:165] Memory required for data: 53745600
I0205 07:15:44.100239 12957 layer_factory.hpp:77] Creating layer fc6
I0205 07:15:44.100250 12957 net.cpp:106] Creating Layer fc6
I0205 07:15:44.100256 12957 net.cpp:454] fc6 <- pool5
I0205 07:15:44.100265 12957 net.cpp:411] fc6 -> fc6
I0205 07:15:44.100991 12957 net.cpp:150] Setting up fc6
I0205 07:15:44.101002 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.101007 12957 net.cpp:165] Memory required for data: 53848000
I0205 07:15:44.101016 12957 layer_factory.hpp:77] Creating layer relu6
I0205 07:15:44.101027 12957 net.cpp:106] Creating Layer relu6
I0205 07:15:44.101033 12957 net.cpp:454] relu6 <- fc6
I0205 07:15:44.101040 12957 net.cpp:397] relu6 -> fc6 (in-place)
I0205 07:15:44.101052 12957 net.cpp:150] Setting up relu6
I0205 07:15:44.101060 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.101065 12957 net.cpp:165] Memory required for data: 53950400
I0205 07:15:44.101070 12957 layer_factory.hpp:77] Creating layer drop6
I0205 07:15:44.101080 12957 net.cpp:106] Creating Layer drop6
I0205 07:15:44.101086 12957 net.cpp:454] drop6 <- fc6
I0205 07:15:44.101115 12957 net.cpp:397] drop6 -> fc6 (in-place)
I0205 07:15:44.101130 12957 net.cpp:150] Setting up drop6
I0205 07:15:44.101135 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.101140 12957 net.cpp:165] Memory required for data: 54052800
I0205 07:15:44.101146 12957 layer_factory.hpp:77] Creating layer fc7
I0205 07:15:44.101156 12957 net.cpp:106] Creating Layer fc7
I0205 07:15:44.101161 12957 net.cpp:454] fc7 <- fc6
I0205 07:15:44.101172 12957 net.cpp:411] fc7 -> fc7
I0205 07:15:44.101910 12957 net.cpp:150] Setting up fc7
I0205 07:15:44.101922 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.101927 12957 net.cpp:165] Memory required for data: 54155200
I0205 07:15:44.101934 12957 layer_factory.hpp:77] Creating layer relu7
I0205 07:15:44.101945 12957 net.cpp:106] Creating Layer relu7
I0205 07:15:44.101951 12957 net.cpp:454] relu7 <- fc7
I0205 07:15:44.101958 12957 net.cpp:397] relu7 -> fc7 (in-place)
I0205 07:15:44.101968 12957 net.cpp:150] Setting up relu7
I0205 07:15:44.101974 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.101980 12957 net.cpp:165] Memory required for data: 54257600
I0205 07:15:44.101986 12957 layer_factory.hpp:77] Creating layer drop7
I0205 07:15:44.101994 12957 net.cpp:106] Creating Layer drop7
I0205 07:15:44.102000 12957 net.cpp:454] drop7 <- fc7
I0205 07:15:44.102008 12957 net.cpp:397] drop7 -> fc7 (in-place)
I0205 07:15:44.102020 12957 net.cpp:150] Setting up drop7
I0205 07:15:44.102026 12957 net.cpp:157] Top shape: 100 256 (25600)
I0205 07:15:44.102031 12957 net.cpp:165] Memory required for data: 54360000
I0205 07:15:44.102037 12957 layer_factory.hpp:77] Creating layer fc8
I0205 07:15:44.102051 12957 net.cpp:106] Creating Layer fc8
I0205 07:15:44.102057 12957 net.cpp:454] fc8 <- fc7
I0205 07:15:44.102068 12957 net.cpp:411] fc8 -> fc8
I0205 07:15:44.102099 12957 net.cpp:150] Setting up fc8
I0205 07:15:44.102108 12957 net.cpp:157] Top shape: 100 2 (200)
I0205 07:15:44.102113 12957 net.cpp:165] Memory required for data: 54360800
I0205 07:15:44.102121 12957 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0205 07:15:44.102129 12957 net.cpp:106] Creating Layer fc8_fc8_0_split
I0205 07:15:44.102135 12957 net.cpp:454] fc8_fc8_0_split <- fc8
I0205 07:15:44.102143 12957 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0205 07:15:44.102151 12957 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0205 07:15:44.102164 12957 net.cpp:150] Setting up fc8_fc8_0_split
I0205 07:15:44.102172 12957 net.cpp:157] Top shape: 100 2 (200)
I0205 07:15:44.102179 12957 net.cpp:157] Top shape: 100 2 (200)
I0205 07:15:44.102185 12957 net.cpp:165] Memory required for data: 54362400
I0205 07:15:44.102190 12957 layer_factory.hpp:77] Creating layer accuracy
I0205 07:15:44.102219 12957 net.cpp:106] Creating Layer accuracy
I0205 07:15:44.102231 12957 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0205 07:15:44.102246 12957 net.cpp:454] accuracy <- label_data_1_split_0
I0205 07:15:44.102257 12957 net.cpp:411] accuracy -> accuracy
I0205 07:15:44.102268 12957 net.cpp:150] Setting up accuracy
I0205 07:15:44.102275 12957 net.cpp:157] Top shape: (1)
I0205 07:15:44.102280 12957 net.cpp:165] Memory required for data: 54362404
I0205 07:15:44.102286 12957 layer_factory.hpp:77] Creating layer loss
I0205 07:15:44.102294 12957 net.cpp:106] Creating Layer loss
I0205 07:15:44.102300 12957 net.cpp:454] loss <- fc8_fc8_0_split_1
I0205 07:15:44.102306 12957 net.cpp:454] loss <- label_data_1_split_1
I0205 07:15:44.102313 12957 net.cpp:411] loss -> loss
I0205 07:15:44.102324 12957 layer_factory.hpp:77] Creating layer loss
I0205 07:15:44.102349 12957 net.cpp:150] Setting up loss
I0205 07:15:44.102357 12957 net.cpp:157] Top shape: (1)
I0205 07:15:44.102363 12957 net.cpp:160]     with loss weight 1
I0205 07:15:44.102381 12957 net.cpp:165] Memory required for data: 54362408
I0205 07:15:44.102387 12957 net.cpp:226] loss needs backward computation.
I0205 07:15:44.102394 12957 net.cpp:228] accuracy does not need backward computation.
I0205 07:15:44.102401 12957 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0205 07:15:44.102406 12957 net.cpp:226] fc8 needs backward computation.
I0205 07:15:44.102412 12957 net.cpp:226] drop7 needs backward computation.
I0205 07:15:44.102417 12957 net.cpp:226] relu7 needs backward computation.
I0205 07:15:44.102422 12957 net.cpp:226] fc7 needs backward computation.
I0205 07:15:44.102428 12957 net.cpp:226] drop6 needs backward computation.
I0205 07:15:44.102433 12957 net.cpp:226] relu6 needs backward computation.
I0205 07:15:44.102439 12957 net.cpp:226] fc6 needs backward computation.
I0205 07:15:44.102445 12957 net.cpp:226] pool5 needs backward computation.
I0205 07:15:44.102452 12957 net.cpp:226] relu5 needs backward computation.
I0205 07:15:44.102457 12957 net.cpp:226] conv5 needs backward computation.
I0205 07:15:44.102463 12957 net.cpp:226] relu4 needs backward computation.
I0205 07:15:44.102468 12957 net.cpp:226] conv4 needs backward computation.
I0205 07:15:44.102473 12957 net.cpp:226] relu3 needs backward computation.
I0205 07:15:44.102479 12957 net.cpp:226] conv3 needs backward computation.
I0205 07:15:44.102485 12957 net.cpp:226] norm2 needs backward computation.
I0205 07:15:44.102490 12957 net.cpp:226] pool2 needs backward computation.
I0205 07:15:44.102499 12957 net.cpp:226] relu2 needs backward computation.
I0205 07:15:44.102504 12957 net.cpp:226] conv2 needs backward computation.
I0205 07:15:44.102512 12957 net.cpp:226] norm1 needs backward computation.
I0205 07:15:44.102519 12957 net.cpp:226] pool1 needs backward computation.
I0205 07:15:44.102524 12957 net.cpp:226] relu1 needs backward computation.
I0205 07:15:44.102530 12957 net.cpp:226] conv1 needs backward computation.
I0205 07:15:44.102536 12957 net.cpp:228] label_data_1_split does not need backward computation.
I0205 07:15:44.102542 12957 net.cpp:228] data does not need backward computation.
I0205 07:15:44.102547 12957 net.cpp:270] This network produces output accuracy
I0205 07:15:44.102555 12957 net.cpp:270] This network produces output loss
I0205 07:15:44.102582 12957 net.cpp:283] Network initialization done.
I0205 07:15:44.102699 12957 solver.cpp:60] Solver scaffolding done.
I0205 07:15:44.102756 12957 caffe.cpp:212] Starting Optimization
I0205 07:15:44.102763 12957 solver.cpp:288] Solving CaffeNet
I0205 07:15:44.102768 12957 solver.cpp:289] Learning Rate Policy: step
I0205 07:15:44.103296 12957 solver.cpp:341] Iteration 0, Testing net (#0)
I0205 07:15:44.103360 12957 blocking_queue.cpp:50] Data layer prefetch queue empty
I0205 07:15:46.488719 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:15:46.488786 12957 solver.cpp:409]     Test net output #1: loss = 12.5254 (* 1 = 12.5254 loss)
I0205 07:15:47.026195 12957 solver.cpp:237] Iteration 0, loss = 17.7294
I0205 07:15:47.026260 12957 solver.cpp:253]     Train net output #0: loss = 17.7294 (* 1 = 17.7294 loss)
I0205 07:15:47.026295 12957 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0205 07:15:51.745962 12957 solver.cpp:237] Iteration 10, loss = 1.21068
I0205 07:15:51.746031 12957 solver.cpp:253]     Train net output #0: loss = 1.21068 (* 1 = 1.21068 loss)
I0205 07:15:51.746042 12957 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0205 07:15:56.442699 12957 solver.cpp:237] Iteration 20, loss = 1.31084
I0205 07:15:56.442765 12957 solver.cpp:253]     Train net output #0: loss = 1.31084 (* 1 = 1.31084 loss)
I0205 07:15:56.442777 12957 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0205 07:16:01.137483 12957 solver.cpp:237] Iteration 30, loss = 1.09327
I0205 07:16:01.137552 12957 solver.cpp:253]     Train net output #0: loss = 1.09327 (* 1 = 1.09327 loss)
I0205 07:16:01.137562 12957 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0205 07:16:05.831634 12957 solver.cpp:237] Iteration 40, loss = 0.918412
I0205 07:16:05.831701 12957 solver.cpp:253]     Train net output #0: loss = 0.918412 (* 1 = 0.918412 loss)
I0205 07:16:05.831712 12957 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0205 07:16:10.524169 12957 solver.cpp:237] Iteration 50, loss = 0.852593
I0205 07:16:10.524237 12957 solver.cpp:253]     Train net output #0: loss = 0.852594 (* 1 = 0.852594 loss)
I0205 07:16:10.524250 12957 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0205 07:16:15.217002 12957 solver.cpp:237] Iteration 60, loss = 1.04664
I0205 07:16:15.217269 12957 solver.cpp:253]     Train net output #0: loss = 1.04664 (* 1 = 1.04664 loss)
I0205 07:16:15.217284 12957 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0205 07:16:19.911196 12957 solver.cpp:237] Iteration 70, loss = 0.872565
I0205 07:16:19.911264 12957 solver.cpp:253]     Train net output #0: loss = 0.872565 (* 1 = 0.872565 loss)
I0205 07:16:19.911276 12957 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0205 07:16:24.604702 12957 solver.cpp:237] Iteration 80, loss = 0.72822
I0205 07:16:24.604775 12957 solver.cpp:253]     Train net output #0: loss = 0.72822 (* 1 = 0.72822 loss)
I0205 07:16:24.604786 12957 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0205 07:16:29.300264 12957 solver.cpp:237] Iteration 90, loss = 0.802147
I0205 07:16:29.300329 12957 solver.cpp:253]     Train net output #0: loss = 0.802147 (* 1 = 0.802147 loss)
I0205 07:16:29.300341 12957 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0205 07:16:33.525239 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_100.caffemodel
I0205 07:16:33.528247 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_100.solverstate
I0205 07:16:33.529047 12957 solver.cpp:341] Iteration 100, Testing net (#0)
I0205 07:16:35.811316 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:16:35.811378 12957 solver.cpp:409]     Test net output #1: loss = 0.698177 (* 1 = 0.698177 loss)
I0205 07:16:36.280452 12957 solver.cpp:237] Iteration 100, loss = 0.786674
I0205 07:16:36.280517 12957 solver.cpp:253]     Train net output #0: loss = 0.786674 (* 1 = 0.786674 loss)
I0205 07:16:36.280529 12957 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0205 07:16:40.976310 12957 solver.cpp:237] Iteration 110, loss = 0.731408
I0205 07:16:40.976378 12957 solver.cpp:253]     Train net output #0: loss = 0.731409 (* 1 = 0.731409 loss)
I0205 07:16:40.976390 12957 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0205 07:16:45.671370 12957 solver.cpp:237] Iteration 120, loss = 0.781033
I0205 07:16:45.671778 12957 solver.cpp:253]     Train net output #0: loss = 0.781033 (* 1 = 0.781033 loss)
I0205 07:16:45.671794 12957 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0205 07:16:50.365926 12957 solver.cpp:237] Iteration 130, loss = 0.732932
I0205 07:16:50.365990 12957 solver.cpp:253]     Train net output #0: loss = 0.732933 (* 1 = 0.732933 loss)
I0205 07:16:50.366003 12957 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0205 07:16:55.060333 12957 solver.cpp:237] Iteration 140, loss = 0.810044
I0205 07:16:55.060401 12957 solver.cpp:253]     Train net output #0: loss = 0.810045 (* 1 = 0.810045 loss)
I0205 07:16:55.060413 12957 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0205 07:16:59.752899 12957 solver.cpp:237] Iteration 150, loss = 0.788279
I0205 07:16:59.752964 12957 solver.cpp:253]     Train net output #0: loss = 0.78828 (* 1 = 0.78828 loss)
I0205 07:16:59.752976 12957 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0205 07:17:04.445492 12957 solver.cpp:237] Iteration 160, loss = 0.684915
I0205 07:17:04.445555 12957 solver.cpp:253]     Train net output #0: loss = 0.684915 (* 1 = 0.684915 loss)
I0205 07:17:04.445567 12957 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0205 07:17:09.140686 12957 solver.cpp:237] Iteration 170, loss = 0.782086
I0205 07:17:09.140748 12957 solver.cpp:253]     Train net output #0: loss = 0.782087 (* 1 = 0.782087 loss)
I0205 07:17:09.140760 12957 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0205 07:17:13.848242 12957 solver.cpp:237] Iteration 180, loss = 0.696462
I0205 07:17:13.848307 12957 solver.cpp:253]     Train net output #0: loss = 0.696462 (* 1 = 0.696462 loss)
I0205 07:17:13.848320 12957 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0205 07:17:18.574409 12957 solver.cpp:237] Iteration 190, loss = 0.68737
I0205 07:17:18.574654 12957 solver.cpp:253]     Train net output #0: loss = 0.68737 (* 1 = 0.68737 loss)
I0205 07:17:18.574668 12957 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0205 07:17:22.827729 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_200.caffemodel
I0205 07:17:22.829759 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_200.solverstate
I0205 07:17:22.830565 12957 solver.cpp:341] Iteration 200, Testing net (#0)
I0205 07:17:25.126678 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:17:25.126739 12957 solver.cpp:409]     Test net output #1: loss = 0.693278 (* 1 = 0.693278 loss)
I0205 07:17:25.599429 12957 solver.cpp:237] Iteration 200, loss = 0.698324
I0205 07:17:25.599491 12957 solver.cpp:253]     Train net output #0: loss = 0.698324 (* 1 = 0.698324 loss)
I0205 07:17:25.599503 12957 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0205 07:17:30.331570 12957 solver.cpp:237] Iteration 210, loss = 0.715193
I0205 07:17:30.331640 12957 solver.cpp:253]     Train net output #0: loss = 0.715194 (* 1 = 0.715194 loss)
I0205 07:17:30.331652 12957 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0205 07:17:35.056437 12957 solver.cpp:237] Iteration 220, loss = 0.771563
I0205 07:17:35.056506 12957 solver.cpp:253]     Train net output #0: loss = 0.771563 (* 1 = 0.771563 loss)
I0205 07:17:35.056517 12957 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0205 07:17:39.783027 12957 solver.cpp:237] Iteration 230, loss = 0.730086
I0205 07:17:39.783098 12957 solver.cpp:253]     Train net output #0: loss = 0.730087 (* 1 = 0.730087 loss)
I0205 07:17:39.783112 12957 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0205 07:17:44.504951 12957 solver.cpp:237] Iteration 240, loss = 0.789732
I0205 07:17:44.505020 12957 solver.cpp:253]     Train net output #0: loss = 0.789733 (* 1 = 0.789733 loss)
I0205 07:17:44.505033 12957 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0205 07:17:49.197494 12957 solver.cpp:237] Iteration 250, loss = 0.750412
I0205 07:17:49.197691 12957 solver.cpp:253]     Train net output #0: loss = 0.750413 (* 1 = 0.750413 loss)
I0205 07:17:49.197706 12957 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0205 07:17:53.893877 12957 solver.cpp:237] Iteration 260, loss = 0.685812
I0205 07:17:53.893947 12957 solver.cpp:253]     Train net output #0: loss = 0.685813 (* 1 = 0.685813 loss)
I0205 07:17:53.893959 12957 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0205 07:17:58.586086 12957 solver.cpp:237] Iteration 270, loss = 0.776185
I0205 07:17:58.586172 12957 solver.cpp:253]     Train net output #0: loss = 0.776185 (* 1 = 0.776185 loss)
I0205 07:17:58.586184 12957 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0205 07:18:03.281502 12957 solver.cpp:237] Iteration 280, loss = 0.689212
I0205 07:18:03.281569 12957 solver.cpp:253]     Train net output #0: loss = 0.689212 (* 1 = 0.689212 loss)
I0205 07:18:03.281581 12957 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0205 07:18:07.975600 12957 solver.cpp:237] Iteration 290, loss = 0.706394
I0205 07:18:07.975668 12957 solver.cpp:253]     Train net output #0: loss = 0.706394 (* 1 = 0.706394 loss)
I0205 07:18:07.975682 12957 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0205 07:18:12.202610 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_300.caffemodel
I0205 07:18:12.204656 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_300.solverstate
I0205 07:18:12.205468 12957 solver.cpp:341] Iteration 300, Testing net (#0)
I0205 07:18:14.487845 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:18:14.487908 12957 solver.cpp:409]     Test net output #1: loss = 0.703528 (* 1 = 0.703528 loss)
I0205 07:18:14.956683 12957 solver.cpp:237] Iteration 300, loss = 0.751541
I0205 07:18:14.956743 12957 solver.cpp:253]     Train net output #0: loss = 0.751542 (* 1 = 0.751542 loss)
I0205 07:18:14.956755 12957 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0205 07:18:19.651432 12957 solver.cpp:237] Iteration 310, loss = 0.737485
I0205 07:18:19.651846 12957 solver.cpp:253]     Train net output #0: loss = 0.737486 (* 1 = 0.737486 loss)
I0205 07:18:19.651862 12957 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0205 07:18:24.346590 12957 solver.cpp:237] Iteration 320, loss = 0.704208
I0205 07:18:24.346660 12957 solver.cpp:253]     Train net output #0: loss = 0.704209 (* 1 = 0.704209 loss)
I0205 07:18:24.346673 12957 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0205 07:18:29.038528 12957 solver.cpp:237] Iteration 330, loss = 0.72674
I0205 07:18:29.038594 12957 solver.cpp:253]     Train net output #0: loss = 0.726741 (* 1 = 0.726741 loss)
I0205 07:18:29.038607 12957 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0205 07:18:33.748280 12957 solver.cpp:237] Iteration 340, loss = 0.740987
I0205 07:18:33.748350 12957 solver.cpp:253]     Train net output #0: loss = 0.740988 (* 1 = 0.740988 loss)
I0205 07:18:33.748363 12957 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0205 07:18:38.470038 12957 solver.cpp:237] Iteration 350, loss = 0.709501
I0205 07:18:38.470108 12957 solver.cpp:253]     Train net output #0: loss = 0.709502 (* 1 = 0.709502 loss)
I0205 07:18:38.470120 12957 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0205 07:18:43.198246 12957 solver.cpp:237] Iteration 360, loss = 0.724304
I0205 07:18:43.198319 12957 solver.cpp:253]     Train net output #0: loss = 0.724304 (* 1 = 0.724304 loss)
I0205 07:18:43.198331 12957 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0205 07:18:47.917474 12957 solver.cpp:237] Iteration 370, loss = 0.73087
I0205 07:18:47.917546 12957 solver.cpp:253]     Train net output #0: loss = 0.730871 (* 1 = 0.730871 loss)
I0205 07:18:47.917557 12957 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0205 07:18:52.635656 12957 solver.cpp:237] Iteration 380, loss = 0.786013
I0205 07:18:52.635862 12957 solver.cpp:253]     Train net output #0: loss = 0.786013 (* 1 = 0.786013 loss)
I0205 07:18:52.635877 12957 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0205 07:18:57.356854 12957 solver.cpp:237] Iteration 390, loss = 0.719742
I0205 07:18:57.356921 12957 solver.cpp:253]     Train net output #0: loss = 0.719743 (* 1 = 0.719743 loss)
I0205 07:18:57.356933 12957 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0205 07:19:01.603139 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_400.caffemodel
I0205 07:19:01.605190 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_400.solverstate
I0205 07:19:01.605978 12957 solver.cpp:341] Iteration 400, Testing net (#0)
I0205 07:19:03.887895 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:19:03.887959 12957 solver.cpp:409]     Test net output #1: loss = 0.69441 (* 1 = 0.69441 loss)
I0205 07:19:04.359164 12957 solver.cpp:237] Iteration 400, loss = 0.690522
I0205 07:19:04.359230 12957 solver.cpp:253]     Train net output #0: loss = 0.690522 (* 1 = 0.690522 loss)
I0205 07:19:04.359241 12957 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0205 07:19:09.076969 12957 solver.cpp:237] Iteration 410, loss = 0.731894
I0205 07:19:09.077039 12957 solver.cpp:253]     Train net output #0: loss = 0.731895 (* 1 = 0.731895 loss)
I0205 07:19:09.077051 12957 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0205 07:19:13.797822 12957 solver.cpp:237] Iteration 420, loss = 0.667288
I0205 07:19:13.797888 12957 solver.cpp:253]     Train net output #0: loss = 0.667288 (* 1 = 0.667288 loss)
I0205 07:19:13.797900 12957 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0205 07:19:18.518163 12957 solver.cpp:237] Iteration 430, loss = 0.704874
I0205 07:19:18.518230 12957 solver.cpp:253]     Train net output #0: loss = 0.704874 (* 1 = 0.704874 loss)
I0205 07:19:18.518242 12957 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0205 07:19:23.238070 12957 solver.cpp:237] Iteration 440, loss = 0.71727
I0205 07:19:23.238299 12957 solver.cpp:253]     Train net output #0: loss = 0.717271 (* 1 = 0.717271 loss)
I0205 07:19:23.238314 12957 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0205 07:19:27.959043 12957 solver.cpp:237] Iteration 450, loss = 0.713987
I0205 07:19:27.959111 12957 solver.cpp:253]     Train net output #0: loss = 0.713987 (* 1 = 0.713987 loss)
I0205 07:19:27.959123 12957 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0205 07:19:32.679054 12957 solver.cpp:237] Iteration 460, loss = 0.711265
I0205 07:19:32.679126 12957 solver.cpp:253]     Train net output #0: loss = 0.711266 (* 1 = 0.711266 loss)
I0205 07:19:32.679139 12957 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0205 07:19:37.399462 12957 solver.cpp:237] Iteration 470, loss = 0.709322
I0205 07:19:37.399533 12957 solver.cpp:253]     Train net output #0: loss = 0.709322 (* 1 = 0.709322 loss)
I0205 07:19:37.399546 12957 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0205 07:19:42.118641 12957 solver.cpp:237] Iteration 480, loss = 0.709282
I0205 07:19:42.118716 12957 solver.cpp:253]     Train net output #0: loss = 0.709283 (* 1 = 0.709283 loss)
I0205 07:19:42.118728 12957 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0205 07:19:46.837355 12957 solver.cpp:237] Iteration 490, loss = 0.748648
I0205 07:19:46.837424 12957 solver.cpp:253]     Train net output #0: loss = 0.748648 (* 1 = 0.748648 loss)
I0205 07:19:46.837436 12957 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0205 07:19:51.081223 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_500.caffemodel
I0205 07:19:51.083266 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_500.solverstate
I0205 07:19:51.084059 12957 solver.cpp:341] Iteration 500, Testing net (#0)
I0205 07:19:53.364259 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:19:53.364446 12957 solver.cpp:409]     Test net output #1: loss = 0.701368 (* 1 = 0.701368 loss)
I0205 07:19:53.836067 12957 solver.cpp:237] Iteration 500, loss = 0.694087
I0205 07:19:53.836138 12957 solver.cpp:253]     Train net output #0: loss = 0.694087 (* 1 = 0.694087 loss)
I0205 07:19:53.836150 12957 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0205 07:19:58.551806 12957 solver.cpp:237] Iteration 510, loss = 0.721967
I0205 07:19:58.551879 12957 solver.cpp:253]     Train net output #0: loss = 0.721967 (* 1 = 0.721967 loss)
I0205 07:19:58.551890 12957 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0205 07:20:03.274777 12957 solver.cpp:237] Iteration 520, loss = 0.719353
I0205 07:20:03.274844 12957 solver.cpp:253]     Train net output #0: loss = 0.719353 (* 1 = 0.719353 loss)
I0205 07:20:03.274857 12957 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0205 07:20:07.991148 12957 solver.cpp:237] Iteration 530, loss = 0.711698
I0205 07:20:07.991224 12957 solver.cpp:253]     Train net output #0: loss = 0.711698 (* 1 = 0.711698 loss)
I0205 07:20:07.991235 12957 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0205 07:20:12.709832 12957 solver.cpp:237] Iteration 540, loss = 0.72717
I0205 07:20:12.709902 12957 solver.cpp:253]     Train net output #0: loss = 0.727171 (* 1 = 0.727171 loss)
I0205 07:20:12.709914 12957 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0205 07:20:17.432833 12957 solver.cpp:237] Iteration 550, loss = 0.706203
I0205 07:20:17.432903 12957 solver.cpp:253]     Train net output #0: loss = 0.706203 (* 1 = 0.706203 loss)
I0205 07:20:17.432915 12957 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0205 07:20:22.157325 12957 solver.cpp:237] Iteration 560, loss = 0.693501
I0205 07:20:22.157390 12957 solver.cpp:253]     Train net output #0: loss = 0.693502 (* 1 = 0.693502 loss)
I0205 07:20:22.157402 12957 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0205 07:20:26.877384 12957 solver.cpp:237] Iteration 570, loss = 0.756149
I0205 07:20:26.877609 12957 solver.cpp:253]     Train net output #0: loss = 0.756149 (* 1 = 0.756149 loss)
I0205 07:20:26.877624 12957 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0205 07:20:31.594768 12957 solver.cpp:237] Iteration 580, loss = 0.684501
I0205 07:20:31.594838 12957 solver.cpp:253]     Train net output #0: loss = 0.684502 (* 1 = 0.684502 loss)
I0205 07:20:31.594849 12957 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0205 07:20:36.312219 12957 solver.cpp:237] Iteration 590, loss = 0.766982
I0205 07:20:36.312300 12957 solver.cpp:253]     Train net output #0: loss = 0.766982 (* 1 = 0.766982 loss)
I0205 07:20:36.312312 12957 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0205 07:20:40.559737 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_600.caffemodel
I0205 07:20:40.561791 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_600.solverstate
I0205 07:20:40.562582 12957 solver.cpp:341] Iteration 600, Testing net (#0)
I0205 07:20:42.844127 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:20:42.844197 12957 solver.cpp:409]     Test net output #1: loss = 0.698957 (* 1 = 0.698957 loss)
I0205 07:20:43.315649 12957 solver.cpp:237] Iteration 600, loss = 0.686136
I0205 07:20:43.315713 12957 solver.cpp:253]     Train net output #0: loss = 0.686137 (* 1 = 0.686137 loss)
I0205 07:20:43.315726 12957 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0205 07:20:48.035605 12957 solver.cpp:237] Iteration 610, loss = 0.706494
I0205 07:20:48.035675 12957 solver.cpp:253]     Train net output #0: loss = 0.706494 (* 1 = 0.706494 loss)
I0205 07:20:48.035687 12957 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0205 07:20:52.755959 12957 solver.cpp:237] Iteration 620, loss = 0.734924
I0205 07:20:52.756028 12957 solver.cpp:253]     Train net output #0: loss = 0.734925 (* 1 = 0.734925 loss)
I0205 07:20:52.756041 12957 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0205 07:20:57.478343 12957 solver.cpp:237] Iteration 630, loss = 0.708898
I0205 07:20:57.478540 12957 solver.cpp:253]     Train net output #0: loss = 0.708899 (* 1 = 0.708899 loss)
I0205 07:20:57.478554 12957 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0205 07:21:02.198295 12957 solver.cpp:237] Iteration 640, loss = 0.712757
I0205 07:21:02.198379 12957 solver.cpp:253]     Train net output #0: loss = 0.712757 (* 1 = 0.712757 loss)
I0205 07:21:02.198390 12957 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0205 07:21:06.917078 12957 solver.cpp:237] Iteration 650, loss = 0.736415
I0205 07:21:06.917151 12957 solver.cpp:253]     Train net output #0: loss = 0.736416 (* 1 = 0.736416 loss)
I0205 07:21:06.917165 12957 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0205 07:21:11.636379 12957 solver.cpp:237] Iteration 660, loss = 0.699713
I0205 07:21:11.932215 12957 solver.cpp:253]     Train net output #0: loss = 0.699713 (* 1 = 0.699713 loss)
I0205 07:21:11.932250 12957 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0205 07:21:16.763864 12957 solver.cpp:237] Iteration 670, loss = 0.717545
I0205 07:21:16.763936 12957 solver.cpp:253]     Train net output #0: loss = 0.717546 (* 1 = 0.717546 loss)
I0205 07:21:16.763948 12957 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0205 07:21:21.592788 12957 solver.cpp:237] Iteration 680, loss = 0.713884
I0205 07:21:21.592864 12957 solver.cpp:253]     Train net output #0: loss = 0.713885 (* 1 = 0.713885 loss)
I0205 07:21:21.592875 12957 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0205 07:21:26.418635 12957 solver.cpp:237] Iteration 690, loss = 0.708174
I0205 07:21:26.418704 12957 solver.cpp:253]     Train net output #0: loss = 0.708174 (* 1 = 0.708174 loss)
I0205 07:21:26.418715 12957 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0205 07:21:30.765287 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_700.caffemodel
I0205 07:21:30.768307 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_700.solverstate
I0205 07:21:30.769106 12957 solver.cpp:341] Iteration 700, Testing net (#0)
I0205 07:21:33.120877 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:21:33.120946 12957 solver.cpp:409]     Test net output #1: loss = 0.696178 (* 1 = 0.696178 loss)
I0205 07:21:33.603070 12957 solver.cpp:237] Iteration 700, loss = 0.735119
I0205 07:21:33.603145 12957 solver.cpp:253]     Train net output #0: loss = 0.735119 (* 1 = 0.735119 loss)
I0205 07:21:33.603158 12957 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0205 07:21:38.431360 12957 solver.cpp:237] Iteration 710, loss = 0.698547
I0205 07:21:38.431428 12957 solver.cpp:253]     Train net output #0: loss = 0.698547 (* 1 = 0.698547 loss)
I0205 07:21:38.431440 12957 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0205 07:21:43.263397 12957 solver.cpp:237] Iteration 720, loss = 0.68574
I0205 07:21:43.263465 12957 solver.cpp:253]     Train net output #0: loss = 0.68574 (* 1 = 0.68574 loss)
I0205 07:21:43.263478 12957 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0205 07:21:48.088168 12957 solver.cpp:237] Iteration 730, loss = 0.729802
I0205 07:21:48.088243 12957 solver.cpp:253]     Train net output #0: loss = 0.729803 (* 1 = 0.729803 loss)
I0205 07:21:48.088255 12957 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0205 07:21:52.913259 12957 solver.cpp:237] Iteration 740, loss = 0.697218
I0205 07:21:52.913326 12957 solver.cpp:253]     Train net output #0: loss = 0.697219 (* 1 = 0.697219 loss)
I0205 07:21:52.913337 12957 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0205 07:21:57.741430 12957 solver.cpp:237] Iteration 750, loss = 0.718071
I0205 07:21:57.741499 12957 solver.cpp:253]     Train net output #0: loss = 0.718071 (* 1 = 0.718071 loss)
I0205 07:21:57.741511 12957 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0205 07:22:02.567389 12957 solver.cpp:237] Iteration 760, loss = 0.709972
I0205 07:22:02.567611 12957 solver.cpp:253]     Train net output #0: loss = 0.709972 (* 1 = 0.709972 loss)
I0205 07:22:02.567627 12957 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0205 07:22:07.390218 12957 solver.cpp:237] Iteration 770, loss = 0.697007
I0205 07:22:07.390290 12957 solver.cpp:253]     Train net output #0: loss = 0.697007 (* 1 = 0.697007 loss)
I0205 07:22:07.390317 12957 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0205 07:22:12.218163 12957 solver.cpp:237] Iteration 780, loss = 0.73716
I0205 07:22:12.218230 12957 solver.cpp:253]     Train net output #0: loss = 0.73716 (* 1 = 0.73716 loss)
I0205 07:22:12.218242 12957 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0205 07:22:17.044370 12957 solver.cpp:237] Iteration 790, loss = 0.675103
I0205 07:22:17.044441 12957 solver.cpp:253]     Train net output #0: loss = 0.675104 (* 1 = 0.675104 loss)
I0205 07:22:17.044453 12957 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0205 07:22:21.389696 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_800.caffemodel
I0205 07:22:21.391779 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_800.solverstate
I0205 07:22:21.392575 12957 solver.cpp:341] Iteration 800, Testing net (#0)
I0205 07:22:23.744917 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:22:23.744981 12957 solver.cpp:409]     Test net output #1: loss = 0.696483 (* 1 = 0.696483 loss)
I0205 07:22:24.227762 12957 solver.cpp:237] Iteration 800, loss = 0.699997
I0205 07:22:24.227824 12957 solver.cpp:253]     Train net output #0: loss = 0.699997 (* 1 = 0.699997 loss)
I0205 07:22:24.227838 12957 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0205 07:22:29.054143 12957 solver.cpp:237] Iteration 810, loss = 0.728305
I0205 07:22:29.054214 12957 solver.cpp:253]     Train net output #0: loss = 0.728305 (* 1 = 0.728305 loss)
I0205 07:22:29.054226 12957 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0205 07:22:33.883708 12957 solver.cpp:237] Iteration 820, loss = 0.68823
I0205 07:22:33.892606 12957 solver.cpp:253]     Train net output #0: loss = 0.68823 (* 1 = 0.68823 loss)
I0205 07:22:33.892637 12957 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0205 07:22:38.721560 12957 solver.cpp:237] Iteration 830, loss = 0.712224
I0205 07:22:38.721629 12957 solver.cpp:253]     Train net output #0: loss = 0.712224 (* 1 = 0.712224 loss)
I0205 07:22:38.721642 12957 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0205 07:22:43.553010 12957 solver.cpp:237] Iteration 840, loss = 0.700808
I0205 07:22:43.553083 12957 solver.cpp:253]     Train net output #0: loss = 0.700809 (* 1 = 0.700809 loss)
I0205 07:22:43.553102 12957 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0205 07:22:48.381254 12957 solver.cpp:237] Iteration 850, loss = 0.730037
I0205 07:22:48.381328 12957 solver.cpp:253]     Train net output #0: loss = 0.730037 (* 1 = 0.730037 loss)
I0205 07:22:48.381340 12957 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0205 07:22:53.209537 12957 solver.cpp:237] Iteration 860, loss = 0.722095
I0205 07:22:53.209605 12957 solver.cpp:253]     Train net output #0: loss = 0.722095 (* 1 = 0.722095 loss)
I0205 07:22:53.209617 12957 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0205 07:22:58.041013 12957 solver.cpp:237] Iteration 870, loss = 0.670684
I0205 07:22:58.041084 12957 solver.cpp:253]     Train net output #0: loss = 0.670685 (* 1 = 0.670685 loss)
I0205 07:22:58.041100 12957 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0205 07:23:02.873622 12957 solver.cpp:237] Iteration 880, loss = 0.702062
I0205 07:23:02.873688 12957 solver.cpp:253]     Train net output #0: loss = 0.702062 (* 1 = 0.702062 loss)
I0205 07:23:02.873700 12957 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0205 07:23:07.703688 12957 solver.cpp:237] Iteration 890, loss = 0.743431
I0205 07:23:07.703891 12957 solver.cpp:253]     Train net output #0: loss = 0.743432 (* 1 = 0.743432 loss)
I0205 07:23:07.703905 12957 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0205 07:23:12.047075 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_900.caffemodel
I0205 07:23:12.049166 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_900.solverstate
I0205 07:23:12.049965 12957 solver.cpp:341] Iteration 900, Testing net (#0)
I0205 07:23:14.402685 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:23:14.402752 12957 solver.cpp:409]     Test net output #1: loss = 0.704518 (* 1 = 0.704518 loss)
I0205 07:23:14.887475 12957 solver.cpp:237] Iteration 900, loss = 0.69186
I0205 07:23:14.887539 12957 solver.cpp:253]     Train net output #0: loss = 0.69186 (* 1 = 0.69186 loss)
I0205 07:23:14.887552 12957 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0205 07:23:19.715896 12957 solver.cpp:237] Iteration 910, loss = 0.714749
I0205 07:23:19.715968 12957 solver.cpp:253]     Train net output #0: loss = 0.714749 (* 1 = 0.714749 loss)
I0205 07:23:19.715981 12957 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0205 07:23:24.544387 12957 solver.cpp:237] Iteration 920, loss = 0.717975
I0205 07:23:24.544456 12957 solver.cpp:253]     Train net output #0: loss = 0.717976 (* 1 = 0.717976 loss)
I0205 07:23:24.544469 12957 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0205 07:23:29.370805 12957 solver.cpp:237] Iteration 930, loss = 0.717297
I0205 07:23:29.370872 12957 solver.cpp:253]     Train net output #0: loss = 0.717297 (* 1 = 0.717297 loss)
I0205 07:23:29.370883 12957 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0205 07:23:34.197474 12957 solver.cpp:237] Iteration 940, loss = 0.744062
I0205 07:23:34.197541 12957 solver.cpp:253]     Train net output #0: loss = 0.744062 (* 1 = 0.744062 loss)
I0205 07:23:34.197553 12957 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0205 07:23:39.027648 12957 solver.cpp:237] Iteration 950, loss = 0.690957
I0205 07:23:39.027876 12957 solver.cpp:253]     Train net output #0: loss = 0.690958 (* 1 = 0.690958 loss)
I0205 07:23:39.027891 12957 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0205 07:23:43.855446 12957 solver.cpp:237] Iteration 960, loss = 0.68083
I0205 07:23:43.855515 12957 solver.cpp:253]     Train net output #0: loss = 0.68083 (* 1 = 0.68083 loss)
I0205 07:23:43.855527 12957 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0205 07:23:48.693763 12957 solver.cpp:237] Iteration 970, loss = 0.725369
I0205 07:23:48.693832 12957 solver.cpp:253]     Train net output #0: loss = 0.72537 (* 1 = 0.72537 loss)
I0205 07:23:48.693845 12957 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0205 07:23:53.520946 12957 solver.cpp:237] Iteration 980, loss = 0.676939
I0205 07:23:53.521018 12957 solver.cpp:253]     Train net output #0: loss = 0.676939 (* 1 = 0.676939 loss)
I0205 07:23:53.521030 12957 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0205 07:23:58.348428 12957 solver.cpp:237] Iteration 990, loss = 0.707953
I0205 07:23:58.348495 12957 solver.cpp:253]     Train net output #0: loss = 0.707953 (* 1 = 0.707953 loss)
I0205 07:23:58.348506 12957 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0205 07:24:02.695317 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1000.caffemodel
I0205 07:24:02.697404 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1000.solverstate
I0205 07:24:02.698209 12957 solver.cpp:341] Iteration 1000, Testing net (#0)
I0205 07:24:05.049571 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:24:05.049636 12957 solver.cpp:409]     Test net output #1: loss = 0.694448 (* 1 = 0.694448 loss)
I0205 07:24:05.532183 12957 solver.cpp:237] Iteration 1000, loss = 0.68672
I0205 07:24:05.532249 12957 solver.cpp:253]     Train net output #0: loss = 0.68672 (* 1 = 0.68672 loss)
I0205 07:24:05.532261 12957 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0205 07:24:10.358422 12957 solver.cpp:237] Iteration 1010, loss = 0.692364
I0205 07:24:10.360036 12957 solver.cpp:253]     Train net output #0: loss = 0.692365 (* 1 = 0.692365 loss)
I0205 07:24:10.360064 12957 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0205 07:24:15.184671 12957 solver.cpp:237] Iteration 1020, loss = 0.701345
I0205 07:24:15.184741 12957 solver.cpp:253]     Train net output #0: loss = 0.701345 (* 1 = 0.701345 loss)
I0205 07:24:15.184752 12957 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0205 07:24:20.013561 12957 solver.cpp:237] Iteration 1030, loss = 0.689611
I0205 07:24:20.013634 12957 solver.cpp:253]     Train net output #0: loss = 0.689612 (* 1 = 0.689612 loss)
I0205 07:24:20.013646 12957 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0205 07:24:24.841552 12957 solver.cpp:237] Iteration 1040, loss = 0.708434
I0205 07:24:24.841619 12957 solver.cpp:253]     Train net output #0: loss = 0.708434 (* 1 = 0.708434 loss)
I0205 07:24:24.841630 12957 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0205 07:24:29.668166 12957 solver.cpp:237] Iteration 1050, loss = 0.730235
I0205 07:24:29.668233 12957 solver.cpp:253]     Train net output #0: loss = 0.730236 (* 1 = 0.730236 loss)
I0205 07:24:29.668246 12957 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0205 07:24:34.495012 12957 solver.cpp:237] Iteration 1060, loss = 0.693557
I0205 07:24:34.495084 12957 solver.cpp:253]     Train net output #0: loss = 0.693558 (* 1 = 0.693558 loss)
I0205 07:24:34.495108 12957 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0205 07:24:39.318801 12957 solver.cpp:237] Iteration 1070, loss = 0.71237
I0205 07:24:39.318869 12957 solver.cpp:253]     Train net output #0: loss = 0.71237 (* 1 = 0.71237 loss)
I0205 07:24:39.318881 12957 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0205 07:24:44.149116 12957 solver.cpp:237] Iteration 1080, loss = 0.71198
I0205 07:24:44.149317 12957 solver.cpp:253]     Train net output #0: loss = 0.71198 (* 1 = 0.71198 loss)
I0205 07:24:44.149332 12957 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0205 07:24:48.974213 12957 solver.cpp:237] Iteration 1090, loss = 0.716043
I0205 07:24:48.974285 12957 solver.cpp:253]     Train net output #0: loss = 0.716044 (* 1 = 0.716044 loss)
I0205 07:24:48.974298 12957 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0205 07:24:53.317484 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1100.caffemodel
I0205 07:24:53.319598 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1100.solverstate
I0205 07:24:53.320431 12957 solver.cpp:341] Iteration 1100, Testing net (#0)
I0205 07:24:55.671056 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:24:55.671124 12957 solver.cpp:409]     Test net output #1: loss = 0.694267 (* 1 = 0.694267 loss)
I0205 07:24:56.153420 12957 solver.cpp:237] Iteration 1100, loss = 0.748503
I0205 07:24:56.153487 12957 solver.cpp:253]     Train net output #0: loss = 0.748503 (* 1 = 0.748503 loss)
I0205 07:24:56.153499 12957 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0205 07:25:00.981693 12957 solver.cpp:237] Iteration 1110, loss = 0.706382
I0205 07:25:00.981766 12957 solver.cpp:253]     Train net output #0: loss = 0.706382 (* 1 = 0.706382 loss)
I0205 07:25:00.981780 12957 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0205 07:25:05.809180 12957 solver.cpp:237] Iteration 1120, loss = 0.690371
I0205 07:25:05.809248 12957 solver.cpp:253]     Train net output #0: loss = 0.690371 (* 1 = 0.690371 loss)
I0205 07:25:05.809260 12957 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0205 07:25:10.635931 12957 solver.cpp:237] Iteration 1130, loss = 0.728138
I0205 07:25:10.636006 12957 solver.cpp:253]     Train net output #0: loss = 0.728138 (* 1 = 0.728138 loss)
I0205 07:25:10.636018 12957 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0205 07:25:15.460902 12957 solver.cpp:237] Iteration 1140, loss = 0.685446
I0205 07:25:15.461135 12957 solver.cpp:253]     Train net output #0: loss = 0.685446 (* 1 = 0.685446 loss)
I0205 07:25:15.461153 12957 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0205 07:25:20.288959 12957 solver.cpp:237] Iteration 1150, loss = 0.708174
I0205 07:25:20.289032 12957 solver.cpp:253]     Train net output #0: loss = 0.708175 (* 1 = 0.708175 loss)
I0205 07:25:20.289046 12957 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0205 07:25:25.112705 12957 solver.cpp:237] Iteration 1160, loss = 0.710383
I0205 07:25:25.112768 12957 solver.cpp:253]     Train net output #0: loss = 0.710383 (* 1 = 0.710383 loss)
I0205 07:25:25.112781 12957 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0205 07:25:29.937587 12957 solver.cpp:237] Iteration 1170, loss = 0.683322
I0205 07:25:29.937654 12957 solver.cpp:253]     Train net output #0: loss = 0.683322 (* 1 = 0.683322 loss)
I0205 07:25:29.937666 12957 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0205 07:25:34.762457 12957 solver.cpp:237] Iteration 1180, loss = 0.717513
I0205 07:25:34.762529 12957 solver.cpp:253]     Train net output #0: loss = 0.717514 (* 1 = 0.717514 loss)
I0205 07:25:34.762542 12957 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0205 07:25:39.589561 12957 solver.cpp:237] Iteration 1190, loss = 0.687681
I0205 07:25:39.589632 12957 solver.cpp:253]     Train net output #0: loss = 0.687681 (* 1 = 0.687681 loss)
I0205 07:25:39.589643 12957 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0205 07:25:43.933353 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1200.caffemodel
I0205 07:25:43.935467 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1200.solverstate
I0205 07:25:43.936291 12957 solver.cpp:341] Iteration 1200, Testing net (#0)
I0205 07:25:46.291105 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:25:46.291311 12957 solver.cpp:409]     Test net output #1: loss = 0.695017 (* 1 = 0.695017 loss)
I0205 07:25:46.773591 12957 solver.cpp:237] Iteration 1200, loss = 0.7064
I0205 07:25:46.773658 12957 solver.cpp:253]     Train net output #0: loss = 0.7064 (* 1 = 0.7064 loss)
I0205 07:25:46.773671 12957 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0205 07:25:51.598744 12957 solver.cpp:237] Iteration 1210, loss = 0.725989
I0205 07:25:51.598815 12957 solver.cpp:253]     Train net output #0: loss = 0.725989 (* 1 = 0.725989 loss)
I0205 07:25:51.598827 12957 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0205 07:25:56.424017 12957 solver.cpp:237] Iteration 1220, loss = 0.711375
I0205 07:25:56.424085 12957 solver.cpp:253]     Train net output #0: loss = 0.711375 (* 1 = 0.711375 loss)
I0205 07:25:56.424104 12957 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0205 07:26:01.254271 12957 solver.cpp:237] Iteration 1230, loss = 0.694635
I0205 07:26:01.254340 12957 solver.cpp:253]     Train net output #0: loss = 0.694636 (* 1 = 0.694636 loss)
I0205 07:26:01.254354 12957 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0205 07:26:06.081897 12957 solver.cpp:237] Iteration 1240, loss = 0.701653
I0205 07:26:06.081964 12957 solver.cpp:253]     Train net output #0: loss = 0.701653 (* 1 = 0.701653 loss)
I0205 07:26:06.081975 12957 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0205 07:26:10.912799 12957 solver.cpp:237] Iteration 1250, loss = 0.701505
I0205 07:26:10.912868 12957 solver.cpp:253]     Train net output #0: loss = 0.701505 (* 1 = 0.701505 loss)
I0205 07:26:10.912879 12957 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0205 07:26:15.745496 12957 solver.cpp:237] Iteration 1260, loss = 0.718409
I0205 07:26:15.745563 12957 solver.cpp:253]     Train net output #0: loss = 0.71841 (* 1 = 0.71841 loss)
I0205 07:26:15.745575 12957 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0205 07:26:20.572674 12957 solver.cpp:237] Iteration 1270, loss = 0.69563
I0205 07:26:20.572944 12957 solver.cpp:253]     Train net output #0: loss = 0.695631 (* 1 = 0.695631 loss)
I0205 07:26:20.572963 12957 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0205 07:26:25.399521 12957 solver.cpp:237] Iteration 1280, loss = 0.690344
I0205 07:26:25.399595 12957 solver.cpp:253]     Train net output #0: loss = 0.690344 (* 1 = 0.690344 loss)
I0205 07:26:25.399606 12957 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0205 07:26:30.224014 12957 solver.cpp:237] Iteration 1290, loss = 0.720061
I0205 07:26:30.224079 12957 solver.cpp:253]     Train net output #0: loss = 0.720062 (* 1 = 0.720062 loss)
I0205 07:26:30.224097 12957 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0205 07:26:34.570353 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1300.caffemodel
I0205 07:26:34.572458 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1300.solverstate
I0205 07:26:34.573274 12957 solver.cpp:341] Iteration 1300, Testing net (#0)
I0205 07:26:36.928705 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:26:36.928764 12957 solver.cpp:409]     Test net output #1: loss = 0.699161 (* 1 = 0.699161 loss)
I0205 07:26:37.412282 12957 solver.cpp:237] Iteration 1300, loss = 0.69995
I0205 07:26:37.412354 12957 solver.cpp:253]     Train net output #0: loss = 0.699951 (* 1 = 0.699951 loss)
I0205 07:26:37.412367 12957 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0205 07:26:42.239065 12957 solver.cpp:237] Iteration 1310, loss = 0.682909
I0205 07:26:42.239140 12957 solver.cpp:253]     Train net output #0: loss = 0.682909 (* 1 = 0.682909 loss)
I0205 07:26:42.239152 12957 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0205 07:26:47.070504 12957 solver.cpp:237] Iteration 1320, loss = 0.701907
I0205 07:26:47.070569 12957 solver.cpp:253]     Train net output #0: loss = 0.701908 (* 1 = 0.701908 loss)
I0205 07:26:47.070580 12957 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0205 07:26:51.893719 12957 solver.cpp:237] Iteration 1330, loss = 0.704913
I0205 07:26:51.893921 12957 solver.cpp:253]     Train net output #0: loss = 0.704913 (* 1 = 0.704913 loss)
I0205 07:26:51.893935 12957 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0205 07:26:56.725464 12957 solver.cpp:237] Iteration 1340, loss = 0.715086
I0205 07:26:56.725535 12957 solver.cpp:253]     Train net output #0: loss = 0.715086 (* 1 = 0.715086 loss)
I0205 07:26:56.725548 12957 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0205 07:27:01.550928 12957 solver.cpp:237] Iteration 1350, loss = 0.691438
I0205 07:27:01.550994 12957 solver.cpp:253]     Train net output #0: loss = 0.691438 (* 1 = 0.691438 loss)
I0205 07:27:01.551007 12957 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0205 07:27:06.378262 12957 solver.cpp:237] Iteration 1360, loss = 0.685989
I0205 07:27:06.378334 12957 solver.cpp:253]     Train net output #0: loss = 0.68599 (* 1 = 0.68599 loss)
I0205 07:27:06.378345 12957 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0205 07:27:11.210883 12957 solver.cpp:237] Iteration 1370, loss = 0.718181
I0205 07:27:11.210952 12957 solver.cpp:253]     Train net output #0: loss = 0.718181 (* 1 = 0.718181 loss)
I0205 07:27:11.210963 12957 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0205 07:27:16.039046 12957 solver.cpp:237] Iteration 1380, loss = 0.685625
I0205 07:27:16.039124 12957 solver.cpp:253]     Train net output #0: loss = 0.685626 (* 1 = 0.685626 loss)
I0205 07:27:16.039136 12957 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0205 07:27:20.868865 12957 solver.cpp:237] Iteration 1390, loss = 0.704114
I0205 07:27:20.868937 12957 solver.cpp:253]     Train net output #0: loss = 0.704114 (* 1 = 0.704114 loss)
I0205 07:27:20.868948 12957 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0205 07:27:25.215003 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1400.caffemodel
I0205 07:27:25.217310 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1400.solverstate
I0205 07:27:25.218137 12957 solver.cpp:341] Iteration 1400, Testing net (#0)
I0205 07:27:27.572733 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:27:27.572798 12957 solver.cpp:409]     Test net output #1: loss = 0.694101 (* 1 = 0.694101 loss)
I0205 07:27:28.056079 12957 solver.cpp:237] Iteration 1400, loss = 0.707965
I0205 07:27:28.056148 12957 solver.cpp:253]     Train net output #0: loss = 0.707965 (* 1 = 0.707965 loss)
I0205 07:27:28.056160 12957 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0205 07:27:32.886330 12957 solver.cpp:237] Iteration 1410, loss = 0.701398
I0205 07:27:32.886397 12957 solver.cpp:253]     Train net output #0: loss = 0.701398 (* 1 = 0.701398 loss)
I0205 07:27:32.886409 12957 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0205 07:27:37.710254 12957 solver.cpp:237] Iteration 1420, loss = 0.72117
I0205 07:27:37.710321 12957 solver.cpp:253]     Train net output #0: loss = 0.72117 (* 1 = 0.72117 loss)
I0205 07:27:37.710335 12957 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0205 07:27:42.536720 12957 solver.cpp:237] Iteration 1430, loss = 0.700778
I0205 07:27:42.536789 12957 solver.cpp:253]     Train net output #0: loss = 0.700779 (* 1 = 0.700779 loss)
I0205 07:27:42.536801 12957 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0205 07:27:47.361567 12957 solver.cpp:237] Iteration 1440, loss = 0.71043
I0205 07:27:47.361640 12957 solver.cpp:253]     Train net output #0: loss = 0.71043 (* 1 = 0.71043 loss)
I0205 07:27:47.361652 12957 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0205 07:27:52.185740 12957 solver.cpp:237] Iteration 1450, loss = 0.729555
I0205 07:27:52.185803 12957 solver.cpp:253]     Train net output #0: loss = 0.729555 (* 1 = 0.729555 loss)
I0205 07:27:52.185816 12957 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0205 07:27:57.010860 12957 solver.cpp:237] Iteration 1460, loss = 0.702285
I0205 07:27:57.011116 12957 solver.cpp:253]     Train net output #0: loss = 0.702286 (* 1 = 0.702286 loss)
I0205 07:27:57.011132 12957 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0205 07:28:01.839365 12957 solver.cpp:237] Iteration 1470, loss = 0.687282
I0205 07:28:01.839439 12957 solver.cpp:253]     Train net output #0: loss = 0.687282 (* 1 = 0.687282 loss)
I0205 07:28:01.839452 12957 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0205 07:28:06.666079 12957 solver.cpp:237] Iteration 1480, loss = 0.682763
I0205 07:28:06.666147 12957 solver.cpp:253]     Train net output #0: loss = 0.682764 (* 1 = 0.682764 loss)
I0205 07:28:06.666159 12957 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0205 07:28:11.493501 12957 solver.cpp:237] Iteration 1490, loss = 0.694217
I0205 07:28:11.493577 12957 solver.cpp:253]     Train net output #0: loss = 0.694217 (* 1 = 0.694217 loss)
I0205 07:28:11.493588 12957 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0205 07:28:15.838387 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1500.caffemodel
I0205 07:28:15.840471 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1500.solverstate
I0205 07:28:15.841292 12957 solver.cpp:341] Iteration 1500, Testing net (#0)
I0205 07:28:18.207145 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:28:18.207213 12957 solver.cpp:409]     Test net output #1: loss = 0.695842 (* 1 = 0.695842 loss)
I0205 07:28:18.689353 12957 solver.cpp:237] Iteration 1500, loss = 0.713823
I0205 07:28:18.689414 12957 solver.cpp:253]     Train net output #0: loss = 0.713823 (* 1 = 0.713823 loss)
I0205 07:28:18.689427 12957 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0205 07:28:23.520114 12957 solver.cpp:237] Iteration 1510, loss = 0.703981
I0205 07:28:23.520184 12957 solver.cpp:253]     Train net output #0: loss = 0.703981 (* 1 = 0.703981 loss)
I0205 07:28:23.520196 12957 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0205 07:28:28.346801 12957 solver.cpp:237] Iteration 1520, loss = 0.685004
I0205 07:28:28.347076 12957 solver.cpp:253]     Train net output #0: loss = 0.685004 (* 1 = 0.685004 loss)
I0205 07:28:28.347096 12957 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0205 07:28:33.173642 12957 solver.cpp:237] Iteration 1530, loss = 0.714829
I0205 07:28:33.173712 12957 solver.cpp:253]     Train net output #0: loss = 0.714829 (* 1 = 0.714829 loss)
I0205 07:28:33.173723 12957 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0205 07:28:38.000102 12957 solver.cpp:237] Iteration 1540, loss = 0.703467
I0205 07:28:38.000176 12957 solver.cpp:253]     Train net output #0: loss = 0.703468 (* 1 = 0.703468 loss)
I0205 07:28:38.000188 12957 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0205 07:28:42.827476 12957 solver.cpp:237] Iteration 1550, loss = 0.699085
I0205 07:28:42.827545 12957 solver.cpp:253]     Train net output #0: loss = 0.699086 (* 1 = 0.699086 loss)
I0205 07:28:42.827558 12957 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0205 07:28:47.655524 12957 solver.cpp:237] Iteration 1560, loss = 0.687308
I0205 07:28:47.655593 12957 solver.cpp:253]     Train net output #0: loss = 0.687309 (* 1 = 0.687309 loss)
I0205 07:28:47.655606 12957 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0205 07:28:52.482623 12957 solver.cpp:237] Iteration 1570, loss = 0.710337
I0205 07:28:52.482692 12957 solver.cpp:253]     Train net output #0: loss = 0.710338 (* 1 = 0.710338 loss)
I0205 07:28:52.482703 12957 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0205 07:28:57.308502 12957 solver.cpp:237] Iteration 1580, loss = 0.728828
I0205 07:28:57.308574 12957 solver.cpp:253]     Train net output #0: loss = 0.728829 (* 1 = 0.728829 loss)
I0205 07:28:57.308588 12957 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0205 07:29:02.134923 12957 solver.cpp:237] Iteration 1590, loss = 0.701085
I0205 07:29:02.135162 12957 solver.cpp:253]     Train net output #0: loss = 0.701086 (* 1 = 0.701086 loss)
I0205 07:29:02.135177 12957 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0205 07:29:06.481132 12957 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1600.caffemodel
I0205 07:29:06.483247 12957 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed242/snaps/snap__iter_1600.solverstate
I0205 07:29:06.720263 12957 solver.cpp:321] Iteration 1600, loss = 0.698323
I0205 07:29:06.720322 12957 solver.cpp:341] Iteration 1600, Testing net (#0)
I0205 07:29:09.073423 12957 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 07:29:09.073488 12957 solver.cpp:409]     Test net output #1: loss = 0.693474 (* 1 = 0.693474 loss)
I0205 07:29:09.073498 12957 solver.cpp:326] Optimization Done.
I0205 07:29:09.073504 12957 caffe.cpp:215] Optimization Done.
