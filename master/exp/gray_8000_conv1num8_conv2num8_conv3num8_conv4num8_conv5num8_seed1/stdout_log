I0204 16:30:48.754868  3457 caffe.cpp:177] Use CPU.
I0204 16:30:48.755384  3457 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap_"
solver_mode: CPU
random_seed: 1
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/train_val.prototxt"
I0204 16:30:48.755527  3457 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/train_val.prototxt
I0204 16:30:48.756103  3457 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:30:48.756139  3457 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:30:48.756377  3457 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.756500  3457 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.756670  3457 net.cpp:106] Creating Layer data
I0204 16:30:48.756686  3457 net.cpp:411] data -> data
I0204 16:30:48.756741  3457 net.cpp:411] data -> label
I0204 16:30:48.756759  3457 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:30:48.756805  3459 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:30:48.757691  3457 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:48.777725  3457 net.cpp:150] Setting up data
I0204 16:30:48.777792  3457 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:48.777801  3457 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.777808  3457 net.cpp:165] Memory required for data: 20612000
I0204 16:30:48.777828  3457 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:48.777854  3457 net.cpp:106] Creating Layer conv1
I0204 16:30:48.777863  3457 net.cpp:454] conv1 <- data
I0204 16:30:48.777883  3457 net.cpp:411] conv1 -> conv1
I0204 16:30:48.777978  3457 net.cpp:150] Setting up conv1
I0204 16:30:48.777989  3457 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.777995  3457 net.cpp:165] Memory required for data: 30292000
I0204 16:30:48.778012  3457 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:48.778023  3457 net.cpp:106] Creating Layer relu1
I0204 16:30:48.778029  3457 net.cpp:454] relu1 <- conv1
I0204 16:30:48.778038  3457 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:48.778049  3457 net.cpp:150] Setting up relu1
I0204 16:30:48.778058  3457 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.778062  3457 net.cpp:165] Memory required for data: 39972000
I0204 16:30:48.778069  3457 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:48.778080  3457 net.cpp:106] Creating Layer pool1
I0204 16:30:48.778085  3457 net.cpp:454] pool1 <- conv1
I0204 16:30:48.778094  3457 net.cpp:411] pool1 -> pool1
I0204 16:30:48.778115  3457 net.cpp:150] Setting up pool1
I0204 16:30:48.778123  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.778128  3457 net.cpp:165] Memory required for data: 42304800
I0204 16:30:48.778139  3457 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:48.778158  3457 net.cpp:106] Creating Layer norm1
I0204 16:30:48.778173  3457 net.cpp:454] norm1 <- pool1
I0204 16:30:48.778182  3457 net.cpp:411] norm1 -> norm1
I0204 16:30:48.778200  3457 net.cpp:150] Setting up norm1
I0204 16:30:48.778208  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.778213  3457 net.cpp:165] Memory required for data: 44637600
I0204 16:30:48.778219  3457 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:48.778229  3457 net.cpp:106] Creating Layer conv2
I0204 16:30:48.778234  3457 net.cpp:454] conv2 <- norm1
I0204 16:30:48.778244  3457 net.cpp:411] conv2 -> conv2
I0204 16:30:48.778273  3457 net.cpp:150] Setting up conv2
I0204 16:30:48.778281  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.778286  3457 net.cpp:165] Memory required for data: 46970400
I0204 16:30:48.778296  3457 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:48.778304  3457 net.cpp:106] Creating Layer relu2
I0204 16:30:48.778312  3457 net.cpp:454] relu2 <- conv2
I0204 16:30:48.778319  3457 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:48.778328  3457 net.cpp:150] Setting up relu2
I0204 16:30:48.778334  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.778340  3457 net.cpp:165] Memory required for data: 49303200
I0204 16:30:48.778345  3457 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:48.778353  3457 net.cpp:106] Creating Layer pool2
I0204 16:30:48.778358  3457 net.cpp:454] pool2 <- conv2
I0204 16:30:48.778365  3457 net.cpp:411] pool2 -> pool2
I0204 16:30:48.778375  3457 net.cpp:150] Setting up pool2
I0204 16:30:48.778383  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778388  3457 net.cpp:165] Memory required for data: 49844000
I0204 16:30:48.778393  3457 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:48.778401  3457 net.cpp:106] Creating Layer norm2
I0204 16:30:48.778406  3457 net.cpp:454] norm2 <- pool2
I0204 16:30:48.778414  3457 net.cpp:411] norm2 -> norm2
I0204 16:30:48.778424  3457 net.cpp:150] Setting up norm2
I0204 16:30:48.778431  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778437  3457 net.cpp:165] Memory required for data: 50384800
I0204 16:30:48.778442  3457 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:48.778451  3457 net.cpp:106] Creating Layer conv3
I0204 16:30:48.778457  3457 net.cpp:454] conv3 <- norm2
I0204 16:30:48.778465  3457 net.cpp:411] conv3 -> conv3
I0204 16:30:48.778493  3457 net.cpp:150] Setting up conv3
I0204 16:30:48.778501  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778506  3457 net.cpp:165] Memory required for data: 50925600
I0204 16:30:48.778515  3457 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:48.778523  3457 net.cpp:106] Creating Layer relu3
I0204 16:30:48.778529  3457 net.cpp:454] relu3 <- conv3
I0204 16:30:48.778538  3457 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:48.778547  3457 net.cpp:150] Setting up relu3
I0204 16:30:48.778553  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778558  3457 net.cpp:165] Memory required for data: 51466400
I0204 16:30:48.778563  3457 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:48.778573  3457 net.cpp:106] Creating Layer conv4
I0204 16:30:48.778578  3457 net.cpp:454] conv4 <- conv3
I0204 16:30:48.778586  3457 net.cpp:411] conv4 -> conv4
I0204 16:30:48.778606  3457 net.cpp:150] Setting up conv4
I0204 16:30:48.778614  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778620  3457 net.cpp:165] Memory required for data: 52007200
I0204 16:30:48.778627  3457 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:48.778633  3457 net.cpp:106] Creating Layer relu4
I0204 16:30:48.778640  3457 net.cpp:454] relu4 <- conv4
I0204 16:30:48.778648  3457 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:48.778656  3457 net.cpp:150] Setting up relu4
I0204 16:30:48.778662  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778667  3457 net.cpp:165] Memory required for data: 52548000
I0204 16:30:48.778673  3457 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:48.778687  3457 net.cpp:106] Creating Layer conv5
I0204 16:30:48.778697  3457 net.cpp:454] conv5 <- conv4
I0204 16:30:48.778705  3457 net.cpp:411] conv5 -> conv5
I0204 16:30:48.778725  3457 net.cpp:150] Setting up conv5
I0204 16:30:48.778733  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778738  3457 net.cpp:165] Memory required for data: 53088800
I0204 16:30:48.778748  3457 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:48.778759  3457 net.cpp:106] Creating Layer relu5
I0204 16:30:48.778764  3457 net.cpp:454] relu5 <- conv5
I0204 16:30:48.778772  3457 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:48.778779  3457 net.cpp:150] Setting up relu5
I0204 16:30:48.778786  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.778791  3457 net.cpp:165] Memory required for data: 53629600
I0204 16:30:48.778797  3457 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:48.778805  3457 net.cpp:106] Creating Layer pool5
I0204 16:30:48.778810  3457 net.cpp:454] pool5 <- conv5
I0204 16:30:48.778817  3457 net.cpp:411] pool5 -> pool5
I0204 16:30:48.778826  3457 net.cpp:150] Setting up pool5
I0204 16:30:48.778833  3457 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:48.778838  3457 net.cpp:165] Memory required for data: 53744800
I0204 16:30:48.778843  3457 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:48.778857  3457 net.cpp:106] Creating Layer fc6
I0204 16:30:48.778863  3457 net.cpp:454] fc6 <- pool5
I0204 16:30:48.778872  3457 net.cpp:411] fc6 -> fc6
I0204 16:30:48.779649  3457 net.cpp:150] Setting up fc6
I0204 16:30:48.779661  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.779667  3457 net.cpp:165] Memory required for data: 53847200
I0204 16:30:48.779675  3457 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:48.779683  3457 net.cpp:106] Creating Layer relu6
I0204 16:30:48.779688  3457 net.cpp:454] relu6 <- fc6
I0204 16:30:48.779696  3457 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:48.779706  3457 net.cpp:150] Setting up relu6
I0204 16:30:48.779713  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.779718  3457 net.cpp:165] Memory required for data: 53949600
I0204 16:30:48.779726  3457 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:48.779734  3457 net.cpp:106] Creating Layer drop6
I0204 16:30:48.779742  3457 net.cpp:454] drop6 <- fc6
I0204 16:30:48.779748  3457 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:48.779764  3457 net.cpp:150] Setting up drop6
I0204 16:30:48.779772  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.779777  3457 net.cpp:165] Memory required for data: 54052000
I0204 16:30:48.779781  3457 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:48.779790  3457 net.cpp:106] Creating Layer fc7
I0204 16:30:48.779795  3457 net.cpp:454] fc7 <- fc6
I0204 16:30:48.779803  3457 net.cpp:411] fc7 -> fc7
I0204 16:30:48.780462  3457 net.cpp:150] Setting up fc7
I0204 16:30:48.780472  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.780478  3457 net.cpp:165] Memory required for data: 54154400
I0204 16:30:48.780485  3457 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:48.780493  3457 net.cpp:106] Creating Layer relu7
I0204 16:30:48.780499  3457 net.cpp:454] relu7 <- fc7
I0204 16:30:48.780506  3457 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:48.780514  3457 net.cpp:150] Setting up relu7
I0204 16:30:48.780520  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.780526  3457 net.cpp:165] Memory required for data: 54256800
I0204 16:30:48.780534  3457 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:48.780542  3457 net.cpp:106] Creating Layer drop7
I0204 16:30:48.780549  3457 net.cpp:454] drop7 <- fc7
I0204 16:30:48.780555  3457 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:48.780565  3457 net.cpp:150] Setting up drop7
I0204 16:30:48.780570  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.780575  3457 net.cpp:165] Memory required for data: 54359200
I0204 16:30:48.780581  3457 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:48.780591  3457 net.cpp:106] Creating Layer fc8
I0204 16:30:48.780601  3457 net.cpp:454] fc8 <- fc7
I0204 16:30:48.780614  3457 net.cpp:411] fc8 -> fc8
I0204 16:30:48.780637  3457 net.cpp:150] Setting up fc8
I0204 16:30:48.780645  3457 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.780650  3457 net.cpp:165] Memory required for data: 54360000
I0204 16:30:48.780658  3457 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.780666  3457 net.cpp:106] Creating Layer loss
I0204 16:30:48.780671  3457 net.cpp:454] loss <- fc8
I0204 16:30:48.780678  3457 net.cpp:454] loss <- label
I0204 16:30:48.780689  3457 net.cpp:411] loss -> loss
I0204 16:30:48.780702  3457 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.780724  3457 net.cpp:150] Setting up loss
I0204 16:30:48.780730  3457 net.cpp:157] Top shape: (1)
I0204 16:30:48.780735  3457 net.cpp:160]     with loss weight 1
I0204 16:30:48.780766  3457 net.cpp:165] Memory required for data: 54360004
I0204 16:30:48.780773  3457 net.cpp:226] loss needs backward computation.
I0204 16:30:48.780779  3457 net.cpp:226] fc8 needs backward computation.
I0204 16:30:48.780786  3457 net.cpp:226] drop7 needs backward computation.
I0204 16:30:48.780791  3457 net.cpp:226] relu7 needs backward computation.
I0204 16:30:48.780796  3457 net.cpp:226] fc7 needs backward computation.
I0204 16:30:48.780802  3457 net.cpp:226] drop6 needs backward computation.
I0204 16:30:48.780807  3457 net.cpp:226] relu6 needs backward computation.
I0204 16:30:48.780812  3457 net.cpp:226] fc6 needs backward computation.
I0204 16:30:48.780817  3457 net.cpp:226] pool5 needs backward computation.
I0204 16:30:48.780822  3457 net.cpp:226] relu5 needs backward computation.
I0204 16:30:48.780827  3457 net.cpp:226] conv5 needs backward computation.
I0204 16:30:48.780833  3457 net.cpp:226] relu4 needs backward computation.
I0204 16:30:48.780838  3457 net.cpp:226] conv4 needs backward computation.
I0204 16:30:48.780844  3457 net.cpp:226] relu3 needs backward computation.
I0204 16:30:48.780849  3457 net.cpp:226] conv3 needs backward computation.
I0204 16:30:48.780858  3457 net.cpp:226] norm2 needs backward computation.
I0204 16:30:48.780864  3457 net.cpp:226] pool2 needs backward computation.
I0204 16:30:48.780871  3457 net.cpp:226] relu2 needs backward computation.
I0204 16:30:48.780877  3457 net.cpp:226] conv2 needs backward computation.
I0204 16:30:48.780882  3457 net.cpp:226] norm1 needs backward computation.
I0204 16:30:48.780889  3457 net.cpp:226] pool1 needs backward computation.
I0204 16:30:48.780894  3457 net.cpp:226] relu1 needs backward computation.
I0204 16:30:48.780900  3457 net.cpp:226] conv1 needs backward computation.
I0204 16:30:48.780905  3457 net.cpp:228] data does not need backward computation.
I0204 16:30:48.780911  3457 net.cpp:270] This network produces output loss
I0204 16:30:48.780939  3457 net.cpp:283] Network initialization done.
I0204 16:30:48.781668  3457 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/train_val.prototxt
I0204 16:30:48.781720  3457 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:30:48.782006  3457 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.782181  3457 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.782326  3457 net.cpp:106] Creating Layer data
I0204 16:30:48.782340  3457 net.cpp:411] data -> data
I0204 16:30:48.782352  3457 net.cpp:411] data -> label
I0204 16:30:48.782363  3457 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:30:48.782521  3471 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:30:48.783182  3457 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:48.815626  3457 net.cpp:150] Setting up data
I0204 16:30:48.815659  3457 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:48.815667  3457 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.815675  3457 net.cpp:165] Memory required for data: 20612000
I0204 16:30:48.815685  3457 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:30:48.815704  3457 net.cpp:106] Creating Layer label_data_1_split
I0204 16:30:48.815712  3457 net.cpp:454] label_data_1_split <- label
I0204 16:30:48.815726  3457 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:30:48.815742  3457 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:30:48.815754  3457 net.cpp:150] Setting up label_data_1_split
I0204 16:30:48.815765  3457 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.815771  3457 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.815779  3457 net.cpp:165] Memory required for data: 20612800
I0204 16:30:48.815785  3457 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:48.815799  3457 net.cpp:106] Creating Layer conv1
I0204 16:30:48.815805  3457 net.cpp:454] conv1 <- data
I0204 16:30:48.815814  3457 net.cpp:411] conv1 -> conv1
I0204 16:30:48.815863  3457 net.cpp:150] Setting up conv1
I0204 16:30:48.815873  3457 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.815878  3457 net.cpp:165] Memory required for data: 30292800
I0204 16:30:48.815891  3457 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:48.815902  3457 net.cpp:106] Creating Layer relu1
I0204 16:30:48.815908  3457 net.cpp:454] relu1 <- conv1
I0204 16:30:48.815917  3457 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:48.815927  3457 net.cpp:150] Setting up relu1
I0204 16:30:48.815934  3457 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.815940  3457 net.cpp:165] Memory required for data: 39972800
I0204 16:30:48.815945  3457 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:48.815958  3457 net.cpp:106] Creating Layer pool1
I0204 16:30:48.815963  3457 net.cpp:454] pool1 <- conv1
I0204 16:30:48.815973  3457 net.cpp:411] pool1 -> pool1
I0204 16:30:48.815989  3457 net.cpp:150] Setting up pool1
I0204 16:30:48.815996  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.816002  3457 net.cpp:165] Memory required for data: 42305600
I0204 16:30:48.816009  3457 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:48.816021  3457 net.cpp:106] Creating Layer norm1
I0204 16:30:48.816027  3457 net.cpp:454] norm1 <- pool1
I0204 16:30:48.816035  3457 net.cpp:411] norm1 -> norm1
I0204 16:30:48.816045  3457 net.cpp:150] Setting up norm1
I0204 16:30:48.816053  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.816059  3457 net.cpp:165] Memory required for data: 44638400
I0204 16:30:48.816066  3457 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:48.816076  3457 net.cpp:106] Creating Layer conv2
I0204 16:30:48.816082  3457 net.cpp:454] conv2 <- norm1
I0204 16:30:48.816090  3457 net.cpp:411] conv2 -> conv2
I0204 16:30:48.816143  3457 net.cpp:150] Setting up conv2
I0204 16:30:48.816153  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.816157  3457 net.cpp:165] Memory required for data: 46971200
I0204 16:30:48.816169  3457 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:48.816177  3457 net.cpp:106] Creating Layer relu2
I0204 16:30:48.816184  3457 net.cpp:454] relu2 <- conv2
I0204 16:30:48.816190  3457 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:48.816205  3457 net.cpp:150] Setting up relu2
I0204 16:30:48.816221  3457 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.816228  3457 net.cpp:165] Memory required for data: 49304000
I0204 16:30:48.816234  3457 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:48.816243  3457 net.cpp:106] Creating Layer pool2
I0204 16:30:48.816248  3457 net.cpp:454] pool2 <- conv2
I0204 16:30:48.816256  3457 net.cpp:411] pool2 -> pool2
I0204 16:30:48.816269  3457 net.cpp:150] Setting up pool2
I0204 16:30:48.816277  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816282  3457 net.cpp:165] Memory required for data: 49844800
I0204 16:30:48.816287  3457 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:48.816296  3457 net.cpp:106] Creating Layer norm2
I0204 16:30:48.816301  3457 net.cpp:454] norm2 <- pool2
I0204 16:30:48.816309  3457 net.cpp:411] norm2 -> norm2
I0204 16:30:48.816318  3457 net.cpp:150] Setting up norm2
I0204 16:30:48.816324  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816329  3457 net.cpp:165] Memory required for data: 50385600
I0204 16:30:48.816335  3457 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:48.816344  3457 net.cpp:106] Creating Layer conv3
I0204 16:30:48.816350  3457 net.cpp:454] conv3 <- norm2
I0204 16:30:48.816360  3457 net.cpp:411] conv3 -> conv3
I0204 16:30:48.816395  3457 net.cpp:150] Setting up conv3
I0204 16:30:48.816406  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816411  3457 net.cpp:165] Memory required for data: 50926400
I0204 16:30:48.816422  3457 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:48.816431  3457 net.cpp:106] Creating Layer relu3
I0204 16:30:48.816437  3457 net.cpp:454] relu3 <- conv3
I0204 16:30:48.816443  3457 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:48.816452  3457 net.cpp:150] Setting up relu3
I0204 16:30:48.816458  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816463  3457 net.cpp:165] Memory required for data: 51467200
I0204 16:30:48.816469  3457 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:48.816479  3457 net.cpp:106] Creating Layer conv4
I0204 16:30:48.816484  3457 net.cpp:454] conv4 <- conv3
I0204 16:30:48.816493  3457 net.cpp:411] conv4 -> conv4
I0204 16:30:48.816516  3457 net.cpp:150] Setting up conv4
I0204 16:30:48.816524  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816529  3457 net.cpp:165] Memory required for data: 52008000
I0204 16:30:48.816537  3457 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:48.816545  3457 net.cpp:106] Creating Layer relu4
I0204 16:30:48.816553  3457 net.cpp:454] relu4 <- conv4
I0204 16:30:48.816562  3457 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:48.816570  3457 net.cpp:150] Setting up relu4
I0204 16:30:48.816577  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816582  3457 net.cpp:165] Memory required for data: 52548800
I0204 16:30:48.816588  3457 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:48.816597  3457 net.cpp:106] Creating Layer conv5
I0204 16:30:48.816603  3457 net.cpp:454] conv5 <- conv4
I0204 16:30:48.816612  3457 net.cpp:411] conv5 -> conv5
I0204 16:30:48.816633  3457 net.cpp:150] Setting up conv5
I0204 16:30:48.816640  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816648  3457 net.cpp:165] Memory required for data: 53089600
I0204 16:30:48.816659  3457 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:48.816668  3457 net.cpp:106] Creating Layer relu5
I0204 16:30:48.816673  3457 net.cpp:454] relu5 <- conv5
I0204 16:30:48.816680  3457 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:48.816689  3457 net.cpp:150] Setting up relu5
I0204 16:30:48.816694  3457 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.816700  3457 net.cpp:165] Memory required for data: 53630400
I0204 16:30:48.816705  3457 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:48.816715  3457 net.cpp:106] Creating Layer pool5
I0204 16:30:48.816721  3457 net.cpp:454] pool5 <- conv5
I0204 16:30:48.816731  3457 net.cpp:411] pool5 -> pool5
I0204 16:30:48.816746  3457 net.cpp:150] Setting up pool5
I0204 16:30:48.816759  3457 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:48.816764  3457 net.cpp:165] Memory required for data: 53745600
I0204 16:30:48.816771  3457 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:48.816781  3457 net.cpp:106] Creating Layer fc6
I0204 16:30:48.816787  3457 net.cpp:454] fc6 <- pool5
I0204 16:30:48.816797  3457 net.cpp:411] fc6 -> fc6
I0204 16:30:48.817533  3457 net.cpp:150] Setting up fc6
I0204 16:30:48.817544  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.817549  3457 net.cpp:165] Memory required for data: 53848000
I0204 16:30:48.817558  3457 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:48.817566  3457 net.cpp:106] Creating Layer relu6
I0204 16:30:48.817574  3457 net.cpp:454] relu6 <- fc6
I0204 16:30:48.817582  3457 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:48.817590  3457 net.cpp:150] Setting up relu6
I0204 16:30:48.817597  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.817602  3457 net.cpp:165] Memory required for data: 53950400
I0204 16:30:48.817608  3457 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:48.817617  3457 net.cpp:106] Creating Layer drop6
I0204 16:30:48.817625  3457 net.cpp:454] drop6 <- fc6
I0204 16:30:48.817632  3457 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:48.817643  3457 net.cpp:150] Setting up drop6
I0204 16:30:48.817651  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.817656  3457 net.cpp:165] Memory required for data: 54052800
I0204 16:30:48.817662  3457 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:48.817672  3457 net.cpp:106] Creating Layer fc7
I0204 16:30:48.817677  3457 net.cpp:454] fc7 <- fc6
I0204 16:30:48.817687  3457 net.cpp:411] fc7 -> fc7
I0204 16:30:48.818382  3457 net.cpp:150] Setting up fc7
I0204 16:30:48.818394  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.818399  3457 net.cpp:165] Memory required for data: 54155200
I0204 16:30:48.818408  3457 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:48.818415  3457 net.cpp:106] Creating Layer relu7
I0204 16:30:48.818421  3457 net.cpp:454] relu7 <- fc7
I0204 16:30:48.818434  3457 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:48.818442  3457 net.cpp:150] Setting up relu7
I0204 16:30:48.818449  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.818454  3457 net.cpp:165] Memory required for data: 54257600
I0204 16:30:48.818460  3457 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:48.818469  3457 net.cpp:106] Creating Layer drop7
I0204 16:30:48.818475  3457 net.cpp:454] drop7 <- fc7
I0204 16:30:48.818483  3457 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:48.818492  3457 net.cpp:150] Setting up drop7
I0204 16:30:48.818500  3457 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.818505  3457 net.cpp:165] Memory required for data: 54360000
I0204 16:30:48.818511  3457 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:48.818522  3457 net.cpp:106] Creating Layer fc8
I0204 16:30:48.818528  3457 net.cpp:454] fc8 <- fc7
I0204 16:30:48.818538  3457 net.cpp:411] fc8 -> fc8
I0204 16:30:48.818560  3457 net.cpp:150] Setting up fc8
I0204 16:30:48.818570  3457 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.818575  3457 net.cpp:165] Memory required for data: 54360800
I0204 16:30:48.818583  3457 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:30:48.818593  3457 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:30:48.818599  3457 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:30:48.818606  3457 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:30:48.818614  3457 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:30:48.818624  3457 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:30:48.818630  3457 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.818637  3457 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.818642  3457 net.cpp:165] Memory required for data: 54362400
I0204 16:30:48.818647  3457 layer_factory.hpp:77] Creating layer accuracy
I0204 16:30:48.818661  3457 net.cpp:106] Creating Layer accuracy
I0204 16:30:48.818671  3457 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:30:48.818684  3457 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:30:48.818694  3457 net.cpp:411] accuracy -> accuracy
I0204 16:30:48.818708  3457 net.cpp:150] Setting up accuracy
I0204 16:30:48.818717  3457 net.cpp:157] Top shape: (1)
I0204 16:30:48.818722  3457 net.cpp:165] Memory required for data: 54362404
I0204 16:30:48.818727  3457 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.818735  3457 net.cpp:106] Creating Layer loss
I0204 16:30:48.818742  3457 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:30:48.818747  3457 net.cpp:454] loss <- label_data_1_split_1
I0204 16:30:48.818755  3457 net.cpp:411] loss -> loss
I0204 16:30:48.818765  3457 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.818784  3457 net.cpp:150] Setting up loss
I0204 16:30:48.818791  3457 net.cpp:157] Top shape: (1)
I0204 16:30:48.818796  3457 net.cpp:160]     with loss weight 1
I0204 16:30:48.818811  3457 net.cpp:165] Memory required for data: 54362408
I0204 16:30:48.818817  3457 net.cpp:226] loss needs backward computation.
I0204 16:30:48.818826  3457 net.cpp:228] accuracy does not need backward computation.
I0204 16:30:48.818832  3457 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:30:48.818838  3457 net.cpp:226] fc8 needs backward computation.
I0204 16:30:48.818845  3457 net.cpp:226] drop7 needs backward computation.
I0204 16:30:48.818850  3457 net.cpp:226] relu7 needs backward computation.
I0204 16:30:48.818856  3457 net.cpp:226] fc7 needs backward computation.
I0204 16:30:48.818861  3457 net.cpp:226] drop6 needs backward computation.
I0204 16:30:48.818867  3457 net.cpp:226] relu6 needs backward computation.
I0204 16:30:48.818872  3457 net.cpp:226] fc6 needs backward computation.
I0204 16:30:48.818878  3457 net.cpp:226] pool5 needs backward computation.
I0204 16:30:48.818884  3457 net.cpp:226] relu5 needs backward computation.
I0204 16:30:48.818891  3457 net.cpp:226] conv5 needs backward computation.
I0204 16:30:48.818895  3457 net.cpp:226] relu4 needs backward computation.
I0204 16:30:48.818902  3457 net.cpp:226] conv4 needs backward computation.
I0204 16:30:48.818907  3457 net.cpp:226] relu3 needs backward computation.
I0204 16:30:48.818912  3457 net.cpp:226] conv3 needs backward computation.
I0204 16:30:48.818918  3457 net.cpp:226] norm2 needs backward computation.
I0204 16:30:48.818924  3457 net.cpp:226] pool2 needs backward computation.
I0204 16:30:48.818931  3457 net.cpp:226] relu2 needs backward computation.
I0204 16:30:48.818938  3457 net.cpp:226] conv2 needs backward computation.
I0204 16:30:48.818943  3457 net.cpp:226] norm1 needs backward computation.
I0204 16:30:48.818949  3457 net.cpp:226] pool1 needs backward computation.
I0204 16:30:48.818955  3457 net.cpp:226] relu1 needs backward computation.
I0204 16:30:48.818961  3457 net.cpp:226] conv1 needs backward computation.
I0204 16:30:48.818967  3457 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:30:48.818974  3457 net.cpp:228] data does not need backward computation.
I0204 16:30:48.818980  3457 net.cpp:270] This network produces output accuracy
I0204 16:30:48.818986  3457 net.cpp:270] This network produces output loss
I0204 16:30:48.819017  3457 net.cpp:283] Network initialization done.
I0204 16:30:48.819134  3457 solver.cpp:60] Solver scaffolding done.
I0204 16:30:48.819190  3457 caffe.cpp:212] Starting Optimization
I0204 16:30:48.819197  3457 solver.cpp:288] Solving CaffeNet
I0204 16:30:48.819203  3457 solver.cpp:289] Learning Rate Policy: step
I0204 16:30:48.819592  3457 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:30:48.819646  3457 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:30:51.742264  3457 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:30:51.742322  3457 solver.cpp:409]     Test net output #1: loss = 4.26442 (* 1 = 4.26442 loss)
I0204 16:30:52.355448  3457 solver.cpp:237] Iteration 0, loss = 7.18328
I0204 16:30:52.355500  3457 solver.cpp:253]     Train net output #0: loss = 7.18328 (* 1 = 7.18328 loss)
I0204 16:30:52.355523  3457 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:30:59.222506  3457 solver.cpp:237] Iteration 10, loss = 1.13927
I0204 16:30:59.222565  3457 solver.cpp:253]     Train net output #0: loss = 1.13927 (* 1 = 1.13927 loss)
I0204 16:30:59.222576  3457 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:31:06.665030  3457 solver.cpp:237] Iteration 20, loss = 0.999086
I0204 16:31:06.665088  3457 solver.cpp:253]     Train net output #0: loss = 0.999086 (* 1 = 0.999086 loss)
I0204 16:31:06.665102  3457 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:31:14.077276  3457 solver.cpp:237] Iteration 30, loss = 0.804725
I0204 16:31:14.077332  3457 solver.cpp:253]     Train net output #0: loss = 0.804725 (* 1 = 0.804725 loss)
I0204 16:31:14.077344  3457 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:31:21.527678  3457 solver.cpp:237] Iteration 40, loss = 0.918129
I0204 16:31:21.527864  3457 solver.cpp:253]     Train net output #0: loss = 0.918129 (* 1 = 0.918129 loss)
I0204 16:31:21.527878  3457 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:31:28.965770  3457 solver.cpp:237] Iteration 50, loss = 0.743195
I0204 16:31:28.965834  3457 solver.cpp:253]     Train net output #0: loss = 0.743195 (* 1 = 0.743195 loss)
I0204 16:31:28.965847  3457 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:31:36.494149  3457 solver.cpp:237] Iteration 60, loss = 0.736403
I0204 16:31:36.494216  3457 solver.cpp:253]     Train net output #0: loss = 0.736403 (* 1 = 0.736403 loss)
I0204 16:31:36.494230  3457 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:31:43.999352  3457 solver.cpp:237] Iteration 70, loss = 0.672718
I0204 16:31:43.999418  3457 solver.cpp:253]     Train net output #0: loss = 0.672718 (* 1 = 0.672718 loss)
I0204 16:31:43.999430  3457 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:31:51.464185  3457 solver.cpp:237] Iteration 80, loss = 0.703211
I0204 16:31:51.464242  3457 solver.cpp:253]     Train net output #0: loss = 0.703211 (* 1 = 0.703211 loss)
I0204 16:31:51.464256  3457 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:59.059247  3457 solver.cpp:237] Iteration 90, loss = 0.627069
I0204 16:31:59.059418  3457 solver.cpp:253]     Train net output #0: loss = 0.627069 (* 1 = 0.627069 loss)
I0204 16:31:59.059433  3457 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:32:05.782382  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_100.caffemodel
I0204 16:32:05.784657  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_100.solverstate
I0204 16:32:05.785600  3457 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:32:09.453908  3457 solver.cpp:409]     Test net output #0: accuracy = 0.801
I0204 16:32:09.453969  3457 solver.cpp:409]     Test net output #1: loss = 0.484738 (* 1 = 0.484738 loss)
I0204 16:32:10.189296  3457 solver.cpp:237] Iteration 100, loss = 0.620847
I0204 16:32:10.189350  3457 solver.cpp:253]     Train net output #0: loss = 0.620847 (* 1 = 0.620847 loss)
I0204 16:32:10.189363  3457 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:17.630542  3457 solver.cpp:237] Iteration 110, loss = 0.521773
I0204 16:32:17.630599  3457 solver.cpp:253]     Train net output #0: loss = 0.521773 (* 1 = 0.521773 loss)
I0204 16:32:17.630612  3457 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:32:25.332427  3457 solver.cpp:237] Iteration 120, loss = 0.472492
I0204 16:32:25.332492  3457 solver.cpp:253]     Train net output #0: loss = 0.472492 (* 1 = 0.472492 loss)
I0204 16:32:25.332505  3457 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:32:32.916613  3457 solver.cpp:237] Iteration 130, loss = 0.33845
I0204 16:32:32.916785  3457 solver.cpp:253]     Train net output #0: loss = 0.33845 (* 1 = 0.33845 loss)
I0204 16:32:32.916798  3457 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:32:40.449563  3457 solver.cpp:237] Iteration 140, loss = 0.274933
I0204 16:32:40.449633  3457 solver.cpp:253]     Train net output #0: loss = 0.274933 (* 1 = 0.274933 loss)
I0204 16:32:40.449646  3457 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:32:47.952590  3457 solver.cpp:237] Iteration 150, loss = 0.238328
I0204 16:32:47.952658  3457 solver.cpp:253]     Train net output #0: loss = 0.238328 (* 1 = 0.238328 loss)
I0204 16:32:47.952672  3457 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:32:55.447162  3457 solver.cpp:237] Iteration 160, loss = 0.234026
I0204 16:32:55.447228  3457 solver.cpp:253]     Train net output #0: loss = 0.234026 (* 1 = 0.234026 loss)
I0204 16:32:55.447240  3457 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:33:02.918601  3457 solver.cpp:237] Iteration 170, loss = 0.123435
I0204 16:33:02.918786  3457 solver.cpp:253]     Train net output #0: loss = 0.123435 (* 1 = 0.123435 loss)
I0204 16:33:02.918798  3457 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:33:10.395845  3457 solver.cpp:237] Iteration 180, loss = 0.198244
I0204 16:33:10.395910  3457 solver.cpp:253]     Train net output #0: loss = 0.198244 (* 1 = 0.198244 loss)
I0204 16:33:10.395921  3457 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:33:17.945451  3457 solver.cpp:237] Iteration 190, loss = 0.0945034
I0204 16:33:17.945520  3457 solver.cpp:253]     Train net output #0: loss = 0.0945033 (* 1 = 0.0945033 loss)
I0204 16:33:17.945533  3457 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:33:24.776739  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_200.caffemodel
I0204 16:33:24.779024  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_200.solverstate
I0204 16:33:24.779963  3457 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:33:28.515557  3457 solver.cpp:409]     Test net output #0: accuracy = 0.952
I0204 16:33:28.515621  3457 solver.cpp:409]     Test net output #1: loss = 0.123461 (* 1 = 0.123461 loss)
I0204 16:33:29.266297  3457 solver.cpp:237] Iteration 200, loss = 0.357026
I0204 16:33:29.266357  3457 solver.cpp:253]     Train net output #0: loss = 0.357026 (* 1 = 0.357026 loss)
I0204 16:33:29.266371  3457 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:33:36.940352  3457 solver.cpp:237] Iteration 210, loss = 0.147733
I0204 16:33:36.940520  3457 solver.cpp:253]     Train net output #0: loss = 0.147733 (* 1 = 0.147733 loss)
I0204 16:33:36.940532  3457 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:33:44.495476  3457 solver.cpp:237] Iteration 220, loss = 0.0654962
I0204 16:33:44.495539  3457 solver.cpp:253]     Train net output #0: loss = 0.0654961 (* 1 = 0.0654961 loss)
I0204 16:33:44.495553  3457 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:33:51.990742  3457 solver.cpp:237] Iteration 230, loss = 0.0608296
I0204 16:33:51.990803  3457 solver.cpp:253]     Train net output #0: loss = 0.0608295 (* 1 = 0.0608295 loss)
I0204 16:33:51.990815  3457 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:33:59.508608  3457 solver.cpp:237] Iteration 240, loss = 0.0724677
I0204 16:33:59.508662  3457 solver.cpp:253]     Train net output #0: loss = 0.0724676 (* 1 = 0.0724676 loss)
I0204 16:33:59.508674  3457 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:34:07.080016  3457 solver.cpp:237] Iteration 250, loss = 0.0378811
I0204 16:34:07.080171  3457 solver.cpp:253]     Train net output #0: loss = 0.0378811 (* 1 = 0.0378811 loss)
I0204 16:34:07.080185  3457 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:34:14.616447  3457 solver.cpp:237] Iteration 260, loss = 0.0473808
I0204 16:34:14.616504  3457 solver.cpp:253]     Train net output #0: loss = 0.0473808 (* 1 = 0.0473808 loss)
I0204 16:34:14.616518  3457 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:34:22.178542  3457 solver.cpp:237] Iteration 270, loss = 0.414618
I0204 16:34:22.178608  3457 solver.cpp:253]     Train net output #0: loss = 0.414618 (* 1 = 0.414618 loss)
I0204 16:34:22.178620  3457 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:34:29.792515  3457 solver.cpp:237] Iteration 280, loss = 0.0337576
I0204 16:34:29.792583  3457 solver.cpp:253]     Train net output #0: loss = 0.0337575 (* 1 = 0.0337575 loss)
I0204 16:34:29.792605  3457 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:34:37.390434  3457 solver.cpp:237] Iteration 290, loss = 0.0515163
I0204 16:34:37.390626  3457 solver.cpp:253]     Train net output #0: loss = 0.0515162 (* 1 = 0.0515162 loss)
I0204 16:34:37.390640  3457 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:34:44.204315  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_300.caffemodel
I0204 16:34:44.206501  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_300.solverstate
I0204 16:34:44.207396  3457 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:34:47.883772  3457 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 16:34:47.883828  3457 solver.cpp:409]     Test net output #1: loss = 0.0208091 (* 1 = 0.0208091 loss)
I0204 16:34:48.649960  3457 solver.cpp:237] Iteration 300, loss = 0.0554656
I0204 16:34:48.650012  3457 solver.cpp:253]     Train net output #0: loss = 0.0554655 (* 1 = 0.0554655 loss)
I0204 16:34:48.650023  3457 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:34:56.219336  3457 solver.cpp:237] Iteration 310, loss = 0.0447761
I0204 16:34:56.219398  3457 solver.cpp:253]     Train net output #0: loss = 0.044776 (* 1 = 0.044776 loss)
I0204 16:34:56.219410  3457 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:35:03.639842  3457 solver.cpp:237] Iteration 320, loss = 0.0938451
I0204 16:35:03.639901  3457 solver.cpp:253]     Train net output #0: loss = 0.093845 (* 1 = 0.093845 loss)
I0204 16:35:03.639917  3457 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:35:11.121563  3457 solver.cpp:237] Iteration 330, loss = 0.0979754
I0204 16:35:11.121747  3457 solver.cpp:253]     Train net output #0: loss = 0.0979753 (* 1 = 0.0979753 loss)
I0204 16:35:11.121760  3457 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:35:18.548121  3457 solver.cpp:237] Iteration 340, loss = 0.117419
I0204 16:35:18.548184  3457 solver.cpp:253]     Train net output #0: loss = 0.117419 (* 1 = 0.117419 loss)
I0204 16:35:18.548197  3457 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:35:25.922368  3457 solver.cpp:237] Iteration 350, loss = 0.0394927
I0204 16:35:25.922430  3457 solver.cpp:253]     Train net output #0: loss = 0.0394926 (* 1 = 0.0394926 loss)
I0204 16:35:25.922441  3457 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:35:33.282448  3457 solver.cpp:237] Iteration 360, loss = 0.0678439
I0204 16:35:33.282515  3457 solver.cpp:253]     Train net output #0: loss = 0.0678438 (* 1 = 0.0678438 loss)
I0204 16:35:33.282527  3457 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:35:40.633543  3457 solver.cpp:237] Iteration 370, loss = 0.0222871
I0204 16:35:40.633606  3457 solver.cpp:253]     Train net output #0: loss = 0.0222871 (* 1 = 0.0222871 loss)
I0204 16:35:40.633617  3457 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:35:47.998059  3457 solver.cpp:237] Iteration 380, loss = 0.0151835
I0204 16:35:47.998205  3457 solver.cpp:253]     Train net output #0: loss = 0.0151834 (* 1 = 0.0151834 loss)
I0204 16:35:47.998219  3457 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:35:55.351143  3457 solver.cpp:237] Iteration 390, loss = 0.0256141
I0204 16:35:55.351207  3457 solver.cpp:253]     Train net output #0: loss = 0.0256141 (* 1 = 0.0256141 loss)
I0204 16:35:55.351220  3457 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:36:01.901193  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_400.caffemodel
I0204 16:36:01.903481  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_400.solverstate
I0204 16:36:01.904511  3457 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:36:05.492260  3457 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:36:05.492322  3457 solver.cpp:409]     Test net output #1: loss = 0.0266452 (* 1 = 0.0266452 loss)
I0204 16:36:06.257542  3457 solver.cpp:237] Iteration 400, loss = 0.0489389
I0204 16:36:06.257609  3457 solver.cpp:253]     Train net output #0: loss = 0.0489388 (* 1 = 0.0489388 loss)
I0204 16:36:06.257622  3457 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:36:13.824322  3457 solver.cpp:237] Iteration 410, loss = 0.0341257
I0204 16:36:13.824388  3457 solver.cpp:253]     Train net output #0: loss = 0.0341256 (* 1 = 0.0341256 loss)
I0204 16:36:13.824401  3457 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:36:21.265888  3457 solver.cpp:237] Iteration 420, loss = 0.0228446
I0204 16:36:21.266108  3457 solver.cpp:253]     Train net output #0: loss = 0.0228446 (* 1 = 0.0228446 loss)
I0204 16:36:21.266121  3457 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:36:28.681339  3457 solver.cpp:237] Iteration 430, loss = 0.0214992
I0204 16:36:28.681407  3457 solver.cpp:253]     Train net output #0: loss = 0.0214992 (* 1 = 0.0214992 loss)
I0204 16:36:28.681430  3457 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:36:36.147267  3457 solver.cpp:237] Iteration 440, loss = 0.0136664
I0204 16:36:36.147323  3457 solver.cpp:253]     Train net output #0: loss = 0.0136663 (* 1 = 0.0136663 loss)
I0204 16:36:36.147336  3457 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:36:43.538117  3457 solver.cpp:237] Iteration 450, loss = 0.00862404
I0204 16:36:43.538173  3457 solver.cpp:253]     Train net output #0: loss = 0.00862399 (* 1 = 0.00862399 loss)
I0204 16:36:43.538185  3457 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:36:50.923121  3457 solver.cpp:237] Iteration 460, loss = 0.0105437
I0204 16:36:50.923182  3457 solver.cpp:253]     Train net output #0: loss = 0.0105437 (* 1 = 0.0105437 loss)
I0204 16:36:50.923195  3457 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:36:58.386865  3457 solver.cpp:237] Iteration 470, loss = 0.0835178
I0204 16:36:58.387033  3457 solver.cpp:253]     Train net output #0: loss = 0.0835177 (* 1 = 0.0835177 loss)
I0204 16:36:58.387048  3457 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:37:05.945860  3457 solver.cpp:237] Iteration 480, loss = 0.145138
I0204 16:37:05.945922  3457 solver.cpp:253]     Train net output #0: loss = 0.145138 (* 1 = 0.145138 loss)
I0204 16:37:05.945935  3457 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:37:13.367502  3457 solver.cpp:237] Iteration 490, loss = 0.0141586
I0204 16:37:13.367568  3457 solver.cpp:253]     Train net output #0: loss = 0.0141585 (* 1 = 0.0141585 loss)
I0204 16:37:13.367581  3457 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:37:19.923391  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_500.caffemodel
I0204 16:37:19.925602  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_500.solverstate
I0204 16:37:19.926523  3457 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:37:23.453534  3457 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 16:37:23.453593  3457 solver.cpp:409]     Test net output #1: loss = 0.00897182 (* 1 = 0.00897182 loss)
I0204 16:37:24.173830  3457 solver.cpp:237] Iteration 500, loss = 0.0301075
I0204 16:37:24.173897  3457 solver.cpp:253]     Train net output #0: loss = 0.0301074 (* 1 = 0.0301074 loss)
I0204 16:37:24.173931  3457 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:37:31.586439  3457 solver.cpp:237] Iteration 510, loss = 0.0375344
I0204 16:37:31.586660  3457 solver.cpp:253]     Train net output #0: loss = 0.0375343 (* 1 = 0.0375343 loss)
I0204 16:37:31.586674  3457 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:37:39.011351  3457 solver.cpp:237] Iteration 520, loss = 0.048593
I0204 16:37:39.011425  3457 solver.cpp:253]     Train net output #0: loss = 0.0485929 (* 1 = 0.0485929 loss)
I0204 16:37:39.011436  3457 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:37:46.554296  3457 solver.cpp:237] Iteration 530, loss = 0.0734349
I0204 16:37:46.554352  3457 solver.cpp:253]     Train net output #0: loss = 0.0734349 (* 1 = 0.0734349 loss)
I0204 16:37:46.554364  3457 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:37:53.948866  3457 solver.cpp:237] Iteration 540, loss = 0.00748027
I0204 16:37:53.948925  3457 solver.cpp:253]     Train net output #0: loss = 0.00748021 (* 1 = 0.00748021 loss)
I0204 16:37:53.948938  3457 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:38:01.366329  3457 solver.cpp:237] Iteration 550, loss = 0.0488412
I0204 16:38:01.366380  3457 solver.cpp:253]     Train net output #0: loss = 0.0488412 (* 1 = 0.0488412 loss)
I0204 16:38:01.366394  3457 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:38:08.868106  3457 solver.cpp:237] Iteration 560, loss = 0.0129696
I0204 16:38:08.872190  3457 solver.cpp:253]     Train net output #0: loss = 0.0129695 (* 1 = 0.0129695 loss)
I0204 16:38:08.872220  3457 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:38:16.318552  3457 solver.cpp:237] Iteration 570, loss = 0.00728965
I0204 16:38:16.318629  3457 solver.cpp:253]     Train net output #0: loss = 0.0072896 (* 1 = 0.0072896 loss)
I0204 16:38:16.318642  3457 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:38:23.720937  3457 solver.cpp:237] Iteration 580, loss = 0.0309192
I0204 16:38:23.721014  3457 solver.cpp:253]     Train net output #0: loss = 0.0309191 (* 1 = 0.0309191 loss)
I0204 16:38:23.721025  3457 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:38:30.981600  3457 solver.cpp:237] Iteration 590, loss = 0.0364423
I0204 16:38:30.981665  3457 solver.cpp:253]     Train net output #0: loss = 0.0364423 (* 1 = 0.0364423 loss)
I0204 16:38:30.981678  3457 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:38:37.484685  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_600.caffemodel
I0204 16:38:37.486898  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_600.solverstate
I0204 16:38:37.487831  3457 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:38:41.100546  3457 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 16:38:41.100937  3457 solver.cpp:409]     Test net output #1: loss = 0.0191951 (* 1 = 0.0191951 loss)
I0204 16:38:41.841509  3457 solver.cpp:237] Iteration 600, loss = 0.0423424
I0204 16:38:41.841565  3457 solver.cpp:253]     Train net output #0: loss = 0.0423423 (* 1 = 0.0423423 loss)
I0204 16:38:41.841578  3457 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:38:49.238646  3457 solver.cpp:237] Iteration 610, loss = 0.00926018
I0204 16:38:49.238711  3457 solver.cpp:253]     Train net output #0: loss = 0.00926013 (* 1 = 0.00926013 loss)
I0204 16:38:49.238723  3457 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:38:56.666795  3457 solver.cpp:237] Iteration 620, loss = 0.0241873
I0204 16:38:56.666868  3457 solver.cpp:253]     Train net output #0: loss = 0.0241873 (* 1 = 0.0241873 loss)
I0204 16:38:56.666903  3457 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:39:04.109542  3457 solver.cpp:237] Iteration 630, loss = 0.0545678
I0204 16:39:04.109602  3457 solver.cpp:253]     Train net output #0: loss = 0.0545677 (* 1 = 0.0545677 loss)
I0204 16:39:04.109632  3457 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:39:11.455843  3457 solver.cpp:237] Iteration 640, loss = 0.0110614
I0204 16:39:11.456015  3457 solver.cpp:253]     Train net output #0: loss = 0.0110613 (* 1 = 0.0110613 loss)
I0204 16:39:11.456028  3457 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:39:18.855645  3457 solver.cpp:237] Iteration 650, loss = 0.0121235
I0204 16:39:18.855702  3457 solver.cpp:253]     Train net output #0: loss = 0.0121235 (* 1 = 0.0121235 loss)
I0204 16:39:18.855715  3457 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:39:26.316769  3457 solver.cpp:237] Iteration 660, loss = 0.159076
I0204 16:39:26.316831  3457 solver.cpp:253]     Train net output #0: loss = 0.159076 (* 1 = 0.159076 loss)
I0204 16:39:26.316843  3457 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:39:33.721843  3457 solver.cpp:237] Iteration 670, loss = 0.0446036
I0204 16:39:33.721912  3457 solver.cpp:253]     Train net output #0: loss = 0.0446036 (* 1 = 0.0446036 loss)
I0204 16:39:33.721925  3457 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:39:41.096951  3457 solver.cpp:237] Iteration 680, loss = 0.0366843
I0204 16:39:41.097018  3457 solver.cpp:253]     Train net output #0: loss = 0.0366843 (* 1 = 0.0366843 loss)
I0204 16:39:41.097030  3457 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:39:48.446231  3457 solver.cpp:237] Iteration 690, loss = 0.0371313
I0204 16:39:48.446405  3457 solver.cpp:253]     Train net output #0: loss = 0.0371313 (* 1 = 0.0371313 loss)
I0204 16:39:48.446419  3457 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:39:55.065682  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_700.caffemodel
I0204 16:39:55.068003  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_700.solverstate
I0204 16:39:55.069015  3457 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:39:58.635109  3457 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:39:58.635169  3457 solver.cpp:409]     Test net output #1: loss = 0.0217255 (* 1 = 0.0217255 loss)
I0204 16:39:59.365320  3457 solver.cpp:237] Iteration 700, loss = 0.0333363
I0204 16:39:59.365384  3457 solver.cpp:253]     Train net output #0: loss = 0.0333362 (* 1 = 0.0333362 loss)
I0204 16:39:59.365396  3457 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:40:06.701596  3457 solver.cpp:237] Iteration 710, loss = 0.0240593
I0204 16:40:06.701655  3457 solver.cpp:253]     Train net output #0: loss = 0.0240592 (* 1 = 0.0240592 loss)
I0204 16:40:06.701668  3457 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:40:14.113224  3457 solver.cpp:237] Iteration 720, loss = 0.0299225
I0204 16:40:14.113284  3457 solver.cpp:253]     Train net output #0: loss = 0.0299225 (* 1 = 0.0299225 loss)
I0204 16:40:14.113296  3457 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:40:21.461597  3457 solver.cpp:237] Iteration 730, loss = 0.0845963
I0204 16:40:21.461735  3457 solver.cpp:253]     Train net output #0: loss = 0.0845963 (* 1 = 0.0845963 loss)
I0204 16:40:21.461746  3457 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:40:28.799921  3457 solver.cpp:237] Iteration 740, loss = 0.0532096
I0204 16:40:28.799985  3457 solver.cpp:253]     Train net output #0: loss = 0.0532096 (* 1 = 0.0532096 loss)
I0204 16:40:28.799998  3457 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 16:40:36.121047  3457 solver.cpp:237] Iteration 750, loss = 0.0216083
I0204 16:40:36.121116  3457 solver.cpp:253]     Train net output #0: loss = 0.0216083 (* 1 = 0.0216083 loss)
I0204 16:40:36.121129  3457 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 16:40:43.383481  3457 solver.cpp:237] Iteration 760, loss = 0.0154174
I0204 16:40:43.383545  3457 solver.cpp:253]     Train net output #0: loss = 0.0154173 (* 1 = 0.0154173 loss)
I0204 16:40:43.383579  3457 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 16:40:50.658226  3457 solver.cpp:237] Iteration 770, loss = 0.0189111
I0204 16:40:50.658289  3457 solver.cpp:253]     Train net output #0: loss = 0.0189111 (* 1 = 0.0189111 loss)
I0204 16:40:50.658301  3457 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 16:40:58.043113  3457 solver.cpp:237] Iteration 780, loss = 0.00651187
I0204 16:40:58.045125  3457 solver.cpp:253]     Train net output #0: loss = 0.00651183 (* 1 = 0.00651183 loss)
I0204 16:40:58.045141  3457 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 16:41:05.160768  3457 solver.cpp:237] Iteration 790, loss = 0.0471987
I0204 16:41:05.160832  3457 solver.cpp:253]     Train net output #0: loss = 0.0471987 (* 1 = 0.0471987 loss)
I0204 16:41:05.160845  3457 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 16:41:11.532652  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_800.caffemodel
I0204 16:41:11.534855  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_800.solverstate
I0204 16:41:11.535792  3457 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 16:41:14.962508  3457 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 16:41:14.962564  3457 solver.cpp:409]     Test net output #1: loss = 0.0103717 (* 1 = 0.0103717 loss)
I0204 16:41:15.670173  3457 solver.cpp:237] Iteration 800, loss = 0.0156043
I0204 16:41:15.670233  3457 solver.cpp:253]     Train net output #0: loss = 0.0156043 (* 1 = 0.0156043 loss)
I0204 16:41:15.670243  3457 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 16:41:22.934890  3457 solver.cpp:237] Iteration 810, loss = 0.0516669
I0204 16:41:22.934957  3457 solver.cpp:253]     Train net output #0: loss = 0.0516669 (* 1 = 0.0516669 loss)
I0204 16:41:22.934968  3457 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 16:41:30.327191  3457 solver.cpp:237] Iteration 820, loss = 0.0163745
I0204 16:41:30.327352  3457 solver.cpp:253]     Train net output #0: loss = 0.0163745 (* 1 = 0.0163745 loss)
I0204 16:41:30.327365  3457 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 16:41:37.591531  3457 solver.cpp:237] Iteration 830, loss = 0.0238793
I0204 16:41:37.591596  3457 solver.cpp:253]     Train net output #0: loss = 0.0238792 (* 1 = 0.0238792 loss)
I0204 16:41:37.591608  3457 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 16:41:44.887805  3457 solver.cpp:237] Iteration 840, loss = 0.00803909
I0204 16:41:44.887862  3457 solver.cpp:253]     Train net output #0: loss = 0.00803907 (* 1 = 0.00803907 loss)
I0204 16:41:44.887876  3457 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 16:41:52.119177  3457 solver.cpp:237] Iteration 850, loss = 0.0557368
I0204 16:41:52.119235  3457 solver.cpp:253]     Train net output #0: loss = 0.0557368 (* 1 = 0.0557368 loss)
I0204 16:41:52.119247  3457 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 16:41:59.434770  3457 solver.cpp:237] Iteration 860, loss = 0.00357649
I0204 16:41:59.434830  3457 solver.cpp:253]     Train net output #0: loss = 0.00357647 (* 1 = 0.00357647 loss)
I0204 16:41:59.434844  3457 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 16:42:06.761654  3457 solver.cpp:237] Iteration 870, loss = 0.00283381
I0204 16:42:06.761804  3457 solver.cpp:253]     Train net output #0: loss = 0.00283379 (* 1 = 0.00283379 loss)
I0204 16:42:06.761818  3457 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 16:42:14.084944  3457 solver.cpp:237] Iteration 880, loss = 0.0136656
I0204 16:42:14.085011  3457 solver.cpp:253]     Train net output #0: loss = 0.0136656 (* 1 = 0.0136656 loss)
I0204 16:42:14.085023  3457 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 16:42:21.380491  3457 solver.cpp:237] Iteration 890, loss = 0.0986476
I0204 16:42:21.380545  3457 solver.cpp:253]     Train net output #0: loss = 0.0986476 (* 1 = 0.0986476 loss)
I0204 16:42:21.380558  3457 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 16:42:27.918010  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_900.caffemodel
I0204 16:42:27.920238  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_900.solverstate
I0204 16:42:27.921160  3457 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 16:42:31.519412  3457 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:42:31.519469  3457 solver.cpp:409]     Test net output #1: loss = 0.00513945 (* 1 = 0.00513945 loss)
I0204 16:42:32.261785  3457 solver.cpp:237] Iteration 900, loss = 0.0138687
I0204 16:42:32.261837  3457 solver.cpp:253]     Train net output #0: loss = 0.0138687 (* 1 = 0.0138687 loss)
I0204 16:42:32.261849  3457 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 16:42:39.609933  3457 solver.cpp:237] Iteration 910, loss = 0.0123059
I0204 16:42:39.610146  3457 solver.cpp:253]     Train net output #0: loss = 0.0123059 (* 1 = 0.0123059 loss)
I0204 16:42:39.610158  3457 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 16:42:46.933972  3457 solver.cpp:237] Iteration 920, loss = 0.00501479
I0204 16:42:46.934033  3457 solver.cpp:253]     Train net output #0: loss = 0.00501477 (* 1 = 0.00501477 loss)
I0204 16:42:46.934046  3457 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 16:42:54.210930  3457 solver.cpp:237] Iteration 930, loss = 0.0194507
I0204 16:42:54.210993  3457 solver.cpp:253]     Train net output #0: loss = 0.0194507 (* 1 = 0.0194507 loss)
I0204 16:42:54.211004  3457 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 16:43:01.491225  3457 solver.cpp:237] Iteration 940, loss = 0.0178565
I0204 16:43:01.491283  3457 solver.cpp:253]     Train net output #0: loss = 0.0178565 (* 1 = 0.0178565 loss)
I0204 16:43:01.491296  3457 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 16:43:08.784837  3457 solver.cpp:237] Iteration 950, loss = 0.0175182
I0204 16:43:08.784895  3457 solver.cpp:253]     Train net output #0: loss = 0.0175182 (* 1 = 0.0175182 loss)
I0204 16:43:08.784909  3457 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 16:43:16.107816  3457 solver.cpp:237] Iteration 960, loss = 0.0149298
I0204 16:43:16.108008  3457 solver.cpp:253]     Train net output #0: loss = 0.0149298 (* 1 = 0.0149298 loss)
I0204 16:43:16.108022  3457 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 16:43:23.358023  3457 solver.cpp:237] Iteration 970, loss = 0.0290121
I0204 16:43:23.358075  3457 solver.cpp:253]     Train net output #0: loss = 0.0290121 (* 1 = 0.0290121 loss)
I0204 16:43:23.358088  3457 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 16:43:30.667290  3457 solver.cpp:237] Iteration 980, loss = 0.0682128
I0204 16:43:30.667369  3457 solver.cpp:253]     Train net output #0: loss = 0.0682128 (* 1 = 0.0682128 loss)
I0204 16:43:30.667443  3457 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 16:43:37.965360  3457 solver.cpp:237] Iteration 990, loss = 0.0310154
I0204 16:43:37.965420  3457 solver.cpp:253]     Train net output #0: loss = 0.0310154 (* 1 = 0.0310154 loss)
I0204 16:43:37.965432  3457 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 16:43:44.471465  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1000.caffemodel
I0204 16:43:44.473685  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1000.solverstate
I0204 16:43:44.474619  3457 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 16:43:47.990200  3457 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:43:47.990393  3457 solver.cpp:409]     Test net output #1: loss = 0.00506514 (* 1 = 0.00506514 loss)
I0204 16:43:48.716290  3457 solver.cpp:237] Iteration 1000, loss = 0.00291512
I0204 16:43:48.716361  3457 solver.cpp:253]     Train net output #0: loss = 0.00291511 (* 1 = 0.00291511 loss)
I0204 16:43:48.716374  3457 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 16:43:55.969764  3457 solver.cpp:237] Iteration 1010, loss = 0.00777316
I0204 16:43:55.969823  3457 solver.cpp:253]     Train net output #0: loss = 0.00777315 (* 1 = 0.00777315 loss)
I0204 16:43:55.969835  3457 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 16:44:03.270787  3457 solver.cpp:237] Iteration 1020, loss = 0.0575099
I0204 16:44:03.270858  3457 solver.cpp:253]     Train net output #0: loss = 0.0575099 (* 1 = 0.0575099 loss)
I0204 16:44:03.270870  3457 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 16:44:10.654059  3457 solver.cpp:237] Iteration 1030, loss = 0.0201504
I0204 16:44:10.654129  3457 solver.cpp:253]     Train net output #0: loss = 0.0201504 (* 1 = 0.0201504 loss)
I0204 16:44:10.654141  3457 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 16:44:17.888155  3457 solver.cpp:237] Iteration 1040, loss = 0.0600036
I0204 16:44:17.888223  3457 solver.cpp:253]     Train net output #0: loss = 0.0600036 (* 1 = 0.0600036 loss)
I0204 16:44:17.888236  3457 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 16:44:25.115269  3457 solver.cpp:237] Iteration 1050, loss = 0.110137
I0204 16:44:25.115461  3457 solver.cpp:253]     Train net output #0: loss = 0.110137 (* 1 = 0.110137 loss)
I0204 16:44:25.115475  3457 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 16:44:32.353930  3457 solver.cpp:237] Iteration 1060, loss = 0.0124182
I0204 16:44:32.354001  3457 solver.cpp:253]     Train net output #0: loss = 0.0124182 (* 1 = 0.0124182 loss)
I0204 16:44:32.354013  3457 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 16:44:39.606391  3457 solver.cpp:237] Iteration 1070, loss = 0.0176606
I0204 16:44:39.606449  3457 solver.cpp:253]     Train net output #0: loss = 0.0176606 (* 1 = 0.0176606 loss)
I0204 16:44:39.606461  3457 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 16:44:46.850337  3457 solver.cpp:237] Iteration 1080, loss = 0.0328852
I0204 16:44:46.850397  3457 solver.cpp:253]     Train net output #0: loss = 0.0328852 (* 1 = 0.0328852 loss)
I0204 16:44:46.850409  3457 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 16:44:54.086210  3457 solver.cpp:237] Iteration 1090, loss = 0.00472084
I0204 16:44:54.086275  3457 solver.cpp:253]     Train net output #0: loss = 0.00472085 (* 1 = 0.00472085 loss)
I0204 16:44:54.086287  3457 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 16:45:00.616032  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1100.caffemodel
I0204 16:45:00.618419  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1100.solverstate
I0204 16:45:00.619417  3457 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 16:45:04.189414  3457 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 16:45:04.189479  3457 solver.cpp:409]     Test net output #1: loss = 0.00371053 (* 1 = 0.00371053 loss)
I0204 16:45:04.910842  3457 solver.cpp:237] Iteration 1100, loss = 0.00247278
I0204 16:45:04.910902  3457 solver.cpp:253]     Train net output #0: loss = 0.00247279 (* 1 = 0.00247279 loss)
I0204 16:45:04.910913  3457 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 16:45:12.140389  3457 solver.cpp:237] Iteration 1110, loss = 0.0178041
I0204 16:45:12.140450  3457 solver.cpp:253]     Train net output #0: loss = 0.0178041 (* 1 = 0.0178041 loss)
I0204 16:45:12.140461  3457 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 16:45:19.571624  3457 solver.cpp:237] Iteration 1120, loss = 0.0172901
I0204 16:45:19.571682  3457 solver.cpp:253]     Train net output #0: loss = 0.0172901 (* 1 = 0.0172901 loss)
I0204 16:45:19.571696  3457 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 16:45:26.844629  3457 solver.cpp:237] Iteration 1130, loss = 0.0256749
I0204 16:45:26.844691  3457 solver.cpp:253]     Train net output #0: loss = 0.0256749 (* 1 = 0.0256749 loss)
I0204 16:45:26.844702  3457 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 16:45:34.040676  3457 solver.cpp:237] Iteration 1140, loss = 0.00222362
I0204 16:45:34.040840  3457 solver.cpp:253]     Train net output #0: loss = 0.00222364 (* 1 = 0.00222364 loss)
I0204 16:45:34.040853  3457 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 16:45:41.180225  3457 solver.cpp:237] Iteration 1150, loss = 0.0748594
I0204 16:45:41.180284  3457 solver.cpp:253]     Train net output #0: loss = 0.0748595 (* 1 = 0.0748595 loss)
I0204 16:45:41.180296  3457 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 16:45:48.303725  3457 solver.cpp:237] Iteration 1160, loss = 0.0138277
I0204 16:45:48.303798  3457 solver.cpp:253]     Train net output #0: loss = 0.0138277 (* 1 = 0.0138277 loss)
I0204 16:45:48.303856  3457 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 16:45:55.350867  3457 solver.cpp:237] Iteration 1170, loss = 0.0430158
I0204 16:45:55.350925  3457 solver.cpp:253]     Train net output #0: loss = 0.0430159 (* 1 = 0.0430159 loss)
I0204 16:45:55.350939  3457 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 16:46:02.430336  3457 solver.cpp:237] Iteration 1180, loss = 0.00573123
I0204 16:46:02.430392  3457 solver.cpp:253]     Train net output #0: loss = 0.00573124 (* 1 = 0.00573124 loss)
I0204 16:46:02.430404  3457 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 16:46:09.539284  3457 solver.cpp:237] Iteration 1190, loss = 0.00169394
I0204 16:46:09.546098  3457 solver.cpp:253]     Train net output #0: loss = 0.00169396 (* 1 = 0.00169396 loss)
I0204 16:46:09.546133  3457 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 16:46:15.929358  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1200.caffemodel
I0204 16:46:15.931546  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1200.solverstate
I0204 16:46:15.932499  3457 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 16:46:19.410128  3457 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 16:46:19.410181  3457 solver.cpp:409]     Test net output #1: loss = 0.00235262 (* 1 = 0.00235262 loss)
I0204 16:46:20.116260  3457 solver.cpp:237] Iteration 1200, loss = 0.0110415
I0204 16:46:20.116307  3457 solver.cpp:253]     Train net output #0: loss = 0.0110416 (* 1 = 0.0110416 loss)
I0204 16:46:20.116320  3457 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 16:46:27.188642  3457 solver.cpp:237] Iteration 1210, loss = 0.101787
I0204 16:46:27.188696  3457 solver.cpp:253]     Train net output #0: loss = 0.101787 (* 1 = 0.101787 loss)
I0204 16:46:27.188709  3457 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 16:46:34.243790  3457 solver.cpp:237] Iteration 1220, loss = 0.00252177
I0204 16:46:34.243850  3457 solver.cpp:253]     Train net output #0: loss = 0.00252179 (* 1 = 0.00252179 loss)
I0204 16:46:34.243863  3457 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 16:46:41.185111  3457 solver.cpp:237] Iteration 1230, loss = 0.0309788
I0204 16:46:41.185263  3457 solver.cpp:253]     Train net output #0: loss = 0.0309789 (* 1 = 0.0309789 loss)
I0204 16:46:41.185277  3457 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 16:46:48.179673  3457 solver.cpp:237] Iteration 1240, loss = 0.00247421
I0204 16:46:48.179731  3457 solver.cpp:253]     Train net output #0: loss = 0.00247424 (* 1 = 0.00247424 loss)
I0204 16:46:48.179745  3457 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 16:46:55.108887  3457 solver.cpp:237] Iteration 1250, loss = 0.0504649
I0204 16:46:55.108942  3457 solver.cpp:253]     Train net output #0: loss = 0.0504649 (* 1 = 0.0504649 loss)
I0204 16:46:55.108958  3457 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 16:47:02.011764  3457 solver.cpp:237] Iteration 1260, loss = 0.00120637
I0204 16:47:02.011842  3457 solver.cpp:253]     Train net output #0: loss = 0.0012064 (* 1 = 0.0012064 loss)
I0204 16:47:02.011855  3457 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 16:47:08.667353  3457 solver.cpp:237] Iteration 1270, loss = 0.0345986
I0204 16:47:08.667412  3457 solver.cpp:253]     Train net output #0: loss = 0.0345986 (* 1 = 0.0345986 loss)
I0204 16:47:08.667423  3457 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 16:47:15.173431  3457 solver.cpp:237] Iteration 1280, loss = 0.0189437
I0204 16:47:15.173645  3457 solver.cpp:253]     Train net output #0: loss = 0.0189438 (* 1 = 0.0189438 loss)
I0204 16:47:15.173658  3457 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 16:47:21.694885  3457 solver.cpp:237] Iteration 1290, loss = 0.0487762
I0204 16:47:21.694941  3457 solver.cpp:253]     Train net output #0: loss = 0.0487763 (* 1 = 0.0487763 loss)
I0204 16:47:21.694952  3457 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 16:47:27.611883  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1300.caffemodel
I0204 16:47:27.614025  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1300.solverstate
I0204 16:47:27.614959  3457 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 16:47:30.809783  3457 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:47:30.809835  3457 solver.cpp:409]     Test net output #1: loss = 0.00299315 (* 1 = 0.00299315 loss)
I0204 16:47:31.474648  3457 solver.cpp:237] Iteration 1300, loss = 0.0618266
I0204 16:47:31.474699  3457 solver.cpp:253]     Train net output #0: loss = 0.0618267 (* 1 = 0.0618267 loss)
I0204 16:47:31.474710  3457 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 16:47:38.115427  3457 solver.cpp:237] Iteration 1310, loss = 0.0194634
I0204 16:47:38.115481  3457 solver.cpp:253]     Train net output #0: loss = 0.0194634 (* 1 = 0.0194634 loss)
I0204 16:47:38.115494  3457 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 16:47:44.769507  3457 solver.cpp:237] Iteration 1320, loss = 0.00607979
I0204 16:47:44.769562  3457 solver.cpp:253]     Train net output #0: loss = 0.00607982 (* 1 = 0.00607982 loss)
I0204 16:47:44.769575  3457 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 16:47:51.427817  3457 solver.cpp:237] Iteration 1330, loss = 0.0447247
I0204 16:47:51.428002  3457 solver.cpp:253]     Train net output #0: loss = 0.0447248 (* 1 = 0.0447248 loss)
I0204 16:47:51.428016  3457 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 16:47:58.077993  3457 solver.cpp:237] Iteration 1340, loss = 0.00374515
I0204 16:47:58.078053  3457 solver.cpp:253]     Train net output #0: loss = 0.00374518 (* 1 = 0.00374518 loss)
I0204 16:47:58.078065  3457 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 16:48:04.683838  3457 solver.cpp:237] Iteration 1350, loss = 0.00220338
I0204 16:48:04.683893  3457 solver.cpp:253]     Train net output #0: loss = 0.00220341 (* 1 = 0.00220341 loss)
I0204 16:48:04.683905  3457 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 16:48:11.300950  3457 solver.cpp:237] Iteration 1360, loss = 0.0280554
I0204 16:48:11.301003  3457 solver.cpp:253]     Train net output #0: loss = 0.0280555 (* 1 = 0.0280555 loss)
I0204 16:48:11.301017  3457 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 16:48:17.851621  3457 solver.cpp:237] Iteration 1370, loss = 0.0108604
I0204 16:48:17.851677  3457 solver.cpp:253]     Train net output #0: loss = 0.0108605 (* 1 = 0.0108605 loss)
I0204 16:48:17.851689  3457 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 16:48:24.421218  3457 solver.cpp:237] Iteration 1380, loss = 0.000694206
I0204 16:48:24.421422  3457 solver.cpp:253]     Train net output #0: loss = 0.000694236 (* 1 = 0.000694236 loss)
I0204 16:48:24.421437  3457 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 16:48:30.968329  3457 solver.cpp:237] Iteration 1390, loss = 0.0116208
I0204 16:48:30.968384  3457 solver.cpp:253]     Train net output #0: loss = 0.0116208 (* 1 = 0.0116208 loss)
I0204 16:48:30.968397  3457 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 16:48:36.892796  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1400.caffemodel
I0204 16:48:36.895045  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1400.solverstate
I0204 16:48:36.896093  3457 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 16:48:40.066762  3457 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:48:40.066812  3457 solver.cpp:409]     Test net output #1: loss = 0.00596216 (* 1 = 0.00596216 loss)
I0204 16:48:40.716367  3457 solver.cpp:237] Iteration 1400, loss = 0.0137403
I0204 16:48:40.716413  3457 solver.cpp:253]     Train net output #0: loss = 0.0137404 (* 1 = 0.0137404 loss)
I0204 16:48:40.716424  3457 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 16:48:47.292455  3457 solver.cpp:237] Iteration 1410, loss = 0.0029306
I0204 16:48:47.292510  3457 solver.cpp:253]     Train net output #0: loss = 0.00293063 (* 1 = 0.00293063 loss)
I0204 16:48:47.292520  3457 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 16:48:53.851320  3457 solver.cpp:237] Iteration 1420, loss = 0.0360678
I0204 16:48:53.851369  3457 solver.cpp:253]     Train net output #0: loss = 0.0360678 (* 1 = 0.0360678 loss)
I0204 16:48:53.851380  3457 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 16:49:00.452621  3457 solver.cpp:237] Iteration 1430, loss = 0.00139276
I0204 16:49:00.452807  3457 solver.cpp:253]     Train net output #0: loss = 0.00139279 (* 1 = 0.00139279 loss)
I0204 16:49:00.452821  3457 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 16:49:07.087357  3457 solver.cpp:237] Iteration 1440, loss = 0.0710638
I0204 16:49:07.087411  3457 solver.cpp:253]     Train net output #0: loss = 0.0710638 (* 1 = 0.0710638 loss)
I0204 16:49:07.087424  3457 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 16:49:13.741508  3457 solver.cpp:237] Iteration 1450, loss = 0.00320705
I0204 16:49:13.741560  3457 solver.cpp:253]     Train net output #0: loss = 0.00320708 (* 1 = 0.00320708 loss)
I0204 16:49:13.741585  3457 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 16:49:20.339979  3457 solver.cpp:237] Iteration 1460, loss = 0.0625032
I0204 16:49:20.340046  3457 solver.cpp:253]     Train net output #0: loss = 0.0625033 (* 1 = 0.0625033 loss)
I0204 16:49:20.340057  3457 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 16:49:26.877583  3457 solver.cpp:237] Iteration 1470, loss = 0.00138401
I0204 16:49:26.877636  3457 solver.cpp:253]     Train net output #0: loss = 0.00138404 (* 1 = 0.00138404 loss)
I0204 16:49:26.877648  3457 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 16:49:33.382897  3457 solver.cpp:237] Iteration 1480, loss = 0.0162825
I0204 16:49:33.383072  3457 solver.cpp:253]     Train net output #0: loss = 0.0162825 (* 1 = 0.0162825 loss)
I0204 16:49:33.383085  3457 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 16:49:39.997787  3457 solver.cpp:237] Iteration 1490, loss = 0.0124135
I0204 16:49:39.997849  3457 solver.cpp:253]     Train net output #0: loss = 0.0124135 (* 1 = 0.0124135 loss)
I0204 16:49:39.997862  3457 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 16:49:46.035289  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1500.caffemodel
I0204 16:49:46.037454  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1500.solverstate
I0204 16:49:46.038353  3457 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 16:49:49.279086  3457 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 16:49:49.279136  3457 solver.cpp:409]     Test net output #1: loss = 0.005386 (* 1 = 0.005386 loss)
I0204 16:49:49.951251  3457 solver.cpp:237] Iteration 1500, loss = 0.00424391
I0204 16:49:49.951303  3457 solver.cpp:253]     Train net output #0: loss = 0.00424394 (* 1 = 0.00424394 loss)
I0204 16:49:49.951313  3457 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 16:49:56.651881  3457 solver.cpp:237] Iteration 1510, loss = 0.00200333
I0204 16:49:56.651935  3457 solver.cpp:253]     Train net output #0: loss = 0.00200336 (* 1 = 0.00200336 loss)
I0204 16:49:56.651960  3457 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 16:50:03.404270  3457 solver.cpp:237] Iteration 1520, loss = 0.00627092
I0204 16:50:03.404471  3457 solver.cpp:253]     Train net output #0: loss = 0.00627095 (* 1 = 0.00627095 loss)
I0204 16:50:03.404485  3457 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 16:50:10.126926  3457 solver.cpp:237] Iteration 1530, loss = 0.00281931
I0204 16:50:10.126986  3457 solver.cpp:253]     Train net output #0: loss = 0.00281934 (* 1 = 0.00281934 loss)
I0204 16:50:10.126997  3457 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 16:50:16.802686  3457 solver.cpp:237] Iteration 1540, loss = 0.00665425
I0204 16:50:16.802742  3457 solver.cpp:253]     Train net output #0: loss = 0.00665428 (* 1 = 0.00665428 loss)
I0204 16:50:16.802754  3457 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 16:50:23.474568  3457 solver.cpp:237] Iteration 1550, loss = 0.000640562
I0204 16:50:23.474624  3457 solver.cpp:253]     Train net output #0: loss = 0.000640597 (* 1 = 0.000640597 loss)
I0204 16:50:23.474637  3457 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 16:50:30.122375  3457 solver.cpp:237] Iteration 1560, loss = 0.00270261
I0204 16:50:30.122431  3457 solver.cpp:253]     Train net output #0: loss = 0.00270264 (* 1 = 0.00270264 loss)
I0204 16:50:30.122443  3457 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 16:50:36.863781  3457 solver.cpp:237] Iteration 1570, loss = 0.00248598
I0204 16:50:36.863957  3457 solver.cpp:253]     Train net output #0: loss = 0.00248602 (* 1 = 0.00248602 loss)
I0204 16:50:36.863971  3457 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 16:50:43.459868  3457 solver.cpp:237] Iteration 1580, loss = 0.00274339
I0204 16:50:43.459926  3457 solver.cpp:253]     Train net output #0: loss = 0.00274343 (* 1 = 0.00274343 loss)
I0204 16:50:43.459939  3457 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 16:50:50.098899  3457 solver.cpp:237] Iteration 1590, loss = 0.00260481
I0204 16:50:50.098955  3457 solver.cpp:253]     Train net output #0: loss = 0.00260485 (* 1 = 0.00260485 loss)
I0204 16:50:50.098968  3457 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 16:50:56.022799  3457 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1600.caffemodel
I0204 16:50:56.024945  3457 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed1/snaps/snap__iter_1600.solverstate
I0204 16:50:56.342829  3457 solver.cpp:321] Iteration 1600, loss = 0.00591898
I0204 16:50:56.342875  3457 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 16:50:59.530308  3457 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 16:50:59.530356  3457 solver.cpp:409]     Test net output #1: loss = 0.0103999 (* 1 = 0.0103999 loss)
I0204 16:50:59.530365  3457 solver.cpp:326] Optimization Done.
I0204 16:50:59.530371  3457 caffe.cpp:215] Optimization Done.
