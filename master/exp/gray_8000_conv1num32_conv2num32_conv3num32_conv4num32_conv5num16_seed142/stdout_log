I0204 22:32:44.433233 10207 caffe.cpp:177] Use CPU.
I0204 22:32:44.434198 10207 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap_"
solver_mode: CPU
random_seed: 142
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/train_val.prototxt"
I0204 22:32:44.434377 10207 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/train_val.prototxt
I0204 22:32:44.435001 10207 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 22:32:44.435037 10207 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 22:32:44.435315 10207 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 22:32:44.435467 10207 layer_factory.hpp:77] Creating layer data
I0204 22:32:44.435673 10207 net.cpp:106] Creating Layer data
I0204 22:32:44.435693 10207 net.cpp:411] data -> data
I0204 22:32:44.435802 10207 net.cpp:411] data -> label
I0204 22:32:44.435832 10207 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 22:32:44.436022 10208 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 22:32:44.436998 10207 data_layer.cpp:41] output data size: 100,1,227,227
I0204 22:32:44.467892 10207 net.cpp:150] Setting up data
I0204 22:32:44.467954 10207 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 22:32:44.467964 10207 net.cpp:157] Top shape: 100 (100)
I0204 22:32:44.467970 10207 net.cpp:165] Memory required for data: 20612000
I0204 22:32:44.467988 10207 layer_factory.hpp:77] Creating layer conv1
I0204 22:32:44.468035 10207 net.cpp:106] Creating Layer conv1
I0204 22:32:44.468046 10207 net.cpp:454] conv1 <- data
I0204 22:32:44.468076 10207 net.cpp:411] conv1 -> conv1
I0204 22:32:44.468217 10207 net.cpp:150] Setting up conv1
I0204 22:32:44.468230 10207 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 22:32:44.468235 10207 net.cpp:165] Memory required for data: 59332000
I0204 22:32:44.468253 10207 layer_factory.hpp:77] Creating layer relu1
I0204 22:32:44.468266 10207 net.cpp:106] Creating Layer relu1
I0204 22:32:44.468271 10207 net.cpp:454] relu1 <- conv1
I0204 22:32:44.468279 10207 net.cpp:397] relu1 -> conv1 (in-place)
I0204 22:32:44.468291 10207 net.cpp:150] Setting up relu1
I0204 22:32:44.468299 10207 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 22:32:44.468304 10207 net.cpp:165] Memory required for data: 98052000
I0204 22:32:44.468309 10207 layer_factory.hpp:77] Creating layer pool1
I0204 22:32:44.468319 10207 net.cpp:106] Creating Layer pool1
I0204 22:32:44.468325 10207 net.cpp:454] pool1 <- conv1
I0204 22:32:44.468334 10207 net.cpp:411] pool1 -> pool1
I0204 22:32:44.468361 10207 net.cpp:150] Setting up pool1
I0204 22:32:44.468369 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.468374 10207 net.cpp:165] Memory required for data: 107383200
I0204 22:32:44.468380 10207 layer_factory.hpp:77] Creating layer norm1
I0204 22:32:44.468408 10207 net.cpp:106] Creating Layer norm1
I0204 22:32:44.468415 10207 net.cpp:454] norm1 <- pool1
I0204 22:32:44.468422 10207 net.cpp:411] norm1 -> norm1
I0204 22:32:44.468441 10207 net.cpp:150] Setting up norm1
I0204 22:32:44.468448 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.468453 10207 net.cpp:165] Memory required for data: 116714400
I0204 22:32:44.468461 10207 layer_factory.hpp:77] Creating layer conv2
I0204 22:32:44.468472 10207 net.cpp:106] Creating Layer conv2
I0204 22:32:44.468477 10207 net.cpp:454] conv2 <- norm1
I0204 22:32:44.468487 10207 net.cpp:411] conv2 -> conv2
I0204 22:32:44.468617 10207 net.cpp:150] Setting up conv2
I0204 22:32:44.468626 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.468631 10207 net.cpp:165] Memory required for data: 126045600
I0204 22:32:44.468642 10207 layer_factory.hpp:77] Creating layer relu2
I0204 22:32:44.468650 10207 net.cpp:106] Creating Layer relu2
I0204 22:32:44.468657 10207 net.cpp:454] relu2 <- conv2
I0204 22:32:44.468675 10207 net.cpp:397] relu2 -> conv2 (in-place)
I0204 22:32:44.468685 10207 net.cpp:150] Setting up relu2
I0204 22:32:44.468693 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.468698 10207 net.cpp:165] Memory required for data: 135376800
I0204 22:32:44.468703 10207 layer_factory.hpp:77] Creating layer pool2
I0204 22:32:44.468710 10207 net.cpp:106] Creating Layer pool2
I0204 22:32:44.468716 10207 net.cpp:454] pool2 <- conv2
I0204 22:32:44.468724 10207 net.cpp:411] pool2 -> pool2
I0204 22:32:44.468736 10207 net.cpp:150] Setting up pool2
I0204 22:32:44.468744 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.468749 10207 net.cpp:165] Memory required for data: 137540000
I0204 22:32:44.468754 10207 layer_factory.hpp:77] Creating layer norm2
I0204 22:32:44.468763 10207 net.cpp:106] Creating Layer norm2
I0204 22:32:44.468768 10207 net.cpp:454] norm2 <- pool2
I0204 22:32:44.468778 10207 net.cpp:411] norm2 -> norm2
I0204 22:32:44.468787 10207 net.cpp:150] Setting up norm2
I0204 22:32:44.468794 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.468799 10207 net.cpp:165] Memory required for data: 139703200
I0204 22:32:44.468804 10207 layer_factory.hpp:77] Creating layer conv3
I0204 22:32:44.468813 10207 net.cpp:106] Creating Layer conv3
I0204 22:32:44.468819 10207 net.cpp:454] conv3 <- norm2
I0204 22:32:44.468827 10207 net.cpp:411] conv3 -> conv3
I0204 22:32:44.468935 10207 net.cpp:150] Setting up conv3
I0204 22:32:44.468945 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.468953 10207 net.cpp:165] Memory required for data: 141866400
I0204 22:32:44.468963 10207 layer_factory.hpp:77] Creating layer relu3
I0204 22:32:44.468974 10207 net.cpp:106] Creating Layer relu3
I0204 22:32:44.468981 10207 net.cpp:454] relu3 <- conv3
I0204 22:32:44.468988 10207 net.cpp:397] relu3 -> conv3 (in-place)
I0204 22:32:44.468997 10207 net.cpp:150] Setting up relu3
I0204 22:32:44.469002 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.469009 10207 net.cpp:165] Memory required for data: 144029600
I0204 22:32:44.469015 10207 layer_factory.hpp:77] Creating layer conv4
I0204 22:32:44.469027 10207 net.cpp:106] Creating Layer conv4
I0204 22:32:44.469033 10207 net.cpp:454] conv4 <- conv3
I0204 22:32:44.469043 10207 net.cpp:411] conv4 -> conv4
I0204 22:32:44.469122 10207 net.cpp:150] Setting up conv4
I0204 22:32:44.469131 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.469138 10207 net.cpp:165] Memory required for data: 146192800
I0204 22:32:44.469147 10207 layer_factory.hpp:77] Creating layer relu4
I0204 22:32:44.469154 10207 net.cpp:106] Creating Layer relu4
I0204 22:32:44.469161 10207 net.cpp:454] relu4 <- conv4
I0204 22:32:44.469168 10207 net.cpp:397] relu4 -> conv4 (in-place)
I0204 22:32:44.469177 10207 net.cpp:150] Setting up relu4
I0204 22:32:44.469183 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.469188 10207 net.cpp:165] Memory required for data: 148356000
I0204 22:32:44.469198 10207 layer_factory.hpp:77] Creating layer conv5
I0204 22:32:44.469221 10207 net.cpp:106] Creating Layer conv5
I0204 22:32:44.469228 10207 net.cpp:454] conv5 <- conv4
I0204 22:32:44.469235 10207 net.cpp:411] conv5 -> conv5
I0204 22:32:44.469285 10207 net.cpp:150] Setting up conv5
I0204 22:32:44.469292 10207 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 22:32:44.469297 10207 net.cpp:165] Memory required for data: 149437600
I0204 22:32:44.469307 10207 layer_factory.hpp:77] Creating layer relu5
I0204 22:32:44.469316 10207 net.cpp:106] Creating Layer relu5
I0204 22:32:44.469321 10207 net.cpp:454] relu5 <- conv5
I0204 22:32:44.469331 10207 net.cpp:397] relu5 -> conv5 (in-place)
I0204 22:32:44.469338 10207 net.cpp:150] Setting up relu5
I0204 22:32:44.469346 10207 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 22:32:44.469351 10207 net.cpp:165] Memory required for data: 150519200
I0204 22:32:44.469355 10207 layer_factory.hpp:77] Creating layer pool5
I0204 22:32:44.469363 10207 net.cpp:106] Creating Layer pool5
I0204 22:32:44.469369 10207 net.cpp:454] pool5 <- conv5
I0204 22:32:44.469379 10207 net.cpp:411] pool5 -> pool5
I0204 22:32:44.469389 10207 net.cpp:150] Setting up pool5
I0204 22:32:44.469398 10207 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 22:32:44.469403 10207 net.cpp:165] Memory required for data: 150749600
I0204 22:32:44.469409 10207 layer_factory.hpp:77] Creating layer fc6
I0204 22:32:44.469424 10207 net.cpp:106] Creating Layer fc6
I0204 22:32:44.469431 10207 net.cpp:454] fc6 <- pool5
I0204 22:32:44.469441 10207 net.cpp:411] fc6 -> fc6
I0204 22:32:44.471056 10207 net.cpp:150] Setting up fc6
I0204 22:32:44.471071 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.471077 10207 net.cpp:165] Memory required for data: 150852000
I0204 22:32:44.471086 10207 layer_factory.hpp:77] Creating layer relu6
I0204 22:32:44.471101 10207 net.cpp:106] Creating Layer relu6
I0204 22:32:44.471108 10207 net.cpp:454] relu6 <- fc6
I0204 22:32:44.471115 10207 net.cpp:397] relu6 -> fc6 (in-place)
I0204 22:32:44.471124 10207 net.cpp:150] Setting up relu6
I0204 22:32:44.471132 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.471137 10207 net.cpp:165] Memory required for data: 150954400
I0204 22:32:44.471143 10207 layer_factory.hpp:77] Creating layer drop6
I0204 22:32:44.471151 10207 net.cpp:106] Creating Layer drop6
I0204 22:32:44.471158 10207 net.cpp:454] drop6 <- fc6
I0204 22:32:44.471165 10207 net.cpp:397] drop6 -> fc6 (in-place)
I0204 22:32:44.471184 10207 net.cpp:150] Setting up drop6
I0204 22:32:44.471191 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.471196 10207 net.cpp:165] Memory required for data: 151056800
I0204 22:32:44.471202 10207 layer_factory.hpp:77] Creating layer fc7
I0204 22:32:44.471210 10207 net.cpp:106] Creating Layer fc7
I0204 22:32:44.471216 10207 net.cpp:454] fc7 <- fc6
I0204 22:32:44.471226 10207 net.cpp:411] fc7 -> fc7
I0204 22:32:44.471947 10207 net.cpp:150] Setting up fc7
I0204 22:32:44.471962 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.471967 10207 net.cpp:165] Memory required for data: 151159200
I0204 22:32:44.471976 10207 layer_factory.hpp:77] Creating layer relu7
I0204 22:32:44.471983 10207 net.cpp:106] Creating Layer relu7
I0204 22:32:44.471989 10207 net.cpp:454] relu7 <- fc7
I0204 22:32:44.471999 10207 net.cpp:397] relu7 -> fc7 (in-place)
I0204 22:32:44.472008 10207 net.cpp:150] Setting up relu7
I0204 22:32:44.472014 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.472019 10207 net.cpp:165] Memory required for data: 151261600
I0204 22:32:44.472024 10207 layer_factory.hpp:77] Creating layer drop7
I0204 22:32:44.472034 10207 net.cpp:106] Creating Layer drop7
I0204 22:32:44.472040 10207 net.cpp:454] drop7 <- fc7
I0204 22:32:44.472050 10207 net.cpp:397] drop7 -> fc7 (in-place)
I0204 22:32:44.472059 10207 net.cpp:150] Setting up drop7
I0204 22:32:44.472066 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.472071 10207 net.cpp:165] Memory required for data: 151364000
I0204 22:32:44.472077 10207 layer_factory.hpp:77] Creating layer fc8
I0204 22:32:44.472101 10207 net.cpp:106] Creating Layer fc8
I0204 22:32:44.472113 10207 net.cpp:454] fc8 <- fc7
I0204 22:32:44.472123 10207 net.cpp:411] fc8 -> fc8
I0204 22:32:44.472146 10207 net.cpp:150] Setting up fc8
I0204 22:32:44.472154 10207 net.cpp:157] Top shape: 100 2 (200)
I0204 22:32:44.472162 10207 net.cpp:165] Memory required for data: 151364800
I0204 22:32:44.472170 10207 layer_factory.hpp:77] Creating layer loss
I0204 22:32:44.472180 10207 net.cpp:106] Creating Layer loss
I0204 22:32:44.472187 10207 net.cpp:454] loss <- fc8
I0204 22:32:44.472193 10207 net.cpp:454] loss <- label
I0204 22:32:44.472201 10207 net.cpp:411] loss -> loss
I0204 22:32:44.472216 10207 layer_factory.hpp:77] Creating layer loss
I0204 22:32:44.472242 10207 net.cpp:150] Setting up loss
I0204 22:32:44.472249 10207 net.cpp:157] Top shape: (1)
I0204 22:32:44.472254 10207 net.cpp:160]     with loss weight 1
I0204 22:32:44.472280 10207 net.cpp:165] Memory required for data: 151364804
I0204 22:32:44.472300 10207 net.cpp:226] loss needs backward computation.
I0204 22:32:44.472307 10207 net.cpp:226] fc8 needs backward computation.
I0204 22:32:44.472312 10207 net.cpp:226] drop7 needs backward computation.
I0204 22:32:44.472317 10207 net.cpp:226] relu7 needs backward computation.
I0204 22:32:44.472322 10207 net.cpp:226] fc7 needs backward computation.
I0204 22:32:44.472328 10207 net.cpp:226] drop6 needs backward computation.
I0204 22:32:44.472333 10207 net.cpp:226] relu6 needs backward computation.
I0204 22:32:44.472338 10207 net.cpp:226] fc6 needs backward computation.
I0204 22:32:44.472344 10207 net.cpp:226] pool5 needs backward computation.
I0204 22:32:44.472349 10207 net.cpp:226] relu5 needs backward computation.
I0204 22:32:44.472354 10207 net.cpp:226] conv5 needs backward computation.
I0204 22:32:44.472360 10207 net.cpp:226] relu4 needs backward computation.
I0204 22:32:44.472365 10207 net.cpp:226] conv4 needs backward computation.
I0204 22:32:44.472371 10207 net.cpp:226] relu3 needs backward computation.
I0204 22:32:44.472376 10207 net.cpp:226] conv3 needs backward computation.
I0204 22:32:44.472385 10207 net.cpp:226] norm2 needs backward computation.
I0204 22:32:44.472391 10207 net.cpp:226] pool2 needs backward computation.
I0204 22:32:44.472396 10207 net.cpp:226] relu2 needs backward computation.
I0204 22:32:44.472403 10207 net.cpp:226] conv2 needs backward computation.
I0204 22:32:44.472407 10207 net.cpp:226] norm1 needs backward computation.
I0204 22:32:44.472412 10207 net.cpp:226] pool1 needs backward computation.
I0204 22:32:44.472420 10207 net.cpp:226] relu1 needs backward computation.
I0204 22:32:44.472426 10207 net.cpp:226] conv1 needs backward computation.
I0204 22:32:44.472432 10207 net.cpp:228] data does not need backward computation.
I0204 22:32:44.472437 10207 net.cpp:270] This network produces output loss
I0204 22:32:44.472465 10207 net.cpp:283] Network initialization done.
I0204 22:32:44.473188 10207 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/train_val.prototxt
I0204 22:32:44.473248 10207 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 22:32:44.473533 10207 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 22:32:44.473706 10207 layer_factory.hpp:77] Creating layer data
I0204 22:32:44.473857 10207 net.cpp:106] Creating Layer data
I0204 22:32:44.473875 10207 net.cpp:411] data -> data
I0204 22:32:44.473888 10207 net.cpp:411] data -> label
I0204 22:32:44.473899 10207 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 22:32:44.474156 10211 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 22:32:44.474848 10207 data_layer.cpp:41] output data size: 100,1,227,227
I0204 22:32:44.503461 10207 net.cpp:150] Setting up data
I0204 22:32:44.503482 10207 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 22:32:44.503490 10207 net.cpp:157] Top shape: 100 (100)
I0204 22:32:44.503499 10207 net.cpp:165] Memory required for data: 20612000
I0204 22:32:44.503505 10207 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 22:32:44.503518 10207 net.cpp:106] Creating Layer label_data_1_split
I0204 22:32:44.503525 10207 net.cpp:454] label_data_1_split <- label
I0204 22:32:44.503535 10207 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 22:32:44.503547 10207 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 22:32:44.503558 10207 net.cpp:150] Setting up label_data_1_split
I0204 22:32:44.503566 10207 net.cpp:157] Top shape: 100 (100)
I0204 22:32:44.503572 10207 net.cpp:157] Top shape: 100 (100)
I0204 22:32:44.503577 10207 net.cpp:165] Memory required for data: 20612800
I0204 22:32:44.503582 10207 layer_factory.hpp:77] Creating layer conv1
I0204 22:32:44.503594 10207 net.cpp:106] Creating Layer conv1
I0204 22:32:44.503602 10207 net.cpp:454] conv1 <- data
I0204 22:32:44.503610 10207 net.cpp:411] conv1 -> conv1
I0204 22:32:44.503671 10207 net.cpp:150] Setting up conv1
I0204 22:32:44.503681 10207 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 22:32:44.503686 10207 net.cpp:165] Memory required for data: 59332800
I0204 22:32:44.503700 10207 layer_factory.hpp:77] Creating layer relu1
I0204 22:32:44.503710 10207 net.cpp:106] Creating Layer relu1
I0204 22:32:44.503715 10207 net.cpp:454] relu1 <- conv1
I0204 22:32:44.503722 10207 net.cpp:397] relu1 -> conv1 (in-place)
I0204 22:32:44.503731 10207 net.cpp:150] Setting up relu1
I0204 22:32:44.503738 10207 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 22:32:44.503743 10207 net.cpp:165] Memory required for data: 98052800
I0204 22:32:44.503751 10207 layer_factory.hpp:77] Creating layer pool1
I0204 22:32:44.503762 10207 net.cpp:106] Creating Layer pool1
I0204 22:32:44.503767 10207 net.cpp:454] pool1 <- conv1
I0204 22:32:44.503773 10207 net.cpp:411] pool1 -> pool1
I0204 22:32:44.503785 10207 net.cpp:150] Setting up pool1
I0204 22:32:44.503793 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.503798 10207 net.cpp:165] Memory required for data: 107384000
I0204 22:32:44.503803 10207 layer_factory.hpp:77] Creating layer norm1
I0204 22:32:44.503811 10207 net.cpp:106] Creating Layer norm1
I0204 22:32:44.503818 10207 net.cpp:454] norm1 <- pool1
I0204 22:32:44.503824 10207 net.cpp:411] norm1 -> norm1
I0204 22:32:44.503834 10207 net.cpp:150] Setting up norm1
I0204 22:32:44.503842 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.503849 10207 net.cpp:165] Memory required for data: 116715200
I0204 22:32:44.503854 10207 layer_factory.hpp:77] Creating layer conv2
I0204 22:32:44.503864 10207 net.cpp:106] Creating Layer conv2
I0204 22:32:44.503868 10207 net.cpp:454] conv2 <- norm1
I0204 22:32:44.503876 10207 net.cpp:411] conv2 -> conv2
I0204 22:32:44.504004 10207 net.cpp:150] Setting up conv2
I0204 22:32:44.504014 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.504020 10207 net.cpp:165] Memory required for data: 126046400
I0204 22:32:44.504031 10207 layer_factory.hpp:77] Creating layer relu2
I0204 22:32:44.504040 10207 net.cpp:106] Creating Layer relu2
I0204 22:32:44.504045 10207 net.cpp:454] relu2 <- conv2
I0204 22:32:44.504062 10207 net.cpp:397] relu2 -> conv2 (in-place)
I0204 22:32:44.504081 10207 net.cpp:150] Setting up relu2
I0204 22:32:44.504088 10207 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 22:32:44.504101 10207 net.cpp:165] Memory required for data: 135377600
I0204 22:32:44.504106 10207 layer_factory.hpp:77] Creating layer pool2
I0204 22:32:44.504115 10207 net.cpp:106] Creating Layer pool2
I0204 22:32:44.504122 10207 net.cpp:454] pool2 <- conv2
I0204 22:32:44.504129 10207 net.cpp:411] pool2 -> pool2
I0204 22:32:44.504140 10207 net.cpp:150] Setting up pool2
I0204 22:32:44.504148 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504153 10207 net.cpp:165] Memory required for data: 137540800
I0204 22:32:44.504158 10207 layer_factory.hpp:77] Creating layer norm2
I0204 22:32:44.504166 10207 net.cpp:106] Creating Layer norm2
I0204 22:32:44.504171 10207 net.cpp:454] norm2 <- pool2
I0204 22:32:44.504180 10207 net.cpp:411] norm2 -> norm2
I0204 22:32:44.504189 10207 net.cpp:150] Setting up norm2
I0204 22:32:44.504196 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504201 10207 net.cpp:165] Memory required for data: 139704000
I0204 22:32:44.504206 10207 layer_factory.hpp:77] Creating layer conv3
I0204 22:32:44.504216 10207 net.cpp:106] Creating Layer conv3
I0204 22:32:44.504223 10207 net.cpp:454] conv3 <- norm2
I0204 22:32:44.504231 10207 net.cpp:411] conv3 -> conv3
I0204 22:32:44.504325 10207 net.cpp:150] Setting up conv3
I0204 22:32:44.504336 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504341 10207 net.cpp:165] Memory required for data: 141867200
I0204 22:32:44.504351 10207 layer_factory.hpp:77] Creating layer relu3
I0204 22:32:44.504359 10207 net.cpp:106] Creating Layer relu3
I0204 22:32:44.504365 10207 net.cpp:454] relu3 <- conv3
I0204 22:32:44.504372 10207 net.cpp:397] relu3 -> conv3 (in-place)
I0204 22:32:44.504384 10207 net.cpp:150] Setting up relu3
I0204 22:32:44.504390 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504395 10207 net.cpp:165] Memory required for data: 144030400
I0204 22:32:44.504401 10207 layer_factory.hpp:77] Creating layer conv4
I0204 22:32:44.504410 10207 net.cpp:106] Creating Layer conv4
I0204 22:32:44.504415 10207 net.cpp:454] conv4 <- conv3
I0204 22:32:44.504422 10207 net.cpp:411] conv4 -> conv4
I0204 22:32:44.504477 10207 net.cpp:150] Setting up conv4
I0204 22:32:44.504487 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504492 10207 net.cpp:165] Memory required for data: 146193600
I0204 22:32:44.504501 10207 layer_factory.hpp:77] Creating layer relu4
I0204 22:32:44.504508 10207 net.cpp:106] Creating Layer relu4
I0204 22:32:44.504513 10207 net.cpp:454] relu4 <- conv4
I0204 22:32:44.504520 10207 net.cpp:397] relu4 -> conv4 (in-place)
I0204 22:32:44.504530 10207 net.cpp:150] Setting up relu4
I0204 22:32:44.504539 10207 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 22:32:44.504544 10207 net.cpp:165] Memory required for data: 148356800
I0204 22:32:44.504549 10207 layer_factory.hpp:77] Creating layer conv5
I0204 22:32:44.504557 10207 net.cpp:106] Creating Layer conv5
I0204 22:32:44.504562 10207 net.cpp:454] conv5 <- conv4
I0204 22:32:44.504570 10207 net.cpp:411] conv5 -> conv5
I0204 22:32:44.504607 10207 net.cpp:150] Setting up conv5
I0204 22:32:44.504616 10207 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 22:32:44.504621 10207 net.cpp:165] Memory required for data: 149438400
I0204 22:32:44.504632 10207 layer_factory.hpp:77] Creating layer relu5
I0204 22:32:44.504640 10207 net.cpp:106] Creating Layer relu5
I0204 22:32:44.504647 10207 net.cpp:454] relu5 <- conv5
I0204 22:32:44.504653 10207 net.cpp:397] relu5 -> conv5 (in-place)
I0204 22:32:44.504662 10207 net.cpp:150] Setting up relu5
I0204 22:32:44.504668 10207 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 22:32:44.504674 10207 net.cpp:165] Memory required for data: 150520000
I0204 22:32:44.504679 10207 layer_factory.hpp:77] Creating layer pool5
I0204 22:32:44.504690 10207 net.cpp:106] Creating Layer pool5
I0204 22:32:44.504700 10207 net.cpp:454] pool5 <- conv5
I0204 22:32:44.504715 10207 net.cpp:411] pool5 -> pool5
I0204 22:32:44.504725 10207 net.cpp:150] Setting up pool5
I0204 22:32:44.504734 10207 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 22:32:44.504739 10207 net.cpp:165] Memory required for data: 150750400
I0204 22:32:44.504744 10207 layer_factory.hpp:77] Creating layer fc6
I0204 22:32:44.504752 10207 net.cpp:106] Creating Layer fc6
I0204 22:32:44.504758 10207 net.cpp:454] fc6 <- pool5
I0204 22:32:44.504765 10207 net.cpp:411] fc6 -> fc6
I0204 22:32:44.506469 10207 net.cpp:150] Setting up fc6
I0204 22:32:44.506484 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.506489 10207 net.cpp:165] Memory required for data: 150852800
I0204 22:32:44.506497 10207 layer_factory.hpp:77] Creating layer relu6
I0204 22:32:44.506505 10207 net.cpp:106] Creating Layer relu6
I0204 22:32:44.506511 10207 net.cpp:454] relu6 <- fc6
I0204 22:32:44.506518 10207 net.cpp:397] relu6 -> fc6 (in-place)
I0204 22:32:44.506527 10207 net.cpp:150] Setting up relu6
I0204 22:32:44.506533 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.506539 10207 net.cpp:165] Memory required for data: 150955200
I0204 22:32:44.506544 10207 layer_factory.hpp:77] Creating layer drop6
I0204 22:32:44.506553 10207 net.cpp:106] Creating Layer drop6
I0204 22:32:44.506558 10207 net.cpp:454] drop6 <- fc6
I0204 22:32:44.506566 10207 net.cpp:397] drop6 -> fc6 (in-place)
I0204 22:32:44.506575 10207 net.cpp:150] Setting up drop6
I0204 22:32:44.506582 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.506587 10207 net.cpp:165] Memory required for data: 151057600
I0204 22:32:44.506592 10207 layer_factory.hpp:77] Creating layer fc7
I0204 22:32:44.506603 10207 net.cpp:106] Creating Layer fc7
I0204 22:32:44.506608 10207 net.cpp:454] fc7 <- fc6
I0204 22:32:44.506618 10207 net.cpp:411] fc7 -> fc7
I0204 22:32:44.507344 10207 net.cpp:150] Setting up fc7
I0204 22:32:44.507355 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.507360 10207 net.cpp:165] Memory required for data: 151160000
I0204 22:32:44.507370 10207 layer_factory.hpp:77] Creating layer relu7
I0204 22:32:44.507378 10207 net.cpp:106] Creating Layer relu7
I0204 22:32:44.507385 10207 net.cpp:454] relu7 <- fc7
I0204 22:32:44.507393 10207 net.cpp:397] relu7 -> fc7 (in-place)
I0204 22:32:44.507402 10207 net.cpp:150] Setting up relu7
I0204 22:32:44.507411 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.507416 10207 net.cpp:165] Memory required for data: 151262400
I0204 22:32:44.507423 10207 layer_factory.hpp:77] Creating layer drop7
I0204 22:32:44.507431 10207 net.cpp:106] Creating Layer drop7
I0204 22:32:44.507436 10207 net.cpp:454] drop7 <- fc7
I0204 22:32:44.507443 10207 net.cpp:397] drop7 -> fc7 (in-place)
I0204 22:32:44.507455 10207 net.cpp:150] Setting up drop7
I0204 22:32:44.507462 10207 net.cpp:157] Top shape: 100 256 (25600)
I0204 22:32:44.507467 10207 net.cpp:165] Memory required for data: 151364800
I0204 22:32:44.507472 10207 layer_factory.hpp:77] Creating layer fc8
I0204 22:32:44.507480 10207 net.cpp:106] Creating Layer fc8
I0204 22:32:44.507485 10207 net.cpp:454] fc8 <- fc7
I0204 22:32:44.507493 10207 net.cpp:411] fc8 -> fc8
I0204 22:32:44.507519 10207 net.cpp:150] Setting up fc8
I0204 22:32:44.507527 10207 net.cpp:157] Top shape: 100 2 (200)
I0204 22:32:44.507532 10207 net.cpp:165] Memory required for data: 151365600
I0204 22:32:44.507539 10207 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 22:32:44.507550 10207 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 22:32:44.507557 10207 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 22:32:44.507565 10207 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 22:32:44.507575 10207 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 22:32:44.507588 10207 net.cpp:150] Setting up fc8_fc8_0_split
I0204 22:32:44.507596 10207 net.cpp:157] Top shape: 100 2 (200)
I0204 22:32:44.507601 10207 net.cpp:157] Top shape: 100 2 (200)
I0204 22:32:44.507606 10207 net.cpp:165] Memory required for data: 151367200
I0204 22:32:44.507611 10207 layer_factory.hpp:77] Creating layer accuracy
I0204 22:32:44.507634 10207 net.cpp:106] Creating Layer accuracy
I0204 22:32:44.507640 10207 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 22:32:44.507647 10207 net.cpp:454] accuracy <- label_data_1_split_0
I0204 22:32:44.507654 10207 net.cpp:411] accuracy -> accuracy
I0204 22:32:44.507665 10207 net.cpp:150] Setting up accuracy
I0204 22:32:44.507673 10207 net.cpp:157] Top shape: (1)
I0204 22:32:44.507678 10207 net.cpp:165] Memory required for data: 151367204
I0204 22:32:44.507683 10207 layer_factory.hpp:77] Creating layer loss
I0204 22:32:44.507693 10207 net.cpp:106] Creating Layer loss
I0204 22:32:44.507699 10207 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 22:32:44.507706 10207 net.cpp:454] loss <- label_data_1_split_1
I0204 22:32:44.507715 10207 net.cpp:411] loss -> loss
I0204 22:32:44.507727 10207 layer_factory.hpp:77] Creating layer loss
I0204 22:32:44.507751 10207 net.cpp:150] Setting up loss
I0204 22:32:44.507758 10207 net.cpp:157] Top shape: (1)
I0204 22:32:44.507763 10207 net.cpp:160]     with loss weight 1
I0204 22:32:44.507776 10207 net.cpp:165] Memory required for data: 151367208
I0204 22:32:44.507782 10207 net.cpp:226] loss needs backward computation.
I0204 22:32:44.507788 10207 net.cpp:228] accuracy does not need backward computation.
I0204 22:32:44.507794 10207 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 22:32:44.507800 10207 net.cpp:226] fc8 needs backward computation.
I0204 22:32:44.507805 10207 net.cpp:226] drop7 needs backward computation.
I0204 22:32:44.507812 10207 net.cpp:226] relu7 needs backward computation.
I0204 22:32:44.507817 10207 net.cpp:226] fc7 needs backward computation.
I0204 22:32:44.507822 10207 net.cpp:226] drop6 needs backward computation.
I0204 22:32:44.507827 10207 net.cpp:226] relu6 needs backward computation.
I0204 22:32:44.507833 10207 net.cpp:226] fc6 needs backward computation.
I0204 22:32:44.507838 10207 net.cpp:226] pool5 needs backward computation.
I0204 22:32:44.507843 10207 net.cpp:226] relu5 needs backward computation.
I0204 22:32:44.507848 10207 net.cpp:226] conv5 needs backward computation.
I0204 22:32:44.507853 10207 net.cpp:226] relu4 needs backward computation.
I0204 22:32:44.507859 10207 net.cpp:226] conv4 needs backward computation.
I0204 22:32:44.507868 10207 net.cpp:226] relu3 needs backward computation.
I0204 22:32:44.507872 10207 net.cpp:226] conv3 needs backward computation.
I0204 22:32:44.507879 10207 net.cpp:226] norm2 needs backward computation.
I0204 22:32:44.507884 10207 net.cpp:226] pool2 needs backward computation.
I0204 22:32:44.507891 10207 net.cpp:226] relu2 needs backward computation.
I0204 22:32:44.507896 10207 net.cpp:226] conv2 needs backward computation.
I0204 22:32:44.507902 10207 net.cpp:226] norm1 needs backward computation.
I0204 22:32:44.507907 10207 net.cpp:226] pool1 needs backward computation.
I0204 22:32:44.507913 10207 net.cpp:226] relu1 needs backward computation.
I0204 22:32:44.507918 10207 net.cpp:226] conv1 needs backward computation.
I0204 22:32:44.507925 10207 net.cpp:228] label_data_1_split does not need backward computation.
I0204 22:32:44.507931 10207 net.cpp:228] data does not need backward computation.
I0204 22:32:44.507936 10207 net.cpp:270] This network produces output accuracy
I0204 22:32:44.507942 10207 net.cpp:270] This network produces output loss
I0204 22:32:44.507972 10207 net.cpp:283] Network initialization done.
I0204 22:32:44.508061 10207 solver.cpp:60] Solver scaffolding done.
I0204 22:32:44.508126 10207 caffe.cpp:212] Starting Optimization
I0204 22:32:44.508133 10207 solver.cpp:288] Solving CaffeNet
I0204 22:32:44.508138 10207 solver.cpp:289] Learning Rate Policy: step
I0204 22:32:44.509037 10207 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 22:32:44.509166 10207 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 22:32:51.814873 10207 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 22:32:51.814944 10207 solver.cpp:409]     Test net output #1: loss = 3.24391 (* 1 = 3.24391 loss)
I0204 22:32:53.453398 10207 solver.cpp:237] Iteration 0, loss = 10.116
I0204 22:32:53.453483 10207 solver.cpp:253]     Train net output #0: loss = 10.116 (* 1 = 10.116 loss)
I0204 22:32:53.453498 10207 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 22:33:13.214610 10207 solver.cpp:237] Iteration 10, loss = 1.31922
I0204 22:33:13.214684 10207 solver.cpp:253]     Train net output #0: loss = 1.31922 (* 1 = 1.31922 loss)
I0204 22:33:13.214696 10207 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 22:33:36.611065 10207 solver.cpp:237] Iteration 20, loss = 1.12055
I0204 22:33:36.611217 10207 solver.cpp:253]     Train net output #0: loss = 1.12055 (* 1 = 1.12055 loss)
I0204 22:33:36.611232 10207 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 22:34:01.032376 10207 solver.cpp:237] Iteration 30, loss = 0.903668
I0204 22:34:01.032454 10207 solver.cpp:253]     Train net output #0: loss = 0.903668 (* 1 = 0.903668 loss)
I0204 22:34:01.032466 10207 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 22:34:24.841804 10207 solver.cpp:237] Iteration 40, loss = 0.979971
I0204 22:34:24.842017 10207 solver.cpp:253]     Train net output #0: loss = 0.979971 (* 1 = 0.979971 loss)
I0204 22:34:24.842032 10207 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 22:34:48.692131 10207 solver.cpp:237] Iteration 50, loss = 0.877518
I0204 22:34:48.692205 10207 solver.cpp:253]     Train net output #0: loss = 0.877518 (* 1 = 0.877518 loss)
I0204 22:34:48.692219 10207 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 22:35:12.896773 10207 solver.cpp:237] Iteration 60, loss = 0.725739
I0204 22:35:12.897001 10207 solver.cpp:253]     Train net output #0: loss = 0.725739 (* 1 = 0.725739 loss)
I0204 22:35:12.897016 10207 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 22:35:36.870816 10207 solver.cpp:237] Iteration 70, loss = 0.680362
I0204 22:35:36.870893 10207 solver.cpp:253]     Train net output #0: loss = 0.680362 (* 1 = 0.680362 loss)
I0204 22:35:36.870905 10207 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 22:36:00.642066 10207 solver.cpp:237] Iteration 80, loss = 0.662994
I0204 22:36:00.642264 10207 solver.cpp:253]     Train net output #0: loss = 0.662994 (* 1 = 0.662994 loss)
I0204 22:36:00.642279 10207 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 22:36:24.526065 10207 solver.cpp:237] Iteration 90, loss = 0.687588
I0204 22:36:24.526146 10207 solver.cpp:253]     Train net output #0: loss = 0.687588 (* 1 = 0.687588 loss)
I0204 22:36:24.526159 10207 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 22:36:46.776296 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_100.caffemodel
I0204 22:36:46.780694 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_100.solverstate
I0204 22:36:46.782084 10207 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 22:36:58.740963 10207 solver.cpp:409]     Test net output #0: accuracy = 0.85
I0204 22:36:58.741034 10207 solver.cpp:409]     Test net output #1: loss = 0.450518 (* 1 = 0.450518 loss)
I0204 22:37:01.283046 10207 solver.cpp:237] Iteration 100, loss = 0.579093
I0204 22:37:01.283116 10207 solver.cpp:253]     Train net output #0: loss = 0.579093 (* 1 = 0.579093 loss)
I0204 22:37:01.283129 10207 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 22:37:27.099393 10207 solver.cpp:237] Iteration 110, loss = 0.479592
I0204 22:37:27.099593 10207 solver.cpp:253]     Train net output #0: loss = 0.479592 (* 1 = 0.479592 loss)
I0204 22:37:27.099608 10207 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 22:37:53.884372 10207 solver.cpp:237] Iteration 120, loss = 0.530444
I0204 22:37:53.884451 10207 solver.cpp:253]     Train net output #0: loss = 0.530444 (* 1 = 0.530444 loss)
I0204 22:37:53.884464 10207 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 22:38:21.571949 10207 solver.cpp:237] Iteration 130, loss = 0.336281
I0204 22:38:21.572219 10207 solver.cpp:253]     Train net output #0: loss = 0.336281 (* 1 = 0.336281 loss)
I0204 22:38:21.572238 10207 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 22:38:49.823390 10207 solver.cpp:237] Iteration 140, loss = 0.253653
I0204 22:38:49.823465 10207 solver.cpp:253]     Train net output #0: loss = 0.253653 (* 1 = 0.253653 loss)
I0204 22:38:49.823477 10207 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 22:39:18.360216 10207 solver.cpp:237] Iteration 150, loss = 0.130418
I0204 22:39:18.360433 10207 solver.cpp:253]     Train net output #0: loss = 0.130418 (* 1 = 0.130418 loss)
I0204 22:39:18.360448 10207 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 22:39:47.336441 10207 solver.cpp:237] Iteration 160, loss = 0.12858
I0204 22:39:47.336518 10207 solver.cpp:253]     Train net output #0: loss = 0.12858 (* 1 = 0.12858 loss)
I0204 22:39:47.336531 10207 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 22:40:16.503392 10207 solver.cpp:237] Iteration 170, loss = 0.160501
I0204 22:40:16.503597 10207 solver.cpp:253]     Train net output #0: loss = 0.160501 (* 1 = 0.160501 loss)
I0204 22:40:16.503612 10207 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 22:40:44.839750 10207 solver.cpp:237] Iteration 180, loss = 0.0665463
I0204 22:40:44.839824 10207 solver.cpp:253]     Train net output #0: loss = 0.0665463 (* 1 = 0.0665463 loss)
I0204 22:40:44.839836 10207 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 22:41:12.498997 10207 solver.cpp:237] Iteration 190, loss = 0.0772995
I0204 22:41:12.499219 10207 solver.cpp:253]     Train net output #0: loss = 0.0772995 (* 1 = 0.0772995 loss)
I0204 22:41:12.499234 10207 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 22:41:37.525676 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_200.caffemodel
I0204 22:41:37.529227 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_200.solverstate
I0204 22:41:37.530591 10207 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 22:41:50.972187 10207 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 22:41:50.972388 10207 solver.cpp:409]     Test net output #1: loss = 0.0280235 (* 1 = 0.0280235 loss)
I0204 22:41:53.764231 10207 solver.cpp:237] Iteration 200, loss = 0.0541463
I0204 22:41:53.764297 10207 solver.cpp:253]     Train net output #0: loss = 0.0541463 (* 1 = 0.0541463 loss)
I0204 22:41:53.764309 10207 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 22:42:22.035171 10207 solver.cpp:237] Iteration 210, loss = 0.223208
I0204 22:42:22.035374 10207 solver.cpp:253]     Train net output #0: loss = 0.223208 (* 1 = 0.223208 loss)
I0204 22:42:22.035389 10207 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 22:42:50.279867 10207 solver.cpp:237] Iteration 220, loss = 0.0347306
I0204 22:42:50.279944 10207 solver.cpp:253]     Train net output #0: loss = 0.0347306 (* 1 = 0.0347306 loss)
I0204 22:42:50.279958 10207 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 22:43:18.751122 10207 solver.cpp:237] Iteration 230, loss = 0.0175176
I0204 22:43:18.751334 10207 solver.cpp:253]     Train net output #0: loss = 0.0175176 (* 1 = 0.0175176 loss)
I0204 22:43:18.751349 10207 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 22:43:47.207518 10207 solver.cpp:237] Iteration 240, loss = 0.0632775
I0204 22:43:47.207597 10207 solver.cpp:253]     Train net output #0: loss = 0.0632775 (* 1 = 0.0632775 loss)
I0204 22:43:47.207608 10207 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 22:44:15.567862 10207 solver.cpp:237] Iteration 250, loss = 0.0209669
I0204 22:44:15.568079 10207 solver.cpp:253]     Train net output #0: loss = 0.0209669 (* 1 = 0.0209669 loss)
I0204 22:44:15.568099 10207 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 22:44:43.783036 10207 solver.cpp:237] Iteration 260, loss = 0.0272254
I0204 22:44:43.783121 10207 solver.cpp:253]     Train net output #0: loss = 0.0272254 (* 1 = 0.0272254 loss)
I0204 22:44:43.783149 10207 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 22:45:11.747936 10207 solver.cpp:237] Iteration 270, loss = 0.0269475
I0204 22:45:11.748208 10207 solver.cpp:253]     Train net output #0: loss = 0.0269476 (* 1 = 0.0269476 loss)
I0204 22:45:11.748222 10207 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 22:45:39.920325 10207 solver.cpp:237] Iteration 280, loss = 0.0840677
I0204 22:45:39.920398 10207 solver.cpp:253]     Train net output #0: loss = 0.0840677 (* 1 = 0.0840677 loss)
I0204 22:45:39.920410 10207 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 22:46:08.355576 10207 solver.cpp:237] Iteration 290, loss = 0.0447113
I0204 22:46:08.355767 10207 solver.cpp:253]     Train net output #0: loss = 0.0447113 (* 1 = 0.0447113 loss)
I0204 22:46:08.355782 10207 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 22:46:34.148375 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_300.caffemodel
I0204 22:46:34.151974 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_300.solverstate
I0204 22:46:34.153384 10207 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 22:46:47.931761 10207 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 22:46:47.931928 10207 solver.cpp:409]     Test net output #1: loss = 0.0227295 (* 1 = 0.0227295 loss)
I0204 22:46:50.858870 10207 solver.cpp:237] Iteration 300, loss = 0.0395271
I0204 22:46:50.858932 10207 solver.cpp:253]     Train net output #0: loss = 0.0395271 (* 1 = 0.0395271 loss)
I0204 22:46:50.858945 10207 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 22:47:19.410598 10207 solver.cpp:237] Iteration 310, loss = 0.0236809
I0204 22:47:19.410825 10207 solver.cpp:253]     Train net output #0: loss = 0.0236809 (* 1 = 0.0236809 loss)
I0204 22:47:19.410841 10207 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 22:47:47.976759 10207 solver.cpp:237] Iteration 320, loss = 0.0512667
I0204 22:47:47.976845 10207 solver.cpp:253]     Train net output #0: loss = 0.0512667 (* 1 = 0.0512667 loss)
I0204 22:47:47.976857 10207 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 22:48:16.679121 10207 solver.cpp:237] Iteration 330, loss = 0.0170765
I0204 22:48:16.679327 10207 solver.cpp:253]     Train net output #0: loss = 0.0170765 (* 1 = 0.0170765 loss)
I0204 22:48:16.679344 10207 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 22:48:46.022106 10207 solver.cpp:237] Iteration 340, loss = 0.0121759
I0204 22:48:46.022187 10207 solver.cpp:253]     Train net output #0: loss = 0.0121759 (* 1 = 0.0121759 loss)
I0204 22:48:46.022202 10207 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 22:49:15.528919 10207 solver.cpp:237] Iteration 350, loss = 0.0508263
I0204 22:49:15.529136 10207 solver.cpp:253]     Train net output #0: loss = 0.0508263 (* 1 = 0.0508263 loss)
I0204 22:49:15.529153 10207 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 22:49:44.807790 10207 solver.cpp:237] Iteration 360, loss = 0.105251
I0204 22:49:44.807873 10207 solver.cpp:253]     Train net output #0: loss = 0.105251 (* 1 = 0.105251 loss)
I0204 22:49:44.807888 10207 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 22:50:14.024098 10207 solver.cpp:237] Iteration 370, loss = 0.10787
I0204 22:50:14.024333 10207 solver.cpp:253]     Train net output #0: loss = 0.10787 (* 1 = 0.10787 loss)
I0204 22:50:14.024350 10207 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 22:50:43.186416 10207 solver.cpp:237] Iteration 380, loss = 0.0946329
I0204 22:50:43.186497 10207 solver.cpp:253]     Train net output #0: loss = 0.0946329 (* 1 = 0.0946329 loss)
I0204 22:50:43.186511 10207 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 22:51:12.359757 10207 solver.cpp:237] Iteration 390, loss = 0.00875458
I0204 22:51:12.360355 10207 solver.cpp:253]     Train net output #0: loss = 0.00875457 (* 1 = 0.00875457 loss)
I0204 22:51:12.360376 10207 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 22:51:38.304292 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_400.caffemodel
I0204 22:51:38.308750 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_400.solverstate
I0204 22:51:38.310134 10207 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 22:51:52.063302 10207 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 22:51:52.063519 10207 solver.cpp:409]     Test net output #1: loss = 0.00459671 (* 1 = 0.00459671 loss)
I0204 22:51:54.982765 10207 solver.cpp:237] Iteration 400, loss = 0.00793492
I0204 22:51:54.982842 10207 solver.cpp:253]     Train net output #0: loss = 0.00793491 (* 1 = 0.00793491 loss)
I0204 22:51:54.982856 10207 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 22:52:23.931438 10207 solver.cpp:237] Iteration 410, loss = 0.00974618
I0204 22:52:23.931644 10207 solver.cpp:253]     Train net output #0: loss = 0.00974617 (* 1 = 0.00974617 loss)
I0204 22:52:23.931660 10207 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 22:52:52.673835 10207 solver.cpp:237] Iteration 420, loss = 0.0948018
I0204 22:52:52.673915 10207 solver.cpp:253]     Train net output #0: loss = 0.0948018 (* 1 = 0.0948018 loss)
I0204 22:52:52.673929 10207 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 22:53:21.324918 10207 solver.cpp:237] Iteration 430, loss = 0.0843093
I0204 22:53:21.325136 10207 solver.cpp:253]     Train net output #0: loss = 0.0843093 (* 1 = 0.0843093 loss)
I0204 22:53:21.325152 10207 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 22:53:49.895733 10207 solver.cpp:237] Iteration 440, loss = 0.0311941
I0204 22:53:49.895814 10207 solver.cpp:253]     Train net output #0: loss = 0.031194 (* 1 = 0.031194 loss)
I0204 22:53:49.895828 10207 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 22:54:18.372328 10207 solver.cpp:237] Iteration 450, loss = 0.00632558
I0204 22:54:18.372540 10207 solver.cpp:253]     Train net output #0: loss = 0.00632556 (* 1 = 0.00632556 loss)
I0204 22:54:18.372555 10207 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 22:54:46.848335 10207 solver.cpp:237] Iteration 460, loss = 0.00170174
I0204 22:54:46.848417 10207 solver.cpp:253]     Train net output #0: loss = 0.00170173 (* 1 = 0.00170173 loss)
I0204 22:54:46.848430 10207 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 22:55:15.513119 10207 solver.cpp:237] Iteration 470, loss = 0.00245984
I0204 22:55:15.513612 10207 solver.cpp:253]     Train net output #0: loss = 0.00245983 (* 1 = 0.00245983 loss)
I0204 22:55:15.513638 10207 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 22:55:44.146667 10207 solver.cpp:237] Iteration 480, loss = 0.0158925
I0204 22:55:44.146746 10207 solver.cpp:253]     Train net output #0: loss = 0.0158925 (* 1 = 0.0158925 loss)
I0204 22:55:44.146760 10207 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 22:56:12.919203 10207 solver.cpp:237] Iteration 490, loss = 0.00546944
I0204 22:56:12.919432 10207 solver.cpp:253]     Train net output #0: loss = 0.00546944 (* 1 = 0.00546944 loss)
I0204 22:56:12.919448 10207 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 22:56:39.081285 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_500.caffemodel
I0204 22:56:39.084974 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_500.solverstate
I0204 22:56:39.086395 10207 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 22:56:52.955119 10207 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 22:56:52.955355 10207 solver.cpp:409]     Test net output #1: loss = 0.00165168 (* 1 = 0.00165168 loss)
I0204 22:56:55.846952 10207 solver.cpp:237] Iteration 500, loss = 0.00547808
I0204 22:56:55.847026 10207 solver.cpp:253]     Train net output #0: loss = 0.00547808 (* 1 = 0.00547808 loss)
I0204 22:56:55.847040 10207 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 22:57:25.713271 10207 solver.cpp:237] Iteration 510, loss = 0.02689
I0204 22:57:25.722216 10207 solver.cpp:253]     Train net output #0: loss = 0.02689 (* 1 = 0.02689 loss)
I0204 22:57:25.722247 10207 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 22:57:55.449753 10207 solver.cpp:237] Iteration 520, loss = 0.00627589
I0204 22:57:55.449834 10207 solver.cpp:253]     Train net output #0: loss = 0.00627588 (* 1 = 0.00627588 loss)
I0204 22:57:55.449847 10207 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 22:58:24.955855 10207 solver.cpp:237] Iteration 530, loss = 0.0376546
I0204 22:58:24.956082 10207 solver.cpp:253]     Train net output #0: loss = 0.0376546 (* 1 = 0.0376546 loss)
I0204 22:58:24.956099 10207 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 22:58:54.233667 10207 solver.cpp:237] Iteration 540, loss = 0.00183084
I0204 22:58:54.233750 10207 solver.cpp:253]     Train net output #0: loss = 0.00183083 (* 1 = 0.00183083 loss)
I0204 22:58:54.233763 10207 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 22:59:23.397732 10207 solver.cpp:237] Iteration 550, loss = 0.000783643
I0204 22:59:23.397955 10207 solver.cpp:253]     Train net output #0: loss = 0.000783636 (* 1 = 0.000783636 loss)
I0204 22:59:23.397972 10207 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 22:59:52.515971 10207 solver.cpp:237] Iteration 560, loss = 0.00298028
I0204 22:59:52.516060 10207 solver.cpp:253]     Train net output #0: loss = 0.00298027 (* 1 = 0.00298027 loss)
I0204 22:59:52.516074 10207 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 23:00:21.675958 10207 solver.cpp:237] Iteration 570, loss = 0.00136592
I0204 23:00:21.676187 10207 solver.cpp:253]     Train net output #0: loss = 0.00136592 (* 1 = 0.00136592 loss)
I0204 23:00:21.676204 10207 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 23:00:51.207526 10207 solver.cpp:237] Iteration 580, loss = 0.00160111
I0204 23:00:51.207610 10207 solver.cpp:253]     Train net output #0: loss = 0.0016011 (* 1 = 0.0016011 loss)
I0204 23:00:51.207624 10207 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 23:01:20.992462 10207 solver.cpp:237] Iteration 590, loss = 0.00678953
I0204 23:01:20.992669 10207 solver.cpp:253]     Train net output #0: loss = 0.00678953 (* 1 = 0.00678953 loss)
I0204 23:01:20.992684 10207 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 23:01:47.954166 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_600.caffemodel
I0204 23:01:47.957722 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_600.solverstate
I0204 23:01:47.959100 10207 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 23:02:02.176071 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:02:02.176273 10207 solver.cpp:409]     Test net output #1: loss = 0.00058524 (* 1 = 0.00058524 loss)
I0204 23:02:05.126200 10207 solver.cpp:237] Iteration 600, loss = 0.00153115
I0204 23:02:05.126282 10207 solver.cpp:253]     Train net output #0: loss = 0.00153114 (* 1 = 0.00153114 loss)
I0204 23:02:05.126296 10207 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 23:02:34.632081 10207 solver.cpp:237] Iteration 610, loss = 0.00180958
I0204 23:02:34.632298 10207 solver.cpp:253]     Train net output #0: loss = 0.00180958 (* 1 = 0.00180958 loss)
I0204 23:02:34.632314 10207 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 23:03:03.959405 10207 solver.cpp:237] Iteration 620, loss = 0.0158913
I0204 23:03:03.959480 10207 solver.cpp:253]     Train net output #0: loss = 0.0158913 (* 1 = 0.0158913 loss)
I0204 23:03:03.959506 10207 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 23:03:33.155973 10207 solver.cpp:237] Iteration 630, loss = 0.000843748
I0204 23:03:33.156229 10207 solver.cpp:253]     Train net output #0: loss = 0.000843745 (* 1 = 0.000843745 loss)
I0204 23:03:33.156245 10207 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 23:04:02.049855 10207 solver.cpp:237] Iteration 640, loss = 0.00324567
I0204 23:04:02.049935 10207 solver.cpp:253]     Train net output #0: loss = 0.00324567 (* 1 = 0.00324567 loss)
I0204 23:04:02.049948 10207 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 23:04:30.592450 10207 solver.cpp:237] Iteration 650, loss = 0.00110159
I0204 23:04:30.592671 10207 solver.cpp:253]     Train net output #0: loss = 0.00110159 (* 1 = 0.00110159 loss)
I0204 23:04:30.592687 10207 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 23:04:59.203099 10207 solver.cpp:237] Iteration 660, loss = 0.00325249
I0204 23:04:59.203183 10207 solver.cpp:253]     Train net output #0: loss = 0.00325249 (* 1 = 0.00325249 loss)
I0204 23:04:59.203196 10207 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 23:05:27.808456 10207 solver.cpp:237] Iteration 670, loss = 0.00305487
I0204 23:05:27.808667 10207 solver.cpp:253]     Train net output #0: loss = 0.00305487 (* 1 = 0.00305487 loss)
I0204 23:05:27.808682 10207 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 23:05:56.394521 10207 solver.cpp:237] Iteration 680, loss = 0.0056567
I0204 23:05:56.394603 10207 solver.cpp:253]     Train net output #0: loss = 0.0056567 (* 1 = 0.0056567 loss)
I0204 23:05:56.394615 10207 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 23:06:25.072422 10207 solver.cpp:237] Iteration 690, loss = 0.00808998
I0204 23:06:25.072651 10207 solver.cpp:253]     Train net output #0: loss = 0.00808998 (* 1 = 0.00808998 loss)
I0204 23:06:25.072667 10207 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 23:06:50.999642 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_700.caffemodel
I0204 23:06:51.003378 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_700.solverstate
I0204 23:06:51.004789 10207 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 23:07:04.827519 10207 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 23:07:04.835209 10207 solver.cpp:409]     Test net output #1: loss = 0.00148306 (* 1 = 0.00148306 loss)
I0204 23:07:07.782346 10207 solver.cpp:237] Iteration 700, loss = 0.000872396
I0204 23:07:07.782415 10207 solver.cpp:253]     Train net output #0: loss = 0.000872399 (* 1 = 0.000872399 loss)
I0204 23:07:07.782428 10207 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 23:07:36.855567 10207 solver.cpp:237] Iteration 710, loss = 0.000374299
I0204 23:07:36.855774 10207 solver.cpp:253]     Train net output #0: loss = 0.0003743 (* 1 = 0.0003743 loss)
I0204 23:07:36.855789 10207 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 23:08:05.955651 10207 solver.cpp:237] Iteration 720, loss = 0.000659825
I0204 23:08:05.955724 10207 solver.cpp:253]     Train net output #0: loss = 0.000659827 (* 1 = 0.000659827 loss)
I0204 23:08:05.955735 10207 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 23:08:35.183230 10207 solver.cpp:237] Iteration 730, loss = 0.00924926
I0204 23:08:35.183425 10207 solver.cpp:253]     Train net output #0: loss = 0.00924926 (* 1 = 0.00924926 loss)
I0204 23:08:35.183441 10207 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 23:09:04.227933 10207 solver.cpp:237] Iteration 740, loss = 0.00749219
I0204 23:09:04.228008 10207 solver.cpp:253]     Train net output #0: loss = 0.00749219 (* 1 = 0.00749219 loss)
I0204 23:09:04.228019 10207 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 23:09:33.227278 10207 solver.cpp:237] Iteration 750, loss = 0.00269645
I0204 23:09:33.227519 10207 solver.cpp:253]     Train net output #0: loss = 0.00269645 (* 1 = 0.00269645 loss)
I0204 23:09:33.227542 10207 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 23:10:02.152217 10207 solver.cpp:237] Iteration 760, loss = 0.000803872
I0204 23:10:02.152293 10207 solver.cpp:253]     Train net output #0: loss = 0.000803877 (* 1 = 0.000803877 loss)
I0204 23:10:02.152305 10207 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 23:10:31.033565 10207 solver.cpp:237] Iteration 770, loss = 0.00112271
I0204 23:10:31.033782 10207 solver.cpp:253]     Train net output #0: loss = 0.00112271 (* 1 = 0.00112271 loss)
I0204 23:10:31.033797 10207 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 23:10:59.959642 10207 solver.cpp:237] Iteration 780, loss = 0.00045339
I0204 23:10:59.959717 10207 solver.cpp:253]     Train net output #0: loss = 0.000453393 (* 1 = 0.000453393 loss)
I0204 23:10:59.959729 10207 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 23:11:28.813107 10207 solver.cpp:237] Iteration 790, loss = 0.00479009
I0204 23:11:28.813318 10207 solver.cpp:253]     Train net output #0: loss = 0.0047901 (* 1 = 0.0047901 loss)
I0204 23:11:28.813334 10207 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 23:11:54.977788 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_800.caffemodel
I0204 23:11:54.981382 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_800.solverstate
I0204 23:11:54.982779 10207 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 23:12:08.817685 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:12:08.817898 10207 solver.cpp:409]     Test net output #1: loss = 0.000463906 (* 1 = 0.000463906 loss)
I0204 23:12:11.762166 10207 solver.cpp:237] Iteration 800, loss = 0.00280846
I0204 23:12:11.762228 10207 solver.cpp:253]     Train net output #0: loss = 0.00280846 (* 1 = 0.00280846 loss)
I0204 23:12:11.762239 10207 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 23:12:40.989913 10207 solver.cpp:237] Iteration 810, loss = 0.00486444
I0204 23:12:40.990113 10207 solver.cpp:253]     Train net output #0: loss = 0.00486444 (* 1 = 0.00486444 loss)
I0204 23:12:40.990128 10207 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 23:13:10.725471 10207 solver.cpp:237] Iteration 820, loss = 0.0318194
I0204 23:13:10.725553 10207 solver.cpp:253]     Train net output #0: loss = 0.0318194 (* 1 = 0.0318194 loss)
I0204 23:13:10.725567 10207 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 23:13:40.077945 10207 solver.cpp:237] Iteration 830, loss = 0.00129248
I0204 23:13:40.078191 10207 solver.cpp:253]     Train net output #0: loss = 0.00129247 (* 1 = 0.00129247 loss)
I0204 23:13:40.078207 10207 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 23:14:09.606317 10207 solver.cpp:237] Iteration 840, loss = 0.00100959
I0204 23:14:09.606402 10207 solver.cpp:253]     Train net output #0: loss = 0.00100959 (* 1 = 0.00100959 loss)
I0204 23:14:09.606415 10207 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 23:14:39.233216 10207 solver.cpp:237] Iteration 850, loss = 0.0266982
I0204 23:14:39.241272 10207 solver.cpp:253]     Train net output #0: loss = 0.0266982 (* 1 = 0.0266982 loss)
I0204 23:14:39.241305 10207 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 23:15:08.868136 10207 solver.cpp:237] Iteration 860, loss = 0.000665434
I0204 23:15:08.868212 10207 solver.cpp:253]     Train net output #0: loss = 0.000665428 (* 1 = 0.000665428 loss)
I0204 23:15:08.868224 10207 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 23:15:38.366756 10207 solver.cpp:237] Iteration 870, loss = 0.000441886
I0204 23:15:38.366977 10207 solver.cpp:253]     Train net output #0: loss = 0.000441878 (* 1 = 0.000441878 loss)
I0204 23:15:38.366993 10207 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 23:16:07.853847 10207 solver.cpp:237] Iteration 880, loss = 0.00060436
I0204 23:16:07.853931 10207 solver.cpp:253]     Train net output #0: loss = 0.000604351 (* 1 = 0.000604351 loss)
I0204 23:16:07.853960 10207 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 23:16:37.406843 10207 solver.cpp:237] Iteration 890, loss = 0.00356004
I0204 23:16:37.407107 10207 solver.cpp:253]     Train net output #0: loss = 0.00356003 (* 1 = 0.00356003 loss)
I0204 23:16:37.407122 10207 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 23:17:04.080873 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_900.caffemodel
I0204 23:17:04.084457 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_900.solverstate
I0204 23:17:04.085872 10207 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 23:17:18.310611 10207 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 23:17:18.310803 10207 solver.cpp:409]     Test net output #1: loss = 0.004589 (* 1 = 0.004589 loss)
I0204 23:17:21.316745 10207 solver.cpp:237] Iteration 900, loss = 0.0257278
I0204 23:17:21.316805 10207 solver.cpp:253]     Train net output #0: loss = 0.0257277 (* 1 = 0.0257277 loss)
I0204 23:17:21.316817 10207 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 23:17:50.939532 10207 solver.cpp:237] Iteration 910, loss = 0.00031573
I0204 23:17:50.939715 10207 solver.cpp:253]     Train net output #0: loss = 0.000315719 (* 1 = 0.000315719 loss)
I0204 23:17:50.939730 10207 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 23:18:20.824326 10207 solver.cpp:237] Iteration 920, loss = 0.000504716
I0204 23:18:20.824404 10207 solver.cpp:253]     Train net output #0: loss = 0.000504706 (* 1 = 0.000504706 loss)
I0204 23:18:20.824416 10207 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 23:18:50.347349 10207 solver.cpp:237] Iteration 930, loss = 0.00737495
I0204 23:18:50.347568 10207 solver.cpp:253]     Train net output #0: loss = 0.00737494 (* 1 = 0.00737494 loss)
I0204 23:18:50.347584 10207 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 23:19:19.832823 10207 solver.cpp:237] Iteration 940, loss = 0.000164896
I0204 23:19:19.832909 10207 solver.cpp:253]     Train net output #0: loss = 0.000164886 (* 1 = 0.000164886 loss)
I0204 23:19:19.832922 10207 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 23:19:49.333832 10207 solver.cpp:237] Iteration 950, loss = 0.00100494
I0204 23:19:49.334084 10207 solver.cpp:253]     Train net output #0: loss = 0.00100493 (* 1 = 0.00100493 loss)
I0204 23:19:49.334100 10207 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 23:20:18.629102 10207 solver.cpp:237] Iteration 960, loss = 0.0173045
I0204 23:20:18.629186 10207 solver.cpp:253]     Train net output #0: loss = 0.0173045 (* 1 = 0.0173045 loss)
I0204 23:20:18.629199 10207 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 23:20:47.817548 10207 solver.cpp:237] Iteration 970, loss = 0.000547424
I0204 23:20:47.817775 10207 solver.cpp:253]     Train net output #0: loss = 0.000547428 (* 1 = 0.000547428 loss)
I0204 23:20:47.817791 10207 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 23:21:17.016954 10207 solver.cpp:237] Iteration 980, loss = 0.24844
I0204 23:21:17.017040 10207 solver.cpp:253]     Train net output #0: loss = 0.24844 (* 1 = 0.24844 loss)
I0204 23:21:17.017057 10207 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 23:21:47.111079 10207 solver.cpp:237] Iteration 990, loss = 0.140354
I0204 23:21:47.111307 10207 solver.cpp:253]     Train net output #0: loss = 0.140354 (* 1 = 0.140354 loss)
I0204 23:21:47.111323 10207 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 23:22:14.065925 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1000.caffemodel
I0204 23:22:14.069505 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1000.solverstate
I0204 23:22:14.070896 10207 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 23:22:28.489969 10207 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 23:22:28.490227 10207 solver.cpp:409]     Test net output #1: loss = 0.00365038 (* 1 = 0.00365038 loss)
I0204 23:22:31.449069 10207 solver.cpp:237] Iteration 1000, loss = 0.00402848
I0204 23:22:31.449137 10207 solver.cpp:253]     Train net output #0: loss = 0.00402848 (* 1 = 0.00402848 loss)
I0204 23:22:31.449151 10207 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 23:23:01.299635 10207 solver.cpp:237] Iteration 1010, loss = 0.00702817
I0204 23:23:01.299867 10207 solver.cpp:253]     Train net output #0: loss = 0.00702817 (* 1 = 0.00702817 loss)
I0204 23:23:01.299885 10207 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 23:23:30.850386 10207 solver.cpp:237] Iteration 1020, loss = 0.00259902
I0204 23:23:30.850473 10207 solver.cpp:253]     Train net output #0: loss = 0.00259902 (* 1 = 0.00259902 loss)
I0204 23:23:30.850486 10207 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 23:24:00.508164 10207 solver.cpp:237] Iteration 1030, loss = 0.000487755
I0204 23:24:00.508388 10207 solver.cpp:253]     Train net output #0: loss = 0.000487755 (* 1 = 0.000487755 loss)
I0204 23:24:00.508404 10207 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 23:24:30.313254 10207 solver.cpp:237] Iteration 1040, loss = 0.00226192
I0204 23:24:30.313343 10207 solver.cpp:253]     Train net output #0: loss = 0.00226193 (* 1 = 0.00226193 loss)
I0204 23:24:30.313355 10207 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 23:25:00.078167 10207 solver.cpp:237] Iteration 1050, loss = 0.0175488
I0204 23:25:00.078392 10207 solver.cpp:253]     Train net output #0: loss = 0.0175488 (* 1 = 0.0175488 loss)
I0204 23:25:00.078408 10207 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 23:25:29.799281 10207 solver.cpp:237] Iteration 1060, loss = 0.00168825
I0204 23:25:29.799370 10207 solver.cpp:253]     Train net output #0: loss = 0.00168825 (* 1 = 0.00168825 loss)
I0204 23:25:29.799382 10207 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 23:25:59.440737 10207 solver.cpp:237] Iteration 1070, loss = 0.0248841
I0204 23:25:59.440959 10207 solver.cpp:253]     Train net output #0: loss = 0.0248841 (* 1 = 0.0248841 loss)
I0204 23:25:59.440976 10207 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 23:26:29.119822 10207 solver.cpp:237] Iteration 1080, loss = 0.00275806
I0204 23:26:29.119907 10207 solver.cpp:253]     Train net output #0: loss = 0.00275806 (* 1 = 0.00275806 loss)
I0204 23:26:29.119920 10207 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 23:26:58.859319 10207 solver.cpp:237] Iteration 1090, loss = 0.014188
I0204 23:26:58.859544 10207 solver.cpp:253]     Train net output #0: loss = 0.014188 (* 1 = 0.014188 loss)
I0204 23:26:58.859561 10207 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 23:27:25.653417 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1100.caffemodel
I0204 23:27:25.657018 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1100.solverstate
I0204 23:27:26.178549 10207 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 23:27:40.464988 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:27:40.465209 10207 solver.cpp:409]     Test net output #1: loss = 0.00017929 (* 1 = 0.00017929 loss)
I0204 23:27:43.458495 10207 solver.cpp:237] Iteration 1100, loss = 0.000667269
I0204 23:27:43.458571 10207 solver.cpp:253]     Train net output #0: loss = 0.000667273 (* 1 = 0.000667273 loss)
I0204 23:27:43.458585 10207 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 23:28:13.259153 10207 solver.cpp:237] Iteration 1110, loss = 0.000230521
I0204 23:28:13.259402 10207 solver.cpp:253]     Train net output #0: loss = 0.000230526 (* 1 = 0.000230526 loss)
I0204 23:28:13.259424 10207 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 23:28:43.117763 10207 solver.cpp:237] Iteration 1120, loss = 0.00111814
I0204 23:28:43.117844 10207 solver.cpp:253]     Train net output #0: loss = 0.00111815 (* 1 = 0.00111815 loss)
I0204 23:28:43.117857 10207 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 23:29:12.823110 10207 solver.cpp:237] Iteration 1130, loss = 0.002559
I0204 23:29:12.823346 10207 solver.cpp:253]     Train net output #0: loss = 0.002559 (* 1 = 0.002559 loss)
I0204 23:29:12.823362 10207 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 23:29:42.309754 10207 solver.cpp:237] Iteration 1140, loss = 0.0603359
I0204 23:29:42.309839 10207 solver.cpp:253]     Train net output #0: loss = 0.0603359 (* 1 = 0.0603359 loss)
I0204 23:29:42.309851 10207 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 23:30:11.575276 10207 solver.cpp:237] Iteration 1150, loss = 0.000516353
I0204 23:30:11.575500 10207 solver.cpp:253]     Train net output #0: loss = 0.000516353 (* 1 = 0.000516353 loss)
I0204 23:30:11.575516 10207 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 23:30:40.712574 10207 solver.cpp:237] Iteration 1160, loss = 0.00110529
I0204 23:30:40.712652 10207 solver.cpp:253]     Train net output #0: loss = 0.00110528 (* 1 = 0.00110528 loss)
I0204 23:30:40.712666 10207 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 23:31:09.702472 10207 solver.cpp:237] Iteration 1170, loss = 0.00406762
I0204 23:31:09.702715 10207 solver.cpp:253]     Train net output #0: loss = 0.00406762 (* 1 = 0.00406762 loss)
I0204 23:31:09.702731 10207 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 23:31:38.655328 10207 solver.cpp:237] Iteration 1180, loss = 0.00101795
I0204 23:31:38.655408 10207 solver.cpp:253]     Train net output #0: loss = 0.00101796 (* 1 = 0.00101796 loss)
I0204 23:31:38.655421 10207 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 23:32:07.838552 10207 solver.cpp:237] Iteration 1190, loss = 0.00339318
I0204 23:32:07.838778 10207 solver.cpp:253]     Train net output #0: loss = 0.00339319 (* 1 = 0.00339319 loss)
I0204 23:32:07.838793 10207 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 23:32:34.198945 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1200.caffemodel
I0204 23:32:34.203289 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1200.solverstate
I0204 23:32:34.204676 10207 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 23:32:48.171773 10207 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 23:32:48.171977 10207 solver.cpp:409]     Test net output #1: loss = 0.00344691 (* 1 = 0.00344691 loss)
I0204 23:32:51.040225 10207 solver.cpp:237] Iteration 1200, loss = 0.00228715
I0204 23:32:51.040300 10207 solver.cpp:253]     Train net output #0: loss = 0.00228715 (* 1 = 0.00228715 loss)
I0204 23:32:51.040313 10207 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 23:33:20.333391 10207 solver.cpp:237] Iteration 1210, loss = 0.00508118
I0204 23:33:20.333616 10207 solver.cpp:253]     Train net output #0: loss = 0.00508118 (* 1 = 0.00508118 loss)
I0204 23:33:20.333631 10207 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 23:33:49.549803 10207 solver.cpp:237] Iteration 1220, loss = 0.000450784
I0204 23:33:49.549885 10207 solver.cpp:253]     Train net output #0: loss = 0.000450786 (* 1 = 0.000450786 loss)
I0204 23:33:49.549898 10207 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 23:34:19.177307 10207 solver.cpp:237] Iteration 1230, loss = 0.00116406
I0204 23:34:19.177517 10207 solver.cpp:253]     Train net output #0: loss = 0.00116406 (* 1 = 0.00116406 loss)
I0204 23:34:19.177533 10207 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 23:34:48.516230 10207 solver.cpp:237] Iteration 1240, loss = 0.00947041
I0204 23:34:48.516329 10207 solver.cpp:253]     Train net output #0: loss = 0.00947041 (* 1 = 0.00947041 loss)
I0204 23:34:48.516341 10207 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 23:35:18.169366 10207 solver.cpp:237] Iteration 1250, loss = 0.00233037
I0204 23:35:18.169626 10207 solver.cpp:253]     Train net output #0: loss = 0.00233037 (* 1 = 0.00233037 loss)
I0204 23:35:18.169642 10207 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 23:35:48.325742 10207 solver.cpp:237] Iteration 1260, loss = 0.00540654
I0204 23:35:48.325953 10207 solver.cpp:253]     Train net output #0: loss = 0.00540654 (* 1 = 0.00540654 loss)
I0204 23:35:48.325968 10207 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 23:36:18.710647 10207 solver.cpp:237] Iteration 1270, loss = 0.00592129
I0204 23:36:18.710877 10207 solver.cpp:253]     Train net output #0: loss = 0.00592129 (* 1 = 0.00592129 loss)
I0204 23:36:18.710894 10207 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 23:36:48.731479 10207 solver.cpp:237] Iteration 1280, loss = 0.013263
I0204 23:36:48.731709 10207 solver.cpp:253]     Train net output #0: loss = 0.013263 (* 1 = 0.013263 loss)
I0204 23:36:48.731726 10207 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 23:37:18.798169 10207 solver.cpp:237] Iteration 1290, loss = 0.0392294
I0204 23:37:18.798391 10207 solver.cpp:253]     Train net output #0: loss = 0.0392294 (* 1 = 0.0392294 loss)
I0204 23:37:18.798408 10207 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 23:37:45.956588 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1300.caffemodel
I0204 23:37:45.960204 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1300.solverstate
I0204 23:37:45.961594 10207 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 23:38:00.311450 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:38:00.311666 10207 solver.cpp:409]     Test net output #1: loss = 0.000405821 (* 1 = 0.000405821 loss)
I0204 23:38:03.335085 10207 solver.cpp:237] Iteration 1300, loss = 0.00411605
I0204 23:38:03.335161 10207 solver.cpp:253]     Train net output #0: loss = 0.00411606 (* 1 = 0.00411606 loss)
I0204 23:38:03.335175 10207 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 23:38:33.395745 10207 solver.cpp:237] Iteration 1310, loss = 0.0190781
I0204 23:38:33.395977 10207 solver.cpp:253]     Train net output #0: loss = 0.0190781 (* 1 = 0.0190781 loss)
I0204 23:38:33.395992 10207 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 23:39:03.342991 10207 solver.cpp:237] Iteration 1320, loss = 0.000458963
I0204 23:39:03.343076 10207 solver.cpp:253]     Train net output #0: loss = 0.000458973 (* 1 = 0.000458973 loss)
I0204 23:39:03.343091 10207 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 23:39:33.547188 10207 solver.cpp:237] Iteration 1330, loss = 0.000896301
I0204 23:39:33.547384 10207 solver.cpp:253]     Train net output #0: loss = 0.000896311 (* 1 = 0.000896311 loss)
I0204 23:39:33.547399 10207 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 23:40:03.909896 10207 solver.cpp:237] Iteration 1340, loss = 0.00199235
I0204 23:40:03.910110 10207 solver.cpp:253]     Train net output #0: loss = 0.00199236 (* 1 = 0.00199236 loss)
I0204 23:40:03.910125 10207 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 23:40:34.408718 10207 solver.cpp:237] Iteration 1350, loss = 0.000421167
I0204 23:40:34.408908 10207 solver.cpp:253]     Train net output #0: loss = 0.000421176 (* 1 = 0.000421176 loss)
I0204 23:40:34.408931 10207 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 23:41:04.882634 10207 solver.cpp:237] Iteration 1360, loss = 0.00149854
I0204 23:41:04.890233 10207 solver.cpp:253]     Train net output #0: loss = 0.00149855 (* 1 = 0.00149855 loss)
I0204 23:41:04.890265 10207 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 23:41:35.012908 10207 solver.cpp:237] Iteration 1370, loss = 0.00101993
I0204 23:41:35.013175 10207 solver.cpp:253]     Train net output #0: loss = 0.00101994 (* 1 = 0.00101994 loss)
I0204 23:41:35.013191 10207 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 23:42:04.904283 10207 solver.cpp:237] Iteration 1380, loss = 0.00219436
I0204 23:42:04.904367 10207 solver.cpp:253]     Train net output #0: loss = 0.00219437 (* 1 = 0.00219437 loss)
I0204 23:42:04.904379 10207 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 23:42:34.893551 10207 solver.cpp:237] Iteration 1390, loss = 0.00406664
I0204 23:42:34.893748 10207 solver.cpp:253]     Train net output #0: loss = 0.00406665 (* 1 = 0.00406665 loss)
I0204 23:42:34.893762 10207 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 23:43:02.051913 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1400.caffemodel
I0204 23:43:02.055495 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1400.solverstate
I0204 23:43:02.056895 10207 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 23:43:16.456800 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:43:16.456974 10207 solver.cpp:409]     Test net output #1: loss = 0.000255155 (* 1 = 0.000255155 loss)
I0204 23:43:19.439363 10207 solver.cpp:237] Iteration 1400, loss = 0.000921251
I0204 23:43:19.439421 10207 solver.cpp:253]     Train net output #0: loss = 0.000921252 (* 1 = 0.000921252 loss)
I0204 23:43:19.439434 10207 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 23:43:49.256816 10207 solver.cpp:237] Iteration 1410, loss = 0.000603151
I0204 23:43:49.257028 10207 solver.cpp:253]     Train net output #0: loss = 0.000603153 (* 1 = 0.000603153 loss)
I0204 23:43:49.257043 10207 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 23:44:18.835321 10207 solver.cpp:237] Iteration 1420, loss = 0.000116201
I0204 23:44:18.835384 10207 solver.cpp:253]     Train net output #0: loss = 0.000116203 (* 1 = 0.000116203 loss)
I0204 23:44:18.835397 10207 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 23:44:48.366657 10207 solver.cpp:237] Iteration 1430, loss = 0.000343179
I0204 23:44:48.366839 10207 solver.cpp:253]     Train net output #0: loss = 0.000343181 (* 1 = 0.000343181 loss)
I0204 23:44:48.366854 10207 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 23:45:17.971245 10207 solver.cpp:237] Iteration 1440, loss = 0.00117535
I0204 23:45:17.971312 10207 solver.cpp:253]     Train net output #0: loss = 0.00117535 (* 1 = 0.00117535 loss)
I0204 23:45:17.971323 10207 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 23:45:47.507586 10207 solver.cpp:237] Iteration 1450, loss = 0.00251093
I0204 23:45:47.507773 10207 solver.cpp:253]     Train net output #0: loss = 0.00251093 (* 1 = 0.00251093 loss)
I0204 23:45:47.507788 10207 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 23:46:17.178625 10207 solver.cpp:237] Iteration 1460, loss = 0.00770615
I0204 23:46:17.178685 10207 solver.cpp:253]     Train net output #0: loss = 0.00770615 (* 1 = 0.00770615 loss)
I0204 23:46:17.178697 10207 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 23:46:46.744303 10207 solver.cpp:237] Iteration 1470, loss = 0.0854241
I0204 23:46:46.744488 10207 solver.cpp:253]     Train net output #0: loss = 0.0854241 (* 1 = 0.0854241 loss)
I0204 23:46:46.744503 10207 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 23:47:16.385113 10207 solver.cpp:237] Iteration 1480, loss = 0.0012661
I0204 23:47:16.385185 10207 solver.cpp:253]     Train net output #0: loss = 0.0012661 (* 1 = 0.0012661 loss)
I0204 23:47:16.385198 10207 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 23:47:45.975023 10207 solver.cpp:237] Iteration 1490, loss = 0.0120384
I0204 23:47:45.975241 10207 solver.cpp:253]     Train net output #0: loss = 0.0120384 (* 1 = 0.0120384 loss)
I0204 23:47:45.975265 10207 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 23:48:12.719785 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1500.caffemodel
I0204 23:48:12.723480 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1500.solverstate
I0204 23:48:12.724871 10207 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 23:48:26.999007 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:48:26.999197 10207 solver.cpp:409]     Test net output #1: loss = 7.6286e-05 (* 1 = 7.6286e-05 loss)
I0204 23:48:29.984246 10207 solver.cpp:237] Iteration 1500, loss = 0.000543623
I0204 23:48:29.984300 10207 solver.cpp:253]     Train net output #0: loss = 0.000543626 (* 1 = 0.000543626 loss)
I0204 23:48:29.984313 10207 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 23:48:59.986942 10207 solver.cpp:237] Iteration 1510, loss = 0.000143519
I0204 23:48:59.987138 10207 solver.cpp:253]     Train net output #0: loss = 0.000143522 (* 1 = 0.000143522 loss)
I0204 23:48:59.987151 10207 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 23:49:30.045522 10207 solver.cpp:237] Iteration 1520, loss = 0.00159026
I0204 23:49:30.045718 10207 solver.cpp:253]     Train net output #0: loss = 0.00159026 (* 1 = 0.00159026 loss)
I0204 23:49:30.045733 10207 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 23:50:00.198745 10207 solver.cpp:237] Iteration 1530, loss = 0.00920928
I0204 23:50:00.198956 10207 solver.cpp:253]     Train net output #0: loss = 0.00920928 (* 1 = 0.00920928 loss)
I0204 23:50:00.198971 10207 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 23:50:30.363654 10207 solver.cpp:237] Iteration 1540, loss = 0.0449679
I0204 23:50:30.363847 10207 solver.cpp:253]     Train net output #0: loss = 0.0449679 (* 1 = 0.0449679 loss)
I0204 23:50:30.363862 10207 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 23:51:00.621966 10207 solver.cpp:237] Iteration 1550, loss = 0.00165769
I0204 23:51:00.622150 10207 solver.cpp:253]     Train net output #0: loss = 0.00165769 (* 1 = 0.00165769 loss)
I0204 23:51:00.622165 10207 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 23:51:30.815238 10207 solver.cpp:237] Iteration 1560, loss = 0.00165346
I0204 23:51:30.815423 10207 solver.cpp:253]     Train net output #0: loss = 0.00165346 (* 1 = 0.00165346 loss)
I0204 23:51:30.815438 10207 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 23:52:01.059231 10207 solver.cpp:237] Iteration 1570, loss = 0.00329909
I0204 23:52:01.059417 10207 solver.cpp:253]     Train net output #0: loss = 0.00329909 (* 1 = 0.00329909 loss)
I0204 23:52:01.059430 10207 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 23:52:31.276610 10207 solver.cpp:237] Iteration 1580, loss = 0.000388545
I0204 23:52:31.276808 10207 solver.cpp:253]     Train net output #0: loss = 0.000388547 (* 1 = 0.000388547 loss)
I0204 23:52:31.276823 10207 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 23:53:01.605648 10207 solver.cpp:237] Iteration 1590, loss = 0.000728091
I0204 23:53:01.605837 10207 solver.cpp:253]     Train net output #0: loss = 0.000728094 (* 1 = 0.000728094 loss)
I0204 23:53:01.605852 10207 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 23:53:28.701050 10207 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1600.caffemodel
I0204 23:53:28.704589 10207 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed142/snaps/snap__iter_1600.solverstate
I0204 23:53:30.151388 10207 solver.cpp:321] Iteration 1600, loss = 0.000401909
I0204 23:53:30.151434 10207 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 23:53:44.561733 10207 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 23:53:44.561957 10207 solver.cpp:409]     Test net output #1: loss = 0.000179277 (* 1 = 0.000179277 loss)
I0204 23:53:44.561969 10207 solver.cpp:326] Optimization Done.
I0204 23:53:44.561975 10207 caffe.cpp:215] Optimization Done.
