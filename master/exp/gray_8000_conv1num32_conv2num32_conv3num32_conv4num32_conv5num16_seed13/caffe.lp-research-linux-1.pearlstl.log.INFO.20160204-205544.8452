Log file created at: 2016/02/04 20:55:44
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 20:55:44.267717  8452 caffe.cpp:177] Use CPU.
I0204 20:55:44.268582  8452 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap_"
solver_mode: CPU
random_seed: 13
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/train_val.prototxt"
I0204 20:55:44.268751  8452 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/train_val.prototxt
I0204 20:55:44.269376  8452 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 20:55:44.269412  8452 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 20:55:44.269664  8452 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 20:55:44.269804  8452 layer_factory.hpp:77] Creating layer data
I0204 20:55:44.269996  8452 net.cpp:106] Creating Layer data
I0204 20:55:44.270015  8452 net.cpp:411] data -> data
I0204 20:55:44.270094  8452 net.cpp:411] data -> label
I0204 20:55:44.270119  8452 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 20:55:44.270273  8453 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 20:55:44.271214  8452 data_layer.cpp:41] output data size: 100,1,227,227
I0204 20:55:44.304268  8452 net.cpp:150] Setting up data
I0204 20:55:44.304299  8452 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 20:55:44.304307  8452 net.cpp:157] Top shape: 100 (100)
I0204 20:55:44.304314  8452 net.cpp:165] Memory required for data: 20612000
I0204 20:55:44.304332  8452 layer_factory.hpp:77] Creating layer conv1
I0204 20:55:44.304376  8452 net.cpp:106] Creating Layer conv1
I0204 20:55:44.304388  8452 net.cpp:454] conv1 <- data
I0204 20:55:44.304407  8452 net.cpp:411] conv1 -> conv1
I0204 20:55:44.304535  8452 net.cpp:150] Setting up conv1
I0204 20:55:44.304548  8452 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 20:55:44.304553  8452 net.cpp:165] Memory required for data: 59332000
I0204 20:55:44.304570  8452 layer_factory.hpp:77] Creating layer relu1
I0204 20:55:44.304582  8452 net.cpp:106] Creating Layer relu1
I0204 20:55:44.304589  8452 net.cpp:454] relu1 <- conv1
I0204 20:55:44.304597  8452 net.cpp:397] relu1 -> conv1 (in-place)
I0204 20:55:44.304610  8452 net.cpp:150] Setting up relu1
I0204 20:55:44.304618  8452 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 20:55:44.304623  8452 net.cpp:165] Memory required for data: 98052000
I0204 20:55:44.304628  8452 layer_factory.hpp:77] Creating layer pool1
I0204 20:55:44.304641  8452 net.cpp:106] Creating Layer pool1
I0204 20:55:44.304646  8452 net.cpp:454] pool1 <- conv1
I0204 20:55:44.304656  8452 net.cpp:411] pool1 -> pool1
I0204 20:55:44.304680  8452 net.cpp:150] Setting up pool1
I0204 20:55:44.304689  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.304694  8452 net.cpp:165] Memory required for data: 107383200
I0204 20:55:44.304700  8452 layer_factory.hpp:77] Creating layer norm1
I0204 20:55:44.304734  8452 net.cpp:106] Creating Layer norm1
I0204 20:55:44.304740  8452 net.cpp:454] norm1 <- pool1
I0204 20:55:44.304749  8452 net.cpp:411] norm1 -> norm1
I0204 20:55:44.304769  8452 net.cpp:150] Setting up norm1
I0204 20:55:44.304779  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.304783  8452 net.cpp:165] Memory required for data: 116714400
I0204 20:55:44.304788  8452 layer_factory.hpp:77] Creating layer conv2
I0204 20:55:44.304800  8452 net.cpp:106] Creating Layer conv2
I0204 20:55:44.304805  8452 net.cpp:454] conv2 <- norm1
I0204 20:55:44.304814  8452 net.cpp:411] conv2 -> conv2
I0204 20:55:44.304946  8452 net.cpp:150] Setting up conv2
I0204 20:55:44.304955  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.304960  8452 net.cpp:165] Memory required for data: 126045600
I0204 20:55:44.304978  8452 layer_factory.hpp:77] Creating layer relu2
I0204 20:55:44.304987  8452 net.cpp:106] Creating Layer relu2
I0204 20:55:44.304993  8452 net.cpp:454] relu2 <- conv2
I0204 20:55:44.305011  8452 net.cpp:397] relu2 -> conv2 (in-place)
I0204 20:55:44.305022  8452 net.cpp:150] Setting up relu2
I0204 20:55:44.305029  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.305034  8452 net.cpp:165] Memory required for data: 135376800
I0204 20:55:44.305040  8452 layer_factory.hpp:77] Creating layer pool2
I0204 20:55:44.305052  8452 net.cpp:106] Creating Layer pool2
I0204 20:55:44.305058  8452 net.cpp:454] pool2 <- conv2
I0204 20:55:44.305065  8452 net.cpp:411] pool2 -> pool2
I0204 20:55:44.305076  8452 net.cpp:150] Setting up pool2
I0204 20:55:44.305084  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305089  8452 net.cpp:165] Memory required for data: 137540000
I0204 20:55:44.305094  8452 layer_factory.hpp:77] Creating layer norm2
I0204 20:55:44.305104  8452 net.cpp:106] Creating Layer norm2
I0204 20:55:44.305110  8452 net.cpp:454] norm2 <- pool2
I0204 20:55:44.305120  8452 net.cpp:411] norm2 -> norm2
I0204 20:55:44.305130  8452 net.cpp:150] Setting up norm2
I0204 20:55:44.305137  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305142  8452 net.cpp:165] Memory required for data: 139703200
I0204 20:55:44.305148  8452 layer_factory.hpp:77] Creating layer conv3
I0204 20:55:44.305160  8452 net.cpp:106] Creating Layer conv3
I0204 20:55:44.305165  8452 net.cpp:454] conv3 <- norm2
I0204 20:55:44.305174  8452 net.cpp:411] conv3 -> conv3
I0204 20:55:44.305285  8452 net.cpp:150] Setting up conv3
I0204 20:55:44.305295  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305300  8452 net.cpp:165] Memory required for data: 141866400
I0204 20:55:44.305313  8452 layer_factory.hpp:77] Creating layer relu3
I0204 20:55:44.305322  8452 net.cpp:106] Creating Layer relu3
I0204 20:55:44.305327  8452 net.cpp:454] relu3 <- conv3
I0204 20:55:44.305338  8452 net.cpp:397] relu3 -> conv3 (in-place)
I0204 20:55:44.305347  8452 net.cpp:150] Setting up relu3
I0204 20:55:44.305354  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305359  8452 net.cpp:165] Memory required for data: 144029600
I0204 20:55:44.305364  8452 layer_factory.hpp:77] Creating layer conv4
I0204 20:55:44.305374  8452 net.cpp:106] Creating Layer conv4
I0204 20:55:44.305380  8452 net.cpp:454] conv4 <- conv3
I0204 20:55:44.305390  8452 net.cpp:411] conv4 -> conv4
I0204 20:55:44.305475  8452 net.cpp:150] Setting up conv4
I0204 20:55:44.305485  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305490  8452 net.cpp:165] Memory required for data: 146192800
I0204 20:55:44.305497  8452 layer_factory.hpp:77] Creating layer relu4
I0204 20:55:44.305505  8452 net.cpp:106] Creating Layer relu4
I0204 20:55:44.305511  8452 net.cpp:454] relu4 <- conv4
I0204 20:55:44.305518  8452 net.cpp:397] relu4 -> conv4 (in-place)
I0204 20:55:44.305527  8452 net.cpp:150] Setting up relu4
I0204 20:55:44.305533  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.305538  8452 net.cpp:165] Memory required for data: 148356000
I0204 20:55:44.305548  8452 layer_factory.hpp:77] Creating layer conv5
I0204 20:55:44.305567  8452 net.cpp:106] Creating Layer conv5
I0204 20:55:44.305573  8452 net.cpp:454] conv5 <- conv4
I0204 20:55:44.305583  8452 net.cpp:411] conv5 -> conv5
I0204 20:55:44.305630  8452 net.cpp:150] Setting up conv5
I0204 20:55:44.305639  8452 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 20:55:44.305644  8452 net.cpp:165] Memory required for data: 149437600
I0204 20:55:44.305655  8452 layer_factory.hpp:77] Creating layer relu5
I0204 20:55:44.305665  8452 net.cpp:106] Creating Layer relu5
I0204 20:55:44.305670  8452 net.cpp:454] relu5 <- conv5
I0204 20:55:44.305678  8452 net.cpp:397] relu5 -> conv5 (in-place)
I0204 20:55:44.305686  8452 net.cpp:150] Setting up relu5
I0204 20:55:44.305693  8452 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 20:55:44.305698  8452 net.cpp:165] Memory required for data: 150519200
I0204 20:55:44.305703  8452 layer_factory.hpp:77] Creating layer pool5
I0204 20:55:44.305711  8452 net.cpp:106] Creating Layer pool5
I0204 20:55:44.305719  8452 net.cpp:454] pool5 <- conv5
I0204 20:55:44.305730  8452 net.cpp:411] pool5 -> pool5
I0204 20:55:44.305742  8452 net.cpp:150] Setting up pool5
I0204 20:55:44.305748  8452 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 20:55:44.305753  8452 net.cpp:165] Memory required for data: 150749600
I0204 20:55:44.305758  8452 layer_factory.hpp:77] Creating layer fc6
I0204 20:55:44.305778  8452 net.cpp:106] Creating Layer fc6
I0204 20:55:44.305784  8452 net.cpp:454] fc6 <- pool5
I0204 20:55:44.305793  8452 net.cpp:411] fc6 -> fc6
I0204 20:55:44.307417  8452 net.cpp:150] Setting up fc6
I0204 20:55:44.307430  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.307435  8452 net.cpp:165] Memory required for data: 150852000
I0204 20:55:44.307443  8452 layer_factory.hpp:77] Creating layer relu6
I0204 20:55:44.307456  8452 net.cpp:106] Creating Layer relu6
I0204 20:55:44.307461  8452 net.cpp:454] relu6 <- fc6
I0204 20:55:44.307468  8452 net.cpp:397] relu6 -> fc6 (in-place)
I0204 20:55:44.307478  8452 net.cpp:150] Setting up relu6
I0204 20:55:44.307485  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.307490  8452 net.cpp:165] Memory required for data: 150954400
I0204 20:55:44.307497  8452 layer_factory.hpp:77] Creating layer drop6
I0204 20:55:44.307507  8452 net.cpp:106] Creating Layer drop6
I0204 20:55:44.307513  8452 net.cpp:454] drop6 <- fc6
I0204 20:55:44.307520  8452 net.cpp:397] drop6 -> fc6 (in-place)
I0204 20:55:44.307539  8452 net.cpp:150] Setting up drop6
I0204 20:55:44.307546  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.307551  8452 net.cpp:165] Memory required for data: 151056800
I0204 20:55:44.307557  8452 layer_factory.hpp:77] Creating layer fc7
I0204 20:55:44.307566  8452 net.cpp:106] Creating Layer fc7
I0204 20:55:44.307571  8452 net.cpp:454] fc7 <- fc6
I0204 20:55:44.307582  8452 net.cpp:411] fc7 -> fc7
I0204 20:55:44.308277  8452 net.cpp:150] Setting up fc7
I0204 20:55:44.308290  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.308296  8452 net.cpp:165] Memory required for data: 151159200
I0204 20:55:44.308305  8452 layer_factory.hpp:77] Creating layer relu7
I0204 20:55:44.308313  8452 net.cpp:106] Creating Layer relu7
I0204 20:55:44.308320  8452 net.cpp:454] relu7 <- fc7
I0204 20:55:44.308329  8452 net.cpp:397] relu7 -> fc7 (in-place)
I0204 20:55:44.308338  8452 net.cpp:150] Setting up relu7
I0204 20:55:44.308346  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.308351  8452 net.cpp:165] Memory required for data: 151261600
I0204 20:55:44.308356  8452 layer_factory.hpp:77] Creating layer drop7
I0204 20:55:44.308363  8452 net.cpp:106] Creating Layer drop7
I0204 20:55:44.308369  8452 net.cpp:454] drop7 <- fc7
I0204 20:55:44.308378  8452 net.cpp:397] drop7 -> fc7 (in-place)
I0204 20:55:44.308389  8452 net.cpp:150] Setting up drop7
I0204 20:55:44.308395  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.308400  8452 net.cpp:165] Memory required for data: 151364000
I0204 20:55:44.308406  8452 layer_factory.hpp:77] Creating layer fc8
I0204 20:55:44.308420  8452 net.cpp:106] Creating Layer fc8
I0204 20:55:44.308434  8452 net.cpp:454] fc8 <- fc7
I0204 20:55:44.308445  8452 net.cpp:411] fc8 -> fc8
I0204 20:55:44.308470  8452 net.cpp:150] Setting up fc8
I0204 20:55:44.308476  8452 net.cpp:157] Top shape: 100 2 (200)
I0204 20:55:44.308481  8452 net.cpp:165] Memory required for data: 151364800
I0204 20:55:44.308490  8452 layer_factory.hpp:77] Creating layer loss
I0204 20:55:44.308501  8452 net.cpp:106] Creating Layer loss
I0204 20:55:44.308506  8452 net.cpp:454] loss <- fc8
I0204 20:55:44.308513  8452 net.cpp:454] loss <- label
I0204 20:55:44.308522  8452 net.cpp:411] loss -> loss
I0204 20:55:44.308537  8452 layer_factory.hpp:77] Creating layer loss
I0204 20:55:44.308565  8452 net.cpp:150] Setting up loss
I0204 20:55:44.308573  8452 net.cpp:157] Top shape: (1)
I0204 20:55:44.308578  8452 net.cpp:160]     with loss weight 1
I0204 20:55:44.308606  8452 net.cpp:165] Memory required for data: 151364804
I0204 20:55:44.308614  8452 net.cpp:226] loss needs backward computation.
I0204 20:55:44.308620  8452 net.cpp:226] fc8 needs backward computation.
I0204 20:55:44.308626  8452 net.cpp:226] drop7 needs backward computation.
I0204 20:55:44.308631  8452 net.cpp:226] relu7 needs backward computation.
I0204 20:55:44.308636  8452 net.cpp:226] fc7 needs backward computation.
I0204 20:55:44.308642  8452 net.cpp:226] drop6 needs backward computation.
I0204 20:55:44.308647  8452 net.cpp:226] relu6 needs backward computation.
I0204 20:55:44.308652  8452 net.cpp:226] fc6 needs backward computation.
I0204 20:55:44.308658  8452 net.cpp:226] pool5 needs backward computation.
I0204 20:55:44.308663  8452 net.cpp:226] relu5 needs backward computation.
I0204 20:55:44.308668  8452 net.cpp:226] conv5 needs backward computation.
I0204 20:55:44.308675  8452 net.cpp:226] relu4 needs backward computation.
I0204 20:55:44.308679  8452 net.cpp:226] conv4 needs backward computation.
I0204 20:55:44.308687  8452 net.cpp:226] relu3 needs backward computation.
I0204 20:55:44.308692  8452 net.cpp:226] conv3 needs backward computation.
I0204 20:55:44.308701  8452 net.cpp:226] norm2 needs backward computation.
I0204 20:55:44.308707  8452 net.cpp:226] pool2 needs backward computation.
I0204 20:55:44.308713  8452 net.cpp:226] relu2 needs backward computation.
I0204 20:55:44.308718  8452 net.cpp:226] conv2 needs backward computation.
I0204 20:55:44.308723  8452 net.cpp:226] norm1 needs backward computation.
I0204 20:55:44.308729  8452 net.cpp:226] pool1 needs backward computation.
I0204 20:55:44.308735  8452 net.cpp:226] relu1 needs backward computation.
I0204 20:55:44.308740  8452 net.cpp:226] conv1 needs backward computation.
I0204 20:55:44.308747  8452 net.cpp:228] data does not need backward computation.
I0204 20:55:44.308753  8452 net.cpp:270] This network produces output loss
I0204 20:55:44.308779  8452 net.cpp:283] Network initialization done.
I0204 20:55:44.309545  8452 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/train_val.prototxt
I0204 20:55:44.309602  8452 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 20:55:44.309896  8452 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 20:55:44.310081  8452 layer_factory.hpp:77] Creating layer data
I0204 20:55:44.310243  8452 net.cpp:106] Creating Layer data
I0204 20:55:44.310272  8452 net.cpp:411] data -> data
I0204 20:55:44.310287  8452 net.cpp:411] data -> label
I0204 20:55:44.310300  8452 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 20:55:44.310467  8456 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 20:55:44.311202  8452 data_layer.cpp:41] output data size: 100,1,227,227
I0204 20:55:44.344902  8452 net.cpp:150] Setting up data
I0204 20:55:44.344936  8452 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 20:55:44.344944  8452 net.cpp:157] Top shape: 100 (100)
I0204 20:55:44.344949  8452 net.cpp:165] Memory required for data: 20612000
I0204 20:55:44.344960  8452 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 20:55:44.344995  8452 net.cpp:106] Creating Layer label_data_1_split
I0204 20:55:44.345001  8452 net.cpp:454] label_data_1_split <- label
I0204 20:55:44.345016  8452 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 20:55:44.345032  8452 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 20:55:44.345046  8452 net.cpp:150] Setting up label_data_1_split
I0204 20:55:44.345053  8452 net.cpp:157] Top shape: 100 (100)
I0204 20:55:44.345059  8452 net.cpp:157] Top shape: 100 (100)
I0204 20:55:44.345065  8452 net.cpp:165] Memory required for data: 20612800
I0204 20:55:44.345073  8452 layer_factory.hpp:77] Creating layer conv1
I0204 20:55:44.345088  8452 net.cpp:106] Creating Layer conv1
I0204 20:55:44.345095  8452 net.cpp:454] conv1 <- data
I0204 20:55:44.345105  8452 net.cpp:411] conv1 -> conv1
I0204 20:55:44.345180  8452 net.cpp:150] Setting up conv1
I0204 20:55:44.345191  8452 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 20:55:44.345196  8452 net.cpp:165] Memory required for data: 59332800
I0204 20:55:44.345211  8452 layer_factory.hpp:77] Creating layer relu1
I0204 20:55:44.345221  8452 net.cpp:106] Creating Layer relu1
I0204 20:55:44.345228  8452 net.cpp:454] relu1 <- conv1
I0204 20:55:44.345237  8452 net.cpp:397] relu1 -> conv1 (in-place)
I0204 20:55:44.345247  8452 net.cpp:150] Setting up relu1
I0204 20:55:44.345254  8452 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 20:55:44.345259  8452 net.cpp:165] Memory required for data: 98052800
I0204 20:55:44.345264  8452 layer_factory.hpp:77] Creating layer pool1
I0204 20:55:44.345275  8452 net.cpp:106] Creating Layer pool1
I0204 20:55:44.345280  8452 net.cpp:454] pool1 <- conv1
I0204 20:55:44.345289  8452 net.cpp:411] pool1 -> pool1
I0204 20:55:44.345304  8452 net.cpp:150] Setting up pool1
I0204 20:55:44.345310  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.345315  8452 net.cpp:165] Memory required for data: 107384000
I0204 20:55:44.345321  8452 layer_factory.hpp:77] Creating layer norm1
I0204 20:55:44.345334  8452 net.cpp:106] Creating Layer norm1
I0204 20:55:44.345340  8452 net.cpp:454] norm1 <- pool1
I0204 20:55:44.345348  8452 net.cpp:411] norm1 -> norm1
I0204 20:55:44.345360  8452 net.cpp:150] Setting up norm1
I0204 20:55:44.345369  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.345376  8452 net.cpp:165] Memory required for data: 116715200
I0204 20:55:44.345381  8452 layer_factory.hpp:77] Creating layer conv2
I0204 20:55:44.345391  8452 net.cpp:106] Creating Layer conv2
I0204 20:55:44.345397  8452 net.cpp:454] conv2 <- norm1
I0204 20:55:44.345407  8452 net.cpp:411] conv2 -> conv2
I0204 20:55:44.345540  8452 net.cpp:150] Setting up conv2
I0204 20:55:44.345548  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.345553  8452 net.cpp:165] Memory required for data: 126046400
I0204 20:55:44.345566  8452 layer_factory.hpp:77] Creating layer relu2
I0204 20:55:44.345574  8452 net.cpp:106] Creating Layer relu2
I0204 20:55:44.345580  8452 net.cpp:454] relu2 <- conv2
I0204 20:55:44.345598  8452 net.cpp:397] relu2 -> conv2 (in-place)
I0204 20:55:44.345620  8452 net.cpp:150] Setting up relu2
I0204 20:55:44.345629  8452 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 20:55:44.345634  8452 net.cpp:165] Memory required for data: 135377600
I0204 20:55:44.345639  8452 layer_factory.hpp:77] Creating layer pool2
I0204 20:55:44.345651  8452 net.cpp:106] Creating Layer pool2
I0204 20:55:44.345657  8452 net.cpp:454] pool2 <- conv2
I0204 20:55:44.345665  8452 net.cpp:411] pool2 -> pool2
I0204 20:55:44.345679  8452 net.cpp:150] Setting up pool2
I0204 20:55:44.345686  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.345691  8452 net.cpp:165] Memory required for data: 137540800
I0204 20:55:44.345696  8452 layer_factory.hpp:77] Creating layer norm2
I0204 20:55:44.345705  8452 net.cpp:106] Creating Layer norm2
I0204 20:55:44.345711  8452 net.cpp:454] norm2 <- pool2
I0204 20:55:44.345718  8452 net.cpp:411] norm2 -> norm2
I0204 20:55:44.345728  8452 net.cpp:150] Setting up norm2
I0204 20:55:44.345734  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.345739  8452 net.cpp:165] Memory required for data: 139704000
I0204 20:55:44.345746  8452 layer_factory.hpp:77] Creating layer conv3
I0204 20:55:44.345757  8452 net.cpp:106] Creating Layer conv3
I0204 20:55:44.345762  8452 net.cpp:454] conv3 <- norm2
I0204 20:55:44.345773  8452 net.cpp:411] conv3 -> conv3
I0204 20:55:44.345873  8452 net.cpp:150] Setting up conv3
I0204 20:55:44.345882  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.345887  8452 net.cpp:165] Memory required for data: 141867200
I0204 20:55:44.345897  8452 layer_factory.hpp:77] Creating layer relu3
I0204 20:55:44.345906  8452 net.cpp:106] Creating Layer relu3
I0204 20:55:44.345911  8452 net.cpp:454] relu3 <- conv3
I0204 20:55:44.345919  8452 net.cpp:397] relu3 -> conv3 (in-place)
I0204 20:55:44.345931  8452 net.cpp:150] Setting up relu3
I0204 20:55:44.345940  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.345945  8452 net.cpp:165] Memory required for data: 144030400
I0204 20:55:44.345950  8452 layer_factory.hpp:77] Creating layer conv4
I0204 20:55:44.345963  8452 net.cpp:106] Creating Layer conv4
I0204 20:55:44.345974  8452 net.cpp:454] conv4 <- conv3
I0204 20:55:44.345983  8452 net.cpp:411] conv4 -> conv4
I0204 20:55:44.346045  8452 net.cpp:150] Setting up conv4
I0204 20:55:44.346052  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.346065  8452 net.cpp:165] Memory required for data: 146193600
I0204 20:55:44.346072  8452 layer_factory.hpp:77] Creating layer relu4
I0204 20:55:44.346081  8452 net.cpp:106] Creating Layer relu4
I0204 20:55:44.346086  8452 net.cpp:454] relu4 <- conv4
I0204 20:55:44.346094  8452 net.cpp:397] relu4 -> conv4 (in-place)
I0204 20:55:44.346107  8452 net.cpp:150] Setting up relu4
I0204 20:55:44.346113  8452 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 20:55:44.346118  8452 net.cpp:165] Memory required for data: 148356800
I0204 20:55:44.346124  8452 layer_factory.hpp:77] Creating layer conv5
I0204 20:55:44.346135  8452 net.cpp:106] Creating Layer conv5
I0204 20:55:44.346143  8452 net.cpp:454] conv5 <- conv4
I0204 20:55:44.346153  8452 net.cpp:411] conv5 -> conv5
I0204 20:55:44.346192  8452 net.cpp:150] Setting up conv5
I0204 20:55:44.346200  8452 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 20:55:44.346205  8452 net.cpp:165] Memory required for data: 149438400
I0204 20:55:44.346216  8452 layer_factory.hpp:77] Creating layer relu5
I0204 20:55:44.346225  8452 net.cpp:106] Creating Layer relu5
I0204 20:55:44.346231  8452 net.cpp:454] relu5 <- conv5
I0204 20:55:44.346238  8452 net.cpp:397] relu5 -> conv5 (in-place)
I0204 20:55:44.346247  8452 net.cpp:150] Setting up relu5
I0204 20:55:44.346253  8452 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 20:55:44.346259  8452 net.cpp:165] Memory required for data: 150520000
I0204 20:55:44.346267  8452 layer_factory.hpp:77] Creating layer pool5
I0204 20:55:44.346278  8452 net.cpp:106] Creating Layer pool5
I0204 20:55:44.346288  8452 net.cpp:454] pool5 <- conv5
I0204 20:55:44.346307  8452 net.cpp:411] pool5 -> pool5
I0204 20:55:44.346321  8452 net.cpp:150] Setting up pool5
I0204 20:55:44.346328  8452 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 20:55:44.346333  8452 net.cpp:165] Memory required for data: 150750400
I0204 20:55:44.346339  8452 layer_factory.hpp:77] Creating layer fc6
I0204 20:55:44.346351  8452 net.cpp:106] Creating Layer fc6
I0204 20:55:44.346356  8452 net.cpp:454] fc6 <- pool5
I0204 20:55:44.346366  8452 net.cpp:411] fc6 -> fc6
I0204 20:55:44.348028  8452 net.cpp:150] Setting up fc6
I0204 20:55:44.348042  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.348050  8452 net.cpp:165] Memory required for data: 150852800
I0204 20:55:44.348059  8452 layer_factory.hpp:77] Creating layer relu6
I0204 20:55:44.348068  8452 net.cpp:106] Creating Layer relu6
I0204 20:55:44.348074  8452 net.cpp:454] relu6 <- fc6
I0204 20:55:44.348083  8452 net.cpp:397] relu6 -> fc6 (in-place)
I0204 20:55:44.348093  8452 net.cpp:150] Setting up relu6
I0204 20:55:44.348098  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.348104  8452 net.cpp:165] Memory required for data: 150955200
I0204 20:55:44.348109  8452 layer_factory.hpp:77] Creating layer drop6
I0204 20:55:44.348119  8452 net.cpp:106] Creating Layer drop6
I0204 20:55:44.348125  8452 net.cpp:454] drop6 <- fc6
I0204 20:55:44.348134  8452 net.cpp:397] drop6 -> fc6 (in-place)
I0204 20:55:44.348145  8452 net.cpp:150] Setting up drop6
I0204 20:55:44.348155  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.348160  8452 net.cpp:165] Memory required for data: 151057600
I0204 20:55:44.348165  8452 layer_factory.hpp:77] Creating layer fc7
I0204 20:55:44.348176  8452 net.cpp:106] Creating Layer fc7
I0204 20:55:44.348181  8452 net.cpp:454] fc7 <- fc6
I0204 20:55:44.348189  8452 net.cpp:411] fc7 -> fc7
I0204 20:55:44.348881  8452 net.cpp:150] Setting up fc7
I0204 20:55:44.348891  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.348896  8452 net.cpp:165] Memory required for data: 151160000
I0204 20:55:44.348906  8452 layer_factory.hpp:77] Creating layer relu7
I0204 20:55:44.348914  8452 net.cpp:106] Creating Layer relu7
I0204 20:55:44.348920  8452 net.cpp:454] relu7 <- fc7
I0204 20:55:44.348930  8452 net.cpp:397] relu7 -> fc7 (in-place)
I0204 20:55:44.348939  8452 net.cpp:150] Setting up relu7
I0204 20:55:44.348947  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.348951  8452 net.cpp:165] Memory required for data: 151262400
I0204 20:55:44.348956  8452 layer_factory.hpp:77] Creating layer drop7
I0204 20:55:44.348970  8452 net.cpp:106] Creating Layer drop7
I0204 20:55:44.348979  8452 net.cpp:454] drop7 <- fc7
I0204 20:55:44.348990  8452 net.cpp:397] drop7 -> fc7 (in-place)
I0204 20:55:44.349000  8452 net.cpp:150] Setting up drop7
I0204 20:55:44.349007  8452 net.cpp:157] Top shape: 100 256 (25600)
I0204 20:55:44.349012  8452 net.cpp:165] Memory required for data: 151364800
I0204 20:55:44.349019  8452 layer_factory.hpp:77] Creating layer fc8
I0204 20:55:44.349028  8452 net.cpp:106] Creating Layer fc8
I0204 20:55:44.349035  8452 net.cpp:454] fc8 <- fc7
I0204 20:55:44.349041  8452 net.cpp:411] fc8 -> fc8
I0204 20:55:44.349077  8452 net.cpp:150] Setting up fc8
I0204 20:55:44.349087  8452 net.cpp:157] Top shape: 100 2 (200)
I0204 20:55:44.349093  8452 net.cpp:165] Memory required for data: 151365600
I0204 20:55:44.349102  8452 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 20:55:44.349133  8452 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 20:55:44.349140  8452 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 20:55:44.349148  8452 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 20:55:44.349164  8452 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 20:55:44.349174  8452 net.cpp:150] Setting up fc8_fc8_0_split
I0204 20:55:44.349180  8452 net.cpp:157] Top shape: 100 2 (200)
I0204 20:55:44.349186  8452 net.cpp:157] Top shape: 100 2 (200)
I0204 20:55:44.349190  8452 net.cpp:165] Memory required for data: 151367200
I0204 20:55:44.349196  8452 layer_factory.hpp:77] Creating layer accuracy
I0204 20:55:44.349220  8452 net.cpp:106] Creating Layer accuracy
I0204 20:55:44.349234  8452 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 20:55:44.349241  8452 net.cpp:454] accuracy <- label_data_1_split_0
I0204 20:55:44.349249  8452 net.cpp:411] accuracy -> accuracy
I0204 20:55:44.349261  8452 net.cpp:150] Setting up accuracy
I0204 20:55:44.349269  8452 net.cpp:157] Top shape: (1)
I0204 20:55:44.349277  8452 net.cpp:165] Memory required for data: 151367204
I0204 20:55:44.349282  8452 layer_factory.hpp:77] Creating layer loss
I0204 20:55:44.349293  8452 net.cpp:106] Creating Layer loss
I0204 20:55:44.349299  8452 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 20:55:44.349306  8452 net.cpp:454] loss <- label_data_1_split_1
I0204 20:55:44.349314  8452 net.cpp:411] loss -> loss
I0204 20:55:44.349325  8452 layer_factory.hpp:77] Creating layer loss
I0204 20:55:44.349345  8452 net.cpp:150] Setting up loss
I0204 20:55:44.349352  8452 net.cpp:157] Top shape: (1)
I0204 20:55:44.349357  8452 net.cpp:160]     with loss weight 1
I0204 20:55:44.349371  8452 net.cpp:165] Memory required for data: 151367208
I0204 20:55:44.349380  8452 net.cpp:226] loss needs backward computation.
I0204 20:55:44.349386  8452 net.cpp:228] accuracy does not need backward computation.
I0204 20:55:44.349392  8452 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 20:55:44.349398  8452 net.cpp:226] fc8 needs backward computation.
I0204 20:55:44.349403  8452 net.cpp:226] drop7 needs backward computation.
I0204 20:55:44.349409  8452 net.cpp:226] relu7 needs backward computation.
I0204 20:55:44.349414  8452 net.cpp:226] fc7 needs backward computation.
I0204 20:55:44.349419  8452 net.cpp:226] drop6 needs backward computation.
I0204 20:55:44.349424  8452 net.cpp:226] relu6 needs backward computation.
I0204 20:55:44.349432  8452 net.cpp:226] fc6 needs backward computation.
I0204 20:55:44.349438  8452 net.cpp:226] pool5 needs backward computation.
I0204 20:55:44.349444  8452 net.cpp:226] relu5 needs backward computation.
I0204 20:55:44.349449  8452 net.cpp:226] conv5 needs backward computation.
I0204 20:55:44.349455  8452 net.cpp:226] relu4 needs backward computation.
I0204 20:55:44.349460  8452 net.cpp:226] conv4 needs backward computation.
I0204 20:55:44.349467  8452 net.cpp:226] relu3 needs backward computation.
I0204 20:55:44.349472  8452 net.cpp:226] conv3 needs backward computation.
I0204 20:55:44.349478  8452 net.cpp:226] norm2 needs backward computation.
I0204 20:55:44.349483  8452 net.cpp:226] pool2 needs backward computation.
I0204 20:55:44.349489  8452 net.cpp:226] relu2 needs backward computation.
I0204 20:55:44.349495  8452 net.cpp:226] conv2 needs backward computation.
I0204 20:55:44.349501  8452 net.cpp:226] norm1 needs backward computation.
I0204 20:55:44.349506  8452 net.cpp:226] pool1 needs backward computation.
I0204 20:55:44.349512  8452 net.cpp:226] relu1 needs backward computation.
I0204 20:55:44.349519  8452 net.cpp:226] conv1 needs backward computation.
I0204 20:55:44.349526  8452 net.cpp:228] label_data_1_split does not need backward computation.
I0204 20:55:44.349532  8452 net.cpp:228] data does not need backward computation.
I0204 20:55:44.349540  8452 net.cpp:270] This network produces output accuracy
I0204 20:55:44.349546  8452 net.cpp:270] This network produces output loss
I0204 20:55:44.349578  8452 net.cpp:283] Network initialization done.
I0204 20:55:44.349690  8452 solver.cpp:60] Solver scaffolding done.
I0204 20:55:44.349746  8452 caffe.cpp:212] Starting Optimization
I0204 20:55:44.349753  8452 solver.cpp:288] Solving CaffeNet
I0204 20:55:44.349758  8452 solver.cpp:289] Learning Rate Policy: step
I0204 20:55:44.350589  8452 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 20:55:44.350733  8452 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 20:55:51.728634  8452 solver.cpp:409]     Test net output #0: accuracy = 0.521
I0204 20:55:51.728691  8452 solver.cpp:409]     Test net output #1: loss = 1.09058 (* 1 = 1.09058 loss)
I0204 20:55:53.400382  8452 solver.cpp:237] Iteration 0, loss = 9.65635
I0204 20:55:53.400450  8452 solver.cpp:253]     Train net output #0: loss = 9.65635 (* 1 = 9.65635 loss)
I0204 20:55:53.400463  8452 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 20:56:08.850000  8452 solver.cpp:237] Iteration 10, loss = 1.26856
I0204 20:56:08.850096  8452 solver.cpp:253]     Train net output #0: loss = 1.26856 (* 1 = 1.26856 loss)
I0204 20:56:08.850111  8452 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 20:56:24.230080  8452 solver.cpp:237] Iteration 20, loss = 1.24237
I0204 20:56:24.230254  8452 solver.cpp:253]     Train net output #0: loss = 1.24237 (* 1 = 1.24237 loss)
I0204 20:56:24.230270  8452 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 20:56:39.596987  8452 solver.cpp:237] Iteration 30, loss = 1.21694
I0204 20:56:39.597079  8452 solver.cpp:253]     Train net output #0: loss = 1.21694 (* 1 = 1.21694 loss)
I0204 20:56:39.597093  8452 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 20:56:54.963063  8452 solver.cpp:237] Iteration 40, loss = 1.01447
I0204 20:56:54.963297  8452 solver.cpp:253]     Train net output #0: loss = 1.01447 (* 1 = 1.01447 loss)
I0204 20:56:54.963315  8452 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 20:57:10.329298  8452 solver.cpp:237] Iteration 50, loss = 0.936267
I0204 20:57:10.329385  8452 solver.cpp:253]     Train net output #0: loss = 0.936267 (* 1 = 0.936267 loss)
I0204 20:57:10.329399  8452 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 20:57:25.696349  8452 solver.cpp:237] Iteration 60, loss = 0.851839
I0204 20:57:25.696596  8452 solver.cpp:253]     Train net output #0: loss = 0.851839 (* 1 = 0.851839 loss)
I0204 20:57:25.696614  8452 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 20:57:41.059479  8452 solver.cpp:237] Iteration 70, loss = 0.947053
I0204 20:57:41.059566  8452 solver.cpp:253]     Train net output #0: loss = 0.947053 (* 1 = 0.947053 loss)
I0204 20:57:41.059581  8452 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 20:57:56.424890  8452 solver.cpp:237] Iteration 80, loss = 0.747183
I0204 20:57:56.425107  8452 solver.cpp:253]     Train net output #0: loss = 0.747183 (* 1 = 0.747183 loss)
I0204 20:57:56.425124  8452 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 20:58:11.791079  8452 solver.cpp:237] Iteration 90, loss = 0.794796
I0204 20:58:11.791172  8452 solver.cpp:253]     Train net output #0: loss = 0.794796 (* 1 = 0.794796 loss)
I0204 20:58:11.791187  8452 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 20:58:25.621570  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_100.caffemodel
I0204 20:58:25.625095  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_100.solverstate
I0204 20:58:25.626512  8452 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 20:58:32.690501  8452 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 20:58:32.690727  8452 solver.cpp:409]     Test net output #1: loss = 0.694318 (* 1 = 0.694318 loss)
I0204 20:58:34.226289  8452 solver.cpp:237] Iteration 100, loss = 0.738312
I0204 20:58:34.226367  8452 solver.cpp:253]     Train net output #0: loss = 0.738312 (* 1 = 0.738312 loss)
I0204 20:58:34.226382  8452 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 20:58:49.590211  8452 solver.cpp:237] Iteration 110, loss = 0.723305
I0204 20:58:49.590299  8452 solver.cpp:253]     Train net output #0: loss = 0.723305 (* 1 = 0.723305 loss)
I0204 20:58:49.590313  8452 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 20:59:04.952129  8452 solver.cpp:237] Iteration 120, loss = 0.692423
I0204 20:59:04.952347  8452 solver.cpp:253]     Train net output #0: loss = 0.692423 (* 1 = 0.692423 loss)
I0204 20:59:04.952364  8452 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 20:59:20.323218  8452 solver.cpp:237] Iteration 130, loss = 0.738689
I0204 20:59:20.323307  8452 solver.cpp:253]     Train net output #0: loss = 0.738689 (* 1 = 0.738689 loss)
I0204 20:59:20.323336  8452 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 20:59:35.682008  8452 solver.cpp:237] Iteration 140, loss = 0.731703
I0204 20:59:35.682286  8452 solver.cpp:253]     Train net output #0: loss = 0.731703 (* 1 = 0.731703 loss)
I0204 20:59:35.682303  8452 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 20:59:51.044571  8452 solver.cpp:237] Iteration 150, loss = 0.707969
I0204 20:59:51.044658  8452 solver.cpp:253]     Train net output #0: loss = 0.707969 (* 1 = 0.707969 loss)
I0204 20:59:51.044673  8452 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 21:00:06.414018  8452 solver.cpp:237] Iteration 160, loss = 0.739694
I0204 21:00:06.414263  8452 solver.cpp:253]     Train net output #0: loss = 0.739694 (* 1 = 0.739694 loss)
I0204 21:00:06.414279  8452 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 21:00:21.781105  8452 solver.cpp:237] Iteration 170, loss = 0.750549
I0204 21:00:21.781180  8452 solver.cpp:253]     Train net output #0: loss = 0.750549 (* 1 = 0.750549 loss)
I0204 21:00:21.781195  8452 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 21:00:37.181119  8452 solver.cpp:237] Iteration 180, loss = 0.715924
I0204 21:00:37.181330  8452 solver.cpp:253]     Train net output #0: loss = 0.715924 (* 1 = 0.715924 loss)
I0204 21:00:37.181347  8452 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 21:00:52.546162  8452 solver.cpp:237] Iteration 190, loss = 0.811175
I0204 21:00:52.546247  8452 solver.cpp:253]     Train net output #0: loss = 0.811175 (* 1 = 0.811175 loss)
I0204 21:00:52.546262  8452 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 21:01:06.406124  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_200.caffemodel
I0204 21:01:06.410648  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_200.solverstate
I0204 21:01:06.412061  8452 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 21:01:13.476374  8452 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:01:13.476596  8452 solver.cpp:409]     Test net output #1: loss = 0.714877 (* 1 = 0.714877 loss)
I0204 21:01:15.011595  8452 solver.cpp:237] Iteration 200, loss = 0.746785
I0204 21:01:15.011672  8452 solver.cpp:253]     Train net output #0: loss = 0.746785 (* 1 = 0.746785 loss)
I0204 21:01:15.011687  8452 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 21:01:30.377125  8452 solver.cpp:237] Iteration 210, loss = 0.728473
I0204 21:01:30.377200  8452 solver.cpp:253]     Train net output #0: loss = 0.728473 (* 1 = 0.728473 loss)
I0204 21:01:30.377214  8452 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 21:01:45.741888  8452 solver.cpp:237] Iteration 220, loss = 0.720379
I0204 21:01:45.742101  8452 solver.cpp:253]     Train net output #0: loss = 0.720379 (* 1 = 0.720379 loss)
I0204 21:01:45.742120  8452 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 21:02:01.107923  8452 solver.cpp:237] Iteration 230, loss = 0.712992
I0204 21:02:01.108006  8452 solver.cpp:253]     Train net output #0: loss = 0.712992 (* 1 = 0.712992 loss)
I0204 21:02:01.108021  8452 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 21:02:16.484119  8452 solver.cpp:237] Iteration 240, loss = 0.681267
I0204 21:02:16.484354  8452 solver.cpp:253]     Train net output #0: loss = 0.681267 (* 1 = 0.681267 loss)
I0204 21:02:16.484372  8452 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 21:02:31.851210  8452 solver.cpp:237] Iteration 250, loss = 0.694689
I0204 21:02:31.851297  8452 solver.cpp:253]     Train net output #0: loss = 0.694689 (* 1 = 0.694689 loss)
I0204 21:02:31.851312  8452 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 21:02:47.215036  8452 solver.cpp:237] Iteration 260, loss = 0.711067
I0204 21:02:47.215309  8452 solver.cpp:253]     Train net output #0: loss = 0.711067 (* 1 = 0.711067 loss)
I0204 21:02:47.215332  8452 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 21:03:02.583948  8452 solver.cpp:237] Iteration 270, loss = 0.778921
I0204 21:03:02.584038  8452 solver.cpp:253]     Train net output #0: loss = 0.778921 (* 1 = 0.778921 loss)
I0204 21:03:02.584060  8452 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 21:03:17.950741  8452 solver.cpp:237] Iteration 280, loss = 0.714021
I0204 21:03:17.950969  8452 solver.cpp:253]     Train net output #0: loss = 0.714021 (* 1 = 0.714021 loss)
I0204 21:03:17.950986  8452 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 21:03:33.322890  8452 solver.cpp:237] Iteration 290, loss = 0.685143
I0204 21:03:33.322976  8452 solver.cpp:253]     Train net output #0: loss = 0.685143 (* 1 = 0.685143 loss)
I0204 21:03:33.322993  8452 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 21:03:47.162770  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_300.caffemodel
I0204 21:03:47.166539  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_300.solverstate
I0204 21:03:47.167948  8452 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 21:03:54.228155  8452 solver.cpp:409]     Test net output #0: accuracy = 0.586
I0204 21:03:54.228379  8452 solver.cpp:409]     Test net output #1: loss = 0.67513 (* 1 = 0.67513 loss)
I0204 21:03:55.764003  8452 solver.cpp:237] Iteration 300, loss = 0.68521
I0204 21:03:55.764089  8452 solver.cpp:253]     Train net output #0: loss = 0.68521 (* 1 = 0.68521 loss)
I0204 21:03:55.764106  8452 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 21:04:11.138778  8452 solver.cpp:237] Iteration 310, loss = 0.666074
I0204 21:04:11.138866  8452 solver.cpp:253]     Train net output #0: loss = 0.666074 (* 1 = 0.666074 loss)
I0204 21:04:11.138880  8452 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 21:04:26.520120  8452 solver.cpp:237] Iteration 320, loss = 0.678765
I0204 21:04:26.520340  8452 solver.cpp:253]     Train net output #0: loss = 0.678765 (* 1 = 0.678765 loss)
I0204 21:04:26.520357  8452 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 21:04:41.901437  8452 solver.cpp:237] Iteration 330, loss = 0.644833
I0204 21:04:41.901520  8452 solver.cpp:253]     Train net output #0: loss = 0.644833 (* 1 = 0.644833 loss)
I0204 21:04:41.901536  8452 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 21:04:57.274041  8452 solver.cpp:237] Iteration 340, loss = 0.642548
I0204 21:04:57.274255  8452 solver.cpp:253]     Train net output #0: loss = 0.642548 (* 1 = 0.642548 loss)
I0204 21:04:57.274272  8452 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 21:05:12.646003  8452 solver.cpp:237] Iteration 350, loss = 0.626272
I0204 21:05:12.646095  8452 solver.cpp:253]     Train net output #0: loss = 0.626272 (* 1 = 0.626272 loss)
I0204 21:05:12.646109  8452 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 21:05:28.024188  8452 solver.cpp:237] Iteration 360, loss = 0.691347
I0204 21:05:28.024394  8452 solver.cpp:253]     Train net output #0: loss = 0.691347 (* 1 = 0.691347 loss)
I0204 21:05:28.024411  8452 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 21:05:43.477067  8452 solver.cpp:237] Iteration 370, loss = 0.70179
I0204 21:05:43.477154  8452 solver.cpp:253]     Train net output #0: loss = 0.70179 (* 1 = 0.70179 loss)
I0204 21:05:43.477167  8452 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 21:05:58.859850  8452 solver.cpp:237] Iteration 380, loss = 0.811214
I0204 21:05:58.860103  8452 solver.cpp:253]     Train net output #0: loss = 0.811214 (* 1 = 0.811214 loss)
I0204 21:05:58.860121  8452 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 21:06:14.249975  8452 solver.cpp:237] Iteration 390, loss = 0.507242
I0204 21:06:14.250066  8452 solver.cpp:253]     Train net output #0: loss = 0.507242 (* 1 = 0.507242 loss)
I0204 21:06:14.250082  8452 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 21:06:28.096041  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_400.caffemodel
I0204 21:06:28.099704  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_400.solverstate
I0204 21:06:28.101105  8452 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 21:06:35.170343  8452 solver.cpp:409]     Test net output #0: accuracy = 0.779
I0204 21:06:35.170614  8452 solver.cpp:409]     Test net output #1: loss = 0.498893 (* 1 = 0.498893 loss)
I0204 21:06:36.711493  8452 solver.cpp:237] Iteration 400, loss = 0.555548
I0204 21:06:36.711573  8452 solver.cpp:253]     Train net output #0: loss = 0.555548 (* 1 = 0.555548 loss)
I0204 21:06:36.711590  8452 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 21:06:52.120100  8452 solver.cpp:237] Iteration 410, loss = 0.608123
I0204 21:06:52.120185  8452 solver.cpp:253]     Train net output #0: loss = 0.608123 (* 1 = 0.608123 loss)
I0204 21:06:52.120200  8452 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 21:07:07.556668  8452 solver.cpp:237] Iteration 420, loss = 0.449871
I0204 21:07:07.557121  8452 solver.cpp:253]     Train net output #0: loss = 0.449871 (* 1 = 0.449871 loss)
I0204 21:07:07.557139  8452 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 21:07:23.045711  8452 solver.cpp:237] Iteration 430, loss = 0.392389
I0204 21:07:23.045794  8452 solver.cpp:253]     Train net output #0: loss = 0.392389 (* 1 = 0.392389 loss)
I0204 21:07:23.045809  8452 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 21:07:38.749007  8452 solver.cpp:237] Iteration 440, loss = 0.360811
I0204 21:07:38.749228  8452 solver.cpp:253]     Train net output #0: loss = 0.360811 (* 1 = 0.360811 loss)
I0204 21:07:38.749245  8452 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 21:07:54.800402  8452 solver.cpp:237] Iteration 450, loss = 0.218402
I0204 21:07:54.800487  8452 solver.cpp:253]     Train net output #0: loss = 0.218402 (* 1 = 0.218402 loss)
I0204 21:07:54.800501  8452 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 21:08:11.275084  8452 solver.cpp:237] Iteration 460, loss = 0.143711
I0204 21:08:11.275313  8452 solver.cpp:253]     Train net output #0: loss = 0.143711 (* 1 = 0.143711 loss)
I0204 21:08:11.275331  8452 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 21:08:28.251488  8452 solver.cpp:237] Iteration 470, loss = 0.141193
I0204 21:08:28.251571  8452 solver.cpp:253]     Train net output #0: loss = 0.141193 (* 1 = 0.141193 loss)
I0204 21:08:28.251586  8452 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 21:08:45.848307  8452 solver.cpp:237] Iteration 480, loss = 0.304272
I0204 21:08:45.848503  8452 solver.cpp:253]     Train net output #0: loss = 0.304272 (* 1 = 0.304272 loss)
I0204 21:08:45.848517  8452 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 21:09:03.711655  8452 solver.cpp:237] Iteration 490, loss = 0.146484
I0204 21:09:03.711740  8452 solver.cpp:253]     Train net output #0: loss = 0.146484 (* 1 = 0.146484 loss)
I0204 21:09:03.711755  8452 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 21:09:19.740309  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_500.caffemodel
I0204 21:09:19.744230  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_500.solverstate
I0204 21:09:19.745688  8452 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 21:09:28.030752  8452 solver.cpp:409]     Test net output #0: accuracy = 0.983
I0204 21:09:28.030823  8452 solver.cpp:409]     Test net output #1: loss = 0.0482085 (* 1 = 0.0482085 loss)
I0204 21:09:29.818495  8452 solver.cpp:237] Iteration 500, loss = 0.102222
I0204 21:09:29.818583  8452 solver.cpp:253]     Train net output #0: loss = 0.102222 (* 1 = 0.102222 loss)
I0204 21:09:29.818598  8452 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 21:09:47.698920  8452 solver.cpp:237] Iteration 510, loss = 0.130961
I0204 21:09:47.699000  8452 solver.cpp:253]     Train net output #0: loss = 0.130961 (* 1 = 0.130961 loss)
I0204 21:09:47.699014  8452 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 21:10:05.575372  8452 solver.cpp:237] Iteration 520, loss = 0.056615
I0204 21:10:05.575647  8452 solver.cpp:253]     Train net output #0: loss = 0.056615 (* 1 = 0.056615 loss)
I0204 21:10:05.575670  8452 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 21:10:23.465494  8452 solver.cpp:237] Iteration 530, loss = 0.133432
I0204 21:10:23.465575  8452 solver.cpp:253]     Train net output #0: loss = 0.133432 (* 1 = 0.133432 loss)
I0204 21:10:23.465590  8452 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 21:10:41.389144  8452 solver.cpp:237] Iteration 540, loss = 0.097258
I0204 21:10:41.389386  8452 solver.cpp:253]     Train net output #0: loss = 0.097258 (* 1 = 0.097258 loss)
I0204 21:10:41.389402  8452 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 21:10:59.456037  8452 solver.cpp:237] Iteration 550, loss = 0.0658692
I0204 21:10:59.456125  8452 solver.cpp:253]     Train net output #0: loss = 0.0658692 (* 1 = 0.0658692 loss)
I0204 21:10:59.456140  8452 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 21:11:17.512840  8452 solver.cpp:237] Iteration 560, loss = 0.0349456
I0204 21:11:17.513088  8452 solver.cpp:253]     Train net output #0: loss = 0.0349456 (* 1 = 0.0349456 loss)
I0204 21:11:17.513105  8452 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 21:11:35.511713  8452 solver.cpp:237] Iteration 570, loss = 0.0347868
I0204 21:11:35.511802  8452 solver.cpp:253]     Train net output #0: loss = 0.0347868 (* 1 = 0.0347868 loss)
I0204 21:11:35.511817  8452 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 21:11:53.546857  8452 solver.cpp:237] Iteration 580, loss = 0.117103
I0204 21:11:53.547098  8452 solver.cpp:253]     Train net output #0: loss = 0.117103 (* 1 = 0.117103 loss)
I0204 21:11:53.547116  8452 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 21:12:11.676486  8452 solver.cpp:237] Iteration 590, loss = 0.0330811
I0204 21:12:11.676550  8452 solver.cpp:253]     Train net output #0: loss = 0.0330811 (* 1 = 0.0330811 loss)
I0204 21:12:11.676617  8452 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 21:12:27.915153  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_600.caffemodel
I0204 21:12:27.918936  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_600.solverstate
I0204 21:12:27.920272  8452 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 21:12:36.288544  8452 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 21:12:36.288599  8452 solver.cpp:409]     Test net output #1: loss = 0.00928829 (* 1 = 0.00928829 loss)
I0204 21:12:38.088129  8452 solver.cpp:237] Iteration 600, loss = 0.0118886
I0204 21:12:38.088184  8452 solver.cpp:253]     Train net output #0: loss = 0.0118886 (* 1 = 0.0118886 loss)
I0204 21:12:38.088196  8452 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 21:12:56.063961  8452 solver.cpp:237] Iteration 610, loss = 0.0258864
I0204 21:12:56.064028  8452 solver.cpp:253]     Train net output #0: loss = 0.0258864 (* 1 = 0.0258864 loss)
I0204 21:12:56.064039  8452 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 21:13:14.127383  8452 solver.cpp:237] Iteration 620, loss = 0.0199409
I0204 21:13:14.127565  8452 solver.cpp:253]     Train net output #0: loss = 0.0199409 (* 1 = 0.0199409 loss)
I0204 21:13:14.127578  8452 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 21:13:32.321604  8452 solver.cpp:237] Iteration 630, loss = 0.0907726
I0204 21:13:32.321662  8452 solver.cpp:253]     Train net output #0: loss = 0.0907726 (* 1 = 0.0907726 loss)
I0204 21:13:32.321692  8452 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 21:13:50.651209  8452 solver.cpp:237] Iteration 640, loss = 0.0372612
I0204 21:13:50.651456  8452 solver.cpp:253]     Train net output #0: loss = 0.0372612 (* 1 = 0.0372612 loss)
I0204 21:13:50.651474  8452 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 21:14:08.846750  8452 solver.cpp:237] Iteration 650, loss = 0.020117
I0204 21:14:08.846834  8452 solver.cpp:253]     Train net output #0: loss = 0.0201171 (* 1 = 0.0201171 loss)
I0204 21:14:08.846850  8452 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 21:14:26.825377  8452 solver.cpp:237] Iteration 660, loss = 0.104204
I0204 21:14:26.825629  8452 solver.cpp:253]     Train net output #0: loss = 0.104204 (* 1 = 0.104204 loss)
I0204 21:14:26.825646  8452 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 21:14:44.934233  8452 solver.cpp:237] Iteration 670, loss = 0.101888
I0204 21:14:44.934321  8452 solver.cpp:253]     Train net output #0: loss = 0.101888 (* 1 = 0.101888 loss)
I0204 21:14:44.934336  8452 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 21:15:03.093490  8452 solver.cpp:237] Iteration 680, loss = 0.00913904
I0204 21:15:03.093706  8452 solver.cpp:253]     Train net output #0: loss = 0.00913906 (* 1 = 0.00913906 loss)
I0204 21:15:03.093724  8452 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 21:15:21.356853  8452 solver.cpp:237] Iteration 690, loss = 0.0665882
I0204 21:15:21.356941  8452 solver.cpp:253]     Train net output #0: loss = 0.0665882 (* 1 = 0.0665882 loss)
I0204 21:15:21.356956  8452 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 21:15:37.770390  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_700.caffemodel
I0204 21:15:37.774682  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_700.solverstate
I0204 21:15:37.776103  8452 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 21:15:46.302137  8452 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 21:15:46.302217  8452 solver.cpp:409]     Test net output #1: loss = 0.00977338 (* 1 = 0.00977338 loss)
I0204 21:15:48.134270  8452 solver.cpp:237] Iteration 700, loss = 0.0203883
I0204 21:15:48.134352  8452 solver.cpp:253]     Train net output #0: loss = 0.0203883 (* 1 = 0.0203883 loss)
I0204 21:15:48.134367  8452 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 21:16:06.472232  8452 solver.cpp:237] Iteration 710, loss = 0.0199767
I0204 21:16:06.472312  8452 solver.cpp:253]     Train net output #0: loss = 0.0199767 (* 1 = 0.0199767 loss)
I0204 21:16:06.472327  8452 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 21:16:24.947903  8452 solver.cpp:237] Iteration 720, loss = 0.00564492
I0204 21:16:24.948118  8452 solver.cpp:253]     Train net output #0: loss = 0.00564495 (* 1 = 0.00564495 loss)
I0204 21:16:24.948135  8452 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 21:16:43.264729  8452 solver.cpp:237] Iteration 730, loss = 0.0244641
I0204 21:16:43.264812  8452 solver.cpp:253]     Train net output #0: loss = 0.0244641 (* 1 = 0.0244641 loss)
I0204 21:16:43.264827  8452 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 21:17:01.687373  8452 solver.cpp:237] Iteration 740, loss = 0.0563579
I0204 21:17:01.687577  8452 solver.cpp:253]     Train net output #0: loss = 0.0563579 (* 1 = 0.0563579 loss)
I0204 21:17:01.687593  8452 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 21:17:20.362098  8452 solver.cpp:237] Iteration 750, loss = 0.0715142
I0204 21:17:20.362175  8452 solver.cpp:253]     Train net output #0: loss = 0.0715143 (* 1 = 0.0715143 loss)
I0204 21:17:20.362190  8452 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 21:17:39.392436  8452 solver.cpp:237] Iteration 760, loss = 0.019182
I0204 21:17:39.392684  8452 solver.cpp:253]     Train net output #0: loss = 0.019182 (* 1 = 0.019182 loss)
I0204 21:17:39.392709  8452 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 21:17:58.296085  8452 solver.cpp:237] Iteration 770, loss = 0.0136895
I0204 21:17:58.296166  8452 solver.cpp:253]     Train net output #0: loss = 0.0136895 (* 1 = 0.0136895 loss)
I0204 21:17:58.296181  8452 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 21:18:17.078346  8452 solver.cpp:237] Iteration 780, loss = 0.00231203
I0204 21:18:17.078573  8452 solver.cpp:253]     Train net output #0: loss = 0.00231206 (* 1 = 0.00231206 loss)
I0204 21:18:17.078590  8452 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 21:18:35.858711  8452 solver.cpp:237] Iteration 790, loss = 0.00464991
I0204 21:18:35.858791  8452 solver.cpp:253]     Train net output #0: loss = 0.00464994 (* 1 = 0.00464994 loss)
I0204 21:18:35.858808  8452 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 21:18:52.716267  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_800.caffemodel
I0204 21:18:52.720013  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_800.solverstate
I0204 21:18:52.721424  8452 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 21:19:01.519773  8452 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 21:19:01.519824  8452 solver.cpp:409]     Test net output #1: loss = 0.0175506 (* 1 = 0.0175506 loss)
I0204 21:19:03.411909  8452 solver.cpp:237] Iteration 800, loss = 0.0957973
I0204 21:19:03.411968  8452 solver.cpp:253]     Train net output #0: loss = 0.0957974 (* 1 = 0.0957974 loss)
I0204 21:19:03.411980  8452 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 21:19:22.165740  8452 solver.cpp:237] Iteration 810, loss = 0.011687
I0204 21:19:22.165801  8452 solver.cpp:253]     Train net output #0: loss = 0.011687 (* 1 = 0.011687 loss)
I0204 21:19:22.165812  8452 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 21:19:40.983384  8452 solver.cpp:237] Iteration 820, loss = 0.0219549
I0204 21:19:40.983572  8452 solver.cpp:253]     Train net output #0: loss = 0.0219549 (* 1 = 0.0219549 loss)
I0204 21:19:40.983587  8452 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 21:19:59.786582  8452 solver.cpp:237] Iteration 830, loss = 0.012257
I0204 21:19:59.786641  8452 solver.cpp:253]     Train net output #0: loss = 0.012257 (* 1 = 0.012257 loss)
I0204 21:19:59.786653  8452 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 21:20:18.562182  8452 solver.cpp:237] Iteration 840, loss = 0.024222
I0204 21:20:18.562919  8452 solver.cpp:253]     Train net output #0: loss = 0.024222 (* 1 = 0.024222 loss)
I0204 21:20:18.562963  8452 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 21:20:37.295805  8452 solver.cpp:237] Iteration 850, loss = 0.0265868
I0204 21:20:37.295866  8452 solver.cpp:253]     Train net output #0: loss = 0.0265868 (* 1 = 0.0265868 loss)
I0204 21:20:37.295877  8452 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 21:20:55.994513  8452 solver.cpp:237] Iteration 860, loss = 0.00421809
I0204 21:20:55.994698  8452 solver.cpp:253]     Train net output #0: loss = 0.00421811 (* 1 = 0.00421811 loss)
I0204 21:20:55.994711  8452 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 21:21:14.835042  8452 solver.cpp:237] Iteration 870, loss = 0.000900301
I0204 21:21:14.835100  8452 solver.cpp:253]     Train net output #0: loss = 0.000900325 (* 1 = 0.000900325 loss)
I0204 21:21:14.835111  8452 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 21:21:33.747400  8452 solver.cpp:237] Iteration 880, loss = 0.0101257
I0204 21:21:33.755686  8452 solver.cpp:253]     Train net output #0: loss = 0.0101258 (* 1 = 0.0101258 loss)
I0204 21:21:33.755717  8452 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 21:21:52.563403  8452 solver.cpp:237] Iteration 890, loss = 0.00610455
I0204 21:21:52.563464  8452 solver.cpp:253]     Train net output #0: loss = 0.00610458 (* 1 = 0.00610458 loss)
I0204 21:21:52.563491  8452 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 21:22:09.667852  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_900.caffemodel
I0204 21:22:09.671669  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_900.solverstate
I0204 21:22:09.673069  8452 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 21:22:18.530700  8452 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 21:22:18.530752  8452 solver.cpp:409]     Test net output #1: loss = 0.00400222 (* 1 = 0.00400222 loss)
I0204 21:22:20.434653  8452 solver.cpp:237] Iteration 900, loss = 0.0032744
I0204 21:22:20.434706  8452 solver.cpp:253]     Train net output #0: loss = 0.00327442 (* 1 = 0.00327442 loss)
I0204 21:22:20.434718  8452 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 21:22:39.387655  8452 solver.cpp:237] Iteration 910, loss = 0.0687873
I0204 21:22:39.387714  8452 solver.cpp:253]     Train net output #0: loss = 0.0687873 (* 1 = 0.0687873 loss)
I0204 21:22:39.387725  8452 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 21:22:58.262825  8452 solver.cpp:237] Iteration 920, loss = 0.00229531
I0204 21:22:58.263041  8452 solver.cpp:253]     Train net output #0: loss = 0.00229533 (* 1 = 0.00229533 loss)
I0204 21:22:58.263054  8452 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 21:23:17.145001  8452 solver.cpp:237] Iteration 930, loss = 0.0317927
I0204 21:23:17.145062  8452 solver.cpp:253]     Train net output #0: loss = 0.0317928 (* 1 = 0.0317928 loss)
I0204 21:23:17.145076  8452 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 21:23:35.812211  8452 solver.cpp:237] Iteration 940, loss = 0.000999123
I0204 21:23:35.812402  8452 solver.cpp:253]     Train net output #0: loss = 0.000999143 (* 1 = 0.000999143 loss)
I0204 21:23:35.812417  8452 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 21:23:54.633947  8452 solver.cpp:237] Iteration 950, loss = 0.00379979
I0204 21:23:54.634004  8452 solver.cpp:253]     Train net output #0: loss = 0.00379981 (* 1 = 0.00379981 loss)
I0204 21:23:54.634016  8452 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 21:24:13.532446  8452 solver.cpp:237] Iteration 960, loss = 0.0310986
I0204 21:24:13.532623  8452 solver.cpp:253]     Train net output #0: loss = 0.0310986 (* 1 = 0.0310986 loss)
I0204 21:24:13.532636  8452 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 21:24:32.321061  8452 solver.cpp:237] Iteration 970, loss = 0.0550528
I0204 21:24:32.321127  8452 solver.cpp:253]     Train net output #0: loss = 0.0550528 (* 1 = 0.0550528 loss)
I0204 21:24:32.321141  8452 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 21:24:51.196131  8452 solver.cpp:237] Iteration 980, loss = 0.0266189
I0204 21:24:51.196362  8452 solver.cpp:253]     Train net output #0: loss = 0.0266189 (* 1 = 0.0266189 loss)
I0204 21:24:51.196390  8452 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 21:25:10.156783  8452 solver.cpp:237] Iteration 990, loss = 0.0180591
I0204 21:25:10.156838  8452 solver.cpp:253]     Train net output #0: loss = 0.0180592 (* 1 = 0.0180592 loss)
I0204 21:25:10.156852  8452 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 21:25:27.093890  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1000.caffemodel
I0204 21:25:27.097671  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1000.solverstate
I0204 21:25:27.099068  8452 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 21:25:36.049257  8452 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 21:25:36.049326  8452 solver.cpp:409]     Test net output #1: loss = 0.0108385 (* 1 = 0.0108385 loss)
I0204 21:25:37.960137  8452 solver.cpp:237] Iteration 1000, loss = 0.030445
I0204 21:25:37.960222  8452 solver.cpp:253]     Train net output #0: loss = 0.0304451 (* 1 = 0.0304451 loss)
I0204 21:25:37.960237  8452 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 21:25:56.562445  8452 solver.cpp:237] Iteration 1010, loss = 0.0137032
I0204 21:25:56.562526  8452 solver.cpp:253]     Train net output #0: loss = 0.0137032 (* 1 = 0.0137032 loss)
I0204 21:25:56.562541  8452 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 21:26:15.556484  8452 solver.cpp:237] Iteration 1020, loss = 0.00271695
I0204 21:26:15.556746  8452 solver.cpp:253]     Train net output #0: loss = 0.00271696 (* 1 = 0.00271696 loss)
I0204 21:26:15.556762  8452 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 21:26:34.801767  8452 solver.cpp:237] Iteration 1030, loss = 0.00746812
I0204 21:26:34.801851  8452 solver.cpp:253]     Train net output #0: loss = 0.00746813 (* 1 = 0.00746813 loss)
I0204 21:26:34.801867  8452 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 21:26:53.933192  8452 solver.cpp:237] Iteration 1040, loss = 0.00305478
I0204 21:26:53.933429  8452 solver.cpp:253]     Train net output #0: loss = 0.00305479 (* 1 = 0.00305479 loss)
I0204 21:26:53.933445  8452 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 21:27:13.323071  8452 solver.cpp:237] Iteration 1050, loss = 0.000850969
I0204 21:27:13.323133  8452 solver.cpp:253]     Train net output #0: loss = 0.000850976 (* 1 = 0.000850976 loss)
I0204 21:27:13.323145  8452 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 21:27:32.967430  8452 solver.cpp:237] Iteration 1060, loss = 0.0040444
I0204 21:27:32.967629  8452 solver.cpp:253]     Train net output #0: loss = 0.00404441 (* 1 = 0.00404441 loss)
I0204 21:27:32.967643  8452 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 21:27:52.753603  8452 solver.cpp:237] Iteration 1070, loss = 0.0331955
I0204 21:27:52.753664  8452 solver.cpp:253]     Train net output #0: loss = 0.0331955 (* 1 = 0.0331955 loss)
I0204 21:27:52.753675  8452 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 21:28:12.452750  8452 solver.cpp:237] Iteration 1080, loss = 0.00072412
I0204 21:28:12.452956  8452 solver.cpp:253]     Train net output #0: loss = 0.000724127 (* 1 = 0.000724127 loss)
I0204 21:28:12.452970  8452 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 21:28:32.174621  8452 solver.cpp:237] Iteration 1090, loss = 0.0871043
I0204 21:28:32.174677  8452 solver.cpp:253]     Train net output #0: loss = 0.0871043 (* 1 = 0.0871043 loss)
I0204 21:28:32.174688  8452 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 21:28:50.047876  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1100.caffemodel
I0204 21:28:50.051688  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1100.solverstate
I0204 21:28:50.053103  8452 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 21:28:59.359012  8452 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 21:28:59.359066  8452 solver.cpp:409]     Test net output #1: loss = 0.00453424 (* 1 = 0.00453424 loss)
I0204 21:29:01.359148  8452 solver.cpp:237] Iteration 1100, loss = 0.0010305
I0204 21:29:01.359203  8452 solver.cpp:253]     Train net output #0: loss = 0.0010305 (* 1 = 0.0010305 loss)
I0204 21:29:01.359216  8452 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 21:29:21.273913  8452 solver.cpp:237] Iteration 1110, loss = 0.000782623
I0204 21:29:21.274101  8452 solver.cpp:253]     Train net output #0: loss = 0.00078263 (* 1 = 0.00078263 loss)
I0204 21:29:21.274116  8452 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 21:29:41.119388  8452 solver.cpp:237] Iteration 1120, loss = 0.000576086
I0204 21:29:41.119453  8452 solver.cpp:253]     Train net output #0: loss = 0.000576094 (* 1 = 0.000576094 loss)
I0204 21:29:41.119477  8452 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 21:30:00.835026  8452 solver.cpp:237] Iteration 1130, loss = 0.00346072
I0204 21:30:00.835238  8452 solver.cpp:253]     Train net output #0: loss = 0.00346073 (* 1 = 0.00346073 loss)
I0204 21:30:00.835253  8452 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 21:30:20.401190  8452 solver.cpp:237] Iteration 1140, loss = 0.00537343
I0204 21:30:20.401243  8452 solver.cpp:253]     Train net output #0: loss = 0.00537344 (* 1 = 0.00537344 loss)
I0204 21:30:20.401255  8452 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 21:30:39.900202  8452 solver.cpp:237] Iteration 1150, loss = 0.0280093
I0204 21:30:39.900406  8452 solver.cpp:253]     Train net output #0: loss = 0.0280093 (* 1 = 0.0280093 loss)
I0204 21:30:39.900421  8452 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 21:30:59.560722  8452 solver.cpp:237] Iteration 1160, loss = 0.00454985
I0204 21:30:59.560783  8452 solver.cpp:253]     Train net output #0: loss = 0.00454986 (* 1 = 0.00454986 loss)
I0204 21:30:59.560796  8452 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 21:31:19.009451  8452 solver.cpp:237] Iteration 1170, loss = 0.00886158
I0204 21:31:19.009671  8452 solver.cpp:253]     Train net output #0: loss = 0.00886159 (* 1 = 0.00886159 loss)
I0204 21:31:19.009687  8452 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 21:31:38.271806  8452 solver.cpp:237] Iteration 1180, loss = 0.000599588
I0204 21:31:38.271894  8452 solver.cpp:253]     Train net output #0: loss = 0.000599596 (* 1 = 0.000599596 loss)
I0204 21:31:38.271908  8452 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 21:31:57.540227  8452 solver.cpp:237] Iteration 1190, loss = 0.00212185
I0204 21:31:57.540447  8452 solver.cpp:253]     Train net output #0: loss = 0.00212186 (* 1 = 0.00212186 loss)
I0204 21:31:57.540465  8452 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 21:32:14.876451  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1200.caffemodel
I0204 21:32:14.881005  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1200.solverstate
I0204 21:32:14.882424  8452 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 21:32:24.107419  8452 solver.cpp:409]     Test net output #0: accuracy = 0.988
I0204 21:32:24.107496  8452 solver.cpp:409]     Test net output #1: loss = 0.0415719 (* 1 = 0.0415719 loss)
I0204 21:32:26.077067  8452 solver.cpp:237] Iteration 1200, loss = 0.0898659
I0204 21:32:26.077147  8452 solver.cpp:253]     Train net output #0: loss = 0.089866 (* 1 = 0.089866 loss)
I0204 21:32:26.077162  8452 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 21:32:45.303828  8452 solver.cpp:237] Iteration 1210, loss = 0.014629
I0204 21:32:45.304039  8452 solver.cpp:253]     Train net output #0: loss = 0.014629 (* 1 = 0.014629 loss)
I0204 21:32:45.304056  8452 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 21:33:04.228327  8452 solver.cpp:237] Iteration 1220, loss = 0.0144114
I0204 21:33:04.228400  8452 solver.cpp:253]     Train net output #0: loss = 0.0144114 (* 1 = 0.0144114 loss)
I0204 21:33:04.228415  8452 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 21:33:23.451225  8452 solver.cpp:237] Iteration 1230, loss = 0.0241329
I0204 21:33:23.451431  8452 solver.cpp:253]     Train net output #0: loss = 0.0241329 (* 1 = 0.0241329 loss)
I0204 21:33:23.451447  8452 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 21:33:42.713619  8452 solver.cpp:237] Iteration 1240, loss = 0.0131692
I0204 21:33:42.713696  8452 solver.cpp:253]     Train net output #0: loss = 0.0131692 (* 1 = 0.0131692 loss)
I0204 21:33:42.713708  8452 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 21:34:02.096300  8452 solver.cpp:237] Iteration 1250, loss = 0.00194971
I0204 21:34:02.096549  8452 solver.cpp:253]     Train net output #0: loss = 0.00194972 (* 1 = 0.00194972 loss)
I0204 21:34:02.096565  8452 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 21:34:22.068945  8452 solver.cpp:237] Iteration 1260, loss = 0.00114294
I0204 21:34:22.069010  8452 solver.cpp:253]     Train net output #0: loss = 0.00114296 (* 1 = 0.00114296 loss)
I0204 21:34:22.069022  8452 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 21:34:42.107334  8452 solver.cpp:237] Iteration 1270, loss = 0.000837309
I0204 21:34:42.107573  8452 solver.cpp:253]     Train net output #0: loss = 0.000837322 (* 1 = 0.000837322 loss)
I0204 21:34:42.107590  8452 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 21:35:01.945307  8452 solver.cpp:237] Iteration 1280, loss = 0.0029259
I0204 21:35:01.945394  8452 solver.cpp:253]     Train net output #0: loss = 0.00292591 (* 1 = 0.00292591 loss)
I0204 21:35:01.945408  8452 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 21:35:21.964784  8452 solver.cpp:237] Iteration 1290, loss = 0.00137856
I0204 21:35:21.965028  8452 solver.cpp:253]     Train net output #0: loss = 0.00137857 (* 1 = 0.00137857 loss)
I0204 21:35:21.965044  8452 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 21:35:40.207028  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1300.caffemodel
I0204 21:35:40.210757  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1300.solverstate
I0204 21:35:40.212153  8452 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 21:35:49.716367  8452 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 21:35:49.716449  8452 solver.cpp:409]     Test net output #1: loss = 0.00903931 (* 1 = 0.00903931 loss)
I0204 21:35:51.738236  8452 solver.cpp:237] Iteration 1300, loss = 0.00604947
I0204 21:35:51.738314  8452 solver.cpp:253]     Train net output #0: loss = 0.00604947 (* 1 = 0.00604947 loss)
I0204 21:35:51.738328  8452 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 21:36:12.046376  8452 solver.cpp:237] Iteration 1310, loss = 0.0159201
I0204 21:36:12.047940  8452 solver.cpp:253]     Train net output #0: loss = 0.0159201 (* 1 = 0.0159201 loss)
I0204 21:36:12.047971  8452 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 21:36:32.101014  8452 solver.cpp:237] Iteration 1320, loss = 0.0118066
I0204 21:36:32.101101  8452 solver.cpp:253]     Train net output #0: loss = 0.0118066 (* 1 = 0.0118066 loss)
I0204 21:36:32.101116  8452 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 21:36:51.955992  8452 solver.cpp:237] Iteration 1330, loss = 0.0161033
I0204 21:36:51.956243  8452 solver.cpp:253]     Train net output #0: loss = 0.0161033 (* 1 = 0.0161033 loss)
I0204 21:36:51.956260  8452 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 21:37:11.832041  8452 solver.cpp:237] Iteration 1340, loss = 0.00216564
I0204 21:37:11.832131  8452 solver.cpp:253]     Train net output #0: loss = 0.00216564 (* 1 = 0.00216564 loss)
I0204 21:37:11.832145  8452 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 21:37:31.952605  8452 solver.cpp:237] Iteration 1350, loss = 0.000380619
I0204 21:37:31.952836  8452 solver.cpp:253]     Train net output #0: loss = 0.000380625 (* 1 = 0.000380625 loss)
I0204 21:37:31.952852  8452 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 21:37:52.030673  8452 solver.cpp:237] Iteration 1360, loss = 0.0043629
I0204 21:37:52.030761  8452 solver.cpp:253]     Train net output #0: loss = 0.00436291 (* 1 = 0.00436291 loss)
I0204 21:37:52.030774  8452 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 21:38:12.289712  8452 solver.cpp:237] Iteration 1370, loss = 0.000580448
I0204 21:38:12.289932  8452 solver.cpp:253]     Train net output #0: loss = 0.000580451 (* 1 = 0.000580451 loss)
I0204 21:38:12.289949  8452 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 21:38:32.675987  8452 solver.cpp:237] Iteration 1380, loss = 0.0120946
I0204 21:38:32.676101  8452 solver.cpp:253]     Train net output #0: loss = 0.0120946 (* 1 = 0.0120946 loss)
I0204 21:38:32.676115  8452 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 21:38:52.715852  8452 solver.cpp:237] Iteration 1390, loss = 0.000606559
I0204 21:38:52.716125  8452 solver.cpp:253]     Train net output #0: loss = 0.00060656 (* 1 = 0.00060656 loss)
I0204 21:38:52.716142  8452 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 21:39:10.820104  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1400.caffemodel
I0204 21:39:10.823727  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1400.solverstate
I0204 21:39:10.825040  8452 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 21:39:20.165781  8452 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 21:39:20.165856  8452 solver.cpp:409]     Test net output #1: loss = 0.00317301 (* 1 = 0.00317301 loss)
I0204 21:39:22.166838  8452 solver.cpp:237] Iteration 1400, loss = 0.000355016
I0204 21:39:22.166918  8452 solver.cpp:253]     Train net output #0: loss = 0.000355021 (* 1 = 0.000355021 loss)
I0204 21:39:22.166934  8452 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 21:39:42.020788  8452 solver.cpp:237] Iteration 1410, loss = 0.0579745
I0204 21:39:42.021035  8452 solver.cpp:253]     Train net output #0: loss = 0.0579745 (* 1 = 0.0579745 loss)
I0204 21:39:42.021057  8452 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 21:40:02.010020  8452 solver.cpp:237] Iteration 1420, loss = 0.00413723
I0204 21:40:02.010114  8452 solver.cpp:253]     Train net output #0: loss = 0.00413723 (* 1 = 0.00413723 loss)
I0204 21:40:02.010129  8452 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 21:40:21.863747  8452 solver.cpp:237] Iteration 1430, loss = 0.000755511
I0204 21:40:21.863978  8452 solver.cpp:253]     Train net output #0: loss = 0.000755512 (* 1 = 0.000755512 loss)
I0204 21:40:21.863994  8452 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 21:40:41.791517  8452 solver.cpp:237] Iteration 1440, loss = 0.00523348
I0204 21:40:41.791605  8452 solver.cpp:253]     Train net output #0: loss = 0.00523348 (* 1 = 0.00523348 loss)
I0204 21:40:41.791620  8452 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 21:41:01.860116  8452 solver.cpp:237] Iteration 1450, loss = 0.00527766
I0204 21:41:01.860344  8452 solver.cpp:253]     Train net output #0: loss = 0.00527766 (* 1 = 0.00527766 loss)
I0204 21:41:01.860360  8452 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 21:41:22.091068  8452 solver.cpp:237] Iteration 1460, loss = 0.0118325
I0204 21:41:22.091152  8452 solver.cpp:253]     Train net output #0: loss = 0.0118325 (* 1 = 0.0118325 loss)
I0204 21:41:22.091167  8452 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 21:41:42.730479  8452 solver.cpp:237] Iteration 1470, loss = 0.000631007
I0204 21:41:42.730720  8452 solver.cpp:253]     Train net output #0: loss = 0.000631004 (* 1 = 0.000631004 loss)
I0204 21:41:42.730736  8452 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 21:42:03.698415  8452 solver.cpp:237] Iteration 1480, loss = 0.0100981
I0204 21:42:03.698500  8452 solver.cpp:253]     Train net output #0: loss = 0.0100981 (* 1 = 0.0100981 loss)
I0204 21:42:03.698514  8452 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 21:42:24.048576  8452 solver.cpp:237] Iteration 1490, loss = 0.000878429
I0204 21:42:24.057250  8452 solver.cpp:253]     Train net output #0: loss = 0.000878431 (* 1 = 0.000878431 loss)
I0204 21:42:24.057282  8452 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 21:42:41.969043  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1500.caffemodel
I0204 21:42:41.972658  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1500.solverstate
I0204 21:42:41.974051  8452 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 21:42:51.455785  8452 solver.cpp:409]     Test net output #0: accuracy = 1
I0204 21:42:51.455852  8452 solver.cpp:409]     Test net output #1: loss = 0.00113222 (* 1 = 0.00113222 loss)
I0204 21:42:53.488437  8452 solver.cpp:237] Iteration 1500, loss = 0.00396162
I0204 21:42:53.488503  8452 solver.cpp:253]     Train net output #0: loss = 0.00396161 (* 1 = 0.00396161 loss)
I0204 21:42:53.488517  8452 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 21:43:13.426344  8452 solver.cpp:237] Iteration 1510, loss = 0.00172937
I0204 21:43:13.426596  8452 solver.cpp:253]     Train net output #0: loss = 0.00172937 (* 1 = 0.00172937 loss)
I0204 21:43:13.426614  8452 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 21:43:33.095064  8452 solver.cpp:237] Iteration 1520, loss = 0.00607217
I0204 21:43:33.095144  8452 solver.cpp:253]     Train net output #0: loss = 0.00607216 (* 1 = 0.00607216 loss)
I0204 21:43:33.095158  8452 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 21:43:53.092087  8452 solver.cpp:237] Iteration 1530, loss = 0.0289712
I0204 21:43:53.092316  8452 solver.cpp:253]     Train net output #0: loss = 0.0289712 (* 1 = 0.0289712 loss)
I0204 21:43:53.092332  8452 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 21:44:13.245141  8452 solver.cpp:237] Iteration 1540, loss = 0.00926865
I0204 21:44:13.245221  8452 solver.cpp:253]     Train net output #0: loss = 0.00926865 (* 1 = 0.00926865 loss)
I0204 21:44:13.245234  8452 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 21:44:33.658745  8452 solver.cpp:237] Iteration 1550, loss = 0.00743062
I0204 21:44:33.658957  8452 solver.cpp:253]     Train net output #0: loss = 0.00743061 (* 1 = 0.00743061 loss)
I0204 21:44:33.658973  8452 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 21:44:54.294281  8452 solver.cpp:237] Iteration 1560, loss = 0.00417052
I0204 21:44:54.294359  8452 solver.cpp:253]     Train net output #0: loss = 0.00417051 (* 1 = 0.00417051 loss)
I0204 21:44:54.294373  8452 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 21:45:14.919386  8452 solver.cpp:237] Iteration 1570, loss = 0.000446666
I0204 21:45:14.919589  8452 solver.cpp:253]     Train net output #0: loss = 0.000446657 (* 1 = 0.000446657 loss)
I0204 21:45:14.919605  8452 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 21:45:35.500066  8452 solver.cpp:237] Iteration 1580, loss = 0.00061959
I0204 21:45:35.500147  8452 solver.cpp:253]     Train net output #0: loss = 0.000619582 (* 1 = 0.000619582 loss)
I0204 21:45:35.500161  8452 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 21:45:56.630512  8452 solver.cpp:237] Iteration 1590, loss = 0.000534511
I0204 21:45:56.630718  8452 solver.cpp:253]     Train net output #0: loss = 0.000534503 (* 1 = 0.000534503 loss)
I0204 21:45:56.630734  8452 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 21:46:15.892163  8452 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1600.caffemodel
I0204 21:46:15.895927  8452 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed13/snaps/snap__iter_1600.solverstate
I0204 21:46:16.909214  8452 solver.cpp:321] Iteration 1600, loss = 0.00133881
I0204 21:46:16.909276  8452 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 21:46:27.007230  8452 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 21:46:27.007439  8452 solver.cpp:409]     Test net output #1: loss = 0.00247872 (* 1 = 0.00247872 loss)
I0204 21:46:27.007450  8452 solver.cpp:326] Optimization Done.
I0204 21:46:27.007458  8452 caffe.cpp:215] Optimization Done.
