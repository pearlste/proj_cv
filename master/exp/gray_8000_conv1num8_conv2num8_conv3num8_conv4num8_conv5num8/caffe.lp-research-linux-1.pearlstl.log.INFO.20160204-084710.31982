Log file created at: 2016/02/04 08:47:10
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 08:47:10.629648 31982 caffe.cpp:177] Use CPU.
I0204 08:47:10.630211 31982 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap_"
solver_mode: CPU
random_seed: 0
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/train_val.prototxt"
I0204 08:47:10.630359 31982 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/train_val.prototxt
I0204 08:47:10.630954 31982 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 08:47:10.630982 31982 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 08:47:10.631228 31982 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.631355 31982 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.631539 31982 net.cpp:106] Creating Layer data
I0204 08:47:10.631556 31982 net.cpp:411] data -> data
I0204 08:47:10.631625 31982 net.cpp:411] data -> label
I0204 08:47:10.631646 31982 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 08:47:10.631691 31984 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 08:47:10.632545 31982 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.656726 31982 net.cpp:150] Setting up data
I0204 08:47:10.656774 31982 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.656782 31982 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.656788 31982 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.656807 31982 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.656832 31982 net.cpp:106] Creating Layer conv1
I0204 08:47:10.656841 31982 net.cpp:454] conv1 <- data
I0204 08:47:10.656862 31982 net.cpp:411] conv1 -> conv1
I0204 08:47:10.656962 31982 net.cpp:150] Setting up conv1
I0204 08:47:10.656973 31982 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 08:47:10.656980 31982 net.cpp:165] Memory required for data: 30292000
I0204 08:47:10.656996 31982 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.657007 31982 net.cpp:106] Creating Layer relu1
I0204 08:47:10.657013 31982 net.cpp:454] relu1 <- conv1
I0204 08:47:10.657021 31982 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.657034 31982 net.cpp:150] Setting up relu1
I0204 08:47:10.657042 31982 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 08:47:10.657047 31982 net.cpp:165] Memory required for data: 39972000
I0204 08:47:10.657053 31982 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.657063 31982 net.cpp:106] Creating Layer pool1
I0204 08:47:10.657075 31982 net.cpp:454] pool1 <- conv1
I0204 08:47:10.657083 31982 net.cpp:411] pool1 -> pool1
I0204 08:47:10.657107 31982 net.cpp:150] Setting up pool1
I0204 08:47:10.657119 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.657124 31982 net.cpp:165] Memory required for data: 42304800
I0204 08:47:10.657130 31982 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.657155 31982 net.cpp:106] Creating Layer norm1
I0204 08:47:10.657168 31982 net.cpp:454] norm1 <- pool1
I0204 08:47:10.657177 31982 net.cpp:411] norm1 -> norm1
I0204 08:47:10.657193 31982 net.cpp:150] Setting up norm1
I0204 08:47:10.657202 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.657207 31982 net.cpp:165] Memory required for data: 44637600
I0204 08:47:10.657212 31982 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.657222 31982 net.cpp:106] Creating Layer conv2
I0204 08:47:10.657228 31982 net.cpp:454] conv2 <- norm1
I0204 08:47:10.657237 31982 net.cpp:411] conv2 -> conv2
I0204 08:47:10.657265 31982 net.cpp:150] Setting up conv2
I0204 08:47:10.657272 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.657277 31982 net.cpp:165] Memory required for data: 46970400
I0204 08:47:10.657287 31982 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.657296 31982 net.cpp:106] Creating Layer relu2
I0204 08:47:10.657301 31982 net.cpp:454] relu2 <- conv2
I0204 08:47:10.657310 31982 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.657317 31982 net.cpp:150] Setting up relu2
I0204 08:47:10.657325 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.657330 31982 net.cpp:165] Memory required for data: 49303200
I0204 08:47:10.657335 31982 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.657342 31982 net.cpp:106] Creating Layer pool2
I0204 08:47:10.657351 31982 net.cpp:454] pool2 <- conv2
I0204 08:47:10.657358 31982 net.cpp:411] pool2 -> pool2
I0204 08:47:10.657368 31982 net.cpp:150] Setting up pool2
I0204 08:47:10.657376 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657380 31982 net.cpp:165] Memory required for data: 49844000
I0204 08:47:10.657385 31982 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.657394 31982 net.cpp:106] Creating Layer norm2
I0204 08:47:10.657400 31982 net.cpp:454] norm2 <- pool2
I0204 08:47:10.657408 31982 net.cpp:411] norm2 -> norm2
I0204 08:47:10.657418 31982 net.cpp:150] Setting up norm2
I0204 08:47:10.657424 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657429 31982 net.cpp:165] Memory required for data: 50384800
I0204 08:47:10.657434 31982 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.657444 31982 net.cpp:106] Creating Layer conv3
I0204 08:47:10.657450 31982 net.cpp:454] conv3 <- norm2
I0204 08:47:10.657459 31982 net.cpp:411] conv3 -> conv3
I0204 08:47:10.657486 31982 net.cpp:150] Setting up conv3
I0204 08:47:10.657495 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657500 31982 net.cpp:165] Memory required for data: 50925600
I0204 08:47:10.657510 31982 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.657517 31982 net.cpp:106] Creating Layer relu3
I0204 08:47:10.657523 31982 net.cpp:454] relu3 <- conv3
I0204 08:47:10.657531 31982 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.657539 31982 net.cpp:150] Setting up relu3
I0204 08:47:10.657546 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657551 31982 net.cpp:165] Memory required for data: 51466400
I0204 08:47:10.657555 31982 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.657568 31982 net.cpp:106] Creating Layer conv4
I0204 08:47:10.657573 31982 net.cpp:454] conv4 <- conv3
I0204 08:47:10.657582 31982 net.cpp:411] conv4 -> conv4
I0204 08:47:10.657601 31982 net.cpp:150] Setting up conv4
I0204 08:47:10.657608 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657614 31982 net.cpp:165] Memory required for data: 52007200
I0204 08:47:10.657621 31982 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.657629 31982 net.cpp:106] Creating Layer relu4
I0204 08:47:10.657634 31982 net.cpp:454] relu4 <- conv4
I0204 08:47:10.657640 31982 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.657649 31982 net.cpp:150] Setting up relu4
I0204 08:47:10.657655 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657661 31982 net.cpp:165] Memory required for data: 52548000
I0204 08:47:10.657667 31982 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.657680 31982 net.cpp:106] Creating Layer conv5
I0204 08:47:10.657692 31982 net.cpp:454] conv5 <- conv4
I0204 08:47:10.657701 31982 net.cpp:411] conv5 -> conv5
I0204 08:47:10.657719 31982 net.cpp:150] Setting up conv5
I0204 08:47:10.657727 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657732 31982 net.cpp:165] Memory required for data: 53088800
I0204 08:47:10.657742 31982 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.657750 31982 net.cpp:106] Creating Layer relu5
I0204 08:47:10.657757 31982 net.cpp:454] relu5 <- conv5
I0204 08:47:10.657763 31982 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.657770 31982 net.cpp:150] Setting up relu5
I0204 08:47:10.657776 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.657781 31982 net.cpp:165] Memory required for data: 53629600
I0204 08:47:10.657788 31982 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.657794 31982 net.cpp:106] Creating Layer pool5
I0204 08:47:10.657799 31982 net.cpp:454] pool5 <- conv5
I0204 08:47:10.657807 31982 net.cpp:411] pool5 -> pool5
I0204 08:47:10.657816 31982 net.cpp:150] Setting up pool5
I0204 08:47:10.657824 31982 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.657829 31982 net.cpp:165] Memory required for data: 53744800
I0204 08:47:10.657834 31982 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.657848 31982 net.cpp:106] Creating Layer fc6
I0204 08:47:10.657853 31982 net.cpp:454] fc6 <- pool5
I0204 08:47:10.657863 31982 net.cpp:411] fc6 -> fc6
I0204 08:47:10.658634 31982 net.cpp:150] Setting up fc6
I0204 08:47:10.658646 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.658651 31982 net.cpp:165] Memory required for data: 53847200
I0204 08:47:10.658660 31982 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.658668 31982 net.cpp:106] Creating Layer relu6
I0204 08:47:10.658674 31982 net.cpp:454] relu6 <- fc6
I0204 08:47:10.658684 31982 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.658691 31982 net.cpp:150] Setting up relu6
I0204 08:47:10.658699 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.658704 31982 net.cpp:165] Memory required for data: 53949600
I0204 08:47:10.658710 31982 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.658720 31982 net.cpp:106] Creating Layer drop6
I0204 08:47:10.658725 31982 net.cpp:454] drop6 <- fc6
I0204 08:47:10.658735 31982 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.658751 31982 net.cpp:150] Setting up drop6
I0204 08:47:10.658758 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.658763 31982 net.cpp:165] Memory required for data: 54052000
I0204 08:47:10.658769 31982 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.658778 31982 net.cpp:106] Creating Layer fc7
I0204 08:47:10.658784 31982 net.cpp:454] fc7 <- fc6
I0204 08:47:10.658792 31982 net.cpp:411] fc7 -> fc7
I0204 08:47:10.659449 31982 net.cpp:150] Setting up fc7
I0204 08:47:10.659461 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.659466 31982 net.cpp:165] Memory required for data: 54154400
I0204 08:47:10.659473 31982 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.659482 31982 net.cpp:106] Creating Layer relu7
I0204 08:47:10.659487 31982 net.cpp:454] relu7 <- fc7
I0204 08:47:10.659493 31982 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.659502 31982 net.cpp:150] Setting up relu7
I0204 08:47:10.659508 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.659513 31982 net.cpp:165] Memory required for data: 54256800
I0204 08:47:10.659518 31982 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.659569 31982 net.cpp:106] Creating Layer drop7
I0204 08:47:10.659576 31982 net.cpp:454] drop7 <- fc7
I0204 08:47:10.659584 31982 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.659595 31982 net.cpp:150] Setting up drop7
I0204 08:47:10.659600 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.659605 31982 net.cpp:165] Memory required for data: 54359200
I0204 08:47:10.659611 31982 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.659627 31982 net.cpp:106] Creating Layer fc8
I0204 08:47:10.659636 31982 net.cpp:454] fc8 <- fc7
I0204 08:47:10.659651 31982 net.cpp:411] fc8 -> fc8
I0204 08:47:10.659673 31982 net.cpp:150] Setting up fc8
I0204 08:47:10.659682 31982 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.659688 31982 net.cpp:165] Memory required for data: 54360000
I0204 08:47:10.659695 31982 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.659703 31982 net.cpp:106] Creating Layer loss
I0204 08:47:10.659709 31982 net.cpp:454] loss <- fc8
I0204 08:47:10.659715 31982 net.cpp:454] loss <- label
I0204 08:47:10.659725 31982 net.cpp:411] loss -> loss
I0204 08:47:10.659739 31982 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.659759 31982 net.cpp:150] Setting up loss
I0204 08:47:10.659766 31982 net.cpp:157] Top shape: (1)
I0204 08:47:10.659771 31982 net.cpp:160]     with loss weight 1
I0204 08:47:10.659800 31982 net.cpp:165] Memory required for data: 54360004
I0204 08:47:10.659807 31982 net.cpp:226] loss needs backward computation.
I0204 08:47:10.659813 31982 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.659818 31982 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.659824 31982 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.659829 31982 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.659834 31982 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.659840 31982 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.659845 31982 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.659850 31982 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.659857 31982 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.659862 31982 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.659868 31982 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.659873 31982 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.659878 31982 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.659883 31982 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.659894 31982 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.659900 31982 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.659907 31982 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.659912 31982 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.659919 31982 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.659924 31982 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.659929 31982 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.659935 31982 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.659941 31982 net.cpp:228] data does not need backward computation.
I0204 08:47:10.659947 31982 net.cpp:270] This network produces output loss
I0204 08:47:10.659973 31982 net.cpp:283] Network initialization done.
I0204 08:47:10.660728 31982 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/train_val.prototxt
I0204 08:47:10.660786 31982 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 08:47:10.661080 31982 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.661244 31982 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.661396 31982 net.cpp:106] Creating Layer data
I0204 08:47:10.661407 31982 net.cpp:411] data -> data
I0204 08:47:10.661424 31982 net.cpp:411] data -> label
I0204 08:47:10.661437 31982 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 08:47:10.675277 31987 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 08:47:10.675460 31982 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.733000 31982 net.cpp:150] Setting up data
I0204 08:47:10.733036 31982 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.733044 31982 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.733050 31982 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.733060 31982 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 08:47:10.733083 31982 net.cpp:106] Creating Layer label_data_1_split
I0204 08:47:10.733091 31982 net.cpp:454] label_data_1_split <- label
I0204 08:47:10.733103 31982 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 08:47:10.733117 31982 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 08:47:10.733129 31982 net.cpp:150] Setting up label_data_1_split
I0204 08:47:10.733137 31982 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.733144 31982 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.733150 31982 net.cpp:165] Memory required for data: 20612800
I0204 08:47:10.733155 31982 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.733170 31982 net.cpp:106] Creating Layer conv1
I0204 08:47:10.733175 31982 net.cpp:454] conv1 <- data
I0204 08:47:10.733185 31982 net.cpp:411] conv1 -> conv1
I0204 08:47:10.733230 31982 net.cpp:150] Setting up conv1
I0204 08:47:10.733239 31982 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 08:47:10.733245 31982 net.cpp:165] Memory required for data: 30292800
I0204 08:47:10.733258 31982 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.733268 31982 net.cpp:106] Creating Layer relu1
I0204 08:47:10.733273 31982 net.cpp:454] relu1 <- conv1
I0204 08:47:10.733281 31982 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.733290 31982 net.cpp:150] Setting up relu1
I0204 08:47:10.733297 31982 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 08:47:10.733304 31982 net.cpp:165] Memory required for data: 39972800
I0204 08:47:10.733309 31982 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.733319 31982 net.cpp:106] Creating Layer pool1
I0204 08:47:10.733325 31982 net.cpp:454] pool1 <- conv1
I0204 08:47:10.733332 31982 net.cpp:411] pool1 -> pool1
I0204 08:47:10.733345 31982 net.cpp:150] Setting up pool1
I0204 08:47:10.733352 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.733358 31982 net.cpp:165] Memory required for data: 42305600
I0204 08:47:10.733363 31982 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.733373 31982 net.cpp:106] Creating Layer norm1
I0204 08:47:10.733378 31982 net.cpp:454] norm1 <- pool1
I0204 08:47:10.733386 31982 net.cpp:411] norm1 -> norm1
I0204 08:47:10.733397 31982 net.cpp:150] Setting up norm1
I0204 08:47:10.733403 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.733408 31982 net.cpp:165] Memory required for data: 44638400
I0204 08:47:10.733414 31982 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.733424 31982 net.cpp:106] Creating Layer conv2
I0204 08:47:10.733430 31982 net.cpp:454] conv2 <- norm1
I0204 08:47:10.733438 31982 net.cpp:411] conv2 -> conv2
I0204 08:47:10.733465 31982 net.cpp:150] Setting up conv2
I0204 08:47:10.733472 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.733477 31982 net.cpp:165] Memory required for data: 46971200
I0204 08:47:10.733487 31982 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.733495 31982 net.cpp:106] Creating Layer relu2
I0204 08:47:10.733501 31982 net.cpp:454] relu2 <- conv2
I0204 08:47:10.733508 31982 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.733517 31982 net.cpp:150] Setting up relu2
I0204 08:47:10.733532 31982 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 08:47:10.733546 31982 net.cpp:165] Memory required for data: 49304000
I0204 08:47:10.733551 31982 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.733561 31982 net.cpp:106] Creating Layer pool2
I0204 08:47:10.733566 31982 net.cpp:454] pool2 <- conv2
I0204 08:47:10.733574 31982 net.cpp:411] pool2 -> pool2
I0204 08:47:10.733585 31982 net.cpp:150] Setting up pool2
I0204 08:47:10.733592 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733597 31982 net.cpp:165] Memory required for data: 49844800
I0204 08:47:10.733603 31982 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.733610 31982 net.cpp:106] Creating Layer norm2
I0204 08:47:10.733616 31982 net.cpp:454] norm2 <- pool2
I0204 08:47:10.733623 31982 net.cpp:411] norm2 -> norm2
I0204 08:47:10.733633 31982 net.cpp:150] Setting up norm2
I0204 08:47:10.733639 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733644 31982 net.cpp:165] Memory required for data: 50385600
I0204 08:47:10.733649 31982 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.733659 31982 net.cpp:106] Creating Layer conv3
I0204 08:47:10.733664 31982 net.cpp:454] conv3 <- norm2
I0204 08:47:10.733672 31982 net.cpp:411] conv3 -> conv3
I0204 08:47:10.733696 31982 net.cpp:150] Setting up conv3
I0204 08:47:10.733703 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733708 31982 net.cpp:165] Memory required for data: 50926400
I0204 08:47:10.733718 31982 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.733726 31982 net.cpp:106] Creating Layer relu3
I0204 08:47:10.733732 31982 net.cpp:454] relu3 <- conv3
I0204 08:47:10.733739 31982 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.733747 31982 net.cpp:150] Setting up relu3
I0204 08:47:10.733753 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733758 31982 net.cpp:165] Memory required for data: 51467200
I0204 08:47:10.733763 31982 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.733773 31982 net.cpp:106] Creating Layer conv4
I0204 08:47:10.733779 31982 net.cpp:454] conv4 <- conv3
I0204 08:47:10.733786 31982 net.cpp:411] conv4 -> conv4
I0204 08:47:10.733806 31982 net.cpp:150] Setting up conv4
I0204 08:47:10.733814 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733819 31982 net.cpp:165] Memory required for data: 52008000
I0204 08:47:10.733825 31982 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.733834 31982 net.cpp:106] Creating Layer relu4
I0204 08:47:10.733839 31982 net.cpp:454] relu4 <- conv4
I0204 08:47:10.733845 31982 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.733853 31982 net.cpp:150] Setting up relu4
I0204 08:47:10.733860 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733865 31982 net.cpp:165] Memory required for data: 52548800
I0204 08:47:10.733870 31982 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.733885 31982 net.cpp:106] Creating Layer conv5
I0204 08:47:10.733891 31982 net.cpp:454] conv5 <- conv4
I0204 08:47:10.733897 31982 net.cpp:411] conv5 -> conv5
I0204 08:47:10.733917 31982 net.cpp:150] Setting up conv5
I0204 08:47:10.733925 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733930 31982 net.cpp:165] Memory required for data: 53089600
I0204 08:47:10.733940 31982 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.733948 31982 net.cpp:106] Creating Layer relu5
I0204 08:47:10.733954 31982 net.cpp:454] relu5 <- conv5
I0204 08:47:10.733961 31982 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.733968 31982 net.cpp:150] Setting up relu5
I0204 08:47:10.733975 31982 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.733980 31982 net.cpp:165] Memory required for data: 53630400
I0204 08:47:10.733985 31982 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.733994 31982 net.cpp:106] Creating Layer pool5
I0204 08:47:10.733999 31982 net.cpp:454] pool5 <- conv5
I0204 08:47:10.734007 31982 net.cpp:411] pool5 -> pool5
I0204 08:47:10.734016 31982 net.cpp:150] Setting up pool5
I0204 08:47:10.734027 31982 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.734040 31982 net.cpp:165] Memory required for data: 53745600
I0204 08:47:10.734046 31982 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.734056 31982 net.cpp:106] Creating Layer fc6
I0204 08:47:10.734061 31982 net.cpp:454] fc6 <- pool5
I0204 08:47:10.734076 31982 net.cpp:411] fc6 -> fc6
I0204 08:47:10.734735 31982 net.cpp:150] Setting up fc6
I0204 08:47:10.734745 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.734750 31982 net.cpp:165] Memory required for data: 53848000
I0204 08:47:10.734757 31982 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.734767 31982 net.cpp:106] Creating Layer relu6
I0204 08:47:10.734773 31982 net.cpp:454] relu6 <- fc6
I0204 08:47:10.734781 31982 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.734787 31982 net.cpp:150] Setting up relu6
I0204 08:47:10.734794 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.734799 31982 net.cpp:165] Memory required for data: 53950400
I0204 08:47:10.734804 31982 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.734813 31982 net.cpp:106] Creating Layer drop6
I0204 08:47:10.734819 31982 net.cpp:454] drop6 <- fc6
I0204 08:47:10.734827 31982 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.734836 31982 net.cpp:150] Setting up drop6
I0204 08:47:10.734843 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.734848 31982 net.cpp:165] Memory required for data: 54052800
I0204 08:47:10.734853 31982 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.734863 31982 net.cpp:106] Creating Layer fc7
I0204 08:47:10.734869 31982 net.cpp:454] fc7 <- fc6
I0204 08:47:10.734877 31982 net.cpp:411] fc7 -> fc7
I0204 08:47:10.739348 31982 net.cpp:150] Setting up fc7
I0204 08:47:10.739378 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.739384 31982 net.cpp:165] Memory required for data: 54155200
I0204 08:47:10.739395 31982 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.739408 31982 net.cpp:106] Creating Layer relu7
I0204 08:47:10.739416 31982 net.cpp:454] relu7 <- fc7
I0204 08:47:10.739426 31982 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.739439 31982 net.cpp:150] Setting up relu7
I0204 08:47:10.739445 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.739450 31982 net.cpp:165] Memory required for data: 54257600
I0204 08:47:10.739456 31982 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.739466 31982 net.cpp:106] Creating Layer drop7
I0204 08:47:10.739472 31982 net.cpp:454] drop7 <- fc7
I0204 08:47:10.739480 31982 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.739490 31982 net.cpp:150] Setting up drop7
I0204 08:47:10.739496 31982 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.739502 31982 net.cpp:165] Memory required for data: 54360000
I0204 08:47:10.739507 31982 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.739519 31982 net.cpp:106] Creating Layer fc8
I0204 08:47:10.739526 31982 net.cpp:454] fc8 <- fc7
I0204 08:47:10.739532 31982 net.cpp:411] fc8 -> fc8
I0204 08:47:10.739562 31982 net.cpp:150] Setting up fc8
I0204 08:47:10.739569 31982 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.739574 31982 net.cpp:165] Memory required for data: 54360800
I0204 08:47:10.739583 31982 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 08:47:10.739593 31982 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 08:47:10.739598 31982 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 08:47:10.739605 31982 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 08:47:10.739614 31982 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 08:47:10.739624 31982 net.cpp:150] Setting up fc8_fc8_0_split
I0204 08:47:10.739630 31982 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.739636 31982 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.739641 31982 net.cpp:165] Memory required for data: 54362400
I0204 08:47:10.739647 31982 layer_factory.hpp:77] Creating layer accuracy
I0204 08:47:10.739661 31982 net.cpp:106] Creating Layer accuracy
I0204 08:47:10.739667 31982 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 08:47:10.739691 31982 net.cpp:454] accuracy <- label_data_1_split_0
I0204 08:47:10.739699 31982 net.cpp:411] accuracy -> accuracy
I0204 08:47:10.739711 31982 net.cpp:150] Setting up accuracy
I0204 08:47:10.739717 31982 net.cpp:157] Top shape: (1)
I0204 08:47:10.739722 31982 net.cpp:165] Memory required for data: 54362404
I0204 08:47:10.739728 31982 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.739738 31982 net.cpp:106] Creating Layer loss
I0204 08:47:10.739743 31982 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 08:47:10.739750 31982 net.cpp:454] loss <- label_data_1_split_1
I0204 08:47:10.739758 31982 net.cpp:411] loss -> loss
I0204 08:47:10.739768 31982 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.739789 31982 net.cpp:150] Setting up loss
I0204 08:47:10.739795 31982 net.cpp:157] Top shape: (1)
I0204 08:47:10.739800 31982 net.cpp:160]     with loss weight 1
I0204 08:47:10.739816 31982 net.cpp:165] Memory required for data: 54362408
I0204 08:47:10.739821 31982 net.cpp:226] loss needs backward computation.
I0204 08:47:10.739828 31982 net.cpp:228] accuracy does not need backward computation.
I0204 08:47:10.739835 31982 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 08:47:10.739840 31982 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.739845 31982 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.739851 31982 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.739856 31982 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.739862 31982 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.739867 31982 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.739872 31982 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.739878 31982 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.739884 31982 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.739891 31982 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.739897 31982 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.739902 31982 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.739907 31982 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.739913 31982 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.739919 31982 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.739925 31982 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.739931 31982 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.739936 31982 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.739943 31982 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.739951 31982 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.739956 31982 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.739962 31982 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.739969 31982 net.cpp:228] label_data_1_split does not need backward computation.
I0204 08:47:10.739975 31982 net.cpp:228] data does not need backward computation.
I0204 08:47:10.739980 31982 net.cpp:270] This network produces output accuracy
I0204 08:47:10.739986 31982 net.cpp:270] This network produces output loss
I0204 08:47:10.740015 31982 net.cpp:283] Network initialization done.
I0204 08:47:10.740123 31982 solver.cpp:60] Solver scaffolding done.
I0204 08:47:10.740173 31982 caffe.cpp:212] Starting Optimization
I0204 08:47:10.740180 31982 solver.cpp:288] Solving CaffeNet
I0204 08:47:10.740185 31982 solver.cpp:289] Learning Rate Policy: step
I0204 08:47:10.740491 31982 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 08:47:10.740545 31982 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 08:47:13.573824 31982 solver.cpp:409]     Test net output #0: accuracy = 0.556
I0204 08:47:13.573894 31982 solver.cpp:409]     Test net output #1: loss = 0.899412 (* 1 = 0.899412 loss)
I0204 08:47:14.176321 31982 solver.cpp:237] Iteration 0, loss = 7.03148
I0204 08:47:14.176379 31982 solver.cpp:253]     Train net output #0: loss = 7.03148 (* 1 = 7.03148 loss)
I0204 08:47:14.176403 31982 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 08:47:19.923166 31982 solver.cpp:237] Iteration 10, loss = 1.55674
I0204 08:47:19.923229 31982 solver.cpp:253]     Train net output #0: loss = 1.55674 (* 1 = 1.55674 loss)
I0204 08:47:19.923240 31982 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 08:47:29.127429 31982 solver.cpp:237] Iteration 20, loss = 1.10485
I0204 08:47:29.127491 31982 solver.cpp:253]     Train net output #0: loss = 1.10485 (* 1 = 1.10485 loss)
I0204 08:47:29.127502 31982 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 08:47:39.621088 31982 solver.cpp:237] Iteration 30, loss = 1.08331
I0204 08:47:39.621157 31982 solver.cpp:253]     Train net output #0: loss = 1.08331 (* 1 = 1.08331 loss)
I0204 08:47:39.621170 31982 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 08:47:50.285985 31982 solver.cpp:237] Iteration 40, loss = 0.903478
I0204 08:47:50.286106 31982 solver.cpp:253]     Train net output #0: loss = 0.903478 (* 1 = 0.903478 loss)
I0204 08:47:50.286124 31982 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 08:48:00.974112 31982 solver.cpp:237] Iteration 50, loss = 0.777876
I0204 08:48:00.974174 31982 solver.cpp:253]     Train net output #0: loss = 0.777876 (* 1 = 0.777876 loss)
I0204 08:48:00.974185 31982 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 08:48:11.762951 31982 solver.cpp:237] Iteration 60, loss = 0.871129
I0204 08:48:11.763008 31982 solver.cpp:253]     Train net output #0: loss = 0.871129 (* 1 = 0.871129 loss)
I0204 08:48:11.763020 31982 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 08:48:22.475138 31982 solver.cpp:237] Iteration 70, loss = 0.760538
I0204 08:48:22.478284 31982 solver.cpp:253]     Train net output #0: loss = 0.760538 (* 1 = 0.760538 loss)
I0204 08:48:22.478305 31982 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 08:48:33.115147 31982 solver.cpp:237] Iteration 80, loss = 0.772324
I0204 08:48:33.115202 31982 solver.cpp:253]     Train net output #0: loss = 0.772324 (* 1 = 0.772324 loss)
I0204 08:48:33.115214 31982 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 08:48:44.093983 31982 solver.cpp:237] Iteration 90, loss = 0.851274
I0204 08:48:44.094059 31982 solver.cpp:253]     Train net output #0: loss = 0.851274 (* 1 = 0.851274 loss)
I0204 08:48:44.094072 31982 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 08:48:53.549360 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_100.caffemodel
I0204 08:48:53.551949 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_100.solverstate
I0204 08:48:53.553035 31982 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 08:48:58.740228 31982 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:48:58.740296 31982 solver.cpp:409]     Test net output #1: loss = 0.694441 (* 1 = 0.694441 loss)
I0204 08:48:59.783928 31982 solver.cpp:237] Iteration 100, loss = 0.757982
I0204 08:48:59.783993 31982 solver.cpp:253]     Train net output #0: loss = 0.757982 (* 1 = 0.757982 loss)
I0204 08:48:59.784044 31982 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 08:49:10.326198 31982 solver.cpp:237] Iteration 110, loss = 0.73164
I0204 08:49:10.326252 31982 solver.cpp:253]     Train net output #0: loss = 0.73164 (* 1 = 0.73164 loss)
I0204 08:49:10.326264 31982 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 08:49:20.859876 31982 solver.cpp:237] Iteration 120, loss = 0.681386
I0204 08:49:20.859932 31982 solver.cpp:253]     Train net output #0: loss = 0.681386 (* 1 = 0.681386 loss)
I0204 08:49:20.859946 31982 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 08:49:31.703593 31982 solver.cpp:237] Iteration 130, loss = 0.758741
I0204 08:49:31.703764 31982 solver.cpp:253]     Train net output #0: loss = 0.758741 (* 1 = 0.758741 loss)
I0204 08:49:31.703778 31982 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 08:49:42.273442 31982 solver.cpp:237] Iteration 140, loss = 0.834612
I0204 08:49:42.273515 31982 solver.cpp:253]     Train net output #0: loss = 0.834612 (* 1 = 0.834612 loss)
I0204 08:49:42.273527 31982 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 08:49:53.058781 31982 solver.cpp:237] Iteration 150, loss = 0.737229
I0204 08:49:53.058838 31982 solver.cpp:253]     Train net output #0: loss = 0.737229 (* 1 = 0.737229 loss)
I0204 08:49:53.058851 31982 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 08:50:03.745990 31982 solver.cpp:237] Iteration 160, loss = 0.705007
I0204 08:50:03.746183 31982 solver.cpp:253]     Train net output #0: loss = 0.705007 (* 1 = 0.705007 loss)
I0204 08:50:03.746197 31982 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 08:50:14.464148 31982 solver.cpp:237] Iteration 170, loss = 0.717237
I0204 08:50:14.464206 31982 solver.cpp:253]     Train net output #0: loss = 0.717237 (* 1 = 0.717237 loss)
I0204 08:50:14.464220 31982 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 08:50:25.112013 31982 solver.cpp:237] Iteration 180, loss = 0.706835
I0204 08:50:25.112071 31982 solver.cpp:253]     Train net output #0: loss = 0.706835 (* 1 = 0.706835 loss)
I0204 08:50:25.112082 31982 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 08:50:35.915541 31982 solver.cpp:237] Iteration 190, loss = 0.728691
I0204 08:50:35.915665 31982 solver.cpp:253]     Train net output #0: loss = 0.728691 (* 1 = 0.728691 loss)
I0204 08:50:35.915678 31982 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 08:50:45.480259 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_200.caffemodel
I0204 08:50:45.482528 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_200.solverstate
I0204 08:50:45.483539 31982 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 08:50:50.836735 31982 solver.cpp:409]     Test net output #0: accuracy = 0.511
I0204 08:50:50.836802 31982 solver.cpp:409]     Test net output #1: loss = 0.692767 (* 1 = 0.692767 loss)
I0204 08:50:51.901645 31982 solver.cpp:237] Iteration 200, loss = 0.668999
I0204 08:50:51.901703 31982 solver.cpp:253]     Train net output #0: loss = 0.668999 (* 1 = 0.668999 loss)
I0204 08:50:51.901716 31982 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 08:51:02.443976 31982 solver.cpp:237] Iteration 210, loss = 0.702227
I0204 08:51:02.444039 31982 solver.cpp:253]     Train net output #0: loss = 0.702227 (* 1 = 0.702227 loss)
I0204 08:51:02.444051 31982 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 08:51:12.995132 31982 solver.cpp:237] Iteration 220, loss = 0.743009
I0204 08:51:12.995302 31982 solver.cpp:253]     Train net output #0: loss = 0.743009 (* 1 = 0.743009 loss)
I0204 08:51:12.995316 31982 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 08:51:23.613586 31982 solver.cpp:237] Iteration 230, loss = 0.684667
I0204 08:51:23.613658 31982 solver.cpp:253]     Train net output #0: loss = 0.684667 (* 1 = 0.684667 loss)
I0204 08:51:23.613672 31982 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 08:51:34.150094 31982 solver.cpp:237] Iteration 240, loss = 0.715111
I0204 08:51:34.150159 31982 solver.cpp:253]     Train net output #0: loss = 0.715111 (* 1 = 0.715111 loss)
I0204 08:51:34.150171 31982 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 08:51:44.756036 31982 solver.cpp:237] Iteration 250, loss = 0.71857
I0204 08:51:44.756227 31982 solver.cpp:253]     Train net output #0: loss = 0.71857 (* 1 = 0.71857 loss)
I0204 08:51:44.756239 31982 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 08:51:55.301836 31982 solver.cpp:237] Iteration 260, loss = 0.719588
I0204 08:51:55.301905 31982 solver.cpp:253]     Train net output #0: loss = 0.719588 (* 1 = 0.719588 loss)
I0204 08:51:55.301918 31982 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 08:52:05.793360 31982 solver.cpp:237] Iteration 270, loss = 0.720803
I0204 08:52:05.793423 31982 solver.cpp:253]     Train net output #0: loss = 0.720803 (* 1 = 0.720803 loss)
I0204 08:52:05.793450 31982 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 08:52:16.378067 31982 solver.cpp:237] Iteration 280, loss = 0.697137
I0204 08:52:16.378276 31982 solver.cpp:253]     Train net output #0: loss = 0.697137 (* 1 = 0.697137 loss)
I0204 08:52:16.378289 31982 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 08:52:26.872668 31982 solver.cpp:237] Iteration 290, loss = 0.712349
I0204 08:52:26.872740 31982 solver.cpp:253]     Train net output #0: loss = 0.712349 (* 1 = 0.712349 loss)
I0204 08:52:26.872750 31982 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 08:52:36.469252 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_300.caffemodel
I0204 08:52:36.471424 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_300.solverstate
I0204 08:52:36.472355 31982 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 08:52:41.718776 31982 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:52:41.718839 31982 solver.cpp:409]     Test net output #1: loss = 0.710277 (* 1 = 0.710277 loss)
I0204 08:52:42.783176 31982 solver.cpp:237] Iteration 300, loss = 0.758042
I0204 08:52:42.783238 31982 solver.cpp:253]     Train net output #0: loss = 0.758042 (* 1 = 0.758042 loss)
I0204 08:52:42.783251 31982 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 08:52:53.322698 31982 solver.cpp:237] Iteration 310, loss = 0.696138
I0204 08:52:53.322865 31982 solver.cpp:253]     Train net output #0: loss = 0.696138 (* 1 = 0.696138 loss)
I0204 08:52:53.322880 31982 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 08:53:04.124719 31982 solver.cpp:237] Iteration 320, loss = 0.66981
I0204 08:53:04.124780 31982 solver.cpp:253]     Train net output #0: loss = 0.66981 (* 1 = 0.66981 loss)
I0204 08:53:04.124794 31982 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 08:53:14.799840 31982 solver.cpp:237] Iteration 330, loss = 0.74853
I0204 08:53:14.799897 31982 solver.cpp:253]     Train net output #0: loss = 0.74853 (* 1 = 0.74853 loss)
I0204 08:53:14.799909 31982 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 08:53:25.335836 31982 solver.cpp:237] Iteration 340, loss = 0.713715
I0204 08:53:25.336005 31982 solver.cpp:253]     Train net output #0: loss = 0.713715 (* 1 = 0.713715 loss)
I0204 08:53:25.336020 31982 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 08:53:35.912102 31982 solver.cpp:237] Iteration 350, loss = 0.723858
I0204 08:53:35.912160 31982 solver.cpp:253]     Train net output #0: loss = 0.723858 (* 1 = 0.723858 loss)
I0204 08:53:35.912173 31982 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 08:53:46.410068 31982 solver.cpp:237] Iteration 360, loss = 0.71984
I0204 08:53:46.410125 31982 solver.cpp:253]     Train net output #0: loss = 0.71984 (* 1 = 0.71984 loss)
I0204 08:53:46.410137 31982 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 08:53:57.288676 31982 solver.cpp:237] Iteration 370, loss = 0.688597
I0204 08:53:57.289157 31982 solver.cpp:253]     Train net output #0: loss = 0.688597 (* 1 = 0.688597 loss)
I0204 08:53:57.289171 31982 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 08:54:08.061405 31982 solver.cpp:237] Iteration 380, loss = 0.766963
I0204 08:54:08.061470 31982 solver.cpp:253]     Train net output #0: loss = 0.766963 (* 1 = 0.766963 loss)
I0204 08:54:08.061481 31982 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 08:54:18.625165 31982 solver.cpp:237] Iteration 390, loss = 0.710186
I0204 08:54:18.625226 31982 solver.cpp:253]     Train net output #0: loss = 0.710186 (* 1 = 0.710186 loss)
I0204 08:54:18.625252 31982 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 08:54:28.124459 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_400.caffemodel
I0204 08:54:28.126766 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_400.solverstate
I0204 08:54:28.127681 31982 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 08:54:33.274835 31982 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:54:33.274885 31982 solver.cpp:409]     Test net output #1: loss = 0.690189 (* 1 = 0.690189 loss)
I0204 08:54:34.323812 31982 solver.cpp:237] Iteration 400, loss = 0.688669
I0204 08:54:34.323863 31982 solver.cpp:253]     Train net output #0: loss = 0.688669 (* 1 = 0.688669 loss)
I0204 08:54:34.323875 31982 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 08:54:44.887523 31982 solver.cpp:237] Iteration 410, loss = 0.735023
I0204 08:54:44.887578 31982 solver.cpp:253]     Train net output #0: loss = 0.735023 (* 1 = 0.735023 loss)
I0204 08:54:44.887589 31982 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 08:54:55.331814 31982 solver.cpp:237] Iteration 420, loss = 0.671109
I0204 08:54:55.331882 31982 solver.cpp:253]     Train net output #0: loss = 0.671109 (* 1 = 0.671109 loss)
I0204 08:54:55.331895 31982 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 08:55:05.751812 31982 solver.cpp:237] Iteration 430, loss = 0.724137
I0204 08:55:05.751998 31982 solver.cpp:253]     Train net output #0: loss = 0.724137 (* 1 = 0.724137 loss)
I0204 08:55:05.752012 31982 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 08:55:16.304359 31982 solver.cpp:237] Iteration 440, loss = 0.70191
I0204 08:55:16.304419 31982 solver.cpp:253]     Train net output #0: loss = 0.70191 (* 1 = 0.70191 loss)
I0204 08:55:16.304430 31982 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 08:55:26.767796 31982 solver.cpp:237] Iteration 450, loss = 0.707969
I0204 08:55:26.767853 31982 solver.cpp:253]     Train net output #0: loss = 0.707969 (* 1 = 0.707969 loss)
I0204 08:55:26.767865 31982 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 08:55:37.151427 31982 solver.cpp:237] Iteration 460, loss = 0.781717
I0204 08:55:37.151576 31982 solver.cpp:253]     Train net output #0: loss = 0.781717 (* 1 = 0.781717 loss)
I0204 08:55:37.151590 31982 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 08:55:47.762079 31982 solver.cpp:237] Iteration 470, loss = 0.687182
I0204 08:55:47.762136 31982 solver.cpp:253]     Train net output #0: loss = 0.687182 (* 1 = 0.687182 loss)
I0204 08:55:47.762148 31982 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 08:55:58.103472 31982 solver.cpp:237] Iteration 480, loss = 0.710604
I0204 08:55:58.103550 31982 solver.cpp:253]     Train net output #0: loss = 0.710604 (* 1 = 0.710604 loss)
I0204 08:55:58.103596 31982 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 08:56:08.537195 31982 solver.cpp:237] Iteration 490, loss = 0.702289
I0204 08:56:08.537366 31982 solver.cpp:253]     Train net output #0: loss = 0.702289 (* 1 = 0.702289 loss)
I0204 08:56:08.537380 31982 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 08:56:17.875263 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_500.caffemodel
I0204 08:56:17.877573 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_500.solverstate
I0204 08:56:17.878546 31982 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 08:56:22.926311 31982 solver.cpp:409]     Test net output #0: accuracy = 0.565
I0204 08:56:22.926380 31982 solver.cpp:409]     Test net output #1: loss = 0.677138 (* 1 = 0.677138 loss)
I0204 08:56:24.072070 31982 solver.cpp:237] Iteration 500, loss = 0.692146
I0204 08:56:24.072142 31982 solver.cpp:253]     Train net output #0: loss = 0.692146 (* 1 = 0.692146 loss)
I0204 08:56:24.072154 31982 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 08:56:34.242039 31982 solver.cpp:237] Iteration 510, loss = 0.678189
I0204 08:56:34.242105 31982 solver.cpp:253]     Train net output #0: loss = 0.678189 (* 1 = 0.678189 loss)
I0204 08:56:34.242133 31982 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 08:56:44.413097 31982 solver.cpp:237] Iteration 520, loss = 0.686856
I0204 08:56:44.413322 31982 solver.cpp:253]     Train net output #0: loss = 0.686856 (* 1 = 0.686856 loss)
I0204 08:56:44.413336 31982 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 08:56:54.634297 31982 solver.cpp:237] Iteration 530, loss = 0.686673
I0204 08:56:54.634362 31982 solver.cpp:253]     Train net output #0: loss = 0.686673 (* 1 = 0.686673 loss)
I0204 08:56:54.634374 31982 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 08:57:04.903728 31982 solver.cpp:237] Iteration 540, loss = 0.756067
I0204 08:57:04.903792 31982 solver.cpp:253]     Train net output #0: loss = 0.756067 (* 1 = 0.756067 loss)
I0204 08:57:04.903805 31982 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 08:57:14.921130 31982 solver.cpp:237] Iteration 550, loss = 0.664291
I0204 08:57:14.921313 31982 solver.cpp:253]     Train net output #0: loss = 0.664291 (* 1 = 0.664291 loss)
I0204 08:57:14.921325 31982 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 08:57:24.814851 31982 solver.cpp:237] Iteration 560, loss = 0.692214
I0204 08:57:24.814913 31982 solver.cpp:253]     Train net output #0: loss = 0.692214 (* 1 = 0.692214 loss)
I0204 08:57:24.814925 31982 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 08:57:34.776890 31982 solver.cpp:237] Iteration 570, loss = 0.708718
I0204 08:57:34.776952 31982 solver.cpp:253]     Train net output #0: loss = 0.708718 (* 1 = 0.708718 loss)
I0204 08:57:34.776983 31982 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 08:57:44.536442 31982 solver.cpp:237] Iteration 580, loss = 0.673847
I0204 08:57:44.536496 31982 solver.cpp:253]     Train net output #0: loss = 0.673847 (* 1 = 0.673847 loss)
I0204 08:57:44.536509 31982 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 08:57:54.321880 31982 solver.cpp:237] Iteration 590, loss = 0.696759
I0204 08:57:54.322010 31982 solver.cpp:253]     Train net output #0: loss = 0.696759 (* 1 = 0.696759 loss)
I0204 08:57:54.322022 31982 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 08:58:03.147658 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_600.caffemodel
I0204 08:58:03.151010 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_600.solverstate
I0204 08:58:03.152022 31982 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 08:58:08.090024 31982 solver.cpp:409]     Test net output #0: accuracy = 0.623
I0204 08:58:08.090086 31982 solver.cpp:409]     Test net output #1: loss = 0.642004 (* 1 = 0.642004 loss)
I0204 08:58:09.081621 31982 solver.cpp:237] Iteration 600, loss = 0.681695
I0204 08:58:09.081675 31982 solver.cpp:253]     Train net output #0: loss = 0.681695 (* 1 = 0.681695 loss)
I0204 08:58:09.081686 31982 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 08:58:18.966609 31982 solver.cpp:237] Iteration 610, loss = 0.630244
I0204 08:58:18.966665 31982 solver.cpp:253]     Train net output #0: loss = 0.630244 (* 1 = 0.630244 loss)
I0204 08:58:18.966678 31982 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 08:58:28.852293 31982 solver.cpp:237] Iteration 620, loss = 0.678053
I0204 08:58:28.852453 31982 solver.cpp:253]     Train net output #0: loss = 0.678053 (* 1 = 0.678053 loss)
I0204 08:58:28.852465 31982 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 08:58:38.535028 31982 solver.cpp:237] Iteration 630, loss = 0.614951
I0204 08:58:38.535082 31982 solver.cpp:253]     Train net output #0: loss = 0.614951 (* 1 = 0.614951 loss)
I0204 08:58:38.535094 31982 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 08:58:48.306680 31982 solver.cpp:237] Iteration 640, loss = 0.597259
I0204 08:58:48.306737 31982 solver.cpp:253]     Train net output #0: loss = 0.597259 (* 1 = 0.597259 loss)
I0204 08:58:48.306763 31982 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 08:58:58.205726 31982 solver.cpp:237] Iteration 650, loss = 0.604317
I0204 08:58:58.205782 31982 solver.cpp:253]     Train net output #0: loss = 0.604317 (* 1 = 0.604317 loss)
I0204 08:58:58.205795 31982 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 08:59:07.877187 31982 solver.cpp:237] Iteration 660, loss = 0.58121
I0204 08:59:07.877393 31982 solver.cpp:253]     Train net output #0: loss = 0.58121 (* 1 = 0.58121 loss)
I0204 08:59:07.877405 31982 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 08:59:17.603129 31982 solver.cpp:237] Iteration 670, loss = 0.678419
I0204 08:59:17.603184 31982 solver.cpp:253]     Train net output #0: loss = 0.678419 (* 1 = 0.678419 loss)
I0204 08:59:17.603196 31982 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 08:59:27.213413 31982 solver.cpp:237] Iteration 680, loss = 0.650549
I0204 08:59:27.213474 31982 solver.cpp:253]     Train net output #0: loss = 0.650549 (* 1 = 0.650549 loss)
I0204 08:59:27.213487 31982 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 08:59:37.004245 31982 solver.cpp:237] Iteration 690, loss = 0.641474
I0204 08:59:37.004304 31982 solver.cpp:253]     Train net output #0: loss = 0.641474 (* 1 = 0.641474 loss)
I0204 08:59:37.004317 31982 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 08:59:45.583169 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_700.caffemodel
I0204 08:59:45.585654 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_700.solverstate
I0204 08:59:45.586680 31982 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 08:59:50.234174 31982 solver.cpp:409]     Test net output #0: accuracy = 0.683
I0204 08:59:50.234236 31982 solver.cpp:409]     Test net output #1: loss = 0.591872 (* 1 = 0.591872 loss)
I0204 08:59:51.179569 31982 solver.cpp:237] Iteration 700, loss = 0.660711
I0204 08:59:51.179638 31982 solver.cpp:253]     Train net output #0: loss = 0.660711 (* 1 = 0.660711 loss)
I0204 08:59:51.179652 31982 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 09:00:00.832276 31982 solver.cpp:237] Iteration 710, loss = 0.634635
I0204 09:00:00.832336 31982 solver.cpp:253]     Train net output #0: loss = 0.634635 (* 1 = 0.634635 loss)
I0204 09:00:00.832350 31982 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 09:00:10.080961 31982 solver.cpp:237] Iteration 720, loss = 0.618741
I0204 09:00:10.081018 31982 solver.cpp:253]     Train net output #0: loss = 0.618741 (* 1 = 0.618741 loss)
I0204 09:00:10.081030 31982 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 09:00:19.434752 31982 solver.cpp:237] Iteration 730, loss = 0.597387
I0204 09:00:19.434916 31982 solver.cpp:253]     Train net output #0: loss = 0.597387 (* 1 = 0.597387 loss)
I0204 09:00:19.434934 31982 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 09:00:28.591025 31982 solver.cpp:237] Iteration 740, loss = 0.623191
I0204 09:00:28.591081 31982 solver.cpp:253]     Train net output #0: loss = 0.623191 (* 1 = 0.623191 loss)
I0204 09:00:28.591094 31982 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 09:00:37.723302 31982 solver.cpp:237] Iteration 750, loss = 0.64234
I0204 09:00:37.723368 31982 solver.cpp:253]     Train net output #0: loss = 0.64234 (* 1 = 0.64234 loss)
I0204 09:00:37.723379 31982 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 09:00:46.730803 31982 solver.cpp:237] Iteration 760, loss = 0.563036
I0204 09:00:46.730877 31982 solver.cpp:253]     Train net output #0: loss = 0.563036 (* 1 = 0.563036 loss)
I0204 09:00:46.730890 31982 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 09:00:55.399886 31982 solver.cpp:237] Iteration 770, loss = 0.564927
I0204 09:00:55.400061 31982 solver.cpp:253]     Train net output #0: loss = 0.564927 (* 1 = 0.564927 loss)
I0204 09:00:55.400080 31982 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 09:01:04.012082 31982 solver.cpp:237] Iteration 780, loss = 0.561314
I0204 09:01:04.012145 31982 solver.cpp:253]     Train net output #0: loss = 0.561314 (* 1 = 0.561314 loss)
I0204 09:01:04.012157 31982 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 09:01:12.502462 31982 solver.cpp:237] Iteration 790, loss = 0.554471
I0204 09:01:12.502522 31982 solver.cpp:253]     Train net output #0: loss = 0.554471 (* 1 = 0.554471 loss)
I0204 09:01:12.502534 31982 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 09:01:20.053030 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_800.caffemodel
I0204 09:01:20.055351 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_800.solverstate
I0204 09:01:20.056385 31982 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 09:01:24.133990 31982 solver.cpp:409]     Test net output #0: accuracy = 0.776
I0204 09:01:24.134045 31982 solver.cpp:409]     Test net output #1: loss = 0.482604 (* 1 = 0.482604 loss)
I0204 09:01:24.962010 31982 solver.cpp:237] Iteration 800, loss = 0.527953
I0204 09:01:24.962064 31982 solver.cpp:253]     Train net output #0: loss = 0.527953 (* 1 = 0.527953 loss)
I0204 09:01:24.962080 31982 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 09:01:33.221124 31982 solver.cpp:237] Iteration 810, loss = 0.557393
I0204 09:01:33.221348 31982 solver.cpp:253]     Train net output #0: loss = 0.557393 (* 1 = 0.557393 loss)
I0204 09:01:33.221361 31982 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 09:01:41.328441 31982 solver.cpp:237] Iteration 820, loss = 0.464298
I0204 09:01:41.328502 31982 solver.cpp:253]     Train net output #0: loss = 0.464298 (* 1 = 0.464298 loss)
I0204 09:01:41.328515 31982 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 09:01:49.278822 31982 solver.cpp:237] Iteration 830, loss = 0.523232
I0204 09:01:49.278887 31982 solver.cpp:253]     Train net output #0: loss = 0.523232 (* 1 = 0.523232 loss)
I0204 09:01:49.278898 31982 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 09:01:57.535563 31982 solver.cpp:237] Iteration 840, loss = 0.520126
I0204 09:01:57.535624 31982 solver.cpp:253]     Train net output #0: loss = 0.520126 (* 1 = 0.520126 loss)
I0204 09:01:57.535636 31982 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 09:02:05.634445 31982 solver.cpp:237] Iteration 850, loss = 0.455484
I0204 09:02:05.634620 31982 solver.cpp:253]     Train net output #0: loss = 0.455484 (* 1 = 0.455484 loss)
I0204 09:02:05.634634 31982 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 09:02:13.768816 31982 solver.cpp:237] Iteration 860, loss = 0.451052
I0204 09:02:13.768874 31982 solver.cpp:253]     Train net output #0: loss = 0.451052 (* 1 = 0.451052 loss)
I0204 09:02:13.768887 31982 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 09:02:22.098109 31982 solver.cpp:237] Iteration 870, loss = 0.503246
I0204 09:02:22.098165 31982 solver.cpp:253]     Train net output #0: loss = 0.503246 (* 1 = 0.503246 loss)
I0204 09:02:22.098176 31982 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 09:02:30.358149 31982 solver.cpp:237] Iteration 880, loss = 0.410081
I0204 09:02:30.358207 31982 solver.cpp:253]     Train net output #0: loss = 0.410081 (* 1 = 0.410081 loss)
I0204 09:02:30.358219 31982 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 09:02:38.743325 31982 solver.cpp:237] Iteration 890, loss = 0.45394
I0204 09:02:38.743474 31982 solver.cpp:253]     Train net output #0: loss = 0.45394 (* 1 = 0.45394 loss)
I0204 09:02:38.743486 31982 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 09:02:46.237066 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_900.caffemodel
I0204 09:02:46.239388 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_900.solverstate
I0204 09:02:46.240384 31982 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 09:02:50.309877 31982 solver.cpp:409]     Test net output #0: accuracy = 0.856
I0204 09:02:50.309927 31982 solver.cpp:409]     Test net output #1: loss = 0.344162 (* 1 = 0.344162 loss)
I0204 09:02:51.149245 31982 solver.cpp:237] Iteration 900, loss = 0.372502
I0204 09:02:51.149294 31982 solver.cpp:253]     Train net output #0: loss = 0.372502 (* 1 = 0.372502 loss)
I0204 09:02:51.149307 31982 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 09:02:59.615458 31982 solver.cpp:237] Iteration 910, loss = 0.474595
I0204 09:02:59.615515 31982 solver.cpp:253]     Train net output #0: loss = 0.474595 (* 1 = 0.474595 loss)
I0204 09:02:59.615528 31982 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 09:03:07.969202 31982 solver.cpp:237] Iteration 920, loss = 0.382094
I0204 09:03:07.969257 31982 solver.cpp:253]     Train net output #0: loss = 0.382094 (* 1 = 0.382094 loss)
I0204 09:03:07.969274 31982 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 09:03:16.109155 31982 solver.cpp:237] Iteration 930, loss = 0.28168
I0204 09:03:16.109369 31982 solver.cpp:253]     Train net output #0: loss = 0.28168 (* 1 = 0.28168 loss)
I0204 09:03:16.109381 31982 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 09:03:24.205976 31982 solver.cpp:237] Iteration 940, loss = 0.288342
I0204 09:03:24.206045 31982 solver.cpp:253]     Train net output #0: loss = 0.288342 (* 1 = 0.288342 loss)
I0204 09:03:24.206059 31982 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 09:03:32.269860 31982 solver.cpp:237] Iteration 950, loss = 0.325544
I0204 09:03:32.269913 31982 solver.cpp:253]     Train net output #0: loss = 0.325544 (* 1 = 0.325544 loss)
I0204 09:03:32.269924 31982 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 09:03:40.448909 31982 solver.cpp:237] Iteration 960, loss = 0.366905
I0204 09:03:40.448962 31982 solver.cpp:253]     Train net output #0: loss = 0.366905 (* 1 = 0.366905 loss)
I0204 09:03:40.448974 31982 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 09:03:48.885287 31982 solver.cpp:237] Iteration 970, loss = 0.205828
I0204 09:03:48.885459 31982 solver.cpp:253]     Train net output #0: loss = 0.205828 (* 1 = 0.205828 loss)
I0204 09:03:48.885471 31982 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 09:03:57.387184 31982 solver.cpp:237] Iteration 980, loss = 0.187626
I0204 09:03:57.387243 31982 solver.cpp:253]     Train net output #0: loss = 0.187626 (* 1 = 0.187626 loss)
I0204 09:03:57.387255 31982 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 09:04:05.819661 31982 solver.cpp:237] Iteration 990, loss = 0.225853
I0204 09:04:05.819722 31982 solver.cpp:253]     Train net output #0: loss = 0.225853 (* 1 = 0.225853 loss)
I0204 09:04:05.819736 31982 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 09:04:13.363950 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1000.caffemodel
I0204 09:04:13.366286 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1000.solverstate
I0204 09:04:13.367378 31982 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 09:04:17.604147 31982 solver.cpp:409]     Test net output #0: accuracy = 0.953
I0204 09:04:17.604215 31982 solver.cpp:409]     Test net output #1: loss = 0.12436 (* 1 = 0.12436 loss)
I0204 09:04:18.482347 31982 solver.cpp:237] Iteration 1000, loss = 0.173882
I0204 09:04:18.482401 31982 solver.cpp:253]     Train net output #0: loss = 0.173882 (* 1 = 0.173882 loss)
I0204 09:04:18.482414 31982 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 09:04:27.290374 31982 solver.cpp:237] Iteration 1010, loss = 0.104414
I0204 09:04:27.290581 31982 solver.cpp:253]     Train net output #0: loss = 0.104414 (* 1 = 0.104414 loss)
I0204 09:04:27.290596 31982 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 09:04:36.107894 31982 solver.cpp:237] Iteration 1020, loss = 0.129688
I0204 09:04:36.107954 31982 solver.cpp:253]     Train net output #0: loss = 0.129688 (* 1 = 0.129688 loss)
I0204 09:04:36.107967 31982 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 09:04:44.908058 31982 solver.cpp:237] Iteration 1030, loss = 0.149546
I0204 09:04:44.908113 31982 solver.cpp:253]     Train net output #0: loss = 0.149546 (* 1 = 0.149546 loss)
I0204 09:04:44.908123 31982 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 09:04:53.613783 31982 solver.cpp:237] Iteration 1040, loss = 0.117831
I0204 09:04:53.613839 31982 solver.cpp:253]     Train net output #0: loss = 0.117831 (* 1 = 0.117831 loss)
I0204 09:04:53.613852 31982 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 09:05:02.288022 31982 solver.cpp:237] Iteration 1050, loss = 0.188054
I0204 09:05:02.293092 31982 solver.cpp:253]     Train net output #0: loss = 0.188054 (* 1 = 0.188054 loss)
I0204 09:05:02.293109 31982 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 09:05:11.319183 31982 solver.cpp:237] Iteration 1060, loss = 0.0777842
I0204 09:05:11.319236 31982 solver.cpp:253]     Train net output #0: loss = 0.0777842 (* 1 = 0.0777842 loss)
I0204 09:05:11.319247 31982 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 09:05:20.554527 31982 solver.cpp:237] Iteration 1070, loss = 0.125272
I0204 09:05:20.554589 31982 solver.cpp:253]     Train net output #0: loss = 0.125272 (* 1 = 0.125272 loss)
I0204 09:05:20.554601 31982 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 09:05:29.519717 31982 solver.cpp:237] Iteration 1080, loss = 0.0983754
I0204 09:05:29.519776 31982 solver.cpp:253]     Train net output #0: loss = 0.0983754 (* 1 = 0.0983754 loss)
I0204 09:05:29.519789 31982 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 09:05:38.683506 31982 solver.cpp:237] Iteration 1090, loss = 0.0453719
I0204 09:05:38.683631 31982 solver.cpp:253]     Train net output #0: loss = 0.0453719 (* 1 = 0.0453719 loss)
I0204 09:05:38.683645 31982 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 09:05:47.128177 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1100.caffemodel
I0204 09:05:47.130527 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1100.solverstate
I0204 09:05:47.131484 31982 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 09:05:51.656605 31982 solver.cpp:409]     Test net output #0: accuracy = 0.985
I0204 09:05:51.656667 31982 solver.cpp:409]     Test net output #1: loss = 0.0442827 (* 1 = 0.0442827 loss)
I0204 09:05:52.590108 31982 solver.cpp:237] Iteration 1100, loss = 0.106713
I0204 09:05:52.590170 31982 solver.cpp:253]     Train net output #0: loss = 0.106713 (* 1 = 0.106713 loss)
I0204 09:05:52.590183 31982 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 09:06:01.720118 31982 solver.cpp:237] Iteration 1110, loss = 0.0272446
I0204 09:06:01.720186 31982 solver.cpp:253]     Train net output #0: loss = 0.0272446 (* 1 = 0.0272446 loss)
I0204 09:06:01.720198 31982 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 09:06:10.867228 31982 solver.cpp:237] Iteration 1120, loss = 0.0774147
I0204 09:06:10.867372 31982 solver.cpp:253]     Train net output #0: loss = 0.0774147 (* 1 = 0.0774147 loss)
I0204 09:06:10.867385 31982 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 09:06:20.318877 31982 solver.cpp:237] Iteration 1130, loss = 0.0539535
I0204 09:06:20.318940 31982 solver.cpp:253]     Train net output #0: loss = 0.0539535 (* 1 = 0.0539535 loss)
I0204 09:06:20.318953 31982 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 09:06:29.816539 31982 solver.cpp:237] Iteration 1140, loss = 0.0379632
I0204 09:06:29.816604 31982 solver.cpp:253]     Train net output #0: loss = 0.0379632 (* 1 = 0.0379632 loss)
I0204 09:06:29.816615 31982 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 09:06:39.245004 31982 solver.cpp:237] Iteration 1150, loss = 0.0943092
I0204 09:06:39.245064 31982 solver.cpp:253]     Train net output #0: loss = 0.0943092 (* 1 = 0.0943092 loss)
I0204 09:06:39.245076 31982 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 09:06:48.821449 31982 solver.cpp:237] Iteration 1160, loss = 0.0567859
I0204 09:06:48.821646 31982 solver.cpp:253]     Train net output #0: loss = 0.0567859 (* 1 = 0.0567859 loss)
I0204 09:06:48.821658 31982 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 09:06:58.317572 31982 solver.cpp:237] Iteration 1170, loss = 0.0149132
I0204 09:06:58.317628 31982 solver.cpp:253]     Train net output #0: loss = 0.0149132 (* 1 = 0.0149132 loss)
I0204 09:06:58.317641 31982 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 09:07:07.929802 31982 solver.cpp:237] Iteration 1180, loss = 0.0185576
I0204 09:07:07.929860 31982 solver.cpp:253]     Train net output #0: loss = 0.0185576 (* 1 = 0.0185576 loss)
I0204 09:07:07.929872 31982 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 09:07:17.648787 31982 solver.cpp:237] Iteration 1190, loss = 0.0282585
I0204 09:07:17.648847 31982 solver.cpp:253]     Train net output #0: loss = 0.0282585 (* 1 = 0.0282585 loss)
I0204 09:07:17.648860 31982 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 09:07:26.350410 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1200.caffemodel
I0204 09:07:26.352872 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1200.solverstate
I0204 09:07:26.353925 31982 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 09:07:31.136816 31982 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 09:07:31.136873 31982 solver.cpp:409]     Test net output #1: loss = 0.00766071 (* 1 = 0.00766071 loss)
I0204 09:07:32.118294 31982 solver.cpp:237] Iteration 1200, loss = 0.0229758
I0204 09:07:32.118351 31982 solver.cpp:253]     Train net output #0: loss = 0.0229758 (* 1 = 0.0229758 loss)
I0204 09:07:32.118365 31982 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 09:07:41.731798 31982 solver.cpp:237] Iteration 1210, loss = 0.0270351
I0204 09:07:41.731868 31982 solver.cpp:253]     Train net output #0: loss = 0.0270351 (* 1 = 0.0270351 loss)
I0204 09:07:41.731879 31982 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 09:07:51.428778 31982 solver.cpp:237] Iteration 1220, loss = 0.0227159
I0204 09:07:51.428835 31982 solver.cpp:253]     Train net output #0: loss = 0.022716 (* 1 = 0.022716 loss)
I0204 09:07:51.428848 31982 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 09:08:01.252815 31982 solver.cpp:237] Iteration 1230, loss = 0.0173439
I0204 09:08:01.257280 31982 solver.cpp:253]     Train net output #0: loss = 0.017344 (* 1 = 0.017344 loss)
I0204 09:08:01.257316 31982 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 09:08:10.876411 31982 solver.cpp:237] Iteration 1240, loss = 0.0701287
I0204 09:08:10.876480 31982 solver.cpp:253]     Train net output #0: loss = 0.0701287 (* 1 = 0.0701287 loss)
I0204 09:08:10.876498 31982 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 09:08:20.528501 31982 solver.cpp:237] Iteration 1250, loss = 0.0569802
I0204 09:08:20.528568 31982 solver.cpp:253]     Train net output #0: loss = 0.0569803 (* 1 = 0.0569803 loss)
I0204 09:08:20.528580 31982 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 09:08:30.253135 31982 solver.cpp:237] Iteration 1260, loss = 0.0221122
I0204 09:08:30.253208 31982 solver.cpp:253]     Train net output #0: loss = 0.0221122 (* 1 = 0.0221122 loss)
I0204 09:08:30.253221 31982 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 09:08:40.020719 31982 solver.cpp:237] Iteration 1270, loss = 0.0240979
I0204 09:08:40.020903 31982 solver.cpp:253]     Train net output #0: loss = 0.0240979 (* 1 = 0.0240979 loss)
I0204 09:08:40.020916 31982 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 09:08:49.744979 31982 solver.cpp:237] Iteration 1280, loss = 0.0523968
I0204 09:08:49.745043 31982 solver.cpp:253]     Train net output #0: loss = 0.0523968 (* 1 = 0.0523968 loss)
I0204 09:08:49.745055 31982 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 09:08:59.368588 31982 solver.cpp:237] Iteration 1290, loss = 0.0037555
I0204 09:08:59.368648 31982 solver.cpp:253]     Train net output #0: loss = 0.00375553 (* 1 = 0.00375553 loss)
I0204 09:08:59.368659 31982 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 09:09:08.014073 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1300.caffemodel
I0204 09:09:08.016335 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1300.solverstate
I0204 09:09:08.017277 31982 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 09:09:12.741972 31982 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 09:09:12.742153 31982 solver.cpp:409]     Test net output #1: loss = 0.0193472 (* 1 = 0.0193472 loss)
I0204 09:09:13.736340 31982 solver.cpp:237] Iteration 1300, loss = 0.127786
I0204 09:09:13.736397 31982 solver.cpp:253]     Train net output #0: loss = 0.127786 (* 1 = 0.127786 loss)
I0204 09:09:13.736409 31982 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 09:09:23.374033 31982 solver.cpp:237] Iteration 1310, loss = 0.0052202
I0204 09:09:23.374089 31982 solver.cpp:253]     Train net output #0: loss = 0.00522023 (* 1 = 0.00522023 loss)
I0204 09:09:23.374101 31982 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 09:09:33.185228 31982 solver.cpp:237] Iteration 1320, loss = 0.0954829
I0204 09:09:33.185288 31982 solver.cpp:253]     Train net output #0: loss = 0.0954829 (* 1 = 0.0954829 loss)
I0204 09:09:33.185300 31982 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 09:09:43.127012 31982 solver.cpp:237] Iteration 1330, loss = 0.0136547
I0204 09:09:43.127172 31982 solver.cpp:253]     Train net output #0: loss = 0.0136548 (* 1 = 0.0136548 loss)
I0204 09:09:43.127185 31982 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 09:09:52.956410 31982 solver.cpp:237] Iteration 1340, loss = 0.0138391
I0204 09:09:52.956472 31982 solver.cpp:253]     Train net output #0: loss = 0.0138391 (* 1 = 0.0138391 loss)
I0204 09:09:52.956485 31982 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 09:10:02.521384 31982 solver.cpp:237] Iteration 1350, loss = 0.00164541
I0204 09:10:02.521441 31982 solver.cpp:253]     Train net output #0: loss = 0.00164545 (* 1 = 0.00164545 loss)
I0204 09:10:02.521453 31982 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 09:10:12.262392 31982 solver.cpp:237] Iteration 1360, loss = 0.00935221
I0204 09:10:12.262464 31982 solver.cpp:253]     Train net output #0: loss = 0.00935225 (* 1 = 0.00935225 loss)
I0204 09:10:12.262476 31982 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 09:10:21.632939 31982 solver.cpp:237] Iteration 1370, loss = 0.0119798
I0204 09:10:21.633105 31982 solver.cpp:253]     Train net output #0: loss = 0.0119798 (* 1 = 0.0119798 loss)
I0204 09:10:21.633118 31982 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 09:10:31.181675 31982 solver.cpp:237] Iteration 1380, loss = 0.0341874
I0204 09:10:31.181732 31982 solver.cpp:253]     Train net output #0: loss = 0.0341874 (* 1 = 0.0341874 loss)
I0204 09:10:31.181745 31982 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 09:10:40.726692 31982 solver.cpp:237] Iteration 1390, loss = 0.0186803
I0204 09:10:40.726763 31982 solver.cpp:253]     Train net output #0: loss = 0.0186803 (* 1 = 0.0186803 loss)
I0204 09:10:40.726809 31982 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 09:10:49.338589 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1400.caffemodel
I0204 09:10:49.340812 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1400.solverstate
I0204 09:10:49.341771 31982 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 09:10:54.019042 31982 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 09:10:54.019249 31982 solver.cpp:409]     Test net output #1: loss = 0.00323365 (* 1 = 0.00323365 loss)
I0204 09:10:54.994779 31982 solver.cpp:237] Iteration 1400, loss = 0.00964573
I0204 09:10:54.994833 31982 solver.cpp:253]     Train net output #0: loss = 0.00964575 (* 1 = 0.00964575 loss)
I0204 09:10:54.994845 31982 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 09:11:04.573575 31982 solver.cpp:237] Iteration 1410, loss = 0.0150067
I0204 09:11:04.573632 31982 solver.cpp:253]     Train net output #0: loss = 0.0150068 (* 1 = 0.0150068 loss)
I0204 09:11:04.573644 31982 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 09:11:13.969059 31982 solver.cpp:237] Iteration 1420, loss = 0.00274361
I0204 09:11:13.969113 31982 solver.cpp:253]     Train net output #0: loss = 0.00274364 (* 1 = 0.00274364 loss)
I0204 09:11:13.969126 31982 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 09:11:23.637634 31982 solver.cpp:237] Iteration 1430, loss = 0.00325625
I0204 09:11:23.637689 31982 solver.cpp:253]     Train net output #0: loss = 0.00325628 (* 1 = 0.00325628 loss)
I0204 09:11:23.637701 31982 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 09:11:33.243943 31982 solver.cpp:237] Iteration 1440, loss = 0.00416894
I0204 09:11:33.244124 31982 solver.cpp:253]     Train net output #0: loss = 0.00416897 (* 1 = 0.00416897 loss)
I0204 09:11:33.244138 31982 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 09:11:42.667512 31982 solver.cpp:237] Iteration 1450, loss = 0.00108477
I0204 09:11:42.667582 31982 solver.cpp:253]     Train net output #0: loss = 0.0010848 (* 1 = 0.0010848 loss)
I0204 09:11:42.667593 31982 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 09:11:52.182324 31982 solver.cpp:237] Iteration 1460, loss = 0.0325938
I0204 09:11:52.182379 31982 solver.cpp:253]     Train net output #0: loss = 0.0325938 (* 1 = 0.0325938 loss)
I0204 09:11:52.182389 31982 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 09:12:01.735628 31982 solver.cpp:237] Iteration 1470, loss = 0.00176342
I0204 09:12:01.735682 31982 solver.cpp:253]     Train net output #0: loss = 0.00176344 (* 1 = 0.00176344 loss)
I0204 09:12:01.735694 31982 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 09:12:11.480789 31982 solver.cpp:237] Iteration 1480, loss = 0.00760049
I0204 09:12:11.480978 31982 solver.cpp:253]     Train net output #0: loss = 0.0076005 (* 1 = 0.0076005 loss)
I0204 09:12:11.480991 31982 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 09:12:21.140079 31982 solver.cpp:237] Iteration 1490, loss = 0.0112766
I0204 09:12:21.140136 31982 solver.cpp:253]     Train net output #0: loss = 0.0112767 (* 1 = 0.0112767 loss)
I0204 09:12:21.140148 31982 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 09:12:29.624505 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1500.caffemodel
I0204 09:12:29.626667 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1500.solverstate
I0204 09:12:29.627578 31982 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 09:12:34.244653 31982 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 09:12:34.244704 31982 solver.cpp:409]     Test net output #1: loss = 0.00231519 (* 1 = 0.00231519 loss)
I0204 09:12:35.193449 31982 solver.cpp:237] Iteration 1500, loss = 0.000806823
I0204 09:12:35.193497 31982 solver.cpp:253]     Train net output #0: loss = 0.000806844 (* 1 = 0.000806844 loss)
I0204 09:12:35.193509 31982 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 09:12:44.790110 31982 solver.cpp:237] Iteration 1510, loss = 0.000983884
I0204 09:12:44.790355 31982 solver.cpp:253]     Train net output #0: loss = 0.000983915 (* 1 = 0.000983915 loss)
I0204 09:12:44.790369 31982 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 09:12:54.202265 31982 solver.cpp:237] Iteration 1520, loss = 0.00272848
I0204 09:12:54.202334 31982 solver.cpp:253]     Train net output #0: loss = 0.00272851 (* 1 = 0.00272851 loss)
I0204 09:12:54.202347 31982 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 09:13:03.592016 31982 solver.cpp:237] Iteration 1530, loss = 0.00263015
I0204 09:13:03.592082 31982 solver.cpp:253]     Train net output #0: loss = 0.00263018 (* 1 = 0.00263018 loss)
I0204 09:13:03.592093 31982 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 09:13:12.996778 31982 solver.cpp:237] Iteration 1540, loss = 0.0806524
I0204 09:13:12.996840 31982 solver.cpp:253]     Train net output #0: loss = 0.0806525 (* 1 = 0.0806525 loss)
I0204 09:13:12.996850 31982 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 09:13:22.573916 31982 solver.cpp:237] Iteration 1550, loss = 0.0101166
I0204 09:13:22.574091 31982 solver.cpp:253]     Train net output #0: loss = 0.0101166 (* 1 = 0.0101166 loss)
I0204 09:13:22.574105 31982 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 09:13:32.097041 31982 solver.cpp:237] Iteration 1560, loss = 0.0163886
I0204 09:13:32.097107 31982 solver.cpp:253]     Train net output #0: loss = 0.0163886 (* 1 = 0.0163886 loss)
I0204 09:13:32.097121 31982 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 09:13:41.676286 31982 solver.cpp:237] Iteration 1570, loss = 0.00787373
I0204 09:13:41.676345 31982 solver.cpp:253]     Train net output #0: loss = 0.00787375 (* 1 = 0.00787375 loss)
I0204 09:13:41.676357 31982 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 09:13:51.235594 31982 solver.cpp:237] Iteration 1580, loss = 0.0284461
I0204 09:13:51.235674 31982 solver.cpp:253]     Train net output #0: loss = 0.0284461 (* 1 = 0.0284461 loss)
I0204 09:13:51.235761 31982 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 09:14:00.639983 31982 solver.cpp:237] Iteration 1590, loss = 0.0135926
I0204 09:14:00.640157 31982 solver.cpp:253]     Train net output #0: loss = 0.0135926 (* 1 = 0.0135926 loss)
I0204 09:14:00.640169 31982 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 09:14:09.075356 31982 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1600.caffemodel
I0204 09:14:09.077567 31982 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1600.solverstate
I0204 09:14:09.532362 31982 solver.cpp:321] Iteration 1600, loss = 0.0183728
I0204 09:14:09.532415 31982 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 09:14:14.060029 31982 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 09:14:14.060084 31982 solver.cpp:409]     Test net output #1: loss = 0.0036197 (* 1 = 0.0036197 loss)
I0204 09:14:14.060093 31982 solver.cpp:326] Optimization Done.
I0204 09:14:14.060099 31982 caffe.cpp:215] Optimization Done.
