Log file created at: 2016/02/04 08:47:10
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 08:47:10.474221 31953 caffe.cpp:177] Use CPU.
I0204 08:47:10.474802 31953 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap_"
solver_mode: CPU
random_seed: 0
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/train_val.prototxt"
I0204 08:47:10.474974 31953 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/train_val.prototxt
I0204 08:47:10.475680 31953 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 08:47:10.475713 31953 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 08:47:10.475970 31953 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.476114 31953 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.476305 31953 net.cpp:106] Creating Layer data
I0204 08:47:10.476325 31953 net.cpp:411] data -> data
I0204 08:47:10.476398 31953 net.cpp:411] data -> label
I0204 08:47:10.476423 31953 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 08:47:10.476536 31956 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 08:47:10.477473 31953 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.530798 31953 net.cpp:150] Setting up data
I0204 08:47:10.531044 31953 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.531059 31953 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.531065 31953 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.531085 31953 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.531278 31953 net.cpp:106] Creating Layer conv1
I0204 08:47:10.531291 31953 net.cpp:454] conv1 <- data
I0204 08:47:10.531311 31953 net.cpp:411] conv1 -> conv1
I0204 08:47:10.531451 31953 net.cpp:150] Setting up conv1
I0204 08:47:10.531464 31953 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.531471 31953 net.cpp:165] Memory required for data: 39972000
I0204 08:47:10.531489 31953 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.531502 31953 net.cpp:106] Creating Layer relu1
I0204 08:47:10.531510 31953 net.cpp:454] relu1 <- conv1
I0204 08:47:10.531520 31953 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.531533 31953 net.cpp:150] Setting up relu1
I0204 08:47:10.531541 31953 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.531548 31953 net.cpp:165] Memory required for data: 59332000
I0204 08:47:10.531553 31953 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.531564 31953 net.cpp:106] Creating Layer pool1
I0204 08:47:10.531570 31953 net.cpp:454] pool1 <- conv1
I0204 08:47:10.531581 31953 net.cpp:411] pool1 -> pool1
I0204 08:47:10.531605 31953 net.cpp:150] Setting up pool1
I0204 08:47:10.531613 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.531620 31953 net.cpp:165] Memory required for data: 63997600
I0204 08:47:10.531625 31953 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.531647 31953 net.cpp:106] Creating Layer norm1
I0204 08:47:10.531666 31953 net.cpp:454] norm1 <- pool1
I0204 08:47:10.531675 31953 net.cpp:411] norm1 -> norm1
I0204 08:47:10.531693 31953 net.cpp:150] Setting up norm1
I0204 08:47:10.531702 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.531708 31953 net.cpp:165] Memory required for data: 68663200
I0204 08:47:10.531713 31953 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.531724 31953 net.cpp:106] Creating Layer conv2
I0204 08:47:10.531733 31953 net.cpp:454] conv2 <- norm1
I0204 08:47:10.531744 31953 net.cpp:411] conv2 -> conv2
I0204 08:47:10.531796 31953 net.cpp:150] Setting up conv2
I0204 08:47:10.531807 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.531812 31953 net.cpp:165] Memory required for data: 73328800
I0204 08:47:10.531823 31953 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.531832 31953 net.cpp:106] Creating Layer relu2
I0204 08:47:10.531838 31953 net.cpp:454] relu2 <- conv2
I0204 08:47:10.531847 31953 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.531857 31953 net.cpp:150] Setting up relu2
I0204 08:47:10.531863 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.531868 31953 net.cpp:165] Memory required for data: 77994400
I0204 08:47:10.531877 31953 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.531885 31953 net.cpp:106] Creating Layer pool2
I0204 08:47:10.531891 31953 net.cpp:454] pool2 <- conv2
I0204 08:47:10.531899 31953 net.cpp:411] pool2 -> pool2
I0204 08:47:10.531910 31953 net.cpp:150] Setting up pool2
I0204 08:47:10.531918 31953 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.531929 31953 net.cpp:165] Memory required for data: 79076000
I0204 08:47:10.531935 31953 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.531949 31953 net.cpp:106] Creating Layer norm2
I0204 08:47:10.531955 31953 net.cpp:454] norm2 <- pool2
I0204 08:47:10.531965 31953 net.cpp:411] norm2 -> norm2
I0204 08:47:10.531975 31953 net.cpp:150] Setting up norm2
I0204 08:47:10.531982 31953 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.531988 31953 net.cpp:165] Memory required for data: 80157600
I0204 08:47:10.531994 31953 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.532006 31953 net.cpp:106] Creating Layer conv3
I0204 08:47:10.532011 31953 net.cpp:454] conv3 <- norm2
I0204 08:47:10.532022 31953 net.cpp:411] conv3 -> conv3
I0204 08:47:10.532057 31953 net.cpp:150] Setting up conv3
I0204 08:47:10.532065 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532071 31953 net.cpp:165] Memory required for data: 80698400
I0204 08:47:10.532083 31953 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.532094 31953 net.cpp:106] Creating Layer relu3
I0204 08:47:10.532100 31953 net.cpp:454] relu3 <- conv3
I0204 08:47:10.532109 31953 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.532116 31953 net.cpp:150] Setting up relu3
I0204 08:47:10.532124 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532130 31953 net.cpp:165] Memory required for data: 81239200
I0204 08:47:10.532135 31953 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.532146 31953 net.cpp:106] Creating Layer conv4
I0204 08:47:10.532152 31953 net.cpp:454] conv4 <- conv3
I0204 08:47:10.532162 31953 net.cpp:411] conv4 -> conv4
I0204 08:47:10.532186 31953 net.cpp:150] Setting up conv4
I0204 08:47:10.532194 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532199 31953 net.cpp:165] Memory required for data: 81780000
I0204 08:47:10.532208 31953 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.532217 31953 net.cpp:106] Creating Layer relu4
I0204 08:47:10.532222 31953 net.cpp:454] relu4 <- conv4
I0204 08:47:10.532229 31953 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.532238 31953 net.cpp:150] Setting up relu4
I0204 08:47:10.532248 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532253 31953 net.cpp:165] Memory required for data: 82320800
I0204 08:47:10.532258 31953 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.532274 31953 net.cpp:106] Creating Layer conv5
I0204 08:47:10.532287 31953 net.cpp:454] conv5 <- conv4
I0204 08:47:10.532296 31953 net.cpp:411] conv5 -> conv5
I0204 08:47:10.532322 31953 net.cpp:150] Setting up conv5
I0204 08:47:10.532331 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532336 31953 net.cpp:165] Memory required for data: 82861600
I0204 08:47:10.532347 31953 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.532356 31953 net.cpp:106] Creating Layer relu5
I0204 08:47:10.532362 31953 net.cpp:454] relu5 <- conv5
I0204 08:47:10.532371 31953 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.532379 31953 net.cpp:150] Setting up relu5
I0204 08:47:10.532388 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.532394 31953 net.cpp:165] Memory required for data: 83402400
I0204 08:47:10.532400 31953 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.532409 31953 net.cpp:106] Creating Layer pool5
I0204 08:47:10.532415 31953 net.cpp:454] pool5 <- conv5
I0204 08:47:10.532424 31953 net.cpp:411] pool5 -> pool5
I0204 08:47:10.532435 31953 net.cpp:150] Setting up pool5
I0204 08:47:10.532443 31953 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.532449 31953 net.cpp:165] Memory required for data: 83517600
I0204 08:47:10.532454 31953 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.532472 31953 net.cpp:106] Creating Layer fc6
I0204 08:47:10.532480 31953 net.cpp:454] fc6 <- pool5
I0204 08:47:10.532488 31953 net.cpp:411] fc6 -> fc6
I0204 08:47:10.533260 31953 net.cpp:150] Setting up fc6
I0204 08:47:10.533272 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.533278 31953 net.cpp:165] Memory required for data: 83620000
I0204 08:47:10.533288 31953 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.533296 31953 net.cpp:106] Creating Layer relu6
I0204 08:47:10.533303 31953 net.cpp:454] relu6 <- fc6
I0204 08:47:10.533310 31953 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.533319 31953 net.cpp:150] Setting up relu6
I0204 08:47:10.533329 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.533334 31953 net.cpp:165] Memory required for data: 83722400
I0204 08:47:10.533339 31953 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.533350 31953 net.cpp:106] Creating Layer drop6
I0204 08:47:10.533356 31953 net.cpp:454] drop6 <- fc6
I0204 08:47:10.533365 31953 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.533381 31953 net.cpp:150] Setting up drop6
I0204 08:47:10.533390 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.533395 31953 net.cpp:165] Memory required for data: 83824800
I0204 08:47:10.533401 31953 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.534181 31953 net.cpp:106] Creating Layer fc7
I0204 08:47:10.534204 31953 net.cpp:454] fc7 <- fc6
I0204 08:47:10.534217 31953 net.cpp:411] fc7 -> fc7
I0204 08:47:10.534901 31953 net.cpp:150] Setting up fc7
I0204 08:47:10.534914 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.534920 31953 net.cpp:165] Memory required for data: 83927200
I0204 08:47:10.534936 31953 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.534946 31953 net.cpp:106] Creating Layer relu7
I0204 08:47:10.534958 31953 net.cpp:454] relu7 <- fc7
I0204 08:47:10.534968 31953 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.534978 31953 net.cpp:150] Setting up relu7
I0204 08:47:10.534986 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.534993 31953 net.cpp:165] Memory required for data: 84029600
I0204 08:47:10.535001 31953 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.535011 31953 net.cpp:106] Creating Layer drop7
I0204 08:47:10.535017 31953 net.cpp:454] drop7 <- fc7
I0204 08:47:10.535024 31953 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.535037 31953 net.cpp:150] Setting up drop7
I0204 08:47:10.535044 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.535050 31953 net.cpp:165] Memory required for data: 84132000
I0204 08:47:10.535058 31953 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.535070 31953 net.cpp:106] Creating Layer fc8
I0204 08:47:10.535084 31953 net.cpp:454] fc8 <- fc7
I0204 08:47:10.535101 31953 net.cpp:411] fc8 -> fc8
I0204 08:47:10.535126 31953 net.cpp:150] Setting up fc8
I0204 08:47:10.535135 31953 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.535141 31953 net.cpp:165] Memory required for data: 84132800
I0204 08:47:10.535151 31953 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.535162 31953 net.cpp:106] Creating Layer loss
I0204 08:47:10.535169 31953 net.cpp:454] loss <- fc8
I0204 08:47:10.535176 31953 net.cpp:454] loss <- label
I0204 08:47:10.535187 31953 net.cpp:411] loss -> loss
I0204 08:47:10.535202 31953 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.535224 31953 net.cpp:150] Setting up loss
I0204 08:47:10.535234 31953 net.cpp:157] Top shape: (1)
I0204 08:47:10.535241 31953 net.cpp:160]     with loss weight 1
I0204 08:47:10.535280 31953 net.cpp:165] Memory required for data: 84132804
I0204 08:47:10.535290 31953 net.cpp:226] loss needs backward computation.
I0204 08:47:10.535296 31953 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.535302 31953 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.535308 31953 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.535315 31953 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.535321 31953 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.535328 31953 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.535336 31953 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.535342 31953 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.535349 31953 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.535359 31953 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.535365 31953 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.535372 31953 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.535379 31953 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.535385 31953 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.535395 31953 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.535401 31953 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.535408 31953 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.535415 31953 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.535423 31953 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.535430 31953 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.535437 31953 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.535444 31953 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.535454 31953 net.cpp:228] data does not need backward computation.
I0204 08:47:10.535460 31953 net.cpp:270] This network produces output loss
I0204 08:47:10.535487 31953 net.cpp:283] Network initialization done.
I0204 08:47:10.541463 31953 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/train_val.prototxt
I0204 08:47:10.541566 31953 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 08:47:10.541872 31953 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 08:47:10.542059 31953 layer_factory.hpp:77] Creating layer data
I0204 08:47:10.542209 31953 net.cpp:106] Creating Layer data
I0204 08:47:10.542222 31953 net.cpp:411] data -> data
I0204 08:47:10.542239 31953 net.cpp:411] data -> label
I0204 08:47:10.542251 31953 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 08:47:10.549382 31969 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 08:47:10.551306 31953 data_layer.cpp:41] output data size: 100,1,227,227
I0204 08:47:10.584388 31953 net.cpp:150] Setting up data
I0204 08:47:10.584420 31953 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 08:47:10.584429 31953 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.584436 31953 net.cpp:165] Memory required for data: 20612000
I0204 08:47:10.584445 31953 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 08:47:10.584465 31953 net.cpp:106] Creating Layer label_data_1_split
I0204 08:47:10.584472 31953 net.cpp:454] label_data_1_split <- label
I0204 08:47:10.584483 31953 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 08:47:10.584498 31953 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 08:47:10.584512 31953 net.cpp:150] Setting up label_data_1_split
I0204 08:47:10.584520 31953 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.584527 31953 net.cpp:157] Top shape: 100 (100)
I0204 08:47:10.584532 31953 net.cpp:165] Memory required for data: 20612800
I0204 08:47:10.584538 31953 layer_factory.hpp:77] Creating layer conv1
I0204 08:47:10.584554 31953 net.cpp:106] Creating Layer conv1
I0204 08:47:10.584561 31953 net.cpp:454] conv1 <- data
I0204 08:47:10.584571 31953 net.cpp:411] conv1 -> conv1
I0204 08:47:10.584624 31953 net.cpp:150] Setting up conv1
I0204 08:47:10.584635 31953 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.584640 31953 net.cpp:165] Memory required for data: 39972800
I0204 08:47:10.584655 31953 layer_factory.hpp:77] Creating layer relu1
I0204 08:47:10.584666 31953 net.cpp:106] Creating Layer relu1
I0204 08:47:10.584671 31953 net.cpp:454] relu1 <- conv1
I0204 08:47:10.584681 31953 net.cpp:397] relu1 -> conv1 (in-place)
I0204 08:47:10.584691 31953 net.cpp:150] Setting up relu1
I0204 08:47:10.584697 31953 net.cpp:157] Top shape: 100 16 55 55 (4840000)
I0204 08:47:10.584703 31953 net.cpp:165] Memory required for data: 59332800
I0204 08:47:10.584709 31953 layer_factory.hpp:77] Creating layer pool1
I0204 08:47:10.584720 31953 net.cpp:106] Creating Layer pool1
I0204 08:47:10.584728 31953 net.cpp:454] pool1 <- conv1
I0204 08:47:10.584736 31953 net.cpp:411] pool1 -> pool1
I0204 08:47:10.584749 31953 net.cpp:150] Setting up pool1
I0204 08:47:10.584758 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.584764 31953 net.cpp:165] Memory required for data: 63998400
I0204 08:47:10.584769 31953 layer_factory.hpp:77] Creating layer norm1
I0204 08:47:10.584780 31953 net.cpp:106] Creating Layer norm1
I0204 08:47:10.584786 31953 net.cpp:454] norm1 <- pool1
I0204 08:47:10.584794 31953 net.cpp:411] norm1 -> norm1
I0204 08:47:10.584805 31953 net.cpp:150] Setting up norm1
I0204 08:47:10.584812 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.584818 31953 net.cpp:165] Memory required for data: 68664000
I0204 08:47:10.584825 31953 layer_factory.hpp:77] Creating layer conv2
I0204 08:47:10.584836 31953 net.cpp:106] Creating Layer conv2
I0204 08:47:10.584842 31953 net.cpp:454] conv2 <- norm1
I0204 08:47:10.584851 31953 net.cpp:411] conv2 -> conv2
I0204 08:47:10.584902 31953 net.cpp:150] Setting up conv2
I0204 08:47:10.584910 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.584915 31953 net.cpp:165] Memory required for data: 73329600
I0204 08:47:10.584926 31953 layer_factory.hpp:77] Creating layer relu2
I0204 08:47:10.584936 31953 net.cpp:106] Creating Layer relu2
I0204 08:47:10.584942 31953 net.cpp:454] relu2 <- conv2
I0204 08:47:10.584954 31953 net.cpp:397] relu2 -> conv2 (in-place)
I0204 08:47:10.584969 31953 net.cpp:150] Setting up relu2
I0204 08:47:10.584986 31953 net.cpp:157] Top shape: 100 16 27 27 (1166400)
I0204 08:47:10.584991 31953 net.cpp:165] Memory required for data: 77995200
I0204 08:47:10.584997 31953 layer_factory.hpp:77] Creating layer pool2
I0204 08:47:10.585007 31953 net.cpp:106] Creating Layer pool2
I0204 08:47:10.585013 31953 net.cpp:454] pool2 <- conv2
I0204 08:47:10.585022 31953 net.cpp:411] pool2 -> pool2
I0204 08:47:10.585050 31953 net.cpp:150] Setting up pool2
I0204 08:47:10.585060 31953 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.585065 31953 net.cpp:165] Memory required for data: 79076800
I0204 08:47:10.585072 31953 layer_factory.hpp:77] Creating layer norm2
I0204 08:47:10.585081 31953 net.cpp:106] Creating Layer norm2
I0204 08:47:10.585088 31953 net.cpp:454] norm2 <- pool2
I0204 08:47:10.585100 31953 net.cpp:411] norm2 -> norm2
I0204 08:47:10.585110 31953 net.cpp:150] Setting up norm2
I0204 08:47:10.585117 31953 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 08:47:10.585124 31953 net.cpp:165] Memory required for data: 80158400
I0204 08:47:10.585129 31953 layer_factory.hpp:77] Creating layer conv3
I0204 08:47:10.585139 31953 net.cpp:106] Creating Layer conv3
I0204 08:47:10.585145 31953 net.cpp:454] conv3 <- norm2
I0204 08:47:10.585155 31953 net.cpp:411] conv3 -> conv3
I0204 08:47:10.585186 31953 net.cpp:150] Setting up conv3
I0204 08:47:10.585194 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585201 31953 net.cpp:165] Memory required for data: 80699200
I0204 08:47:10.585211 31953 layer_factory.hpp:77] Creating layer relu3
I0204 08:47:10.585221 31953 net.cpp:106] Creating Layer relu3
I0204 08:47:10.585227 31953 net.cpp:454] relu3 <- conv3
I0204 08:47:10.585234 31953 net.cpp:397] relu3 -> conv3 (in-place)
I0204 08:47:10.585243 31953 net.cpp:150] Setting up relu3
I0204 08:47:10.585250 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585257 31953 net.cpp:165] Memory required for data: 81240000
I0204 08:47:10.585263 31953 layer_factory.hpp:77] Creating layer conv4
I0204 08:47:10.585273 31953 net.cpp:106] Creating Layer conv4
I0204 08:47:10.585278 31953 net.cpp:454] conv4 <- conv3
I0204 08:47:10.585286 31953 net.cpp:411] conv4 -> conv4
I0204 08:47:10.585309 31953 net.cpp:150] Setting up conv4
I0204 08:47:10.585316 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585321 31953 net.cpp:165] Memory required for data: 81780800
I0204 08:47:10.585330 31953 layer_factory.hpp:77] Creating layer relu4
I0204 08:47:10.585338 31953 net.cpp:106] Creating Layer relu4
I0204 08:47:10.585345 31953 net.cpp:454] relu4 <- conv4
I0204 08:47:10.585352 31953 net.cpp:397] relu4 -> conv4 (in-place)
I0204 08:47:10.585361 31953 net.cpp:150] Setting up relu4
I0204 08:47:10.585368 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585374 31953 net.cpp:165] Memory required for data: 82321600
I0204 08:47:10.585381 31953 layer_factory.hpp:77] Creating layer conv5
I0204 08:47:10.585391 31953 net.cpp:106] Creating Layer conv5
I0204 08:47:10.585397 31953 net.cpp:454] conv5 <- conv4
I0204 08:47:10.585405 31953 net.cpp:411] conv5 -> conv5
I0204 08:47:10.585433 31953 net.cpp:150] Setting up conv5
I0204 08:47:10.585441 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585446 31953 net.cpp:165] Memory required for data: 82862400
I0204 08:47:10.585458 31953 layer_factory.hpp:77] Creating layer relu5
I0204 08:47:10.585466 31953 net.cpp:106] Creating Layer relu5
I0204 08:47:10.585472 31953 net.cpp:454] relu5 <- conv5
I0204 08:47:10.585480 31953 net.cpp:397] relu5 -> conv5 (in-place)
I0204 08:47:10.585489 31953 net.cpp:150] Setting up relu5
I0204 08:47:10.585495 31953 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 08:47:10.585501 31953 net.cpp:165] Memory required for data: 83403200
I0204 08:47:10.585507 31953 layer_factory.hpp:77] Creating layer pool5
I0204 08:47:10.585518 31953 net.cpp:106] Creating Layer pool5
I0204 08:47:10.585525 31953 net.cpp:454] pool5 <- conv5
I0204 08:47:10.585532 31953 net.cpp:411] pool5 -> pool5
I0204 08:47:10.585551 31953 net.cpp:150] Setting up pool5
I0204 08:47:10.585564 31953 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 08:47:10.585569 31953 net.cpp:165] Memory required for data: 83518400
I0204 08:47:10.585575 31953 layer_factory.hpp:77] Creating layer fc6
I0204 08:47:10.585587 31953 net.cpp:106] Creating Layer fc6
I0204 08:47:10.585593 31953 net.cpp:454] fc6 <- pool5
I0204 08:47:10.585602 31953 net.cpp:411] fc6 -> fc6
I0204 08:47:10.593580 31953 net.cpp:150] Setting up fc6
I0204 08:47:10.593618 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.593626 31953 net.cpp:165] Memory required for data: 83620800
I0204 08:47:10.593641 31953 layer_factory.hpp:77] Creating layer relu6
I0204 08:47:10.593654 31953 net.cpp:106] Creating Layer relu6
I0204 08:47:10.593663 31953 net.cpp:454] relu6 <- fc6
I0204 08:47:10.593675 31953 net.cpp:397] relu6 -> fc6 (in-place)
I0204 08:47:10.593689 31953 net.cpp:150] Setting up relu6
I0204 08:47:10.593698 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.593704 31953 net.cpp:165] Memory required for data: 83723200
I0204 08:47:10.593711 31953 layer_factory.hpp:77] Creating layer drop6
I0204 08:47:10.593722 31953 net.cpp:106] Creating Layer drop6
I0204 08:47:10.593729 31953 net.cpp:454] drop6 <- fc6
I0204 08:47:10.593740 31953 net.cpp:397] drop6 -> fc6 (in-place)
I0204 08:47:10.593755 31953 net.cpp:150] Setting up drop6
I0204 08:47:10.593763 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.593770 31953 net.cpp:165] Memory required for data: 83825600
I0204 08:47:10.593775 31953 layer_factory.hpp:77] Creating layer fc7
I0204 08:47:10.593788 31953 net.cpp:106] Creating Layer fc7
I0204 08:47:10.593794 31953 net.cpp:454] fc7 <- fc6
I0204 08:47:10.593806 31953 net.cpp:411] fc7 -> fc7
I0204 08:47:10.594565 31953 net.cpp:150] Setting up fc7
I0204 08:47:10.594579 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.594585 31953 net.cpp:165] Memory required for data: 83928000
I0204 08:47:10.594595 31953 layer_factory.hpp:77] Creating layer relu7
I0204 08:47:10.594609 31953 net.cpp:106] Creating Layer relu7
I0204 08:47:10.594616 31953 net.cpp:454] relu7 <- fc7
I0204 08:47:10.594625 31953 net.cpp:397] relu7 -> fc7 (in-place)
I0204 08:47:10.594635 31953 net.cpp:150] Setting up relu7
I0204 08:47:10.594643 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.594650 31953 net.cpp:165] Memory required for data: 84030400
I0204 08:47:10.594655 31953 layer_factory.hpp:77] Creating layer drop7
I0204 08:47:10.594666 31953 net.cpp:106] Creating Layer drop7
I0204 08:47:10.594671 31953 net.cpp:454] drop7 <- fc7
I0204 08:47:10.594683 31953 net.cpp:397] drop7 -> fc7 (in-place)
I0204 08:47:10.594696 31953 net.cpp:150] Setting up drop7
I0204 08:47:10.594702 31953 net.cpp:157] Top shape: 100 256 (25600)
I0204 08:47:10.594709 31953 net.cpp:165] Memory required for data: 84132800
I0204 08:47:10.594715 31953 layer_factory.hpp:77] Creating layer fc8
I0204 08:47:10.594725 31953 net.cpp:106] Creating Layer fc8
I0204 08:47:10.594732 31953 net.cpp:454] fc8 <- fc7
I0204 08:47:10.594743 31953 net.cpp:411] fc8 -> fc8
I0204 08:47:10.594774 31953 net.cpp:150] Setting up fc8
I0204 08:47:10.594784 31953 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.594790 31953 net.cpp:165] Memory required for data: 84133600
I0204 08:47:10.594799 31953 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 08:47:10.594808 31953 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 08:47:10.594815 31953 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 08:47:10.594826 31953 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 08:47:10.594840 31953 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 08:47:10.594851 31953 net.cpp:150] Setting up fc8_fc8_0_split
I0204 08:47:10.594858 31953 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.594866 31953 net.cpp:157] Top shape: 100 2 (200)
I0204 08:47:10.594871 31953 net.cpp:165] Memory required for data: 84135200
I0204 08:47:10.594877 31953 layer_factory.hpp:77] Creating layer accuracy
I0204 08:47:10.594890 31953 net.cpp:106] Creating Layer accuracy
I0204 08:47:10.594907 31953 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 08:47:10.594925 31953 net.cpp:454] accuracy <- label_data_1_split_0
I0204 08:47:10.594938 31953 net.cpp:411] accuracy -> accuracy
I0204 08:47:10.594950 31953 net.cpp:150] Setting up accuracy
I0204 08:47:10.594959 31953 net.cpp:157] Top shape: (1)
I0204 08:47:10.594965 31953 net.cpp:165] Memory required for data: 84135204
I0204 08:47:10.594974 31953 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.594982 31953 net.cpp:106] Creating Layer loss
I0204 08:47:10.594990 31953 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 08:47:10.594996 31953 net.cpp:454] loss <- label_data_1_split_1
I0204 08:47:10.595049 31953 net.cpp:411] loss -> loss
I0204 08:47:10.595064 31953 layer_factory.hpp:77] Creating layer loss
I0204 08:47:10.595084 31953 net.cpp:150] Setting up loss
I0204 08:47:10.595093 31953 net.cpp:157] Top shape: (1)
I0204 08:47:10.595099 31953 net.cpp:160]     with loss weight 1
I0204 08:47:10.595113 31953 net.cpp:165] Memory required for data: 84135208
I0204 08:47:10.595120 31953 net.cpp:226] loss needs backward computation.
I0204 08:47:10.595127 31953 net.cpp:228] accuracy does not need backward computation.
I0204 08:47:10.595135 31953 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 08:47:10.595141 31953 net.cpp:226] fc8 needs backward computation.
I0204 08:47:10.595147 31953 net.cpp:226] drop7 needs backward computation.
I0204 08:47:10.595154 31953 net.cpp:226] relu7 needs backward computation.
I0204 08:47:10.595160 31953 net.cpp:226] fc7 needs backward computation.
I0204 08:47:10.595166 31953 net.cpp:226] drop6 needs backward computation.
I0204 08:47:10.595173 31953 net.cpp:226] relu6 needs backward computation.
I0204 08:47:10.595180 31953 net.cpp:226] fc6 needs backward computation.
I0204 08:47:10.595185 31953 net.cpp:226] pool5 needs backward computation.
I0204 08:47:10.595192 31953 net.cpp:226] relu5 needs backward computation.
I0204 08:47:10.595199 31953 net.cpp:226] conv5 needs backward computation.
I0204 08:47:10.595206 31953 net.cpp:226] relu4 needs backward computation.
I0204 08:47:10.595212 31953 net.cpp:226] conv4 needs backward computation.
I0204 08:47:10.595233 31953 net.cpp:226] relu3 needs backward computation.
I0204 08:47:10.595242 31953 net.cpp:226] conv3 needs backward computation.
I0204 08:47:10.595252 31953 net.cpp:226] norm2 needs backward computation.
I0204 08:47:10.595262 31953 net.cpp:226] pool2 needs backward computation.
I0204 08:47:10.595270 31953 net.cpp:226] relu2 needs backward computation.
I0204 08:47:10.595280 31953 net.cpp:226] conv2 needs backward computation.
I0204 08:47:10.595289 31953 net.cpp:226] norm1 needs backward computation.
I0204 08:47:10.595299 31953 net.cpp:226] pool1 needs backward computation.
I0204 08:47:10.595309 31953 net.cpp:226] relu1 needs backward computation.
I0204 08:47:10.595317 31953 net.cpp:226] conv1 needs backward computation.
I0204 08:47:10.595329 31953 net.cpp:228] label_data_1_split does not need backward computation.
I0204 08:47:10.595338 31953 net.cpp:228] data does not need backward computation.
I0204 08:47:10.595347 31953 net.cpp:270] This network produces output accuracy
I0204 08:47:10.595361 31953 net.cpp:270] This network produces output loss
I0204 08:47:10.595403 31953 net.cpp:283] Network initialization done.
I0204 08:47:10.595556 31953 solver.cpp:60] Solver scaffolding done.
I0204 08:47:10.595641 31953 caffe.cpp:212] Starting Optimization
I0204 08:47:10.595652 31953 solver.cpp:288] Solving CaffeNet
I0204 08:47:10.595661 31953 solver.cpp:289] Learning Rate Policy: step
I0204 08:47:10.599972 31953 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 08:47:10.600049 31953 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 08:47:15.237393 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:47:15.237471 31953 solver.cpp:409]     Test net output #1: loss = 3.20423 (* 1 = 3.20423 loss)
I0204 08:47:16.233176 31953 solver.cpp:237] Iteration 0, loss = 5.826
I0204 08:47:16.233239 31953 solver.cpp:253]     Train net output #0: loss = 5.826 (* 1 = 5.826 loss)
I0204 08:47:16.233264 31953 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 08:47:25.749140 31953 solver.cpp:237] Iteration 10, loss = 1.32592
I0204 08:47:25.749208 31953 solver.cpp:253]     Train net output #0: loss = 1.32592 (* 1 = 1.32592 loss)
I0204 08:47:25.749220 31953 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 08:47:35.191942 31953 solver.cpp:237] Iteration 20, loss = 0.88749
I0204 08:47:35.192008 31953 solver.cpp:253]     Train net output #0: loss = 0.88749 (* 1 = 0.88749 loss)
I0204 08:47:35.192020 31953 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 08:47:44.599741 31953 solver.cpp:237] Iteration 30, loss = 0.96085
I0204 08:47:44.599877 31953 solver.cpp:253]     Train net output #0: loss = 0.96085 (* 1 = 0.96085 loss)
I0204 08:47:44.599889 31953 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 08:47:54.044783 31953 solver.cpp:237] Iteration 40, loss = 0.803871
I0204 08:47:54.044854 31953 solver.cpp:253]     Train net output #0: loss = 0.803871 (* 1 = 0.803871 loss)
I0204 08:47:54.044867 31953 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 08:48:03.418561 31953 solver.cpp:237] Iteration 50, loss = 0.814673
I0204 08:48:03.418633 31953 solver.cpp:253]     Train net output #0: loss = 0.814673 (* 1 = 0.814673 loss)
I0204 08:48:03.418648 31953 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 08:48:12.845552 31953 solver.cpp:237] Iteration 60, loss = 0.735539
I0204 08:48:12.845621 31953 solver.cpp:253]     Train net output #0: loss = 0.735539 (* 1 = 0.735539 loss)
I0204 08:48:12.845634 31953 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 08:48:22.252460 31953 solver.cpp:237] Iteration 70, loss = 0.836285
I0204 08:48:22.252636 31953 solver.cpp:253]     Train net output #0: loss = 0.836285 (* 1 = 0.836285 loss)
I0204 08:48:22.252650 31953 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 08:48:31.698395 31953 solver.cpp:237] Iteration 80, loss = 0.701416
I0204 08:48:31.698467 31953 solver.cpp:253]     Train net output #0: loss = 0.701416 (* 1 = 0.701416 loss)
I0204 08:48:31.698479 31953 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 08:48:41.114647 31953 solver.cpp:237] Iteration 90, loss = 0.798492
I0204 08:48:41.114717 31953 solver.cpp:253]     Train net output #0: loss = 0.798492 (* 1 = 0.798492 loss)
I0204 08:48:41.114730 31953 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 08:48:49.605155 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_100.caffemodel
I0204 08:48:49.607728 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_100.solverstate
I0204 08:48:49.608763 31953 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 08:48:54.184901 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:48:54.185089 31953 solver.cpp:409]     Test net output #1: loss = 0.694304 (* 1 = 0.694304 loss)
I0204 08:48:55.138721 31953 solver.cpp:237] Iteration 100, loss = 0.750748
I0204 08:48:55.138787 31953 solver.cpp:253]     Train net output #0: loss = 0.750748 (* 1 = 0.750748 loss)
I0204 08:48:55.138800 31953 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 08:49:04.679306 31953 solver.cpp:237] Iteration 110, loss = 0.726999
I0204 08:49:04.679364 31953 solver.cpp:253]     Train net output #0: loss = 0.726999 (* 1 = 0.726999 loss)
I0204 08:49:04.679376 31953 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 08:49:14.244505 31953 solver.cpp:237] Iteration 120, loss = 0.763366
I0204 08:49:14.244559 31953 solver.cpp:253]     Train net output #0: loss = 0.763366 (* 1 = 0.763366 loss)
I0204 08:49:14.244570 31953 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 08:49:23.801162 31953 solver.cpp:237] Iteration 130, loss = 0.71165
I0204 08:49:23.801218 31953 solver.cpp:253]     Train net output #0: loss = 0.71165 (* 1 = 0.71165 loss)
I0204 08:49:23.801230 31953 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 08:49:33.314262 31953 solver.cpp:237] Iteration 140, loss = 0.845578
I0204 08:49:33.314455 31953 solver.cpp:253]     Train net output #0: loss = 0.845578 (* 1 = 0.845578 loss)
I0204 08:49:33.314468 31953 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 08:49:42.841271 31953 solver.cpp:237] Iteration 150, loss = 0.704229
I0204 08:49:42.841320 31953 solver.cpp:253]     Train net output #0: loss = 0.704229 (* 1 = 0.704229 loss)
I0204 08:49:42.841331 31953 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 08:49:52.363087 31953 solver.cpp:237] Iteration 160, loss = 0.747456
I0204 08:49:52.363147 31953 solver.cpp:253]     Train net output #0: loss = 0.747456 (* 1 = 0.747456 loss)
I0204 08:49:52.363159 31953 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 08:50:01.920857 31953 solver.cpp:237] Iteration 170, loss = 0.779158
I0204 08:50:01.920909 31953 solver.cpp:253]     Train net output #0: loss = 0.779158 (* 1 = 0.779158 loss)
I0204 08:50:01.920920 31953 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 08:50:11.484984 31953 solver.cpp:237] Iteration 180, loss = 0.714674
I0204 08:50:11.485172 31953 solver.cpp:253]     Train net output #0: loss = 0.714674 (* 1 = 0.714674 loss)
I0204 08:50:11.485184 31953 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 08:50:20.987476 31953 solver.cpp:237] Iteration 190, loss = 0.749381
I0204 08:50:20.987529 31953 solver.cpp:253]     Train net output #0: loss = 0.749381 (* 1 = 0.749381 loss)
I0204 08:50:20.987540 31953 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 08:50:29.550645 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_200.caffemodel
I0204 08:50:29.552863 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_200.solverstate
I0204 08:50:29.553766 31953 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 08:50:34.108372 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:50:34.108443 31953 solver.cpp:409]     Test net output #1: loss = 0.693193 (* 1 = 0.693193 loss)
I0204 08:50:35.062512 31953 solver.cpp:237] Iteration 200, loss = 0.726553
I0204 08:50:35.062577 31953 solver.cpp:253]     Train net output #0: loss = 0.726553 (* 1 = 0.726553 loss)
I0204 08:50:35.062589 31953 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 08:50:44.506567 31953 solver.cpp:237] Iteration 210, loss = 0.691755
I0204 08:50:44.506723 31953 solver.cpp:253]     Train net output #0: loss = 0.691755 (* 1 = 0.691755 loss)
I0204 08:50:44.506738 31953 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 08:50:54.122735 31953 solver.cpp:237] Iteration 220, loss = 0.789949
I0204 08:50:54.122789 31953 solver.cpp:253]     Train net output #0: loss = 0.789949 (* 1 = 0.789949 loss)
I0204 08:50:54.122802 31953 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 08:51:03.700932 31953 solver.cpp:237] Iteration 230, loss = 0.731275
I0204 08:51:03.700997 31953 solver.cpp:253]     Train net output #0: loss = 0.731275 (* 1 = 0.731275 loss)
I0204 08:51:03.701009 31953 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 08:51:13.273581 31953 solver.cpp:237] Iteration 240, loss = 0.71552
I0204 08:51:13.273638 31953 solver.cpp:253]     Train net output #0: loss = 0.71552 (* 1 = 0.71552 loss)
I0204 08:51:13.273649 31953 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 08:51:22.902276 31953 solver.cpp:237] Iteration 250, loss = 0.783434
I0204 08:51:22.902446 31953 solver.cpp:253]     Train net output #0: loss = 0.783434 (* 1 = 0.783434 loss)
I0204 08:51:22.902458 31953 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 08:51:32.508077 31953 solver.cpp:237] Iteration 260, loss = 0.674686
I0204 08:51:32.508136 31953 solver.cpp:253]     Train net output #0: loss = 0.674686 (* 1 = 0.674686 loss)
I0204 08:51:32.508148 31953 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 08:51:42.061141 31953 solver.cpp:237] Iteration 270, loss = 0.747516
I0204 08:51:42.061208 31953 solver.cpp:253]     Train net output #0: loss = 0.747516 (* 1 = 0.747516 loss)
I0204 08:51:42.061220 31953 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 08:51:51.663084 31953 solver.cpp:237] Iteration 280, loss = 0.69085
I0204 08:51:51.663137 31953 solver.cpp:253]     Train net output #0: loss = 0.69085 (* 1 = 0.69085 loss)
I0204 08:51:51.663148 31953 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 08:52:01.149230 31953 solver.cpp:237] Iteration 290, loss = 0.720304
I0204 08:52:01.149428 31953 solver.cpp:253]     Train net output #0: loss = 0.720304 (* 1 = 0.720304 loss)
I0204 08:52:01.149441 31953 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 08:52:09.672659 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_300.caffemodel
I0204 08:52:09.675113 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_300.solverstate
I0204 08:52:09.676093 31953 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 08:52:14.209853 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:52:14.209918 31953 solver.cpp:409]     Test net output #1: loss = 0.713027 (* 1 = 0.713027 loss)
I0204 08:52:15.167467 31953 solver.cpp:237] Iteration 300, loss = 0.755336
I0204 08:52:15.167554 31953 solver.cpp:253]     Train net output #0: loss = 0.755336 (* 1 = 0.755336 loss)
I0204 08:52:15.167567 31953 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 08:52:24.531486 31953 solver.cpp:237] Iteration 310, loss = 0.722329
I0204 08:52:24.531550 31953 solver.cpp:253]     Train net output #0: loss = 0.722329 (* 1 = 0.722329 loss)
I0204 08:52:24.531564 31953 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 08:52:33.958993 31953 solver.cpp:237] Iteration 320, loss = 0.714544
I0204 08:52:33.959180 31953 solver.cpp:253]     Train net output #0: loss = 0.714544 (* 1 = 0.714544 loss)
I0204 08:52:33.959194 31953 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 08:52:43.441570 31953 solver.cpp:237] Iteration 330, loss = 0.7423
I0204 08:52:43.441637 31953 solver.cpp:253]     Train net output #0: loss = 0.7423 (* 1 = 0.7423 loss)
I0204 08:52:43.441651 31953 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 08:52:52.861888 31953 solver.cpp:237] Iteration 340, loss = 0.677007
I0204 08:52:52.861949 31953 solver.cpp:253]     Train net output #0: loss = 0.677007 (* 1 = 0.677007 loss)
I0204 08:52:52.861963 31953 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 08:53:02.480387 31953 solver.cpp:237] Iteration 350, loss = 0.71183
I0204 08:53:02.480448 31953 solver.cpp:253]     Train net output #0: loss = 0.71183 (* 1 = 0.71183 loss)
I0204 08:53:02.480459 31953 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 08:53:12.048640 31953 solver.cpp:237] Iteration 360, loss = 0.701715
I0204 08:53:12.048795 31953 solver.cpp:253]     Train net output #0: loss = 0.701715 (* 1 = 0.701715 loss)
I0204 08:53:12.048809 31953 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 08:53:21.529809 31953 solver.cpp:237] Iteration 370, loss = 0.731131
I0204 08:53:21.529861 31953 solver.cpp:253]     Train net output #0: loss = 0.731131 (* 1 = 0.731131 loss)
I0204 08:53:21.529873 31953 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 08:53:31.054703 31953 solver.cpp:237] Iteration 380, loss = 0.776218
I0204 08:53:31.054756 31953 solver.cpp:253]     Train net output #0: loss = 0.776218 (* 1 = 0.776218 loss)
I0204 08:53:31.054769 31953 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 08:53:40.715431 31953 solver.cpp:237] Iteration 390, loss = 0.74963
I0204 08:53:40.715492 31953 solver.cpp:253]     Train net output #0: loss = 0.74963 (* 1 = 0.74963 loss)
I0204 08:53:40.715504 31953 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 08:53:49.532547 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_400.caffemodel
I0204 08:53:49.535202 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_400.solverstate
I0204 08:53:49.536276 31953 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 08:53:53.999277 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:53:53.999352 31953 solver.cpp:409]     Test net output #1: loss = 0.693994 (* 1 = 0.693994 loss)
I0204 08:53:54.919158 31953 solver.cpp:237] Iteration 400, loss = 0.688537
I0204 08:53:54.919220 31953 solver.cpp:253]     Train net output #0: loss = 0.688537 (* 1 = 0.688537 loss)
I0204 08:53:54.919234 31953 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 08:54:04.189762 31953 solver.cpp:237] Iteration 410, loss = 0.719406
I0204 08:54:04.189836 31953 solver.cpp:253]     Train net output #0: loss = 0.719406 (* 1 = 0.719406 loss)
I0204 08:54:04.189849 31953 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 08:54:13.646960 31953 solver.cpp:237] Iteration 420, loss = 0.689637
I0204 08:54:13.647034 31953 solver.cpp:253]     Train net output #0: loss = 0.689637 (* 1 = 0.689637 loss)
I0204 08:54:13.647049 31953 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 08:54:23.053063 31953 solver.cpp:237] Iteration 430, loss = 0.76008
I0204 08:54:23.053218 31953 solver.cpp:253]     Train net output #0: loss = 0.76008 (* 1 = 0.76008 loss)
I0204 08:54:23.053232 31953 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 08:54:32.528074 31953 solver.cpp:237] Iteration 440, loss = 0.71174
I0204 08:54:32.528144 31953 solver.cpp:253]     Train net output #0: loss = 0.71174 (* 1 = 0.71174 loss)
I0204 08:54:32.528163 31953 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 08:54:42.028070 31953 solver.cpp:237] Iteration 450, loss = 0.703855
I0204 08:54:42.028147 31953 solver.cpp:253]     Train net output #0: loss = 0.703855 (* 1 = 0.703855 loss)
I0204 08:54:42.028162 31953 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 08:54:51.477982 31953 solver.cpp:237] Iteration 460, loss = 0.73632
I0204 08:54:51.478052 31953 solver.cpp:253]     Train net output #0: loss = 0.73632 (* 1 = 0.73632 loss)
I0204 08:54:51.478066 31953 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 08:55:00.836514 31953 solver.cpp:237] Iteration 470, loss = 0.719321
I0204 08:55:00.836995 31953 solver.cpp:253]     Train net output #0: loss = 0.719321 (* 1 = 0.719321 loss)
I0204 08:55:00.837013 31953 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 08:55:10.078855 31953 solver.cpp:237] Iteration 480, loss = 0.678704
I0204 08:55:10.078919 31953 solver.cpp:253]     Train net output #0: loss = 0.678704 (* 1 = 0.678704 loss)
I0204 08:55:10.078935 31953 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 08:55:19.320642 31953 solver.cpp:237] Iteration 490, loss = 0.731838
I0204 08:55:19.320715 31953 solver.cpp:253]     Train net output #0: loss = 0.731838 (* 1 = 0.731838 loss)
I0204 08:55:19.320729 31953 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 08:55:27.660135 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_500.caffemodel
I0204 08:55:27.662442 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_500.solverstate
I0204 08:55:27.663383 31953 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 08:55:32.094391 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:55:32.094579 31953 solver.cpp:409]     Test net output #1: loss = 0.703632 (* 1 = 0.703632 loss)
I0204 08:55:33.011936 31953 solver.cpp:237] Iteration 500, loss = 0.720081
I0204 08:55:33.012008 31953 solver.cpp:253]     Train net output #0: loss = 0.720081 (* 1 = 0.720081 loss)
I0204 08:55:33.012022 31953 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 08:55:42.247256 31953 solver.cpp:237] Iteration 510, loss = 0.717021
I0204 08:55:42.247334 31953 solver.cpp:253]     Train net output #0: loss = 0.717021 (* 1 = 0.717021 loss)
I0204 08:55:42.247347 31953 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 08:55:51.472666 31953 solver.cpp:237] Iteration 520, loss = 0.711511
I0204 08:55:51.472731 31953 solver.cpp:253]     Train net output #0: loss = 0.711511 (* 1 = 0.711511 loss)
I0204 08:55:51.472743 31953 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 08:56:00.751636 31953 solver.cpp:237] Iteration 530, loss = 0.694194
I0204 08:56:00.751703 31953 solver.cpp:253]     Train net output #0: loss = 0.694194 (* 1 = 0.694194 loss)
I0204 08:56:00.751715 31953 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 08:56:10.151569 31953 solver.cpp:237] Iteration 540, loss = 0.750683
I0204 08:56:10.151778 31953 solver.cpp:253]     Train net output #0: loss = 0.750683 (* 1 = 0.750683 loss)
I0204 08:56:10.151793 31953 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 08:56:19.729678 31953 solver.cpp:237] Iteration 550, loss = 0.693531
I0204 08:56:19.729737 31953 solver.cpp:253]     Train net output #0: loss = 0.693531 (* 1 = 0.693531 loss)
I0204 08:56:19.729749 31953 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 08:56:29.303736 31953 solver.cpp:237] Iteration 560, loss = 0.678883
I0204 08:56:29.303789 31953 solver.cpp:253]     Train net output #0: loss = 0.678883 (* 1 = 0.678883 loss)
I0204 08:56:29.303800 31953 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 08:56:38.847165 31953 solver.cpp:237] Iteration 570, loss = 0.759362
I0204 08:56:38.847218 31953 solver.cpp:253]     Train net output #0: loss = 0.759362 (* 1 = 0.759362 loss)
I0204 08:56:38.847230 31953 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 08:56:48.588994 31953 solver.cpp:237] Iteration 580, loss = 0.700907
I0204 08:56:48.589150 31953 solver.cpp:253]     Train net output #0: loss = 0.700907 (* 1 = 0.700907 loss)
I0204 08:56:48.589164 31953 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 08:56:58.152796 31953 solver.cpp:237] Iteration 590, loss = 0.718201
I0204 08:56:58.152853 31953 solver.cpp:253]     Train net output #0: loss = 0.718201 (* 1 = 0.718201 loss)
I0204 08:56:58.152864 31953 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 08:57:06.855588 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_600.caffemodel
I0204 08:57:06.857866 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_600.solverstate
I0204 08:57:06.858867 31953 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 08:57:11.410729 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:57:11.410780 31953 solver.cpp:409]     Test net output #1: loss = 0.695256 (* 1 = 0.695256 loss)
I0204 08:57:12.360606 31953 solver.cpp:237] Iteration 600, loss = 0.712863
I0204 08:57:12.360654 31953 solver.cpp:253]     Train net output #0: loss = 0.712863 (* 1 = 0.712863 loss)
I0204 08:57:12.360667 31953 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 08:57:21.790683 31953 solver.cpp:237] Iteration 610, loss = 0.706442
I0204 08:57:21.790856 31953 solver.cpp:253]     Train net output #0: loss = 0.706442 (* 1 = 0.706442 loss)
I0204 08:57:21.790870 31953 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 08:57:31.359333 31953 solver.cpp:237] Iteration 620, loss = 0.730915
I0204 08:57:31.359387 31953 solver.cpp:253]     Train net output #0: loss = 0.730915 (* 1 = 0.730915 loss)
I0204 08:57:31.359400 31953 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 08:57:40.957155 31953 solver.cpp:237] Iteration 630, loss = 0.715016
I0204 08:57:40.957212 31953 solver.cpp:253]     Train net output #0: loss = 0.715016 (* 1 = 0.715016 loss)
I0204 08:57:40.957224 31953 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 08:57:50.505004 31953 solver.cpp:237] Iteration 640, loss = 0.690649
I0204 08:57:50.505060 31953 solver.cpp:253]     Train net output #0: loss = 0.690649 (* 1 = 0.690649 loss)
I0204 08:57:50.505086 31953 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 08:58:00.012604 31953 solver.cpp:237] Iteration 650, loss = 0.720709
I0204 08:58:00.012809 31953 solver.cpp:253]     Train net output #0: loss = 0.720709 (* 1 = 0.720709 loss)
I0204 08:58:00.012821 31953 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 08:58:09.558326 31953 solver.cpp:237] Iteration 660, loss = 0.696612
I0204 08:58:09.558382 31953 solver.cpp:253]     Train net output #0: loss = 0.696612 (* 1 = 0.696612 loss)
I0204 08:58:09.558393 31953 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 08:58:19.057210 31953 solver.cpp:237] Iteration 670, loss = 0.692333
I0204 08:58:19.057265 31953 solver.cpp:253]     Train net output #0: loss = 0.692333 (* 1 = 0.692333 loss)
I0204 08:58:19.057276 31953 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 08:58:28.572738 31953 solver.cpp:237] Iteration 680, loss = 0.702795
I0204 08:58:28.572790 31953 solver.cpp:253]     Train net output #0: loss = 0.702795 (* 1 = 0.702795 loss)
I0204 08:58:28.572808 31953 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 08:58:38.162742 31953 solver.cpp:237] Iteration 690, loss = 0.698004
I0204 08:58:38.163221 31953 solver.cpp:253]     Train net output #0: loss = 0.698004 (* 1 = 0.698004 loss)
I0204 08:58:38.163236 31953 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 08:58:46.641476 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_700.caffemodel
I0204 08:58:46.644582 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_700.solverstate
I0204 08:58:46.646062 31953 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 08:58:51.141111 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 08:58:51.141180 31953 solver.cpp:409]     Test net output #1: loss = 0.696755 (* 1 = 0.696755 loss)
I0204 08:58:52.093245 31953 solver.cpp:237] Iteration 700, loss = 0.73575
I0204 08:58:52.093308 31953 solver.cpp:253]     Train net output #0: loss = 0.73575 (* 1 = 0.73575 loss)
I0204 08:58:52.093322 31953 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 08:59:01.533566 31953 solver.cpp:237] Iteration 710, loss = 0.692041
I0204 08:59:01.533634 31953 solver.cpp:253]     Train net output #0: loss = 0.692041 (* 1 = 0.692041 loss)
I0204 08:59:01.533648 31953 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 08:59:10.927152 31953 solver.cpp:237] Iteration 720, loss = 0.702249
I0204 08:59:10.927345 31953 solver.cpp:253]     Train net output #0: loss = 0.702249 (* 1 = 0.702249 loss)
I0204 08:59:10.927361 31953 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 08:59:20.443303 31953 solver.cpp:237] Iteration 730, loss = 0.735357
I0204 08:59:20.443374 31953 solver.cpp:253]     Train net output #0: loss = 0.735357 (* 1 = 0.735357 loss)
I0204 08:59:20.443388 31953 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 08:59:29.914633 31953 solver.cpp:237] Iteration 740, loss = 0.695104
I0204 08:59:29.914698 31953 solver.cpp:253]     Train net output #0: loss = 0.695104 (* 1 = 0.695104 loss)
I0204 08:59:29.914713 31953 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 08:59:39.715610 31953 solver.cpp:237] Iteration 750, loss = 0.699279
I0204 08:59:39.715679 31953 solver.cpp:253]     Train net output #0: loss = 0.699279 (* 1 = 0.699279 loss)
I0204 08:59:39.715693 31953 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 08:59:49.153317 31953 solver.cpp:237] Iteration 760, loss = 0.689819
I0204 08:59:49.154559 31953 solver.cpp:253]     Train net output #0: loss = 0.689819 (* 1 = 0.689819 loss)
I0204 08:59:49.154578 31953 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 08:59:58.560247 31953 solver.cpp:237] Iteration 770, loss = 0.697738
I0204 08:59:58.560324 31953 solver.cpp:253]     Train net output #0: loss = 0.697738 (* 1 = 0.697738 loss)
I0204 08:59:58.560338 31953 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 09:00:07.859709 31953 solver.cpp:237] Iteration 780, loss = 0.742046
I0204 09:00:07.859786 31953 solver.cpp:253]     Train net output #0: loss = 0.742046 (* 1 = 0.742046 loss)
I0204 09:00:07.859798 31953 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 09:00:17.066162 31953 solver.cpp:237] Iteration 790, loss = 0.70201
I0204 09:00:17.066238 31953 solver.cpp:253]     Train net output #0: loss = 0.70201 (* 1 = 0.70201 loss)
I0204 09:00:17.066251 31953 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 09:00:25.302292 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_800.caffemodel
I0204 09:00:25.311079 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_800.solverstate
I0204 09:00:25.312315 31953 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 09:00:30.023170 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:00:30.023223 31953 solver.cpp:409]     Test net output #1: loss = 0.694231 (* 1 = 0.694231 loss)
I0204 09:00:31.039510 31953 solver.cpp:237] Iteration 800, loss = 0.698298
I0204 09:00:31.039566 31953 solver.cpp:253]     Train net output #0: loss = 0.698298 (* 1 = 0.698298 loss)
I0204 09:00:31.039579 31953 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 09:00:40.575639 31953 solver.cpp:237] Iteration 810, loss = 0.729722
I0204 09:00:40.575692 31953 solver.cpp:253]     Train net output #0: loss = 0.729722 (* 1 = 0.729722 loss)
I0204 09:00:40.575705 31953 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 09:00:50.075448 31953 solver.cpp:237] Iteration 820, loss = 0.695012
I0204 09:00:50.075505 31953 solver.cpp:253]     Train net output #0: loss = 0.695012 (* 1 = 0.695012 loss)
I0204 09:00:50.075517 31953 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 09:00:59.643954 31953 solver.cpp:237] Iteration 830, loss = 0.709654
I0204 09:00:59.644134 31953 solver.cpp:253]     Train net output #0: loss = 0.709654 (* 1 = 0.709654 loss)
I0204 09:00:59.644148 31953 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 09:01:09.301152 31953 solver.cpp:237] Iteration 840, loss = 0.704208
I0204 09:01:09.301210 31953 solver.cpp:253]     Train net output #0: loss = 0.704208 (* 1 = 0.704208 loss)
I0204 09:01:09.301223 31953 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 09:01:18.889452 31953 solver.cpp:237] Iteration 850, loss = 0.703374
I0204 09:01:18.889506 31953 solver.cpp:253]     Train net output #0: loss = 0.703374 (* 1 = 0.703374 loss)
I0204 09:01:18.889518 31953 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 09:01:28.457432 31953 solver.cpp:237] Iteration 860, loss = 0.71729
I0204 09:01:28.457489 31953 solver.cpp:253]     Train net output #0: loss = 0.71729 (* 1 = 0.71729 loss)
I0204 09:01:28.457501 31953 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 09:01:38.021039 31953 solver.cpp:237] Iteration 870, loss = 0.710199
I0204 09:01:38.021159 31953 solver.cpp:253]     Train net output #0: loss = 0.710199 (* 1 = 0.710199 loss)
I0204 09:01:38.021173 31953 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 09:01:47.609542 31953 solver.cpp:237] Iteration 880, loss = 0.677673
I0204 09:01:47.609597 31953 solver.cpp:253]     Train net output #0: loss = 0.677673 (* 1 = 0.677673 loss)
I0204 09:01:47.609611 31953 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 09:01:57.176765 31953 solver.cpp:237] Iteration 890, loss = 0.727175
I0204 09:01:57.176818 31953 solver.cpp:253]     Train net output #0: loss = 0.727175 (* 1 = 0.727175 loss)
I0204 09:01:57.176831 31953 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 09:02:05.783316 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_900.caffemodel
I0204 09:02:05.785583 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_900.solverstate
I0204 09:02:05.786557 31953 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 09:02:10.322476 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:02:10.322649 31953 solver.cpp:409]     Test net output #1: loss = 0.70002 (* 1 = 0.70002 loss)
I0204 09:02:11.278995 31953 solver.cpp:237] Iteration 900, loss = 0.71723
I0204 09:02:11.279044 31953 solver.cpp:253]     Train net output #0: loss = 0.71723 (* 1 = 0.71723 loss)
I0204 09:02:11.279057 31953 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 09:02:20.844362 31953 solver.cpp:237] Iteration 910, loss = 0.703977
I0204 09:02:20.844429 31953 solver.cpp:253]     Train net output #0: loss = 0.703977 (* 1 = 0.703977 loss)
I0204 09:02:20.844440 31953 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 09:02:30.306169 31953 solver.cpp:237] Iteration 920, loss = 0.731928
I0204 09:02:30.306221 31953 solver.cpp:253]     Train net output #0: loss = 0.731928 (* 1 = 0.731928 loss)
I0204 09:02:30.306233 31953 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 09:02:39.659196 31953 solver.cpp:237] Iteration 930, loss = 0.716539
I0204 09:02:39.659250 31953 solver.cpp:253]     Train net output #0: loss = 0.716539 (* 1 = 0.716539 loss)
I0204 09:02:39.659262 31953 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 09:02:48.958663 31953 solver.cpp:237] Iteration 940, loss = 0.708802
I0204 09:02:48.958827 31953 solver.cpp:253]     Train net output #0: loss = 0.708802 (* 1 = 0.708802 loss)
I0204 09:02:48.958842 31953 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 09:02:58.250416 31953 solver.cpp:237] Iteration 950, loss = 0.710804
I0204 09:02:58.250471 31953 solver.cpp:253]     Train net output #0: loss = 0.710804 (* 1 = 0.710804 loss)
I0204 09:02:58.250483 31953 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 09:03:07.541784 31953 solver.cpp:237] Iteration 960, loss = 0.693781
I0204 09:03:07.541836 31953 solver.cpp:253]     Train net output #0: loss = 0.693781 (* 1 = 0.693781 loss)
I0204 09:03:07.541847 31953 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 09:03:16.806540 31953 solver.cpp:237] Iteration 970, loss = 0.715089
I0204 09:03:16.807099 31953 solver.cpp:253]     Train net output #0: loss = 0.715089 (* 1 = 0.715089 loss)
I0204 09:03:16.807117 31953 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 09:03:26.262650 31953 solver.cpp:237] Iteration 980, loss = 0.690908
I0204 09:03:26.262841 31953 solver.cpp:253]     Train net output #0: loss = 0.690908 (* 1 = 0.690908 loss)
I0204 09:03:26.262856 31953 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 09:03:35.705730 31953 solver.cpp:237] Iteration 990, loss = 0.712328
I0204 09:03:35.705801 31953 solver.cpp:253]     Train net output #0: loss = 0.712328 (* 1 = 0.712328 loss)
I0204 09:03:35.705814 31953 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 09:03:44.255122 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1000.caffemodel
I0204 09:03:44.257521 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1000.solverstate
I0204 09:03:44.258553 31953 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 09:03:48.780520 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:03:48.780587 31953 solver.cpp:409]     Test net output #1: loss = 0.694304 (* 1 = 0.694304 loss)
I0204 09:03:49.730784 31953 solver.cpp:237] Iteration 1000, loss = 0.705519
I0204 09:03:49.730849 31953 solver.cpp:253]     Train net output #0: loss = 0.705519 (* 1 = 0.705519 loss)
I0204 09:03:49.730862 31953 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 09:03:59.189944 31953 solver.cpp:237] Iteration 1010, loss = 0.709262
I0204 09:03:59.190163 31953 solver.cpp:253]     Train net output #0: loss = 0.709262 (* 1 = 0.709262 loss)
I0204 09:03:59.190184 31953 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 09:04:08.663758 31953 solver.cpp:237] Iteration 1020, loss = 0.72293
I0204 09:04:08.663827 31953 solver.cpp:253]     Train net output #0: loss = 0.72293 (* 1 = 0.72293 loss)
I0204 09:04:08.663841 31953 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 09:04:18.132068 31953 solver.cpp:237] Iteration 1030, loss = 0.687051
I0204 09:04:18.132140 31953 solver.cpp:253]     Train net output #0: loss = 0.687051 (* 1 = 0.687051 loss)
I0204 09:04:18.132154 31953 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 09:04:27.548936 31953 solver.cpp:237] Iteration 1040, loss = 0.717899
I0204 09:04:27.549003 31953 solver.cpp:253]     Train net output #0: loss = 0.717899 (* 1 = 0.717899 loss)
I0204 09:04:27.549017 31953 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 09:04:36.976150 31953 solver.cpp:237] Iteration 1050, loss = 0.721819
I0204 09:04:36.976335 31953 solver.cpp:253]     Train net output #0: loss = 0.721819 (* 1 = 0.721819 loss)
I0204 09:04:36.976349 31953 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 09:04:46.377936 31953 solver.cpp:237] Iteration 1060, loss = 0.682297
I0204 09:04:46.378005 31953 solver.cpp:253]     Train net output #0: loss = 0.682297 (* 1 = 0.682297 loss)
I0204 09:04:46.378018 31953 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 09:04:55.772081 31953 solver.cpp:237] Iteration 1070, loss = 0.712283
I0204 09:04:55.772150 31953 solver.cpp:253]     Train net output #0: loss = 0.712283 (* 1 = 0.712283 loss)
I0204 09:04:55.772163 31953 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 09:05:05.283927 31953 solver.cpp:237] Iteration 1080, loss = 0.690195
I0204 09:05:05.283984 31953 solver.cpp:253]     Train net output #0: loss = 0.690195 (* 1 = 0.690195 loss)
I0204 09:05:05.284001 31953 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 09:05:14.785747 31953 solver.cpp:237] Iteration 1090, loss = 0.701376
I0204 09:05:14.785910 31953 solver.cpp:253]     Train net output #0: loss = 0.701376 (* 1 = 0.701376 loss)
I0204 09:05:14.785923 31953 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 09:05:23.349293 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1100.caffemodel
I0204 09:05:23.351603 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1100.solverstate
I0204 09:05:23.352665 31953 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 09:05:28.025995 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:05:28.026082 31953 solver.cpp:409]     Test net output #1: loss = 0.693544 (* 1 = 0.693544 loss)
I0204 09:05:28.988611 31953 solver.cpp:237] Iteration 1100, loss = 0.709869
I0204 09:05:28.988682 31953 solver.cpp:253]     Train net output #0: loss = 0.709869 (* 1 = 0.709869 loss)
I0204 09:05:28.988695 31953 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 09:05:38.661340 31953 solver.cpp:237] Iteration 1110, loss = 0.70405
I0204 09:05:38.661406 31953 solver.cpp:253]     Train net output #0: loss = 0.70405 (* 1 = 0.70405 loss)
I0204 09:05:38.661424 31953 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 09:05:48.114105 31953 solver.cpp:237] Iteration 1120, loss = 0.682085
I0204 09:05:48.114297 31953 solver.cpp:253]     Train net output #0: loss = 0.682085 (* 1 = 0.682085 loss)
I0204 09:05:48.114312 31953 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 09:05:57.518115 31953 solver.cpp:237] Iteration 1130, loss = 0.746094
I0204 09:05:57.518188 31953 solver.cpp:253]     Train net output #0: loss = 0.746094 (* 1 = 0.746094 loss)
I0204 09:05:57.518203 31953 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 09:06:06.944633 31953 solver.cpp:237] Iteration 1140, loss = 0.687638
I0204 09:06:06.944695 31953 solver.cpp:253]     Train net output #0: loss = 0.687638 (* 1 = 0.687638 loss)
I0204 09:06:06.944708 31953 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 09:06:16.414078 31953 solver.cpp:237] Iteration 1150, loss = 0.717674
I0204 09:06:16.414149 31953 solver.cpp:253]     Train net output #0: loss = 0.717674 (* 1 = 0.717674 loss)
I0204 09:06:16.414163 31953 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 09:06:25.884708 31953 solver.cpp:237] Iteration 1160, loss = 0.717872
I0204 09:06:25.884928 31953 solver.cpp:253]     Train net output #0: loss = 0.717872 (* 1 = 0.717872 loss)
I0204 09:06:25.884943 31953 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 09:06:35.455649 31953 solver.cpp:237] Iteration 1170, loss = 0.712993
I0204 09:06:35.455720 31953 solver.cpp:253]     Train net output #0: loss = 0.712993 (* 1 = 0.712993 loss)
I0204 09:06:35.455734 31953 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 09:06:44.875337 31953 solver.cpp:237] Iteration 1180, loss = 0.731326
I0204 09:06:44.875407 31953 solver.cpp:253]     Train net output #0: loss = 0.731326 (* 1 = 0.731326 loss)
I0204 09:06:44.875422 31953 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 09:06:54.344553 31953 solver.cpp:237] Iteration 1190, loss = 0.693858
I0204 09:06:54.344624 31953 solver.cpp:253]     Train net output #0: loss = 0.693858 (* 1 = 0.693858 loss)
I0204 09:06:54.344636 31953 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 09:07:02.847316 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1200.caffemodel
I0204 09:07:02.859002 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1200.solverstate
I0204 09:07:02.861156 31953 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 09:07:07.437782 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:07:07.437852 31953 solver.cpp:409]     Test net output #1: loss = 0.69406 (* 1 = 0.69406 loss)
I0204 09:07:08.370937 31953 solver.cpp:237] Iteration 1200, loss = 0.696412
I0204 09:07:08.371009 31953 solver.cpp:253]     Train net output #0: loss = 0.696412 (* 1 = 0.696412 loss)
I0204 09:07:08.371024 31953 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 09:07:17.807777 31953 solver.cpp:237] Iteration 1210, loss = 0.72667
I0204 09:07:17.807847 31953 solver.cpp:253]     Train net output #0: loss = 0.72667 (* 1 = 0.72667 loss)
I0204 09:07:17.807860 31953 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 09:07:27.252446 31953 solver.cpp:237] Iteration 1220, loss = 0.718874
I0204 09:07:27.252516 31953 solver.cpp:253]     Train net output #0: loss = 0.718874 (* 1 = 0.718874 loss)
I0204 09:07:27.252531 31953 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 09:07:36.668056 31953 solver.cpp:237] Iteration 1230, loss = 0.715857
I0204 09:07:36.668236 31953 solver.cpp:253]     Train net output #0: loss = 0.715857 (* 1 = 0.715857 loss)
I0204 09:07:36.668251 31953 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 09:07:46.114042 31953 solver.cpp:237] Iteration 1240, loss = 0.705322
I0204 09:07:46.114114 31953 solver.cpp:253]     Train net output #0: loss = 0.705322 (* 1 = 0.705322 loss)
I0204 09:07:46.114126 31953 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 09:07:55.567582 31953 solver.cpp:237] Iteration 1250, loss = 0.706456
I0204 09:07:55.567653 31953 solver.cpp:253]     Train net output #0: loss = 0.706456 (* 1 = 0.706456 loss)
I0204 09:07:55.567667 31953 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 09:08:05.036662 31953 solver.cpp:237] Iteration 1260, loss = 0.700216
I0204 09:08:05.036731 31953 solver.cpp:253]     Train net output #0: loss = 0.700216 (* 1 = 0.700216 loss)
I0204 09:08:05.036746 31953 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 09:08:14.615622 31953 solver.cpp:237] Iteration 1270, loss = 0.69607
I0204 09:08:14.615805 31953 solver.cpp:253]     Train net output #0: loss = 0.69607 (* 1 = 0.69607 loss)
I0204 09:08:14.615821 31953 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 09:08:24.010004 31953 solver.cpp:237] Iteration 1280, loss = 0.686794
I0204 09:08:24.010089 31953 solver.cpp:253]     Train net output #0: loss = 0.686794 (* 1 = 0.686794 loss)
I0204 09:08:24.010102 31953 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 09:08:33.455122 31953 solver.cpp:237] Iteration 1290, loss = 0.745196
I0204 09:08:33.455199 31953 solver.cpp:253]     Train net output #0: loss = 0.745196 (* 1 = 0.745196 loss)
I0204 09:08:33.455211 31953 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 09:08:41.958240 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1300.caffemodel
I0204 09:08:41.960925 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1300.solverstate
I0204 09:08:41.962146 31953 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 09:08:46.471714 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:08:46.480602 31953 solver.cpp:409]     Test net output #1: loss = 0.698143 (* 1 = 0.698143 loss)
I0204 09:08:47.423638 31953 solver.cpp:237] Iteration 1300, loss = 0.676156
I0204 09:08:47.423699 31953 solver.cpp:253]     Train net output #0: loss = 0.676156 (* 1 = 0.676156 loss)
I0204 09:08:47.423712 31953 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 09:08:56.882143 31953 solver.cpp:237] Iteration 1310, loss = 0.710233
I0204 09:08:56.882208 31953 solver.cpp:253]     Train net output #0: loss = 0.710233 (* 1 = 0.710233 loss)
I0204 09:08:56.882221 31953 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 09:09:06.378164 31953 solver.cpp:237] Iteration 1320, loss = 0.696343
I0204 09:09:06.378223 31953 solver.cpp:253]     Train net output #0: loss = 0.696343 (* 1 = 0.696343 loss)
I0204 09:09:06.378235 31953 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 09:09:15.680094 31953 solver.cpp:237] Iteration 1330, loss = 0.707284
I0204 09:09:15.680177 31953 solver.cpp:253]     Train net output #0: loss = 0.707284 (* 1 = 0.707284 loss)
I0204 09:09:15.680222 31953 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 09:09:24.932760 31953 solver.cpp:237] Iteration 1340, loss = 0.73462
I0204 09:09:24.932958 31953 solver.cpp:253]     Train net output #0: loss = 0.73462 (* 1 = 0.73462 loss)
I0204 09:09:24.932973 31953 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 09:09:34.157559 31953 solver.cpp:237] Iteration 1350, loss = 0.704774
I0204 09:09:34.157627 31953 solver.cpp:253]     Train net output #0: loss = 0.704774 (* 1 = 0.704774 loss)
I0204 09:09:34.157640 31953 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 09:09:43.312768 31953 solver.cpp:237] Iteration 1360, loss = 0.712393
I0204 09:09:43.312834 31953 solver.cpp:253]     Train net output #0: loss = 0.712393 (* 1 = 0.712393 loss)
I0204 09:09:43.312849 31953 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 09:09:52.929282 31953 solver.cpp:237] Iteration 1370, loss = 0.738703
I0204 09:09:52.929359 31953 solver.cpp:253]     Train net output #0: loss = 0.738703 (* 1 = 0.738703 loss)
I0204 09:09:52.929373 31953 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 09:10:02.345327 31953 solver.cpp:237] Iteration 1380, loss = 0.688202
I0204 09:10:02.345500 31953 solver.cpp:253]     Train net output #0: loss = 0.688202 (* 1 = 0.688202 loss)
I0204 09:10:02.345515 31953 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 09:10:11.894129 31953 solver.cpp:237] Iteration 1390, loss = 0.704504
I0204 09:10:11.894201 31953 solver.cpp:253]     Train net output #0: loss = 0.704504 (* 1 = 0.704504 loss)
I0204 09:10:11.894214 31953 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 09:10:20.637552 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1400.caffemodel
I0204 09:10:20.639888 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1400.solverstate
I0204 09:10:20.640890 31953 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 09:10:25.216419 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:10:25.216490 31953 solver.cpp:409]     Test net output #1: loss = 0.693154 (* 1 = 0.693154 loss)
I0204 09:10:26.167790 31953 solver.cpp:237] Iteration 1400, loss = 0.700134
I0204 09:10:26.167855 31953 solver.cpp:253]     Train net output #0: loss = 0.700134 (* 1 = 0.700134 loss)
I0204 09:10:26.167870 31953 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 09:10:35.628929 31953 solver.cpp:237] Iteration 1410, loss = 0.705581
I0204 09:10:35.637240 31953 solver.cpp:253]     Train net output #0: loss = 0.705581 (* 1 = 0.705581 loss)
I0204 09:10:35.637271 31953 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 09:10:45.180671 31953 solver.cpp:237] Iteration 1420, loss = 0.706921
I0204 09:10:45.180740 31953 solver.cpp:253]     Train net output #0: loss = 0.706921 (* 1 = 0.706921 loss)
I0204 09:10:45.180755 31953 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 09:10:54.671810 31953 solver.cpp:237] Iteration 1430, loss = 0.702254
I0204 09:10:54.671883 31953 solver.cpp:253]     Train net output #0: loss = 0.702254 (* 1 = 0.702254 loss)
I0204 09:10:54.671897 31953 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 09:11:03.929482 31953 solver.cpp:237] Iteration 1440, loss = 0.68843
I0204 09:11:03.929546 31953 solver.cpp:253]     Train net output #0: loss = 0.68843 (* 1 = 0.68843 loss)
I0204 09:11:03.929558 31953 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 09:11:13.391069 31953 solver.cpp:237] Iteration 1450, loss = 0.711413
I0204 09:11:13.397018 31953 solver.cpp:253]     Train net output #0: loss = 0.711413 (* 1 = 0.711413 loss)
I0204 09:11:13.397045 31953 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 09:11:22.976393 31953 solver.cpp:237] Iteration 1460, loss = 0.69738
I0204 09:11:22.976445 31953 solver.cpp:253]     Train net output #0: loss = 0.69738 (* 1 = 0.69738 loss)
I0204 09:11:22.976457 31953 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 09:11:32.543691 31953 solver.cpp:237] Iteration 1470, loss = 0.694325
I0204 09:11:32.543771 31953 solver.cpp:253]     Train net output #0: loss = 0.694325 (* 1 = 0.694325 loss)
I0204 09:11:32.543786 31953 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 09:11:42.077679 31953 solver.cpp:237] Iteration 1480, loss = 0.691655
I0204 09:11:42.077751 31953 solver.cpp:253]     Train net output #0: loss = 0.691655 (* 1 = 0.691655 loss)
I0204 09:11:42.077764 31953 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 09:11:51.615945 31953 solver.cpp:237] Iteration 1490, loss = 0.700002
I0204 09:11:51.616119 31953 solver.cpp:253]     Train net output #0: loss = 0.700002 (* 1 = 0.700002 loss)
I0204 09:11:51.616133 31953 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 09:12:00.164360 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1500.caffemodel
I0204 09:12:00.166725 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1500.solverstate
I0204 09:12:00.167752 31953 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 09:12:04.678027 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:12:04.678100 31953 solver.cpp:409]     Test net output #1: loss = 0.695586 (* 1 = 0.695586 loss)
I0204 09:12:05.614289 31953 solver.cpp:237] Iteration 1500, loss = 0.719381
I0204 09:12:05.614354 31953 solver.cpp:253]     Train net output #0: loss = 0.719381 (* 1 = 0.719381 loss)
I0204 09:12:05.614368 31953 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 09:12:14.911048 31953 solver.cpp:237] Iteration 1510, loss = 0.685506
I0204 09:12:14.911128 31953 solver.cpp:253]     Train net output #0: loss = 0.685506 (* 1 = 0.685506 loss)
I0204 09:12:14.911157 31953 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 09:12:24.202014 31953 solver.cpp:237] Iteration 1520, loss = 0.69847
I0204 09:12:24.202535 31953 solver.cpp:253]     Train net output #0: loss = 0.69847 (* 1 = 0.69847 loss)
I0204 09:12:24.202550 31953 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 09:12:33.402879 31953 solver.cpp:237] Iteration 1530, loss = 0.73156
I0204 09:12:33.402953 31953 solver.cpp:253]     Train net output #0: loss = 0.73156 (* 1 = 0.73156 loss)
I0204 09:12:33.402967 31953 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 09:12:42.518363 31953 solver.cpp:237] Iteration 1540, loss = 0.692072
I0204 09:12:42.518429 31953 solver.cpp:253]     Train net output #0: loss = 0.692072 (* 1 = 0.692072 loss)
I0204 09:12:42.518442 31953 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 09:12:51.611570 31953 solver.cpp:237] Iteration 1550, loss = 0.711416
I0204 09:12:51.611636 31953 solver.cpp:253]     Train net output #0: loss = 0.711416 (* 1 = 0.711416 loss)
I0204 09:12:51.611650 31953 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 09:13:00.625638 31953 solver.cpp:237] Iteration 1560, loss = 0.695875
I0204 09:13:00.625784 31953 solver.cpp:253]     Train net output #0: loss = 0.695875 (* 1 = 0.695875 loss)
I0204 09:13:00.625797 31953 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 09:13:09.612570 31953 solver.cpp:237] Iteration 1570, loss = 0.705507
I0204 09:13:09.612634 31953 solver.cpp:253]     Train net output #0: loss = 0.705507 (* 1 = 0.705507 loss)
I0204 09:13:09.612648 31953 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 09:13:18.705981 31953 solver.cpp:237] Iteration 1580, loss = 0.707319
I0204 09:13:18.706053 31953 solver.cpp:253]     Train net output #0: loss = 0.707319 (* 1 = 0.707319 loss)
I0204 09:13:18.706066 31953 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 09:13:27.955112 31953 solver.cpp:237] Iteration 1590, loss = 0.694157
I0204 09:13:27.955185 31953 solver.cpp:253]     Train net output #0: loss = 0.694157 (* 1 = 0.694157 loss)
I0204 09:13:27.955199 31953 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 09:13:36.229383 31953 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1600.caffemodel
I0204 09:13:36.231791 31953 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num16_conv2num16_conv3num8_conv4num8_conv5num8/snaps/snap__iter_1600.solverstate
I0204 09:13:36.676941 31953 solver.cpp:321] Iteration 1600, loss = 0.702205
I0204 09:13:36.676995 31953 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 09:13:41.109614 31953 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 09:13:41.109676 31953 solver.cpp:409]     Test net output #1: loss = 0.694546 (* 1 = 0.694546 loss)
I0204 09:13:41.109688 31953 solver.cpp:326] Optimization Done.
I0204 09:13:41.109694 31953 caffe.cpp:215] Optimization Done.
