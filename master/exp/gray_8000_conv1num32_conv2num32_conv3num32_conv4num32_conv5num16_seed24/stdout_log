I0205 03:46:44.427525 12024 caffe.cpp:177] Use CPU.
I0205 03:46:44.428442 12024 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap_"
solver_mode: CPU
random_seed: 24
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/train_val.prototxt"
I0205 03:46:44.428628 12024 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/train_val.prototxt
I0205 03:46:44.429255 12024 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0205 03:46:44.429291 12024 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0205 03:46:44.429543 12024 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 03:46:44.429687 12024 layer_factory.hpp:77] Creating layer data
I0205 03:46:44.429877 12024 net.cpp:106] Creating Layer data
I0205 03:46:44.429898 12024 net.cpp:411] data -> data
I0205 03:46:44.430011 12024 net.cpp:411] data -> label
I0205 03:46:44.430039 12024 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0205 03:46:44.430214 12025 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0205 03:46:44.431233 12024 data_layer.cpp:41] output data size: 100,1,227,227
I0205 03:46:44.462872 12024 net.cpp:150] Setting up data
I0205 03:46:44.462954 12024 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 03:46:44.462965 12024 net.cpp:157] Top shape: 100 (100)
I0205 03:46:44.462970 12024 net.cpp:165] Memory required for data: 20612000
I0205 03:46:44.462993 12024 layer_factory.hpp:77] Creating layer conv1
I0205 03:46:44.463021 12024 net.cpp:106] Creating Layer conv1
I0205 03:46:44.463030 12024 net.cpp:454] conv1 <- data
I0205 03:46:44.463052 12024 net.cpp:411] conv1 -> conv1
I0205 03:46:44.463194 12024 net.cpp:150] Setting up conv1
I0205 03:46:44.463207 12024 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 03:46:44.463213 12024 net.cpp:165] Memory required for data: 59332000
I0205 03:46:44.463232 12024 layer_factory.hpp:77] Creating layer relu1
I0205 03:46:44.463244 12024 net.cpp:106] Creating Layer relu1
I0205 03:46:44.463250 12024 net.cpp:454] relu1 <- conv1
I0205 03:46:44.463260 12024 net.cpp:397] relu1 -> conv1 (in-place)
I0205 03:46:44.463274 12024 net.cpp:150] Setting up relu1
I0205 03:46:44.463280 12024 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 03:46:44.463289 12024 net.cpp:165] Memory required for data: 98052000
I0205 03:46:44.463295 12024 layer_factory.hpp:77] Creating layer pool1
I0205 03:46:44.463306 12024 net.cpp:106] Creating Layer pool1
I0205 03:46:44.463312 12024 net.cpp:454] pool1 <- conv1
I0205 03:46:44.463320 12024 net.cpp:411] pool1 -> pool1
I0205 03:46:44.463346 12024 net.cpp:150] Setting up pool1
I0205 03:46:44.463356 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.463361 12024 net.cpp:165] Memory required for data: 107383200
I0205 03:46:44.463367 12024 layer_factory.hpp:77] Creating layer norm1
I0205 03:46:44.463400 12024 net.cpp:106] Creating Layer norm1
I0205 03:46:44.463407 12024 net.cpp:454] norm1 <- pool1
I0205 03:46:44.463417 12024 net.cpp:411] norm1 -> norm1
I0205 03:46:44.463435 12024 net.cpp:150] Setting up norm1
I0205 03:46:44.463444 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.463450 12024 net.cpp:165] Memory required for data: 116714400
I0205 03:46:44.463455 12024 layer_factory.hpp:77] Creating layer conv2
I0205 03:46:44.463469 12024 net.cpp:106] Creating Layer conv2
I0205 03:46:44.463474 12024 net.cpp:454] conv2 <- norm1
I0205 03:46:44.463484 12024 net.cpp:411] conv2 -> conv2
I0205 03:46:44.463616 12024 net.cpp:150] Setting up conv2
I0205 03:46:44.463626 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.463631 12024 net.cpp:165] Memory required for data: 126045600
I0205 03:46:44.463644 12024 layer_factory.hpp:77] Creating layer relu2
I0205 03:46:44.463652 12024 net.cpp:106] Creating Layer relu2
I0205 03:46:44.463660 12024 net.cpp:454] relu2 <- conv2
I0205 03:46:44.463667 12024 net.cpp:397] relu2 -> conv2 (in-place)
I0205 03:46:44.463676 12024 net.cpp:150] Setting up relu2
I0205 03:46:44.463683 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.463690 12024 net.cpp:165] Memory required for data: 135376800
I0205 03:46:44.463695 12024 layer_factory.hpp:77] Creating layer pool2
I0205 03:46:44.463711 12024 net.cpp:106] Creating Layer pool2
I0205 03:46:44.463718 12024 net.cpp:454] pool2 <- conv2
I0205 03:46:44.463726 12024 net.cpp:411] pool2 -> pool2
I0205 03:46:44.463740 12024 net.cpp:150] Setting up pool2
I0205 03:46:44.463748 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.463753 12024 net.cpp:165] Memory required for data: 137540000
I0205 03:46:44.463759 12024 layer_factory.hpp:77] Creating layer norm2
I0205 03:46:44.463770 12024 net.cpp:106] Creating Layer norm2
I0205 03:46:44.463776 12024 net.cpp:454] norm2 <- pool2
I0205 03:46:44.463786 12024 net.cpp:411] norm2 -> norm2
I0205 03:46:44.463796 12024 net.cpp:150] Setting up norm2
I0205 03:46:44.463804 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.463809 12024 net.cpp:165] Memory required for data: 139703200
I0205 03:46:44.463815 12024 layer_factory.hpp:77] Creating layer conv3
I0205 03:46:44.463825 12024 net.cpp:106] Creating Layer conv3
I0205 03:46:44.463831 12024 net.cpp:454] conv3 <- norm2
I0205 03:46:44.463840 12024 net.cpp:411] conv3 -> conv3
I0205 03:46:44.463953 12024 net.cpp:150] Setting up conv3
I0205 03:46:44.463965 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.463970 12024 net.cpp:165] Memory required for data: 141866400
I0205 03:46:44.463981 12024 layer_factory.hpp:77] Creating layer relu3
I0205 03:46:44.463994 12024 net.cpp:106] Creating Layer relu3
I0205 03:46:44.463999 12024 net.cpp:454] relu3 <- conv3
I0205 03:46:44.464007 12024 net.cpp:397] relu3 -> conv3 (in-place)
I0205 03:46:44.464016 12024 net.cpp:150] Setting up relu3
I0205 03:46:44.464023 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.464028 12024 net.cpp:165] Memory required for data: 144029600
I0205 03:46:44.464033 12024 layer_factory.hpp:77] Creating layer conv4
I0205 03:46:44.464046 12024 net.cpp:106] Creating Layer conv4
I0205 03:46:44.464053 12024 net.cpp:454] conv4 <- conv3
I0205 03:46:44.464064 12024 net.cpp:411] conv4 -> conv4
I0205 03:46:44.464155 12024 net.cpp:150] Setting up conv4
I0205 03:46:44.464166 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.464171 12024 net.cpp:165] Memory required for data: 146192800
I0205 03:46:44.464179 12024 layer_factory.hpp:77] Creating layer relu4
I0205 03:46:44.464189 12024 net.cpp:106] Creating Layer relu4
I0205 03:46:44.464195 12024 net.cpp:454] relu4 <- conv4
I0205 03:46:44.464203 12024 net.cpp:397] relu4 -> conv4 (in-place)
I0205 03:46:44.464212 12024 net.cpp:150] Setting up relu4
I0205 03:46:44.464220 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.464224 12024 net.cpp:165] Memory required for data: 148356000
I0205 03:46:44.464236 12024 layer_factory.hpp:77] Creating layer conv5
I0205 03:46:44.464254 12024 net.cpp:106] Creating Layer conv5
I0205 03:46:44.464262 12024 net.cpp:454] conv5 <- conv4
I0205 03:46:44.464269 12024 net.cpp:411] conv5 -> conv5
I0205 03:46:44.464318 12024 net.cpp:150] Setting up conv5
I0205 03:46:44.464328 12024 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 03:46:44.464332 12024 net.cpp:165] Memory required for data: 149437600
I0205 03:46:44.464344 12024 layer_factory.hpp:77] Creating layer relu5
I0205 03:46:44.464351 12024 net.cpp:106] Creating Layer relu5
I0205 03:46:44.464357 12024 net.cpp:454] relu5 <- conv5
I0205 03:46:44.464367 12024 net.cpp:397] relu5 -> conv5 (in-place)
I0205 03:46:44.464376 12024 net.cpp:150] Setting up relu5
I0205 03:46:44.464383 12024 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 03:46:44.464388 12024 net.cpp:165] Memory required for data: 150519200
I0205 03:46:44.464395 12024 layer_factory.hpp:77] Creating layer pool5
I0205 03:46:44.464402 12024 net.cpp:106] Creating Layer pool5
I0205 03:46:44.464408 12024 net.cpp:454] pool5 <- conv5
I0205 03:46:44.464418 12024 net.cpp:411] pool5 -> pool5
I0205 03:46:44.464432 12024 net.cpp:150] Setting up pool5
I0205 03:46:44.464439 12024 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0205 03:46:44.464445 12024 net.cpp:165] Memory required for data: 150749600
I0205 03:46:44.464450 12024 layer_factory.hpp:77] Creating layer fc6
I0205 03:46:44.464467 12024 net.cpp:106] Creating Layer fc6
I0205 03:46:44.464473 12024 net.cpp:454] fc6 <- pool5
I0205 03:46:44.464484 12024 net.cpp:411] fc6 -> fc6
I0205 03:46:44.466083 12024 net.cpp:150] Setting up fc6
I0205 03:46:44.466104 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.466109 12024 net.cpp:165] Memory required for data: 150852000
I0205 03:46:44.466119 12024 layer_factory.hpp:77] Creating layer relu6
I0205 03:46:44.466130 12024 net.cpp:106] Creating Layer relu6
I0205 03:46:44.466137 12024 net.cpp:454] relu6 <- fc6
I0205 03:46:44.466145 12024 net.cpp:397] relu6 -> fc6 (in-place)
I0205 03:46:44.466155 12024 net.cpp:150] Setting up relu6
I0205 03:46:44.466161 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.466166 12024 net.cpp:165] Memory required for data: 150954400
I0205 03:46:44.466172 12024 layer_factory.hpp:77] Creating layer drop6
I0205 03:46:44.466183 12024 net.cpp:106] Creating Layer drop6
I0205 03:46:44.466189 12024 net.cpp:454] drop6 <- fc6
I0205 03:46:44.466197 12024 net.cpp:397] drop6 -> fc6 (in-place)
I0205 03:46:44.466217 12024 net.cpp:150] Setting up drop6
I0205 03:46:44.466224 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.466230 12024 net.cpp:165] Memory required for data: 151056800
I0205 03:46:44.466235 12024 layer_factory.hpp:77] Creating layer fc7
I0205 03:46:44.466246 12024 net.cpp:106] Creating Layer fc7
I0205 03:46:44.466253 12024 net.cpp:454] fc7 <- fc6
I0205 03:46:44.466262 12024 net.cpp:411] fc7 -> fc7
I0205 03:46:44.466959 12024 net.cpp:150] Setting up fc7
I0205 03:46:44.466972 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.466977 12024 net.cpp:165] Memory required for data: 151159200
I0205 03:46:44.466986 12024 layer_factory.hpp:77] Creating layer relu7
I0205 03:46:44.466995 12024 net.cpp:106] Creating Layer relu7
I0205 03:46:44.467000 12024 net.cpp:454] relu7 <- fc7
I0205 03:46:44.467012 12024 net.cpp:397] relu7 -> fc7 (in-place)
I0205 03:46:44.467022 12024 net.cpp:150] Setting up relu7
I0205 03:46:44.467030 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.467034 12024 net.cpp:165] Memory required for data: 151261600
I0205 03:46:44.467041 12024 layer_factory.hpp:77] Creating layer drop7
I0205 03:46:44.467048 12024 net.cpp:106] Creating Layer drop7
I0205 03:46:44.467054 12024 net.cpp:454] drop7 <- fc7
I0205 03:46:44.467064 12024 net.cpp:397] drop7 -> fc7 (in-place)
I0205 03:46:44.467074 12024 net.cpp:150] Setting up drop7
I0205 03:46:44.467080 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.467087 12024 net.cpp:165] Memory required for data: 151364000
I0205 03:46:44.467099 12024 layer_factory.hpp:77] Creating layer fc8
I0205 03:46:44.467114 12024 net.cpp:106] Creating Layer fc8
I0205 03:46:44.467128 12024 net.cpp:454] fc8 <- fc7
I0205 03:46:44.467139 12024 net.cpp:411] fc8 -> fc8
I0205 03:46:44.467164 12024 net.cpp:150] Setting up fc8
I0205 03:46:44.467172 12024 net.cpp:157] Top shape: 100 2 (200)
I0205 03:46:44.467178 12024 net.cpp:165] Memory required for data: 151364800
I0205 03:46:44.467186 12024 layer_factory.hpp:77] Creating layer loss
I0205 03:46:44.467197 12024 net.cpp:106] Creating Layer loss
I0205 03:46:44.467203 12024 net.cpp:454] loss <- fc8
I0205 03:46:44.467211 12024 net.cpp:454] loss <- label
I0205 03:46:44.467226 12024 net.cpp:411] loss -> loss
I0205 03:46:44.467241 12024 layer_factory.hpp:77] Creating layer loss
I0205 03:46:44.467270 12024 net.cpp:150] Setting up loss
I0205 03:46:44.467278 12024 net.cpp:157] Top shape: (1)
I0205 03:46:44.467285 12024 net.cpp:160]     with loss weight 1
I0205 03:46:44.467319 12024 net.cpp:165] Memory required for data: 151364804
I0205 03:46:44.467326 12024 net.cpp:226] loss needs backward computation.
I0205 03:46:44.467334 12024 net.cpp:226] fc8 needs backward computation.
I0205 03:46:44.467339 12024 net.cpp:226] drop7 needs backward computation.
I0205 03:46:44.467344 12024 net.cpp:226] relu7 needs backward computation.
I0205 03:46:44.467350 12024 net.cpp:226] fc7 needs backward computation.
I0205 03:46:44.467355 12024 net.cpp:226] drop6 needs backward computation.
I0205 03:46:44.467360 12024 net.cpp:226] relu6 needs backward computation.
I0205 03:46:44.467366 12024 net.cpp:226] fc6 needs backward computation.
I0205 03:46:44.467371 12024 net.cpp:226] pool5 needs backward computation.
I0205 03:46:44.467377 12024 net.cpp:226] relu5 needs backward computation.
I0205 03:46:44.467382 12024 net.cpp:226] conv5 needs backward computation.
I0205 03:46:44.467388 12024 net.cpp:226] relu4 needs backward computation.
I0205 03:46:44.467394 12024 net.cpp:226] conv4 needs backward computation.
I0205 03:46:44.467399 12024 net.cpp:226] relu3 needs backward computation.
I0205 03:46:44.467406 12024 net.cpp:226] conv3 needs backward computation.
I0205 03:46:44.467416 12024 net.cpp:226] norm2 needs backward computation.
I0205 03:46:44.467423 12024 net.cpp:226] pool2 needs backward computation.
I0205 03:46:44.467429 12024 net.cpp:226] relu2 needs backward computation.
I0205 03:46:44.467434 12024 net.cpp:226] conv2 needs backward computation.
I0205 03:46:44.467442 12024 net.cpp:226] norm1 needs backward computation.
I0205 03:46:44.467448 12024 net.cpp:226] pool1 needs backward computation.
I0205 03:46:44.467453 12024 net.cpp:226] relu1 needs backward computation.
I0205 03:46:44.467459 12024 net.cpp:226] conv1 needs backward computation.
I0205 03:46:44.467465 12024 net.cpp:228] data does not need backward computation.
I0205 03:46:44.467471 12024 net.cpp:270] This network produces output loss
I0205 03:46:44.467500 12024 net.cpp:283] Network initialization done.
I0205 03:46:44.468282 12024 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/train_val.prototxt
I0205 03:46:44.468360 12024 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0205 03:46:44.468660 12024 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 03:46:44.468849 12024 layer_factory.hpp:77] Creating layer data
I0205 03:46:44.468996 12024 net.cpp:106] Creating Layer data
I0205 03:46:44.469012 12024 net.cpp:411] data -> data
I0205 03:46:44.469027 12024 net.cpp:411] data -> label
I0205 03:46:44.469039 12024 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0205 03:46:44.469283 12029 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0205 03:46:44.470021 12024 data_layer.cpp:41] output data size: 100,1,227,227
I0205 03:46:44.501448 12024 net.cpp:150] Setting up data
I0205 03:46:44.501489 12024 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 03:46:44.501497 12024 net.cpp:157] Top shape: 100 (100)
I0205 03:46:44.501503 12024 net.cpp:165] Memory required for data: 20612000
I0205 03:46:44.501515 12024 layer_factory.hpp:77] Creating layer label_data_1_split
I0205 03:46:44.501538 12024 net.cpp:106] Creating Layer label_data_1_split
I0205 03:46:44.501548 12024 net.cpp:454] label_data_1_split <- label
I0205 03:46:44.501560 12024 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0205 03:46:44.501577 12024 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0205 03:46:44.501596 12024 net.cpp:150] Setting up label_data_1_split
I0205 03:46:44.501605 12024 net.cpp:157] Top shape: 100 (100)
I0205 03:46:44.501611 12024 net.cpp:157] Top shape: 100 (100)
I0205 03:46:44.501617 12024 net.cpp:165] Memory required for data: 20612800
I0205 03:46:44.501623 12024 layer_factory.hpp:77] Creating layer conv1
I0205 03:46:44.501642 12024 net.cpp:106] Creating Layer conv1
I0205 03:46:44.501649 12024 net.cpp:454] conv1 <- data
I0205 03:46:44.501658 12024 net.cpp:411] conv1 -> conv1
I0205 03:46:44.501736 12024 net.cpp:150] Setting up conv1
I0205 03:46:44.501746 12024 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 03:46:44.501752 12024 net.cpp:165] Memory required for data: 59332800
I0205 03:46:44.501768 12024 layer_factory.hpp:77] Creating layer relu1
I0205 03:46:44.501780 12024 net.cpp:106] Creating Layer relu1
I0205 03:46:44.501786 12024 net.cpp:454] relu1 <- conv1
I0205 03:46:44.501796 12024 net.cpp:397] relu1 -> conv1 (in-place)
I0205 03:46:44.501807 12024 net.cpp:150] Setting up relu1
I0205 03:46:44.501816 12024 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 03:46:44.501821 12024 net.cpp:165] Memory required for data: 98052800
I0205 03:46:44.501827 12024 layer_factory.hpp:77] Creating layer pool1
I0205 03:46:44.501838 12024 net.cpp:106] Creating Layer pool1
I0205 03:46:44.501844 12024 net.cpp:454] pool1 <- conv1
I0205 03:46:44.501853 12024 net.cpp:411] pool1 -> pool1
I0205 03:46:44.501868 12024 net.cpp:150] Setting up pool1
I0205 03:46:44.501875 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.501880 12024 net.cpp:165] Memory required for data: 107384000
I0205 03:46:44.501886 12024 layer_factory.hpp:77] Creating layer norm1
I0205 03:46:44.501899 12024 net.cpp:106] Creating Layer norm1
I0205 03:46:44.501904 12024 net.cpp:454] norm1 <- pool1
I0205 03:46:44.501914 12024 net.cpp:411] norm1 -> norm1
I0205 03:46:44.501926 12024 net.cpp:150] Setting up norm1
I0205 03:46:44.501937 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.501942 12024 net.cpp:165] Memory required for data: 116715200
I0205 03:46:44.501948 12024 layer_factory.hpp:77] Creating layer conv2
I0205 03:46:44.501960 12024 net.cpp:106] Creating Layer conv2
I0205 03:46:44.501966 12024 net.cpp:454] conv2 <- norm1
I0205 03:46:44.501977 12024 net.cpp:411] conv2 -> conv2
I0205 03:46:44.502121 12024 net.cpp:150] Setting up conv2
I0205 03:46:44.502131 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.502137 12024 net.cpp:165] Memory required for data: 126046400
I0205 03:46:44.502148 12024 layer_factory.hpp:77] Creating layer relu2
I0205 03:46:44.502158 12024 net.cpp:106] Creating Layer relu2
I0205 03:46:44.502167 12024 net.cpp:454] relu2 <- conv2
I0205 03:46:44.502188 12024 net.cpp:397] relu2 -> conv2 (in-place)
I0205 03:46:44.502207 12024 net.cpp:150] Setting up relu2
I0205 03:46:44.502214 12024 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 03:46:44.502220 12024 net.cpp:165] Memory required for data: 135377600
I0205 03:46:44.502226 12024 layer_factory.hpp:77] Creating layer pool2
I0205 03:46:44.502236 12024 net.cpp:106] Creating Layer pool2
I0205 03:46:44.502243 12024 net.cpp:454] pool2 <- conv2
I0205 03:46:44.502251 12024 net.cpp:411] pool2 -> pool2
I0205 03:46:44.502264 12024 net.cpp:150] Setting up pool2
I0205 03:46:44.502271 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502276 12024 net.cpp:165] Memory required for data: 137540800
I0205 03:46:44.502281 12024 layer_factory.hpp:77] Creating layer norm2
I0205 03:46:44.502295 12024 net.cpp:106] Creating Layer norm2
I0205 03:46:44.502300 12024 net.cpp:454] norm2 <- pool2
I0205 03:46:44.502310 12024 net.cpp:411] norm2 -> norm2
I0205 03:46:44.502320 12024 net.cpp:150] Setting up norm2
I0205 03:46:44.502329 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502336 12024 net.cpp:165] Memory required for data: 139704000
I0205 03:46:44.502341 12024 layer_factory.hpp:77] Creating layer conv3
I0205 03:46:44.502352 12024 net.cpp:106] Creating Layer conv3
I0205 03:46:44.502358 12024 net.cpp:454] conv3 <- norm2
I0205 03:46:44.502367 12024 net.cpp:411] conv3 -> conv3
I0205 03:46:44.502472 12024 net.cpp:150] Setting up conv3
I0205 03:46:44.502480 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502486 12024 net.cpp:165] Memory required for data: 141867200
I0205 03:46:44.502496 12024 layer_factory.hpp:77] Creating layer relu3
I0205 03:46:44.502507 12024 net.cpp:106] Creating Layer relu3
I0205 03:46:44.502514 12024 net.cpp:454] relu3 <- conv3
I0205 03:46:44.502522 12024 net.cpp:397] relu3 -> conv3 (in-place)
I0205 03:46:44.502532 12024 net.cpp:150] Setting up relu3
I0205 03:46:44.502538 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502543 12024 net.cpp:165] Memory required for data: 144030400
I0205 03:46:44.502549 12024 layer_factory.hpp:77] Creating layer conv4
I0205 03:46:44.502560 12024 net.cpp:106] Creating Layer conv4
I0205 03:46:44.502565 12024 net.cpp:454] conv4 <- conv3
I0205 03:46:44.502575 12024 net.cpp:411] conv4 -> conv4
I0205 03:46:44.502635 12024 net.cpp:150] Setting up conv4
I0205 03:46:44.502643 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502650 12024 net.cpp:165] Memory required for data: 146193600
I0205 03:46:44.502658 12024 layer_factory.hpp:77] Creating layer relu4
I0205 03:46:44.502668 12024 net.cpp:106] Creating Layer relu4
I0205 03:46:44.502674 12024 net.cpp:454] relu4 <- conv4
I0205 03:46:44.502686 12024 net.cpp:397] relu4 -> conv4 (in-place)
I0205 03:46:44.502694 12024 net.cpp:150] Setting up relu4
I0205 03:46:44.502701 12024 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 03:46:44.502707 12024 net.cpp:165] Memory required for data: 148356800
I0205 03:46:44.502712 12024 layer_factory.hpp:77] Creating layer conv5
I0205 03:46:44.502723 12024 net.cpp:106] Creating Layer conv5
I0205 03:46:44.502729 12024 net.cpp:454] conv5 <- conv4
I0205 03:46:44.502739 12024 net.cpp:411] conv5 -> conv5
I0205 03:46:44.502780 12024 net.cpp:150] Setting up conv5
I0205 03:46:44.502789 12024 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 03:46:44.502794 12024 net.cpp:165] Memory required for data: 149438400
I0205 03:46:44.502804 12024 layer_factory.hpp:77] Creating layer relu5
I0205 03:46:44.502816 12024 net.cpp:106] Creating Layer relu5
I0205 03:46:44.502822 12024 net.cpp:454] relu5 <- conv5
I0205 03:46:44.502831 12024 net.cpp:397] relu5 -> conv5 (in-place)
I0205 03:46:44.502840 12024 net.cpp:150] Setting up relu5
I0205 03:46:44.502848 12024 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 03:46:44.502854 12024 net.cpp:165] Memory required for data: 150520000
I0205 03:46:44.502861 12024 layer_factory.hpp:77] Creating layer pool5
I0205 03:46:44.502871 12024 net.cpp:106] Creating Layer pool5
I0205 03:46:44.502882 12024 net.cpp:454] pool5 <- conv5
I0205 03:46:44.502900 12024 net.cpp:411] pool5 -> pool5
I0205 03:46:44.502912 12024 net.cpp:150] Setting up pool5
I0205 03:46:44.502919 12024 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0205 03:46:44.502924 12024 net.cpp:165] Memory required for data: 150750400
I0205 03:46:44.502930 12024 layer_factory.hpp:77] Creating layer fc6
I0205 03:46:44.502943 12024 net.cpp:106] Creating Layer fc6
I0205 03:46:44.502948 12024 net.cpp:454] fc6 <- pool5
I0205 03:46:44.502959 12024 net.cpp:411] fc6 -> fc6
I0205 03:46:44.504715 12024 net.cpp:150] Setting up fc6
I0205 03:46:44.504729 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.504734 12024 net.cpp:165] Memory required for data: 150852800
I0205 03:46:44.504744 12024 layer_factory.hpp:77] Creating layer relu6
I0205 03:46:44.504751 12024 net.cpp:106] Creating Layer relu6
I0205 03:46:44.504758 12024 net.cpp:454] relu6 <- fc6
I0205 03:46:44.504767 12024 net.cpp:397] relu6 -> fc6 (in-place)
I0205 03:46:44.504776 12024 net.cpp:150] Setting up relu6
I0205 03:46:44.504783 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.504788 12024 net.cpp:165] Memory required for data: 150955200
I0205 03:46:44.504794 12024 layer_factory.hpp:77] Creating layer drop6
I0205 03:46:44.504806 12024 net.cpp:106] Creating Layer drop6
I0205 03:46:44.504812 12024 net.cpp:454] drop6 <- fc6
I0205 03:46:44.504820 12024 net.cpp:397] drop6 -> fc6 (in-place)
I0205 03:46:44.504834 12024 net.cpp:150] Setting up drop6
I0205 03:46:44.504843 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.504849 12024 net.cpp:165] Memory required for data: 151057600
I0205 03:46:44.504854 12024 layer_factory.hpp:77] Creating layer fc7
I0205 03:46:44.504865 12024 net.cpp:106] Creating Layer fc7
I0205 03:46:44.504871 12024 net.cpp:454] fc7 <- fc6
I0205 03:46:44.504879 12024 net.cpp:411] fc7 -> fc7
I0205 03:46:44.505648 12024 net.cpp:150] Setting up fc7
I0205 03:46:44.505661 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.505667 12024 net.cpp:165] Memory required for data: 151160000
I0205 03:46:44.505676 12024 layer_factory.hpp:77] Creating layer relu7
I0205 03:46:44.505684 12024 net.cpp:106] Creating Layer relu7
I0205 03:46:44.505691 12024 net.cpp:454] relu7 <- fc7
I0205 03:46:44.505702 12024 net.cpp:397] relu7 -> fc7 (in-place)
I0205 03:46:44.505712 12024 net.cpp:150] Setting up relu7
I0205 03:46:44.505720 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.505725 12024 net.cpp:165] Memory required for data: 151262400
I0205 03:46:44.505733 12024 layer_factory.hpp:77] Creating layer drop7
I0205 03:46:44.505741 12024 net.cpp:106] Creating Layer drop7
I0205 03:46:44.505748 12024 net.cpp:454] drop7 <- fc7
I0205 03:46:44.505755 12024 net.cpp:397] drop7 -> fc7 (in-place)
I0205 03:46:44.505769 12024 net.cpp:150] Setting up drop7
I0205 03:46:44.505774 12024 net.cpp:157] Top shape: 100 256 (25600)
I0205 03:46:44.505780 12024 net.cpp:165] Memory required for data: 151364800
I0205 03:46:44.505785 12024 layer_factory.hpp:77] Creating layer fc8
I0205 03:46:44.505795 12024 net.cpp:106] Creating Layer fc8
I0205 03:46:44.505800 12024 net.cpp:454] fc8 <- fc7
I0205 03:46:44.505808 12024 net.cpp:411] fc8 -> fc8
I0205 03:46:44.505836 12024 net.cpp:150] Setting up fc8
I0205 03:46:44.505846 12024 net.cpp:157] Top shape: 100 2 (200)
I0205 03:46:44.505851 12024 net.cpp:165] Memory required for data: 151365600
I0205 03:46:44.505858 12024 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0205 03:46:44.505868 12024 net.cpp:106] Creating Layer fc8_fc8_0_split
I0205 03:46:44.505877 12024 net.cpp:454] fc8_fc8_0_split <- fc8
I0205 03:46:44.505885 12024 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0205 03:46:44.505914 12024 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0205 03:46:44.505926 12024 net.cpp:150] Setting up fc8_fc8_0_split
I0205 03:46:44.505934 12024 net.cpp:157] Top shape: 100 2 (200)
I0205 03:46:44.505940 12024 net.cpp:157] Top shape: 100 2 (200)
I0205 03:46:44.505945 12024 net.cpp:165] Memory required for data: 151367200
I0205 03:46:44.505951 12024 layer_factory.hpp:77] Creating layer accuracy
I0205 03:46:44.505976 12024 net.cpp:106] Creating Layer accuracy
I0205 03:46:44.505982 12024 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0205 03:46:44.505990 12024 net.cpp:454] accuracy <- label_data_1_split_0
I0205 03:46:44.505997 12024 net.cpp:411] accuracy -> accuracy
I0205 03:46:44.506009 12024 net.cpp:150] Setting up accuracy
I0205 03:46:44.506017 12024 net.cpp:157] Top shape: (1)
I0205 03:46:44.506022 12024 net.cpp:165] Memory required for data: 151367204
I0205 03:46:44.506027 12024 layer_factory.hpp:77] Creating layer loss
I0205 03:46:44.506039 12024 net.cpp:106] Creating Layer loss
I0205 03:46:44.506045 12024 net.cpp:454] loss <- fc8_fc8_0_split_1
I0205 03:46:44.506052 12024 net.cpp:454] loss <- label_data_1_split_1
I0205 03:46:44.506060 12024 net.cpp:411] loss -> loss
I0205 03:46:44.506073 12024 layer_factory.hpp:77] Creating layer loss
I0205 03:46:44.506135 12024 net.cpp:150] Setting up loss
I0205 03:46:44.506144 12024 net.cpp:157] Top shape: (1)
I0205 03:46:44.506148 12024 net.cpp:160]     with loss weight 1
I0205 03:46:44.506166 12024 net.cpp:165] Memory required for data: 151367208
I0205 03:46:44.506172 12024 net.cpp:226] loss needs backward computation.
I0205 03:46:44.506180 12024 net.cpp:228] accuracy does not need backward computation.
I0205 03:46:44.506186 12024 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0205 03:46:44.506191 12024 net.cpp:226] fc8 needs backward computation.
I0205 03:46:44.506197 12024 net.cpp:226] drop7 needs backward computation.
I0205 03:46:44.506202 12024 net.cpp:226] relu7 needs backward computation.
I0205 03:46:44.506208 12024 net.cpp:226] fc7 needs backward computation.
I0205 03:46:44.506213 12024 net.cpp:226] drop6 needs backward computation.
I0205 03:46:44.506219 12024 net.cpp:226] relu6 needs backward computation.
I0205 03:46:44.506224 12024 net.cpp:226] fc6 needs backward computation.
I0205 03:46:44.506230 12024 net.cpp:226] pool5 needs backward computation.
I0205 03:46:44.506235 12024 net.cpp:226] relu5 needs backward computation.
I0205 03:46:44.506242 12024 net.cpp:226] conv5 needs backward computation.
I0205 03:46:44.506247 12024 net.cpp:226] relu4 needs backward computation.
I0205 03:46:44.506253 12024 net.cpp:226] conv4 needs backward computation.
I0205 03:46:44.506259 12024 net.cpp:226] relu3 needs backward computation.
I0205 03:46:44.506265 12024 net.cpp:226] conv3 needs backward computation.
I0205 03:46:44.506273 12024 net.cpp:226] norm2 needs backward computation.
I0205 03:46:44.506278 12024 net.cpp:226] pool2 needs backward computation.
I0205 03:46:44.506284 12024 net.cpp:226] relu2 needs backward computation.
I0205 03:46:44.506290 12024 net.cpp:226] conv2 needs backward computation.
I0205 03:46:44.506295 12024 net.cpp:226] norm1 needs backward computation.
I0205 03:46:44.506301 12024 net.cpp:226] pool1 needs backward computation.
I0205 03:46:44.506307 12024 net.cpp:226] relu1 needs backward computation.
I0205 03:46:44.506314 12024 net.cpp:226] conv1 needs backward computation.
I0205 03:46:44.506319 12024 net.cpp:228] label_data_1_split does not need backward computation.
I0205 03:46:44.506326 12024 net.cpp:228] data does not need backward computation.
I0205 03:46:44.506331 12024 net.cpp:270] This network produces output accuracy
I0205 03:46:44.506337 12024 net.cpp:270] This network produces output loss
I0205 03:46:44.506372 12024 net.cpp:283] Network initialization done.
I0205 03:46:44.506495 12024 solver.cpp:60] Solver scaffolding done.
I0205 03:46:44.506553 12024 caffe.cpp:212] Starting Optimization
I0205 03:46:44.506561 12024 solver.cpp:288] Solving CaffeNet
I0205 03:46:44.506567 12024 solver.cpp:289] Learning Rate Policy: step
I0205 03:46:44.507532 12024 solver.cpp:341] Iteration 0, Testing net (#0)
I0205 03:46:44.507669 12024 blocking_queue.cpp:50] Data layer prefetch queue empty
I0205 03:46:51.691998 12024 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0205 03:46:51.692070 12024 solver.cpp:409]     Test net output #1: loss = 4.4814 (* 1 = 4.4814 loss)
I0205 03:46:53.378765 12024 solver.cpp:237] Iteration 0, loss = 9.76503
I0205 03:46:53.378862 12024 solver.cpp:253]     Train net output #0: loss = 9.76503 (* 1 = 9.76503 loss)
I0205 03:46:53.378877 12024 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0205 03:47:09.114807 12024 solver.cpp:237] Iteration 10, loss = 1.3091
I0205 03:47:09.114881 12024 solver.cpp:253]     Train net output #0: loss = 1.3091 (* 1 = 1.3091 loss)
I0205 03:47:09.114894 12024 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0205 03:47:26.445497 12024 solver.cpp:237] Iteration 20, loss = 1.04087
I0205 03:47:26.445647 12024 solver.cpp:253]     Train net output #0: loss = 1.04087 (* 1 = 1.04087 loss)
I0205 03:47:26.445660 12024 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0205 03:47:44.359205 12024 solver.cpp:237] Iteration 30, loss = 0.886281
I0205 03:47:44.359275 12024 solver.cpp:253]     Train net output #0: loss = 0.886281 (* 1 = 0.886281 loss)
I0205 03:47:44.359288 12024 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0205 03:48:02.231627 12024 solver.cpp:237] Iteration 40, loss = 0.81974
I0205 03:48:02.231822 12024 solver.cpp:253]     Train net output #0: loss = 0.81974 (* 1 = 0.81974 loss)
I0205 03:48:02.231837 12024 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0205 03:48:20.045294 12024 solver.cpp:237] Iteration 50, loss = 0.811372
I0205 03:48:20.045372 12024 solver.cpp:253]     Train net output #0: loss = 0.811372 (* 1 = 0.811372 loss)
I0205 03:48:20.045387 12024 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0205 03:48:37.936120 12024 solver.cpp:237] Iteration 60, loss = 0.833645
I0205 03:48:37.936311 12024 solver.cpp:253]     Train net output #0: loss = 0.833645 (* 1 = 0.833645 loss)
I0205 03:48:37.936326 12024 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0205 03:48:55.933210 12024 solver.cpp:237] Iteration 70, loss = 0.699339
I0205 03:48:55.933279 12024 solver.cpp:253]     Train net output #0: loss = 0.699339 (* 1 = 0.699339 loss)
I0205 03:48:55.933291 12024 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0205 03:49:13.910243 12024 solver.cpp:237] Iteration 80, loss = 0.750718
I0205 03:49:13.910436 12024 solver.cpp:253]     Train net output #0: loss = 0.750718 (* 1 = 0.750718 loss)
I0205 03:49:13.910451 12024 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0205 03:49:31.804553 12024 solver.cpp:237] Iteration 90, loss = 0.750646
I0205 03:49:31.804632 12024 solver.cpp:253]     Train net output #0: loss = 0.750646 (* 1 = 0.750646 loss)
I0205 03:49:31.804646 12024 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0205 03:49:47.888115 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_100.caffemodel
I0205 03:49:47.892590 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_100.solverstate
I0205 03:49:47.893975 12024 solver.cpp:341] Iteration 100, Testing net (#0)
I0205 03:49:56.161068 12024 solver.cpp:409]     Test net output #0: accuracy = 0.541
I0205 03:49:56.161136 12024 solver.cpp:409]     Test net output #1: loss = 0.689225 (* 1 = 0.689225 loss)
I0205 03:49:57.942417 12024 solver.cpp:237] Iteration 100, loss = 0.725258
I0205 03:49:57.942484 12024 solver.cpp:253]     Train net output #0: loss = 0.725258 (* 1 = 0.725258 loss)
I0205 03:49:57.942497 12024 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0205 03:50:15.797871 12024 solver.cpp:237] Iteration 110, loss = 0.705922
I0205 03:50:15.797941 12024 solver.cpp:253]     Train net output #0: loss = 0.705922 (* 1 = 0.705922 loss)
I0205 03:50:15.797955 12024 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0205 03:50:33.637410 12024 solver.cpp:237] Iteration 120, loss = 0.751329
I0205 03:50:33.637617 12024 solver.cpp:253]     Train net output #0: loss = 0.751329 (* 1 = 0.751329 loss)
I0205 03:50:33.637631 12024 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0205 03:50:51.451192 12024 solver.cpp:237] Iteration 130, loss = 0.686807
I0205 03:50:51.451269 12024 solver.cpp:253]     Train net output #0: loss = 0.686807 (* 1 = 0.686807 loss)
I0205 03:50:51.451297 12024 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0205 03:51:09.226506 12024 solver.cpp:237] Iteration 140, loss = 0.748336
I0205 03:51:09.226747 12024 solver.cpp:253]     Train net output #0: loss = 0.748336 (* 1 = 0.748336 loss)
I0205 03:51:09.226761 12024 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0205 03:51:26.963534 12024 solver.cpp:237] Iteration 150, loss = 0.717322
I0205 03:51:26.963609 12024 solver.cpp:253]     Train net output #0: loss = 0.717322 (* 1 = 0.717322 loss)
I0205 03:51:26.963623 12024 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0205 03:51:44.704535 12024 solver.cpp:237] Iteration 160, loss = 0.712731
I0205 03:51:44.704771 12024 solver.cpp:253]     Train net output #0: loss = 0.712731 (* 1 = 0.712731 loss)
I0205 03:51:44.704785 12024 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0205 03:52:02.410208 12024 solver.cpp:237] Iteration 170, loss = 0.758822
I0205 03:52:02.410282 12024 solver.cpp:253]     Train net output #0: loss = 0.758822 (* 1 = 0.758822 loss)
I0205 03:52:02.410295 12024 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0205 03:52:20.109161 12024 solver.cpp:237] Iteration 180, loss = 0.728423
I0205 03:52:20.109372 12024 solver.cpp:253]     Train net output #0: loss = 0.728423 (* 1 = 0.728423 loss)
I0205 03:52:20.109387 12024 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0205 03:52:37.803326 12024 solver.cpp:237] Iteration 190, loss = 0.736662
I0205 03:52:37.803405 12024 solver.cpp:253]     Train net output #0: loss = 0.736662 (* 1 = 0.736662 loss)
I0205 03:52:37.803417 12024 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0205 03:52:53.676381 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_200.caffemodel
I0205 03:52:53.680071 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_200.solverstate
I0205 03:52:53.681432 12024 solver.cpp:341] Iteration 200, Testing net (#0)
I0205 03:53:01.839890 12024 solver.cpp:409]     Test net output #0: accuracy = 0.624
I0205 03:53:01.839958 12024 solver.cpp:409]     Test net output #1: loss = 0.684852 (* 1 = 0.684852 loss)
I0205 03:53:03.611331 12024 solver.cpp:237] Iteration 200, loss = 0.675595
I0205 03:53:03.611397 12024 solver.cpp:253]     Train net output #0: loss = 0.675595 (* 1 = 0.675595 loss)
I0205 03:53:03.611410 12024 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0205 03:53:21.269608 12024 solver.cpp:237] Iteration 210, loss = 0.690221
I0205 03:53:21.269688 12024 solver.cpp:253]     Train net output #0: loss = 0.690221 (* 1 = 0.690221 loss)
I0205 03:53:21.269702 12024 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0205 03:53:38.916595 12024 solver.cpp:237] Iteration 220, loss = 0.771538
I0205 03:53:38.916803 12024 solver.cpp:253]     Train net output #0: loss = 0.771538 (* 1 = 0.771538 loss)
I0205 03:53:38.916818 12024 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0205 03:53:56.509379 12024 solver.cpp:237] Iteration 230, loss = 0.67295
I0205 03:53:56.509454 12024 solver.cpp:253]     Train net output #0: loss = 0.67295 (* 1 = 0.67295 loss)
I0205 03:53:56.509467 12024 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0205 03:54:14.130812 12024 solver.cpp:237] Iteration 240, loss = 0.697009
I0205 03:54:14.131036 12024 solver.cpp:253]     Train net output #0: loss = 0.697009 (* 1 = 0.697009 loss)
I0205 03:54:14.131052 12024 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0205 03:54:31.669330 12024 solver.cpp:237] Iteration 250, loss = 0.752544
I0205 03:54:31.669410 12024 solver.cpp:253]     Train net output #0: loss = 0.752544 (* 1 = 0.752544 loss)
I0205 03:54:31.669423 12024 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0205 03:54:49.177845 12024 solver.cpp:237] Iteration 260, loss = 0.666469
I0205 03:54:49.178103 12024 solver.cpp:253]     Train net output #0: loss = 0.666469 (* 1 = 0.666469 loss)
I0205 03:54:49.178122 12024 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0205 03:55:06.676542 12024 solver.cpp:237] Iteration 270, loss = 0.706828
I0205 03:55:06.676621 12024 solver.cpp:253]     Train net output #0: loss = 0.706828 (* 1 = 0.706828 loss)
I0205 03:55:06.676633 12024 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0205 03:55:24.128121 12024 solver.cpp:237] Iteration 280, loss = 0.673968
I0205 03:55:24.128345 12024 solver.cpp:253]     Train net output #0: loss = 0.673968 (* 1 = 0.673968 loss)
I0205 03:55:24.128360 12024 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0205 03:55:41.538218 12024 solver.cpp:237] Iteration 290, loss = 0.650691
I0205 03:55:41.538298 12024 solver.cpp:253]     Train net output #0: loss = 0.650691 (* 1 = 0.650691 loss)
I0205 03:55:41.538311 12024 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0205 03:55:57.196789 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_300.caffemodel
I0205 03:55:57.200525 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_300.solverstate
I0205 03:55:57.201879 12024 solver.cpp:341] Iteration 300, Testing net (#0)
I0205 03:56:05.229470 12024 solver.cpp:409]     Test net output #0: accuracy = 0.616
I0205 03:56:05.229532 12024 solver.cpp:409]     Test net output #1: loss = 0.629711 (* 1 = 0.629711 loss)
I0205 03:56:06.966001 12024 solver.cpp:237] Iteration 300, loss = 0.729718
I0205 03:56:06.966069 12024 solver.cpp:253]     Train net output #0: loss = 0.729718 (* 1 = 0.729718 loss)
I0205 03:56:06.966083 12024 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0205 03:56:24.357002 12024 solver.cpp:237] Iteration 310, loss = 0.608705
I0205 03:56:24.357085 12024 solver.cpp:253]     Train net output #0: loss = 0.608705 (* 1 = 0.608705 loss)
I0205 03:56:24.357105 12024 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0205 03:56:41.684053 12024 solver.cpp:237] Iteration 320, loss = 0.589392
I0205 03:56:41.684458 12024 solver.cpp:253]     Train net output #0: loss = 0.589392 (* 1 = 0.589392 loss)
I0205 03:56:41.684474 12024 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0205 03:56:59.047263 12024 solver.cpp:237] Iteration 330, loss = 0.598832
I0205 03:56:59.047338 12024 solver.cpp:253]     Train net output #0: loss = 0.598832 (* 1 = 0.598832 loss)
I0205 03:56:59.047351 12024 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0205 03:57:16.457447 12024 solver.cpp:237] Iteration 340, loss = 0.5482
I0205 03:57:16.457665 12024 solver.cpp:253]     Train net output #0: loss = 0.5482 (* 1 = 0.5482 loss)
I0205 03:57:16.457680 12024 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0205 03:57:33.908540 12024 solver.cpp:237] Iteration 350, loss = 0.570966
I0205 03:57:33.908618 12024 solver.cpp:253]     Train net output #0: loss = 0.570966 (* 1 = 0.570966 loss)
I0205 03:57:33.908632 12024 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0205 03:57:51.498075 12024 solver.cpp:237] Iteration 360, loss = 0.543106
I0205 03:57:51.498282 12024 solver.cpp:253]     Train net output #0: loss = 0.543106 (* 1 = 0.543106 loss)
I0205 03:57:51.498297 12024 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0205 03:58:09.250421 12024 solver.cpp:237] Iteration 370, loss = 0.543257
I0205 03:58:09.250499 12024 solver.cpp:253]     Train net output #0: loss = 0.543257 (* 1 = 0.543257 loss)
I0205 03:58:09.250512 12024 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0205 03:58:27.226408 12024 solver.cpp:237] Iteration 380, loss = 0.387301
I0205 03:58:27.226610 12024 solver.cpp:253]     Train net output #0: loss = 0.387301 (* 1 = 0.387301 loss)
I0205 03:58:27.226626 12024 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0205 03:58:45.392426 12024 solver.cpp:237] Iteration 390, loss = 0.385907
I0205 03:58:45.392508 12024 solver.cpp:253]     Train net output #0: loss = 0.385907 (* 1 = 0.385907 loss)
I0205 03:58:45.392521 12024 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0205 03:59:01.730101 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_400.caffemodel
I0205 03:59:01.734634 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_400.solverstate
I0205 03:59:01.736001 12024 solver.cpp:341] Iteration 400, Testing net (#0)
I0205 03:59:10.151252 12024 solver.cpp:409]     Test net output #0: accuracy = 0.866
I0205 03:59:10.151320 12024 solver.cpp:409]     Test net output #1: loss = 0.333082 (* 1 = 0.333082 loss)
I0205 03:59:11.967625 12024 solver.cpp:237] Iteration 400, loss = 0.333453
I0205 03:59:11.967691 12024 solver.cpp:253]     Train net output #0: loss = 0.333453 (* 1 = 0.333453 loss)
I0205 03:59:11.967705 12024 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0205 03:59:30.219308 12024 solver.cpp:237] Iteration 410, loss = 0.405338
I0205 03:59:30.219390 12024 solver.cpp:253]     Train net output #0: loss = 0.405338 (* 1 = 0.405338 loss)
I0205 03:59:30.219403 12024 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0205 03:59:48.573431 12024 solver.cpp:237] Iteration 420, loss = 0.398439
I0205 03:59:48.573662 12024 solver.cpp:253]     Train net output #0: loss = 0.398439 (* 1 = 0.398439 loss)
I0205 03:59:48.573678 12024 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0205 04:00:06.908972 12024 solver.cpp:237] Iteration 430, loss = 0.532333
I0205 04:00:06.909044 12024 solver.cpp:253]     Train net output #0: loss = 0.532333 (* 1 = 0.532333 loss)
I0205 04:00:06.909056 12024 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0205 04:00:25.200508 12024 solver.cpp:237] Iteration 440, loss = 0.377943
I0205 04:00:25.200716 12024 solver.cpp:253]     Train net output #0: loss = 0.377943 (* 1 = 0.377943 loss)
I0205 04:00:25.200731 12024 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0205 04:00:43.435544 12024 solver.cpp:237] Iteration 450, loss = 0.327027
I0205 04:00:43.435623 12024 solver.cpp:253]     Train net output #0: loss = 0.327027 (* 1 = 0.327027 loss)
I0205 04:00:43.435637 12024 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0205 04:01:01.747964 12024 solver.cpp:237] Iteration 460, loss = 0.219824
I0205 04:01:01.748178 12024 solver.cpp:253]     Train net output #0: loss = 0.219824 (* 1 = 0.219824 loss)
I0205 04:01:01.748193 12024 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0205 04:01:20.093080 12024 solver.cpp:237] Iteration 470, loss = 0.169688
I0205 04:01:20.093159 12024 solver.cpp:253]     Train net output #0: loss = 0.169688 (* 1 = 0.169688 loss)
I0205 04:01:20.093173 12024 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0205 04:01:38.361672 12024 solver.cpp:237] Iteration 480, loss = 0.173864
I0205 04:01:38.361873 12024 solver.cpp:253]     Train net output #0: loss = 0.173864 (* 1 = 0.173864 loss)
I0205 04:01:38.361888 12024 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0205 04:01:56.615810 12024 solver.cpp:237] Iteration 490, loss = 0.231176
I0205 04:01:56.615888 12024 solver.cpp:253]     Train net output #0: loss = 0.231176 (* 1 = 0.231176 loss)
I0205 04:01:56.615901 12024 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0205 04:02:12.965898 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_500.caffemodel
I0205 04:02:12.969832 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_500.solverstate
I0205 04:02:12.971210 12024 solver.cpp:341] Iteration 500, Testing net (#0)
I0205 04:02:21.416702 12024 solver.cpp:409]     Test net output #0: accuracy = 0.9
I0205 04:02:21.416764 12024 solver.cpp:409]     Test net output #1: loss = 0.236735 (* 1 = 0.236735 loss)
I0205 04:02:23.241355 12024 solver.cpp:237] Iteration 500, loss = 0.220843
I0205 04:02:23.241442 12024 solver.cpp:253]     Train net output #0: loss = 0.220843 (* 1 = 0.220843 loss)
I0205 04:02:23.241456 12024 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0205 04:02:41.323968 12024 solver.cpp:237] Iteration 510, loss = 0.247017
I0205 04:02:41.324038 12024 solver.cpp:253]     Train net output #0: loss = 0.247017 (* 1 = 0.247017 loss)
I0205 04:02:41.324049 12024 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0205 04:02:59.271142 12024 solver.cpp:237] Iteration 520, loss = 0.428443
I0205 04:02:59.271395 12024 solver.cpp:253]     Train net output #0: loss = 0.428443 (* 1 = 0.428443 loss)
I0205 04:02:59.271411 12024 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0205 04:03:17.100047 12024 solver.cpp:237] Iteration 530, loss = 0.110885
I0205 04:03:17.100136 12024 solver.cpp:253]     Train net output #0: loss = 0.110885 (* 1 = 0.110885 loss)
I0205 04:03:17.100148 12024 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0205 04:03:34.817047 12024 solver.cpp:237] Iteration 540, loss = 0.177187
I0205 04:03:34.817278 12024 solver.cpp:253]     Train net output #0: loss = 0.177187 (* 1 = 0.177187 loss)
I0205 04:03:34.817292 12024 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0205 04:03:52.556659 12024 solver.cpp:237] Iteration 550, loss = 0.132874
I0205 04:03:52.556740 12024 solver.cpp:253]     Train net output #0: loss = 0.132874 (* 1 = 0.132874 loss)
I0205 04:03:52.556752 12024 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0205 04:04:10.280238 12024 solver.cpp:237] Iteration 560, loss = 0.129352
I0205 04:04:10.280443 12024 solver.cpp:253]     Train net output #0: loss = 0.129352 (* 1 = 0.129352 loss)
I0205 04:04:10.280458 12024 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0205 04:04:27.965142 12024 solver.cpp:237] Iteration 570, loss = 0.0891797
I0205 04:04:27.965215 12024 solver.cpp:253]     Train net output #0: loss = 0.0891797 (* 1 = 0.0891797 loss)
I0205 04:04:27.965227 12024 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0205 04:04:45.624727 12024 solver.cpp:237] Iteration 580, loss = 0.0547621
I0205 04:04:45.624933 12024 solver.cpp:253]     Train net output #0: loss = 0.0547621 (* 1 = 0.0547621 loss)
I0205 04:04:45.624949 12024 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0205 04:05:03.277834 12024 solver.cpp:237] Iteration 590, loss = 0.0521097
I0205 04:05:03.277915 12024 solver.cpp:253]     Train net output #0: loss = 0.0521097 (* 1 = 0.0521097 loss)
I0205 04:05:03.277927 12024 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0205 04:05:19.222050 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_600.caffemodel
I0205 04:05:19.225790 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_600.solverstate
I0205 04:05:19.227154 12024 solver.cpp:341] Iteration 600, Testing net (#0)
I0205 04:05:27.457298 12024 solver.cpp:409]     Test net output #0: accuracy = 0.926
I0205 04:05:27.457362 12024 solver.cpp:409]     Test net output #1: loss = 0.186228 (* 1 = 0.186228 loss)
I0205 04:05:29.236824 12024 solver.cpp:237] Iteration 600, loss = 0.21423
I0205 04:05:29.236891 12024 solver.cpp:253]     Train net output #0: loss = 0.21423 (* 1 = 0.21423 loss)
I0205 04:05:29.236902 12024 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0205 04:05:46.978482 12024 solver.cpp:237] Iteration 610, loss = 0.074737
I0205 04:05:46.978564 12024 solver.cpp:253]     Train net output #0: loss = 0.074737 (* 1 = 0.074737 loss)
I0205 04:05:46.978577 12024 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0205 04:06:04.716917 12024 solver.cpp:237] Iteration 620, loss = 0.0263503
I0205 04:06:04.717130 12024 solver.cpp:253]     Train net output #0: loss = 0.0263503 (* 1 = 0.0263503 loss)
I0205 04:06:04.717145 12024 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0205 04:06:22.528785 12024 solver.cpp:237] Iteration 630, loss = 0.0803176
I0205 04:06:22.528863 12024 solver.cpp:253]     Train net output #0: loss = 0.0803176 (* 1 = 0.0803176 loss)
I0205 04:06:22.528890 12024 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0205 04:06:40.412020 12024 solver.cpp:237] Iteration 640, loss = 0.141388
I0205 04:06:40.412245 12024 solver.cpp:253]     Train net output #0: loss = 0.141388 (* 1 = 0.141388 loss)
I0205 04:06:40.412261 12024 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0205 04:06:58.399024 12024 solver.cpp:237] Iteration 650, loss = 0.278657
I0205 04:06:58.399101 12024 solver.cpp:253]     Train net output #0: loss = 0.278657 (* 1 = 0.278657 loss)
I0205 04:06:58.399114 12024 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0205 04:07:16.447695 12024 solver.cpp:237] Iteration 660, loss = 0.0209266
I0205 04:07:16.447933 12024 solver.cpp:253]     Train net output #0: loss = 0.0209266 (* 1 = 0.0209266 loss)
I0205 04:07:16.447948 12024 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0205 04:07:34.460402 12024 solver.cpp:237] Iteration 670, loss = 0.104819
I0205 04:07:34.460475 12024 solver.cpp:253]     Train net output #0: loss = 0.104819 (* 1 = 0.104819 loss)
I0205 04:07:34.460489 12024 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0205 04:07:52.524155 12024 solver.cpp:237] Iteration 680, loss = 0.0324033
I0205 04:07:52.524370 12024 solver.cpp:253]     Train net output #0: loss = 0.0324033 (* 1 = 0.0324033 loss)
I0205 04:07:52.524385 12024 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0205 04:08:10.596335 12024 solver.cpp:237] Iteration 690, loss = 0.105171
I0205 04:08:10.596413 12024 solver.cpp:253]     Train net output #0: loss = 0.105171 (* 1 = 0.105171 loss)
I0205 04:08:10.596426 12024 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0205 04:08:26.878438 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_700.caffemodel
I0205 04:08:26.882217 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_700.solverstate
I0205 04:08:26.883584 12024 solver.cpp:341] Iteration 700, Testing net (#0)
I0205 04:08:35.285356 12024 solver.cpp:409]     Test net output #0: accuracy = 0.988
I0205 04:08:35.285421 12024 solver.cpp:409]     Test net output #1: loss = 0.0301405 (* 1 = 0.0301405 loss)
I0205 04:08:37.091625 12024 solver.cpp:237] Iteration 700, loss = 0.0379872
I0205 04:08:37.091691 12024 solver.cpp:253]     Train net output #0: loss = 0.0379872 (* 1 = 0.0379872 loss)
I0205 04:08:37.091703 12024 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0205 04:08:55.161087 12024 solver.cpp:237] Iteration 710, loss = 0.0190319
I0205 04:08:55.161175 12024 solver.cpp:253]     Train net output #0: loss = 0.0190319 (* 1 = 0.0190319 loss)
I0205 04:08:55.161188 12024 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0205 04:09:13.267073 12024 solver.cpp:237] Iteration 720, loss = 0.0505256
I0205 04:09:13.267287 12024 solver.cpp:253]     Train net output #0: loss = 0.0505256 (* 1 = 0.0505256 loss)
I0205 04:09:13.267302 12024 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0205 04:09:31.401063 12024 solver.cpp:237] Iteration 730, loss = 0.0218986
I0205 04:09:31.401149 12024 solver.cpp:253]     Train net output #0: loss = 0.0218986 (* 1 = 0.0218986 loss)
I0205 04:09:31.401162 12024 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0205 04:09:49.552492 12024 solver.cpp:237] Iteration 740, loss = 0.0211803
I0205 04:09:49.552700 12024 solver.cpp:253]     Train net output #0: loss = 0.0211802 (* 1 = 0.0211802 loss)
I0205 04:09:49.552714 12024 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0205 04:10:07.690194 12024 solver.cpp:237] Iteration 750, loss = 0.0460581
I0205 04:10:07.690271 12024 solver.cpp:253]     Train net output #0: loss = 0.0460581 (* 1 = 0.0460581 loss)
I0205 04:10:07.690284 12024 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0205 04:10:25.819701 12024 solver.cpp:237] Iteration 760, loss = 0.00435684
I0205 04:10:25.819952 12024 solver.cpp:253]     Train net output #0: loss = 0.00435683 (* 1 = 0.00435683 loss)
I0205 04:10:25.819972 12024 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0205 04:10:43.957567 12024 solver.cpp:237] Iteration 770, loss = 0.0162812
I0205 04:10:43.957646 12024 solver.cpp:253]     Train net output #0: loss = 0.0162812 (* 1 = 0.0162812 loss)
I0205 04:10:43.957660 12024 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0205 04:11:02.096410 12024 solver.cpp:237] Iteration 780, loss = 0.00288287
I0205 04:11:02.096628 12024 solver.cpp:253]     Train net output #0: loss = 0.00288285 (* 1 = 0.00288285 loss)
I0205 04:11:02.096644 12024 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0205 04:11:20.165009 12024 solver.cpp:237] Iteration 790, loss = 0.00509789
I0205 04:11:20.165102 12024 solver.cpp:253]     Train net output #0: loss = 0.00509788 (* 1 = 0.00509788 loss)
I0205 04:11:20.165117 12024 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0205 04:11:36.412062 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_800.caffemodel
I0205 04:11:36.415802 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_800.solverstate
I0205 04:11:36.417183 12024 solver.cpp:341] Iteration 800, Testing net (#0)
I0205 04:11:44.754444 12024 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0205 04:11:44.754511 12024 solver.cpp:409]     Test net output #1: loss = 0.0085795 (* 1 = 0.0085795 loss)
I0205 04:11:46.558498 12024 solver.cpp:237] Iteration 800, loss = 0.0429129
I0205 04:11:46.558568 12024 solver.cpp:253]     Train net output #0: loss = 0.0429129 (* 1 = 0.0429129 loss)
I0205 04:11:46.558581 12024 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0205 04:12:04.585582 12024 solver.cpp:237] Iteration 810, loss = 0.00391973
I0205 04:12:04.585664 12024 solver.cpp:253]     Train net output #0: loss = 0.00391972 (* 1 = 0.00391972 loss)
I0205 04:12:04.585676 12024 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0205 04:12:22.645001 12024 solver.cpp:237] Iteration 820, loss = 0.0509
I0205 04:12:22.645215 12024 solver.cpp:253]     Train net output #0: loss = 0.0509 (* 1 = 0.0509 loss)
I0205 04:12:22.645231 12024 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0205 04:12:40.772477 12024 solver.cpp:237] Iteration 830, loss = 0.0152795
I0205 04:12:40.772552 12024 solver.cpp:253]     Train net output #0: loss = 0.0152795 (* 1 = 0.0152795 loss)
I0205 04:12:40.772565 12024 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0205 04:12:58.900787 12024 solver.cpp:237] Iteration 840, loss = 0.020762
I0205 04:12:58.901008 12024 solver.cpp:253]     Train net output #0: loss = 0.020762 (* 1 = 0.020762 loss)
I0205 04:12:58.901023 12024 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0205 04:13:17.050575 12024 solver.cpp:237] Iteration 850, loss = 0.00381058
I0205 04:13:17.050653 12024 solver.cpp:253]     Train net output #0: loss = 0.00381056 (* 1 = 0.00381056 loss)
I0205 04:13:17.050667 12024 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0205 04:13:35.204538 12024 solver.cpp:237] Iteration 860, loss = 0.00496677
I0205 04:13:35.204740 12024 solver.cpp:253]     Train net output #0: loss = 0.00496676 (* 1 = 0.00496676 loss)
I0205 04:13:35.204756 12024 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0205 04:13:53.312608 12024 solver.cpp:237] Iteration 870, loss = 0.0171976
I0205 04:13:53.312686 12024 solver.cpp:253]     Train net output #0: loss = 0.0171976 (* 1 = 0.0171976 loss)
I0205 04:13:53.312700 12024 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0205 04:14:11.551813 12024 solver.cpp:237] Iteration 880, loss = 0.0300561
I0205 04:14:11.552042 12024 solver.cpp:253]     Train net output #0: loss = 0.0300561 (* 1 = 0.0300561 loss)
I0205 04:14:11.552058 12024 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0205 04:14:29.806638 12024 solver.cpp:237] Iteration 890, loss = 0.0200532
I0205 04:14:29.806713 12024 solver.cpp:253]     Train net output #0: loss = 0.0200532 (* 1 = 0.0200532 loss)
I0205 04:14:29.806743 12024 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0205 04:14:46.280470 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_900.caffemodel
I0205 04:14:46.284301 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_900.solverstate
I0205 04:14:46.285678 12024 solver.cpp:341] Iteration 900, Testing net (#0)
I0205 04:14:54.754212 12024 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0205 04:14:54.754279 12024 solver.cpp:409]     Test net output #1: loss = 0.0128814 (* 1 = 0.0128814 loss)
I0205 04:14:56.580545 12024 solver.cpp:237] Iteration 900, loss = 0.041324
I0205 04:14:56.580611 12024 solver.cpp:253]     Train net output #0: loss = 0.041324 (* 1 = 0.041324 loss)
I0205 04:14:56.580623 12024 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0205 04:15:14.843611 12024 solver.cpp:237] Iteration 910, loss = 0.0206257
I0205 04:15:14.843689 12024 solver.cpp:253]     Train net output #0: loss = 0.0206256 (* 1 = 0.0206256 loss)
I0205 04:15:14.843703 12024 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0205 04:15:33.088063 12024 solver.cpp:237] Iteration 920, loss = 0.0239694
I0205 04:15:33.088287 12024 solver.cpp:253]     Train net output #0: loss = 0.0239694 (* 1 = 0.0239694 loss)
I0205 04:15:33.088302 12024 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0205 04:15:51.378216 12024 solver.cpp:237] Iteration 930, loss = 0.00412478
I0205 04:15:51.378291 12024 solver.cpp:253]     Train net output #0: loss = 0.00412475 (* 1 = 0.00412475 loss)
I0205 04:15:51.378304 12024 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0205 04:16:09.697898 12024 solver.cpp:237] Iteration 940, loss = 0.00275114
I0205 04:16:09.698130 12024 solver.cpp:253]     Train net output #0: loss = 0.00275111 (* 1 = 0.00275111 loss)
I0205 04:16:09.698146 12024 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0205 04:16:28.176915 12024 solver.cpp:237] Iteration 950, loss = 0.0646523
I0205 04:16:28.176995 12024 solver.cpp:253]     Train net output #0: loss = 0.0646523 (* 1 = 0.0646523 loss)
I0205 04:16:28.177008 12024 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0205 04:16:46.817731 12024 solver.cpp:237] Iteration 960, loss = 0.00557857
I0205 04:16:46.817945 12024 solver.cpp:253]     Train net output #0: loss = 0.00557854 (* 1 = 0.00557854 loss)
I0205 04:16:46.817961 12024 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0205 04:17:05.514333 12024 solver.cpp:237] Iteration 970, loss = 0.112593
I0205 04:17:05.514410 12024 solver.cpp:253]     Train net output #0: loss = 0.112593 (* 1 = 0.112593 loss)
I0205 04:17:05.514425 12024 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0205 04:17:24.349017 12024 solver.cpp:237] Iteration 980, loss = 0.0166113
I0205 04:17:24.349249 12024 solver.cpp:253]     Train net output #0: loss = 0.0166113 (* 1 = 0.0166113 loss)
I0205 04:17:24.349264 12024 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0205 04:17:43.128813 12024 solver.cpp:237] Iteration 990, loss = 0.0300579
I0205 04:17:43.128890 12024 solver.cpp:253]     Train net output #0: loss = 0.0300578 (* 1 = 0.0300578 loss)
I0205 04:17:43.128902 12024 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0205 04:17:59.839912 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1000.caffemodel
I0205 04:17:59.843660 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1000.solverstate
I0205 04:17:59.845033 12024 solver.cpp:341] Iteration 1000, Testing net (#0)
I0205 04:18:08.481786 12024 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0205 04:18:08.481855 12024 solver.cpp:409]     Test net output #1: loss = 0.0146809 (* 1 = 0.0146809 loss)
I0205 04:18:10.329656 12024 solver.cpp:237] Iteration 1000, loss = 0.0144248
I0205 04:18:10.329725 12024 solver.cpp:253]     Train net output #0: loss = 0.0144248 (* 1 = 0.0144248 loss)
I0205 04:18:10.329737 12024 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0205 04:18:28.706240 12024 solver.cpp:237] Iteration 1010, loss = 0.00679112
I0205 04:18:28.706320 12024 solver.cpp:253]     Train net output #0: loss = 0.0067911 (* 1 = 0.0067911 loss)
I0205 04:18:28.706332 12024 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0205 04:18:47.089138 12024 solver.cpp:237] Iteration 1020, loss = 0.0105571
I0205 04:18:47.089406 12024 solver.cpp:253]     Train net output #0: loss = 0.0105571 (* 1 = 0.0105571 loss)
I0205 04:18:47.089421 12024 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0205 04:19:05.487218 12024 solver.cpp:237] Iteration 1030, loss = 0.0130566
I0205 04:19:05.487298 12024 solver.cpp:253]     Train net output #0: loss = 0.0130566 (* 1 = 0.0130566 loss)
I0205 04:19:05.487310 12024 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0205 04:19:23.885130 12024 solver.cpp:237] Iteration 1040, loss = 0.0216439
I0205 04:19:23.885335 12024 solver.cpp:253]     Train net output #0: loss = 0.0216439 (* 1 = 0.0216439 loss)
I0205 04:19:23.885350 12024 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0205 04:19:42.214819 12024 solver.cpp:237] Iteration 1050, loss = 0.00764328
I0205 04:19:42.214900 12024 solver.cpp:253]     Train net output #0: loss = 0.00764326 (* 1 = 0.00764326 loss)
I0205 04:19:42.214912 12024 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0205 04:20:00.546500 12024 solver.cpp:237] Iteration 1060, loss = 0.00634912
I0205 04:20:00.546710 12024 solver.cpp:253]     Train net output #0: loss = 0.0063491 (* 1 = 0.0063491 loss)
I0205 04:20:00.546725 12024 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0205 04:20:18.834558 12024 solver.cpp:237] Iteration 1070, loss = 0.00977837
I0205 04:20:18.834633 12024 solver.cpp:253]     Train net output #0: loss = 0.00977836 (* 1 = 0.00977836 loss)
I0205 04:20:18.834647 12024 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0205 04:20:37.135440 12024 solver.cpp:237] Iteration 1080, loss = 0.00148533
I0205 04:20:37.135648 12024 solver.cpp:253]     Train net output #0: loss = 0.00148531 (* 1 = 0.00148531 loss)
I0205 04:20:37.135664 12024 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0205 04:20:55.385860 12024 solver.cpp:237] Iteration 1090, loss = 0.0198883
I0205 04:20:55.385937 12024 solver.cpp:253]     Train net output #0: loss = 0.0198883 (* 1 = 0.0198883 loss)
I0205 04:20:55.385951 12024 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0205 04:21:11.842397 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1100.caffemodel
I0205 04:21:11.846196 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1100.solverstate
I0205 04:21:11.847550 12024 solver.cpp:341] Iteration 1100, Testing net (#0)
I0205 04:21:20.330291 12024 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 04:21:20.330353 12024 solver.cpp:409]     Test net output #1: loss = 0.00421942 (* 1 = 0.00421942 loss)
I0205 04:21:22.151810 12024 solver.cpp:237] Iteration 1100, loss = 0.00696603
I0205 04:21:22.151875 12024 solver.cpp:253]     Train net output #0: loss = 0.00696602 (* 1 = 0.00696602 loss)
I0205 04:21:22.151890 12024 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0205 04:21:40.497681 12024 solver.cpp:237] Iteration 1110, loss = 0.00504132
I0205 04:21:40.497759 12024 solver.cpp:253]     Train net output #0: loss = 0.0050413 (* 1 = 0.0050413 loss)
I0205 04:21:40.497772 12024 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0205 04:21:58.841500 12024 solver.cpp:237] Iteration 1120, loss = 0.00559019
I0205 04:21:58.841748 12024 solver.cpp:253]     Train net output #0: loss = 0.00559018 (* 1 = 0.00559018 loss)
I0205 04:21:58.841769 12024 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0205 04:22:17.178351 12024 solver.cpp:237] Iteration 1130, loss = 0.0017609
I0205 04:22:17.178427 12024 solver.cpp:253]     Train net output #0: loss = 0.00176089 (* 1 = 0.00176089 loss)
I0205 04:22:17.178441 12024 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0205 04:22:35.559437 12024 solver.cpp:237] Iteration 1140, loss = 0.00852196
I0205 04:22:35.559648 12024 solver.cpp:253]     Train net output #0: loss = 0.00852194 (* 1 = 0.00852194 loss)
I0205 04:22:35.559662 12024 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0205 04:22:53.915457 12024 solver.cpp:237] Iteration 1150, loss = 0.012173
I0205 04:22:53.915537 12024 solver.cpp:253]     Train net output #0: loss = 0.012173 (* 1 = 0.012173 loss)
I0205 04:22:53.915550 12024 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0205 04:23:12.289994 12024 solver.cpp:237] Iteration 1160, loss = 0.00107675
I0205 04:23:12.290212 12024 solver.cpp:253]     Train net output #0: loss = 0.00107673 (* 1 = 0.00107673 loss)
I0205 04:23:12.290228 12024 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0205 04:23:30.598814 12024 solver.cpp:237] Iteration 1170, loss = 0.00901375
I0205 04:23:30.598891 12024 solver.cpp:253]     Train net output #0: loss = 0.00901373 (* 1 = 0.00901373 loss)
I0205 04:23:30.598904 12024 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0205 04:23:48.904866 12024 solver.cpp:237] Iteration 1180, loss = 0.000843465
I0205 04:23:48.905072 12024 solver.cpp:253]     Train net output #0: loss = 0.000843445 (* 1 = 0.000843445 loss)
I0205 04:23:48.905087 12024 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0205 04:24:07.180613 12024 solver.cpp:237] Iteration 1190, loss = 0.00189689
I0205 04:24:07.180688 12024 solver.cpp:253]     Train net output #0: loss = 0.00189687 (* 1 = 0.00189687 loss)
I0205 04:24:07.180701 12024 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0205 04:24:23.589109 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1200.caffemodel
I0205 04:24:23.592854 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1200.solverstate
I0205 04:24:23.594223 12024 solver.cpp:341] Iteration 1200, Testing net (#0)
I0205 04:24:32.076450 12024 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0205 04:24:32.076519 12024 solver.cpp:409]     Test net output #1: loss = 0.00173097 (* 1 = 0.00173097 loss)
I0205 04:24:33.898838 12024 solver.cpp:237] Iteration 1200, loss = 0.00139194
I0205 04:24:33.898905 12024 solver.cpp:253]     Train net output #0: loss = 0.00139192 (* 1 = 0.00139192 loss)
I0205 04:24:33.898917 12024 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0205 04:24:52.107550 12024 solver.cpp:237] Iteration 1210, loss = 0.00336727
I0205 04:24:52.107633 12024 solver.cpp:253]     Train net output #0: loss = 0.00336725 (* 1 = 0.00336725 loss)
I0205 04:24:52.107646 12024 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0205 04:25:10.282536 12024 solver.cpp:237] Iteration 1220, loss = 0.0193865
I0205 04:25:10.282752 12024 solver.cpp:253]     Train net output #0: loss = 0.0193865 (* 1 = 0.0193865 loss)
I0205 04:25:10.282766 12024 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0205 04:25:28.452605 12024 solver.cpp:237] Iteration 1230, loss = 0.0117903
I0205 04:25:28.452679 12024 solver.cpp:253]     Train net output #0: loss = 0.0117902 (* 1 = 0.0117902 loss)
I0205 04:25:28.452692 12024 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0205 04:25:46.622587 12024 solver.cpp:237] Iteration 1240, loss = 0.00187848
I0205 04:25:46.622786 12024 solver.cpp:253]     Train net output #0: loss = 0.00187845 (* 1 = 0.00187845 loss)
I0205 04:25:46.622802 12024 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0205 04:26:04.784801 12024 solver.cpp:237] Iteration 1250, loss = 0.0038514
I0205 04:26:04.784878 12024 solver.cpp:253]     Train net output #0: loss = 0.00385137 (* 1 = 0.00385137 loss)
I0205 04:26:04.784907 12024 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0205 04:26:22.941458 12024 solver.cpp:237] Iteration 1260, loss = 0.00303616
I0205 04:26:22.941697 12024 solver.cpp:253]     Train net output #0: loss = 0.00303614 (* 1 = 0.00303614 loss)
I0205 04:26:22.941712 12024 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0205 04:26:41.151906 12024 solver.cpp:237] Iteration 1270, loss = 0.00155637
I0205 04:26:41.151984 12024 solver.cpp:253]     Train net output #0: loss = 0.00155635 (* 1 = 0.00155635 loss)
I0205 04:26:41.151998 12024 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0205 04:26:59.310111 12024 solver.cpp:237] Iteration 1280, loss = 0.00538092
I0205 04:26:59.310322 12024 solver.cpp:253]     Train net output #0: loss = 0.00538089 (* 1 = 0.00538089 loss)
I0205 04:26:59.310338 12024 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0205 04:27:17.434428 12024 solver.cpp:237] Iteration 1290, loss = 0.00641667
I0205 04:27:17.434509 12024 solver.cpp:253]     Train net output #0: loss = 0.00641664 (* 1 = 0.00641664 loss)
I0205 04:27:17.434522 12024 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0205 04:27:33.772130 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1300.caffemodel
I0205 04:27:33.775907 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1300.solverstate
I0205 04:27:33.777279 12024 solver.cpp:341] Iteration 1300, Testing net (#0)
I0205 04:27:42.191937 12024 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0205 04:27:42.192003 12024 solver.cpp:409]     Test net output #1: loss = 0.00259211 (* 1 = 0.00259211 loss)
I0205 04:27:43.998217 12024 solver.cpp:237] Iteration 1300, loss = 0.0202572
I0205 04:27:43.998283 12024 solver.cpp:253]     Train net output #0: loss = 0.0202571 (* 1 = 0.0202571 loss)
I0205 04:27:43.998296 12024 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0205 04:28:02.164827 12024 solver.cpp:237] Iteration 1310, loss = 0.00348814
I0205 04:28:02.164901 12024 solver.cpp:253]     Train net output #0: loss = 0.00348812 (* 1 = 0.00348812 loss)
I0205 04:28:02.164913 12024 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0205 04:28:20.304296 12024 solver.cpp:237] Iteration 1320, loss = 0.000500407
I0205 04:28:20.304502 12024 solver.cpp:253]     Train net output #0: loss = 0.000500392 (* 1 = 0.000500392 loss)
I0205 04:28:20.304517 12024 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0205 04:28:38.384313 12024 solver.cpp:237] Iteration 1330, loss = 0.00177701
I0205 04:28:38.384385 12024 solver.cpp:253]     Train net output #0: loss = 0.00177699 (* 1 = 0.00177699 loss)
I0205 04:28:38.384398 12024 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0205 04:28:56.500221 12024 solver.cpp:237] Iteration 1340, loss = 0.011121
I0205 04:28:56.500419 12024 solver.cpp:253]     Train net output #0: loss = 0.011121 (* 1 = 0.011121 loss)
I0205 04:28:56.500435 12024 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0205 04:29:14.620383 12024 solver.cpp:237] Iteration 1350, loss = 0.00219838
I0205 04:29:14.620456 12024 solver.cpp:253]     Train net output #0: loss = 0.00219837 (* 1 = 0.00219837 loss)
I0205 04:29:14.620470 12024 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0205 04:29:32.626724 12024 solver.cpp:237] Iteration 1360, loss = 0.00113021
I0205 04:29:32.626952 12024 solver.cpp:253]     Train net output #0: loss = 0.0011302 (* 1 = 0.0011302 loss)
I0205 04:29:32.626967 12024 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0205 04:29:50.667157 12024 solver.cpp:237] Iteration 1370, loss = 0.00114344
I0205 04:29:50.667227 12024 solver.cpp:253]     Train net output #0: loss = 0.00114343 (* 1 = 0.00114343 loss)
I0205 04:29:50.667242 12024 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0205 04:30:08.981402 12024 solver.cpp:237] Iteration 1380, loss = 0.00123227
I0205 04:30:08.981642 12024 solver.cpp:253]     Train net output #0: loss = 0.00123226 (* 1 = 0.00123226 loss)
I0205 04:30:08.981657 12024 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0205 04:30:27.147302 12024 solver.cpp:237] Iteration 1390, loss = 0.00203418
I0205 04:30:27.147366 12024 solver.cpp:253]     Train net output #0: loss = 0.00203417 (* 1 = 0.00203417 loss)
I0205 04:30:27.147378 12024 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0205 04:30:43.546253 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1400.caffemodel
I0205 04:30:43.550060 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1400.solverstate
I0205 04:30:43.551479 12024 solver.cpp:341] Iteration 1400, Testing net (#0)
I0205 04:30:52.000444 12024 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0205 04:30:52.000506 12024 solver.cpp:409]     Test net output #1: loss = 0.00267173 (* 1 = 0.00267173 loss)
I0205 04:30:53.810871 12024 solver.cpp:237] Iteration 1400, loss = 0.00431487
I0205 04:30:53.810936 12024 solver.cpp:253]     Train net output #0: loss = 0.00431486 (* 1 = 0.00431486 loss)
I0205 04:30:53.810950 12024 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0205 04:31:11.978101 12024 solver.cpp:237] Iteration 1410, loss = 0.00385618
I0205 04:31:11.978165 12024 solver.cpp:253]     Train net output #0: loss = 0.00385618 (* 1 = 0.00385618 loss)
I0205 04:31:11.978178 12024 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0205 04:31:30.140439 12024 solver.cpp:237] Iteration 1420, loss = 0.0023259
I0205 04:31:30.140631 12024 solver.cpp:253]     Train net output #0: loss = 0.0023259 (* 1 = 0.0023259 loss)
I0205 04:31:30.140646 12024 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0205 04:31:48.295635 12024 solver.cpp:237] Iteration 1430, loss = 0.00240161
I0205 04:31:48.295701 12024 solver.cpp:253]     Train net output #0: loss = 0.0024016 (* 1 = 0.0024016 loss)
I0205 04:31:48.295713 12024 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0205 04:32:06.463829 12024 solver.cpp:237] Iteration 1440, loss = 0.00163566
I0205 04:32:06.464020 12024 solver.cpp:253]     Train net output #0: loss = 0.00163565 (* 1 = 0.00163565 loss)
I0205 04:32:06.464035 12024 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0205 04:32:24.617631 12024 solver.cpp:237] Iteration 1450, loss = 0.0123237
I0205 04:32:24.617698 12024 solver.cpp:253]     Train net output #0: loss = 0.0123237 (* 1 = 0.0123237 loss)
I0205 04:32:24.617712 12024 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0205 04:32:42.805426 12024 solver.cpp:237] Iteration 1460, loss = 0.00342897
I0205 04:32:43.339216 12024 solver.cpp:253]     Train net output #0: loss = 0.00342895 (* 1 = 0.00342895 loss)
I0205 04:32:43.339252 12024 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0205 04:33:01.586652 12024 solver.cpp:237] Iteration 1470, loss = 0.0202776
I0205 04:33:01.586714 12024 solver.cpp:253]     Train net output #0: loss = 0.0202776 (* 1 = 0.0202776 loss)
I0205 04:33:01.586727 12024 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0205 04:33:19.809104 12024 solver.cpp:237] Iteration 1480, loss = 0.00331659
I0205 04:33:19.809291 12024 solver.cpp:253]     Train net output #0: loss = 0.00331657 (* 1 = 0.00331657 loss)
I0205 04:33:19.809306 12024 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0205 04:33:38.040535 12024 solver.cpp:237] Iteration 1490, loss = 0.048759
I0205 04:33:38.040598 12024 solver.cpp:253]     Train net output #0: loss = 0.048759 (* 1 = 0.048759 loss)
I0205 04:33:38.040611 12024 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0205 04:33:54.417330 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1500.caffemodel
I0205 04:33:54.421124 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1500.solverstate
I0205 04:33:54.422564 12024 solver.cpp:341] Iteration 1500, Testing net (#0)
I0205 04:34:02.926828 12024 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 04:34:02.926884 12024 solver.cpp:409]     Test net output #1: loss = 0.0076916 (* 1 = 0.0076916 loss)
I0205 04:34:04.744284 12024 solver.cpp:237] Iteration 1500, loss = 0.00894364
I0205 04:34:04.744341 12024 solver.cpp:253]     Train net output #0: loss = 0.00894363 (* 1 = 0.00894363 loss)
I0205 04:34:04.744354 12024 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0205 04:34:22.962107 12024 solver.cpp:237] Iteration 1510, loss = 0.00381264
I0205 04:34:22.962173 12024 solver.cpp:253]     Train net output #0: loss = 0.00381262 (* 1 = 0.00381262 loss)
I0205 04:34:22.962185 12024 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0205 04:34:41.242553 12024 solver.cpp:237] Iteration 1520, loss = 0.0440314
I0205 04:34:41.242745 12024 solver.cpp:253]     Train net output #0: loss = 0.0440314 (* 1 = 0.0440314 loss)
I0205 04:34:41.242760 12024 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0205 04:34:59.556141 12024 solver.cpp:237] Iteration 1530, loss = 0.011138
I0205 04:34:59.556216 12024 solver.cpp:253]     Train net output #0: loss = 0.0111379 (* 1 = 0.0111379 loss)
I0205 04:34:59.556228 12024 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0205 04:35:17.892868 12024 solver.cpp:237] Iteration 1540, loss = 0.00109662
I0205 04:35:17.893065 12024 solver.cpp:253]     Train net output #0: loss = 0.00109659 (* 1 = 0.00109659 loss)
I0205 04:35:17.893080 12024 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0205 04:35:36.160280 12024 solver.cpp:237] Iteration 1550, loss = 0.0107385
I0205 04:35:36.160346 12024 solver.cpp:253]     Train net output #0: loss = 0.0107384 (* 1 = 0.0107384 loss)
I0205 04:35:36.160358 12024 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0205 04:35:54.459913 12024 solver.cpp:237] Iteration 1560, loss = 0.00281201
I0205 04:35:54.460100 12024 solver.cpp:253]     Train net output #0: loss = 0.00281198 (* 1 = 0.00281198 loss)
I0205 04:35:54.460115 12024 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0205 04:36:12.673461 12024 solver.cpp:237] Iteration 1570, loss = 0.00166911
I0205 04:36:12.673528 12024 solver.cpp:253]     Train net output #0: loss = 0.00166909 (* 1 = 0.00166909 loss)
I0205 04:36:12.673542 12024 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0205 04:36:30.854079 12024 solver.cpp:237] Iteration 1580, loss = 0.000817232
I0205 04:36:31.399221 12024 solver.cpp:253]     Train net output #0: loss = 0.000817202 (* 1 = 0.000817202 loss)
I0205 04:36:31.399258 12024 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0205 04:36:49.609215 12024 solver.cpp:237] Iteration 1590, loss = 0.000775074
I0205 04:36:49.609279 12024 solver.cpp:253]     Train net output #0: loss = 0.000775044 (* 1 = 0.000775044 loss)
I0205 04:36:49.609292 12024 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0205 04:37:05.987429 12024 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1600.caffemodel
I0205 04:37:05.991222 12024 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed24/snaps/snap__iter_1600.solverstate
I0205 04:37:06.837144 12024 solver.cpp:321] Iteration 1600, loss = 0.00203623
I0205 04:37:06.837195 12024 solver.cpp:341] Iteration 1600, Testing net (#0)
I0205 04:37:15.341835 12024 solver.cpp:409]     Test net output #0: accuracy = 1
I0205 04:37:15.341889 12024 solver.cpp:409]     Test net output #1: loss = 0.00127753 (* 1 = 0.00127753 loss)
I0205 04:37:15.341898 12024 solver.cpp:326] Optimization Done.
I0205 04:37:15.341904 12024 caffe.cpp:215] Optimization Done.
