I0204 16:30:48.852318  3484 caffe.cpp:177] Use CPU.
I0204 16:30:48.852800  3484 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap_"
solver_mode: CPU
random_seed: 3
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/train_val.prototxt"
I0204 16:30:48.852949  3484 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/train_val.prototxt
I0204 16:30:48.853557  3484 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:30:48.853588  3484 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:30:48.853829  3484 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.853957  3484 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.854137  3484 net.cpp:106] Creating Layer data
I0204 16:30:48.854177  3484 net.cpp:411] data -> data
I0204 16:30:48.854223  3484 net.cpp:411] data -> label
I0204 16:30:48.854243  3484 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:30:48.854308  3496 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:30:48.858044  3484 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:48.880028  3484 net.cpp:150] Setting up data
I0204 16:30:48.880071  3484 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:48.880080  3484 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.880086  3484 net.cpp:165] Memory required for data: 20612000
I0204 16:30:48.880102  3484 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:48.880130  3484 net.cpp:106] Creating Layer conv1
I0204 16:30:48.880139  3484 net.cpp:454] conv1 <- data
I0204 16:30:48.880163  3484 net.cpp:411] conv1 -> conv1
I0204 16:30:48.880255  3484 net.cpp:150] Setting up conv1
I0204 16:30:48.880266  3484 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.880273  3484 net.cpp:165] Memory required for data: 30292000
I0204 16:30:48.880290  3484 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:48.880301  3484 net.cpp:106] Creating Layer relu1
I0204 16:30:48.880307  3484 net.cpp:454] relu1 <- conv1
I0204 16:30:48.880316  3484 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:48.880329  3484 net.cpp:150] Setting up relu1
I0204 16:30:48.880336  3484 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.880343  3484 net.cpp:165] Memory required for data: 39972000
I0204 16:30:48.880349  3484 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:48.880359  3484 net.cpp:106] Creating Layer pool1
I0204 16:30:48.880365  3484 net.cpp:454] pool1 <- conv1
I0204 16:30:48.880373  3484 net.cpp:411] pool1 -> pool1
I0204 16:30:48.880395  3484 net.cpp:150] Setting up pool1
I0204 16:30:48.880403  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.880410  3484 net.cpp:165] Memory required for data: 42304800
I0204 16:30:48.880416  3484 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:48.880437  3484 net.cpp:106] Creating Layer norm1
I0204 16:30:48.880451  3484 net.cpp:454] norm1 <- pool1
I0204 16:30:48.880460  3484 net.cpp:411] norm1 -> norm1
I0204 16:30:48.880478  3484 net.cpp:150] Setting up norm1
I0204 16:30:48.880486  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.880492  3484 net.cpp:165] Memory required for data: 44637600
I0204 16:30:48.880497  3484 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:48.880508  3484 net.cpp:106] Creating Layer conv2
I0204 16:30:48.880513  3484 net.cpp:454] conv2 <- norm1
I0204 16:30:48.880522  3484 net.cpp:411] conv2 -> conv2
I0204 16:30:48.880555  3484 net.cpp:150] Setting up conv2
I0204 16:30:48.880563  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.880568  3484 net.cpp:165] Memory required for data: 46970400
I0204 16:30:48.880578  3484 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:48.880587  3484 net.cpp:106] Creating Layer relu2
I0204 16:30:48.880592  3484 net.cpp:454] relu2 <- conv2
I0204 16:30:48.880600  3484 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:48.880610  3484 net.cpp:150] Setting up relu2
I0204 16:30:48.880619  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.880625  3484 net.cpp:165] Memory required for data: 49303200
I0204 16:30:48.880630  3484 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:48.880637  3484 net.cpp:106] Creating Layer pool2
I0204 16:30:48.880643  3484 net.cpp:454] pool2 <- conv2
I0204 16:30:48.880651  3484 net.cpp:411] pool2 -> pool2
I0204 16:30:48.880661  3484 net.cpp:150] Setting up pool2
I0204 16:30:48.880669  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880674  3484 net.cpp:165] Memory required for data: 49844000
I0204 16:30:48.880681  3484 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:48.880691  3484 net.cpp:106] Creating Layer norm2
I0204 16:30:48.880697  3484 net.cpp:454] norm2 <- pool2
I0204 16:30:48.880704  3484 net.cpp:411] norm2 -> norm2
I0204 16:30:48.880713  3484 net.cpp:150] Setting up norm2
I0204 16:30:48.880720  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880727  3484 net.cpp:165] Memory required for data: 50384800
I0204 16:30:48.880731  3484 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:48.880741  3484 net.cpp:106] Creating Layer conv3
I0204 16:30:48.880746  3484 net.cpp:454] conv3 <- norm2
I0204 16:30:48.880758  3484 net.cpp:411] conv3 -> conv3
I0204 16:30:48.880784  3484 net.cpp:150] Setting up conv3
I0204 16:30:48.880792  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880797  3484 net.cpp:165] Memory required for data: 50925600
I0204 16:30:48.880807  3484 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:48.880815  3484 net.cpp:106] Creating Layer relu3
I0204 16:30:48.880823  3484 net.cpp:454] relu3 <- conv3
I0204 16:30:48.880831  3484 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:48.880841  3484 net.cpp:150] Setting up relu3
I0204 16:30:48.880846  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880851  3484 net.cpp:165] Memory required for data: 51466400
I0204 16:30:48.880857  3484 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:48.880867  3484 net.cpp:106] Creating Layer conv4
I0204 16:30:48.880872  3484 net.cpp:454] conv4 <- conv3
I0204 16:30:48.880880  3484 net.cpp:411] conv4 -> conv4
I0204 16:30:48.880906  3484 net.cpp:150] Setting up conv4
I0204 16:30:48.880913  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880918  3484 net.cpp:165] Memory required for data: 52007200
I0204 16:30:48.880926  3484 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:48.880934  3484 net.cpp:106] Creating Layer relu4
I0204 16:30:48.880939  3484 net.cpp:454] relu4 <- conv4
I0204 16:30:48.880946  3484 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:48.880957  3484 net.cpp:150] Setting up relu4
I0204 16:30:48.880964  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.880970  3484 net.cpp:165] Memory required for data: 52548000
I0204 16:30:48.880975  3484 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:48.880990  3484 net.cpp:106] Creating Layer conv5
I0204 16:30:48.881001  3484 net.cpp:454] conv5 <- conv4
I0204 16:30:48.881011  3484 net.cpp:411] conv5 -> conv5
I0204 16:30:48.881034  3484 net.cpp:150] Setting up conv5
I0204 16:30:48.881042  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.881048  3484 net.cpp:165] Memory required for data: 53088800
I0204 16:30:48.881059  3484 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:48.881067  3484 net.cpp:106] Creating Layer relu5
I0204 16:30:48.881073  3484 net.cpp:454] relu5 <- conv5
I0204 16:30:48.881081  3484 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:48.881089  3484 net.cpp:150] Setting up relu5
I0204 16:30:48.881098  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.881103  3484 net.cpp:165] Memory required for data: 53629600
I0204 16:30:48.881109  3484 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:48.881117  3484 net.cpp:106] Creating Layer pool5
I0204 16:30:48.881124  3484 net.cpp:454] pool5 <- conv5
I0204 16:30:48.881131  3484 net.cpp:411] pool5 -> pool5
I0204 16:30:48.881141  3484 net.cpp:150] Setting up pool5
I0204 16:30:48.881148  3484 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:48.881160  3484 net.cpp:165] Memory required for data: 53744800
I0204 16:30:48.881165  3484 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:48.881181  3484 net.cpp:106] Creating Layer fc6
I0204 16:30:48.881188  3484 net.cpp:454] fc6 <- pool5
I0204 16:30:48.881197  3484 net.cpp:411] fc6 -> fc6
I0204 16:30:48.881961  3484 net.cpp:150] Setting up fc6
I0204 16:30:48.881973  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.881978  3484 net.cpp:165] Memory required for data: 53847200
I0204 16:30:48.881986  3484 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:48.881996  3484 net.cpp:106] Creating Layer relu6
I0204 16:30:48.882002  3484 net.cpp:454] relu6 <- fc6
I0204 16:30:48.882011  3484 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:48.882021  3484 net.cpp:150] Setting up relu6
I0204 16:30:48.882028  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.882033  3484 net.cpp:165] Memory required for data: 53949600
I0204 16:30:48.882040  3484 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:48.882050  3484 net.cpp:106] Creating Layer drop6
I0204 16:30:48.882055  3484 net.cpp:454] drop6 <- fc6
I0204 16:30:48.882063  3484 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:48.882079  3484 net.cpp:150] Setting up drop6
I0204 16:30:48.882088  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.882093  3484 net.cpp:165] Memory required for data: 54052000
I0204 16:30:48.882099  3484 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:48.882108  3484 net.cpp:106] Creating Layer fc7
I0204 16:30:48.882113  3484 net.cpp:454] fc7 <- fc6
I0204 16:30:48.882122  3484 net.cpp:411] fc7 -> fc7
I0204 16:30:48.882777  3484 net.cpp:150] Setting up fc7
I0204 16:30:48.882788  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.882794  3484 net.cpp:165] Memory required for data: 54154400
I0204 16:30:48.882802  3484 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:48.882812  3484 net.cpp:106] Creating Layer relu7
I0204 16:30:48.882818  3484 net.cpp:454] relu7 <- fc7
I0204 16:30:48.882825  3484 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:48.882834  3484 net.cpp:150] Setting up relu7
I0204 16:30:48.882840  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.882845  3484 net.cpp:165] Memory required for data: 54256800
I0204 16:30:48.882853  3484 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:48.882860  3484 net.cpp:106] Creating Layer drop7
I0204 16:30:48.882866  3484 net.cpp:454] drop7 <- fc7
I0204 16:30:48.882875  3484 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:48.882885  3484 net.cpp:150] Setting up drop7
I0204 16:30:48.882892  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.882897  3484 net.cpp:165] Memory required for data: 54359200
I0204 16:30:48.882904  3484 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:48.882911  3484 net.cpp:106] Creating Layer fc8
I0204 16:30:48.882923  3484 net.cpp:454] fc8 <- fc7
I0204 16:30:48.882939  3484 net.cpp:411] fc8 -> fc8
I0204 16:30:48.882963  3484 net.cpp:150] Setting up fc8
I0204 16:30:48.882972  3484 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.882977  3484 net.cpp:165] Memory required for data: 54360000
I0204 16:30:48.882985  3484 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.882995  3484 net.cpp:106] Creating Layer loss
I0204 16:30:48.883002  3484 net.cpp:454] loss <- fc8
I0204 16:30:48.883008  3484 net.cpp:454] loss <- label
I0204 16:30:48.883018  3484 net.cpp:411] loss -> loss
I0204 16:30:48.883031  3484 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.883054  3484 net.cpp:150] Setting up loss
I0204 16:30:48.883064  3484 net.cpp:157] Top shape: (1)
I0204 16:30:48.883069  3484 net.cpp:160]     with loss weight 1
I0204 16:30:48.883097  3484 net.cpp:165] Memory required for data: 54360004
I0204 16:30:48.883105  3484 net.cpp:226] loss needs backward computation.
I0204 16:30:48.883112  3484 net.cpp:226] fc8 needs backward computation.
I0204 16:30:48.883118  3484 net.cpp:226] drop7 needs backward computation.
I0204 16:30:48.883123  3484 net.cpp:226] relu7 needs backward computation.
I0204 16:30:48.883131  3484 net.cpp:226] fc7 needs backward computation.
I0204 16:30:48.883137  3484 net.cpp:226] drop6 needs backward computation.
I0204 16:30:48.883142  3484 net.cpp:226] relu6 needs backward computation.
I0204 16:30:48.883147  3484 net.cpp:226] fc6 needs backward computation.
I0204 16:30:48.883158  3484 net.cpp:226] pool5 needs backward computation.
I0204 16:30:48.883164  3484 net.cpp:226] relu5 needs backward computation.
I0204 16:30:48.883169  3484 net.cpp:226] conv5 needs backward computation.
I0204 16:30:48.883175  3484 net.cpp:226] relu4 needs backward computation.
I0204 16:30:48.883180  3484 net.cpp:226] conv4 needs backward computation.
I0204 16:30:48.883186  3484 net.cpp:226] relu3 needs backward computation.
I0204 16:30:48.883191  3484 net.cpp:226] conv3 needs backward computation.
I0204 16:30:48.883203  3484 net.cpp:226] norm2 needs backward computation.
I0204 16:30:48.883209  3484 net.cpp:226] pool2 needs backward computation.
I0204 16:30:48.883215  3484 net.cpp:226] relu2 needs backward computation.
I0204 16:30:48.883220  3484 net.cpp:226] conv2 needs backward computation.
I0204 16:30:48.883226  3484 net.cpp:226] norm1 needs backward computation.
I0204 16:30:48.883232  3484 net.cpp:226] pool1 needs backward computation.
I0204 16:30:48.883239  3484 net.cpp:226] relu1 needs backward computation.
I0204 16:30:48.883244  3484 net.cpp:226] conv1 needs backward computation.
I0204 16:30:48.883250  3484 net.cpp:228] data does not need backward computation.
I0204 16:30:48.883255  3484 net.cpp:270] This network produces output loss
I0204 16:30:48.883286  3484 net.cpp:283] Network initialization done.
I0204 16:30:48.884033  3484 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/train_val.prototxt
I0204 16:30:48.884089  3484 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:30:48.884392  3484 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.884559  3484 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.884706  3484 net.cpp:106] Creating Layer data
I0204 16:30:48.884719  3484 net.cpp:411] data -> data
I0204 16:30:48.884732  3484 net.cpp:411] data -> label
I0204 16:30:48.884744  3484 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:30:48.895226  3501 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:30:48.895500  3484 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:48.945225  3484 net.cpp:150] Setting up data
I0204 16:30:48.945264  3484 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:48.945272  3484 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.945278  3484 net.cpp:165] Memory required for data: 20612000
I0204 16:30:48.945289  3484 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:30:48.945310  3484 net.cpp:106] Creating Layer label_data_1_split
I0204 16:30:48.945318  3484 net.cpp:454] label_data_1_split <- label
I0204 16:30:48.945330  3484 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:30:48.945348  3484 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:30:48.945363  3484 net.cpp:150] Setting up label_data_1_split
I0204 16:30:48.945374  3484 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.945380  3484 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.945385  3484 net.cpp:165] Memory required for data: 20612800
I0204 16:30:48.945391  3484 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:48.945406  3484 net.cpp:106] Creating Layer conv1
I0204 16:30:48.945413  3484 net.cpp:454] conv1 <- data
I0204 16:30:48.945422  3484 net.cpp:411] conv1 -> conv1
I0204 16:30:48.945471  3484 net.cpp:150] Setting up conv1
I0204 16:30:48.945480  3484 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.945487  3484 net.cpp:165] Memory required for data: 30292800
I0204 16:30:48.945499  3484 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:48.945508  3484 net.cpp:106] Creating Layer relu1
I0204 16:30:48.945514  3484 net.cpp:454] relu1 <- conv1
I0204 16:30:48.945524  3484 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:48.945535  3484 net.cpp:150] Setting up relu1
I0204 16:30:48.945543  3484 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.945547  3484 net.cpp:165] Memory required for data: 39972800
I0204 16:30:48.945554  3484 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:48.945564  3484 net.cpp:106] Creating Layer pool1
I0204 16:30:48.945570  3484 net.cpp:454] pool1 <- conv1
I0204 16:30:48.945579  3484 net.cpp:411] pool1 -> pool1
I0204 16:30:48.945593  3484 net.cpp:150] Setting up pool1
I0204 16:30:48.945601  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.945606  3484 net.cpp:165] Memory required for data: 42305600
I0204 16:30:48.945612  3484 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:48.945623  3484 net.cpp:106] Creating Layer norm1
I0204 16:30:48.945629  3484 net.cpp:454] norm1 <- pool1
I0204 16:30:48.945636  3484 net.cpp:411] norm1 -> norm1
I0204 16:30:48.945647  3484 net.cpp:150] Setting up norm1
I0204 16:30:48.945655  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.945660  3484 net.cpp:165] Memory required for data: 44638400
I0204 16:30:48.945665  3484 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:48.945675  3484 net.cpp:106] Creating Layer conv2
I0204 16:30:48.945683  3484 net.cpp:454] conv2 <- norm1
I0204 16:30:48.945693  3484 net.cpp:411] conv2 -> conv2
I0204 16:30:48.945722  3484 net.cpp:150] Setting up conv2
I0204 16:30:48.945730  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.945735  3484 net.cpp:165] Memory required for data: 46971200
I0204 16:30:48.945745  3484 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:48.945756  3484 net.cpp:106] Creating Layer relu2
I0204 16:30:48.945762  3484 net.cpp:454] relu2 <- conv2
I0204 16:30:48.945770  3484 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:48.945788  3484 net.cpp:150] Setting up relu2
I0204 16:30:48.945804  3484 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.945809  3484 net.cpp:165] Memory required for data: 49304000
I0204 16:30:48.945816  3484 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:48.945824  3484 net.cpp:106] Creating Layer pool2
I0204 16:30:48.945832  3484 net.cpp:454] pool2 <- conv2
I0204 16:30:48.945840  3484 net.cpp:411] pool2 -> pool2
I0204 16:30:48.945852  3484 net.cpp:150] Setting up pool2
I0204 16:30:48.945860  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.945865  3484 net.cpp:165] Memory required for data: 49844800
I0204 16:30:48.945870  3484 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:48.945878  3484 net.cpp:106] Creating Layer norm2
I0204 16:30:48.945884  3484 net.cpp:454] norm2 <- pool2
I0204 16:30:48.945893  3484 net.cpp:411] norm2 -> norm2
I0204 16:30:48.945904  3484 net.cpp:150] Setting up norm2
I0204 16:30:48.945911  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.945916  3484 net.cpp:165] Memory required for data: 50385600
I0204 16:30:48.945922  3484 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:48.945932  3484 net.cpp:106] Creating Layer conv3
I0204 16:30:48.945938  3484 net.cpp:454] conv3 <- norm2
I0204 16:30:48.945947  3484 net.cpp:411] conv3 -> conv3
I0204 16:30:48.945974  3484 net.cpp:150] Setting up conv3
I0204 16:30:48.945982  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.945988  3484 net.cpp:165] Memory required for data: 50926400
I0204 16:30:48.945999  3484 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:48.946007  3484 net.cpp:106] Creating Layer relu3
I0204 16:30:48.946013  3484 net.cpp:454] relu3 <- conv3
I0204 16:30:48.946022  3484 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:48.946030  3484 net.cpp:150] Setting up relu3
I0204 16:30:48.946036  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.946041  3484 net.cpp:165] Memory required for data: 51467200
I0204 16:30:48.946048  3484 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:48.946059  3484 net.cpp:106] Creating Layer conv4
I0204 16:30:48.946064  3484 net.cpp:454] conv4 <- conv3
I0204 16:30:48.946074  3484 net.cpp:411] conv4 -> conv4
I0204 16:30:48.946094  3484 net.cpp:150] Setting up conv4
I0204 16:30:48.946102  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.946108  3484 net.cpp:165] Memory required for data: 52008000
I0204 16:30:48.946116  3484 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:48.946125  3484 net.cpp:106] Creating Layer relu4
I0204 16:30:48.946132  3484 net.cpp:454] relu4 <- conv4
I0204 16:30:48.946141  3484 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:48.946148  3484 net.cpp:150] Setting up relu4
I0204 16:30:48.946161  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.946167  3484 net.cpp:165] Memory required for data: 52548800
I0204 16:30:48.946173  3484 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:48.946183  3484 net.cpp:106] Creating Layer conv5
I0204 16:30:48.946189  3484 net.cpp:454] conv5 <- conv4
I0204 16:30:48.946199  3484 net.cpp:411] conv5 -> conv5
I0204 16:30:48.946223  3484 net.cpp:150] Setting up conv5
I0204 16:30:48.946230  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.946235  3484 net.cpp:165] Memory required for data: 53089600
I0204 16:30:48.946246  3484 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:48.946254  3484 net.cpp:106] Creating Layer relu5
I0204 16:30:48.946259  3484 net.cpp:454] relu5 <- conv5
I0204 16:30:48.946266  3484 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:48.946277  3484 net.cpp:150] Setting up relu5
I0204 16:30:48.946285  3484 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.946290  3484 net.cpp:165] Memory required for data: 53630400
I0204 16:30:48.946295  3484 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:48.946305  3484 net.cpp:106] Creating Layer pool5
I0204 16:30:48.946310  3484 net.cpp:454] pool5 <- conv5
I0204 16:30:48.946318  3484 net.cpp:411] pool5 -> pool5
I0204 16:30:48.946333  3484 net.cpp:150] Setting up pool5
I0204 16:30:48.946348  3484 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:48.946354  3484 net.cpp:165] Memory required for data: 53745600
I0204 16:30:48.946360  3484 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:48.946372  3484 net.cpp:106] Creating Layer fc6
I0204 16:30:48.946378  3484 net.cpp:454] fc6 <- pool5
I0204 16:30:48.946387  3484 net.cpp:411] fc6 -> fc6
I0204 16:30:48.950336  3484 net.cpp:150] Setting up fc6
I0204 16:30:48.950367  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.950373  3484 net.cpp:165] Memory required for data: 53848000
I0204 16:30:48.950386  3484 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:48.950397  3484 net.cpp:106] Creating Layer relu6
I0204 16:30:48.950404  3484 net.cpp:454] relu6 <- fc6
I0204 16:30:48.950413  3484 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:48.950426  3484 net.cpp:150] Setting up relu6
I0204 16:30:48.950434  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.950440  3484 net.cpp:165] Memory required for data: 53950400
I0204 16:30:48.950445  3484 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:48.950459  3484 net.cpp:106] Creating Layer drop6
I0204 16:30:48.950464  3484 net.cpp:454] drop6 <- fc6
I0204 16:30:48.950472  3484 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:48.950484  3484 net.cpp:150] Setting up drop6
I0204 16:30:48.950491  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.950496  3484 net.cpp:165] Memory required for data: 54052800
I0204 16:30:48.950505  3484 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:48.950517  3484 net.cpp:106] Creating Layer fc7
I0204 16:30:48.950523  3484 net.cpp:454] fc7 <- fc6
I0204 16:30:48.950531  3484 net.cpp:411] fc7 -> fc7
I0204 16:30:48.951223  3484 net.cpp:150] Setting up fc7
I0204 16:30:48.951236  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.951241  3484 net.cpp:165] Memory required for data: 54155200
I0204 16:30:48.951251  3484 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:48.951261  3484 net.cpp:106] Creating Layer relu7
I0204 16:30:48.951267  3484 net.cpp:454] relu7 <- fc7
I0204 16:30:48.951273  3484 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:48.951282  3484 net.cpp:150] Setting up relu7
I0204 16:30:48.951289  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.951294  3484 net.cpp:165] Memory required for data: 54257600
I0204 16:30:48.951300  3484 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:48.951310  3484 net.cpp:106] Creating Layer drop7
I0204 16:30:48.951316  3484 net.cpp:454] drop7 <- fc7
I0204 16:30:48.951323  3484 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:48.951333  3484 net.cpp:150] Setting up drop7
I0204 16:30:48.951342  3484 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.951347  3484 net.cpp:165] Memory required for data: 54360000
I0204 16:30:48.951354  3484 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:48.951367  3484 net.cpp:106] Creating Layer fc8
I0204 16:30:48.951373  3484 net.cpp:454] fc8 <- fc7
I0204 16:30:48.951381  3484 net.cpp:411] fc8 -> fc8
I0204 16:30:48.951408  3484 net.cpp:150] Setting up fc8
I0204 16:30:48.951418  3484 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.951424  3484 net.cpp:165] Memory required for data: 54360800
I0204 16:30:48.951432  3484 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:30:48.951441  3484 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:30:48.951447  3484 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:30:48.951457  3484 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:30:48.951465  3484 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:30:48.951475  3484 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:30:48.951483  3484 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.951490  3484 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.951496  3484 net.cpp:165] Memory required for data: 54362400
I0204 16:30:48.951501  3484 layer_factory.hpp:77] Creating layer accuracy
I0204 16:30:48.951516  3484 net.cpp:106] Creating Layer accuracy
I0204 16:30:48.951529  3484 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:30:48.951545  3484 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:30:48.951553  3484 net.cpp:411] accuracy -> accuracy
I0204 16:30:48.951568  3484 net.cpp:150] Setting up accuracy
I0204 16:30:48.951575  3484 net.cpp:157] Top shape: (1)
I0204 16:30:48.951581  3484 net.cpp:165] Memory required for data: 54362404
I0204 16:30:48.951586  3484 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.951596  3484 net.cpp:106] Creating Layer loss
I0204 16:30:48.951602  3484 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:30:48.951609  3484 net.cpp:454] loss <- label_data_1_split_1
I0204 16:30:48.951617  3484 net.cpp:411] loss -> loss
I0204 16:30:48.951628  3484 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.951648  3484 net.cpp:150] Setting up loss
I0204 16:30:48.951655  3484 net.cpp:157] Top shape: (1)
I0204 16:30:48.951660  3484 net.cpp:160]     with loss weight 1
I0204 16:30:48.951675  3484 net.cpp:165] Memory required for data: 54362408
I0204 16:30:48.951683  3484 net.cpp:226] loss needs backward computation.
I0204 16:30:48.951689  3484 net.cpp:228] accuracy does not need backward computation.
I0204 16:30:48.951695  3484 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:30:48.951709  3484 net.cpp:226] fc8 needs backward computation.
I0204 16:30:48.951716  3484 net.cpp:226] drop7 needs backward computation.
I0204 16:30:48.951721  3484 net.cpp:226] relu7 needs backward computation.
I0204 16:30:48.951726  3484 net.cpp:226] fc7 needs backward computation.
I0204 16:30:48.951732  3484 net.cpp:226] drop6 needs backward computation.
I0204 16:30:48.951737  3484 net.cpp:226] relu6 needs backward computation.
I0204 16:30:48.951743  3484 net.cpp:226] fc6 needs backward computation.
I0204 16:30:48.951750  3484 net.cpp:226] pool5 needs backward computation.
I0204 16:30:48.951756  3484 net.cpp:226] relu5 needs backward computation.
I0204 16:30:48.951761  3484 net.cpp:226] conv5 needs backward computation.
I0204 16:30:48.951766  3484 net.cpp:226] relu4 needs backward computation.
I0204 16:30:48.951772  3484 net.cpp:226] conv4 needs backward computation.
I0204 16:30:48.951778  3484 net.cpp:226] relu3 needs backward computation.
I0204 16:30:48.951786  3484 net.cpp:226] conv3 needs backward computation.
I0204 16:30:48.951792  3484 net.cpp:226] norm2 needs backward computation.
I0204 16:30:48.951798  3484 net.cpp:226] pool2 needs backward computation.
I0204 16:30:48.951804  3484 net.cpp:226] relu2 needs backward computation.
I0204 16:30:48.951810  3484 net.cpp:226] conv2 needs backward computation.
I0204 16:30:48.951815  3484 net.cpp:226] norm1 needs backward computation.
I0204 16:30:48.951822  3484 net.cpp:226] pool1 needs backward computation.
I0204 16:30:48.951828  3484 net.cpp:226] relu1 needs backward computation.
I0204 16:30:48.951834  3484 net.cpp:226] conv1 needs backward computation.
I0204 16:30:48.951840  3484 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:30:48.951848  3484 net.cpp:228] data does not need backward computation.
I0204 16:30:48.951854  3484 net.cpp:270] This network produces output accuracy
I0204 16:30:48.951861  3484 net.cpp:270] This network produces output loss
I0204 16:30:48.951889  3484 net.cpp:283] Network initialization done.
I0204 16:30:48.951995  3484 solver.cpp:60] Solver scaffolding done.
I0204 16:30:48.952049  3484 caffe.cpp:212] Starting Optimization
I0204 16:30:48.952055  3484 solver.cpp:288] Solving CaffeNet
I0204 16:30:48.952061  3484 solver.cpp:289] Learning Rate Policy: step
I0204 16:30:48.954417  3484 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:30:48.954504  3484 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:30:51.745077  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:30:51.745127  3484 solver.cpp:409]     Test net output #1: loss = 8.39784 (* 1 = 8.39784 loss)
I0204 16:30:52.434075  3484 solver.cpp:237] Iteration 0, loss = 10.2071
I0204 16:30:52.434144  3484 solver.cpp:253]     Train net output #0: loss = 10.2071 (* 1 = 10.2071 loss)
I0204 16:30:52.434170  3484 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:30:58.289754  3484 solver.cpp:237] Iteration 10, loss = 1.31371
I0204 16:30:58.289816  3484 solver.cpp:253]     Train net output #0: loss = 1.31371 (* 1 = 1.31371 loss)
I0204 16:30:58.289829  3484 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:31:04.057360  3484 solver.cpp:237] Iteration 20, loss = 0.915319
I0204 16:31:04.057422  3484 solver.cpp:253]     Train net output #0: loss = 0.915319 (* 1 = 0.915319 loss)
I0204 16:31:04.057433  3484 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:31:09.812747  3484 solver.cpp:237] Iteration 30, loss = 0.956599
I0204 16:31:09.812809  3484 solver.cpp:253]     Train net output #0: loss = 0.956599 (* 1 = 0.956599 loss)
I0204 16:31:09.812819  3484 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:31:15.596674  3484 solver.cpp:237] Iteration 40, loss = 0.856146
I0204 16:31:15.596735  3484 solver.cpp:253]     Train net output #0: loss = 0.856146 (* 1 = 0.856146 loss)
I0204 16:31:15.596747  3484 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:31:21.433475  3484 solver.cpp:237] Iteration 50, loss = 0.910719
I0204 16:31:21.433699  3484 solver.cpp:253]     Train net output #0: loss = 0.910719 (* 1 = 0.910719 loss)
I0204 16:31:21.433712  3484 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:31:27.236146  3484 solver.cpp:237] Iteration 60, loss = 0.8626
I0204 16:31:27.236207  3484 solver.cpp:253]     Train net output #0: loss = 0.8626 (* 1 = 0.8626 loss)
I0204 16:31:27.236218  3484 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:31:33.028064  3484 solver.cpp:237] Iteration 70, loss = 0.773868
I0204 16:31:33.028120  3484 solver.cpp:253]     Train net output #0: loss = 0.773868 (* 1 = 0.773868 loss)
I0204 16:31:33.028131  3484 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:31:38.788774  3484 solver.cpp:237] Iteration 80, loss = 0.821987
I0204 16:31:38.788839  3484 solver.cpp:253]     Train net output #0: loss = 0.821987 (* 1 = 0.821987 loss)
I0204 16:31:38.788852  3484 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:44.622499  3484 solver.cpp:237] Iteration 90, loss = 0.865575
I0204 16:31:44.622556  3484 solver.cpp:253]     Train net output #0: loss = 0.865575 (* 1 = 0.865575 loss)
I0204 16:31:44.622570  3484 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:31:49.853185  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_100.caffemodel
I0204 16:31:49.855689  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_100.solverstate
I0204 16:31:49.856837  3484 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:31:52.636637  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:31:52.636806  3484 solver.cpp:409]     Test net output #1: loss = 0.693453 (* 1 = 0.693453 loss)
I0204 16:31:53.210746  3484 solver.cpp:237] Iteration 100, loss = 0.769453
I0204 16:31:53.210803  3484 solver.cpp:253]     Train net output #0: loss = 0.769453 (* 1 = 0.769453 loss)
I0204 16:31:53.210814  3484 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:31:58.930851  3484 solver.cpp:237] Iteration 110, loss = 0.805045
I0204 16:31:58.930913  3484 solver.cpp:253]     Train net output #0: loss = 0.805045 (* 1 = 0.805045 loss)
I0204 16:31:58.930927  3484 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:32:04.652595  3484 solver.cpp:237] Iteration 120, loss = 0.701266
I0204 16:32:04.652655  3484 solver.cpp:253]     Train net output #0: loss = 0.701266 (* 1 = 0.701266 loss)
I0204 16:32:04.652668  3484 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:32:10.372509  3484 solver.cpp:237] Iteration 130, loss = 0.722423
I0204 16:32:10.372572  3484 solver.cpp:253]     Train net output #0: loss = 0.722423 (* 1 = 0.722423 loss)
I0204 16:32:10.372584  3484 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:32:16.106858  3484 solver.cpp:237] Iteration 140, loss = 0.810676
I0204 16:32:16.106917  3484 solver.cpp:253]     Train net output #0: loss = 0.810676 (* 1 = 0.810676 loss)
I0204 16:32:16.106928  3484 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:32:21.858621  3484 solver.cpp:237] Iteration 150, loss = 0.687202
I0204 16:32:21.858681  3484 solver.cpp:253]     Train net output #0: loss = 0.687202 (* 1 = 0.687202 loss)
I0204 16:32:21.858692  3484 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:32:27.572670  3484 solver.cpp:237] Iteration 160, loss = 0.723868
I0204 16:32:27.572881  3484 solver.cpp:253]     Train net output #0: loss = 0.723868 (* 1 = 0.723868 loss)
I0204 16:32:27.572893  3484 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:32:33.264103  3484 solver.cpp:237] Iteration 170, loss = 0.781458
I0204 16:32:33.264165  3484 solver.cpp:253]     Train net output #0: loss = 0.781458 (* 1 = 0.781458 loss)
I0204 16:32:33.264176  3484 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:32:38.996351  3484 solver.cpp:237] Iteration 180, loss = 0.712425
I0204 16:32:38.996408  3484 solver.cpp:253]     Train net output #0: loss = 0.712425 (* 1 = 0.712425 loss)
I0204 16:32:38.996419  3484 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:32:44.683923  3484 solver.cpp:237] Iteration 190, loss = 0.700376
I0204 16:32:44.683985  3484 solver.cpp:253]     Train net output #0: loss = 0.700376 (* 1 = 0.700376 loss)
I0204 16:32:44.683997  3484 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:32:49.842452  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_200.caffemodel
I0204 16:32:49.844758  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_200.solverstate
I0204 16:32:49.845726  3484 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:32:52.623881  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:32:52.623939  3484 solver.cpp:409]     Test net output #1: loss = 0.69348 (* 1 = 0.69348 loss)
I0204 16:32:53.193204  3484 solver.cpp:237] Iteration 200, loss = 0.674548
I0204 16:32:53.193259  3484 solver.cpp:253]     Train net output #0: loss = 0.674548 (* 1 = 0.674548 loss)
I0204 16:32:53.193270  3484 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:32:58.894613  3484 solver.cpp:237] Iteration 210, loss = 0.700216
I0204 16:32:58.894786  3484 solver.cpp:253]     Train net output #0: loss = 0.700216 (* 1 = 0.700216 loss)
I0204 16:32:58.894799  3484 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:33:04.619690  3484 solver.cpp:237] Iteration 220, loss = 0.786187
I0204 16:33:04.619753  3484 solver.cpp:253]     Train net output #0: loss = 0.786187 (* 1 = 0.786187 loss)
I0204 16:33:04.619765  3484 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:33:10.292479  3484 solver.cpp:237] Iteration 230, loss = 0.696515
I0204 16:33:10.292543  3484 solver.cpp:253]     Train net output #0: loss = 0.696515 (* 1 = 0.696515 loss)
I0204 16:33:10.292556  3484 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:33:16.000366  3484 solver.cpp:237] Iteration 240, loss = 0.72844
I0204 16:33:16.000428  3484 solver.cpp:253]     Train net output #0: loss = 0.72844 (* 1 = 0.72844 loss)
I0204 16:33:16.000439  3484 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:33:21.713094  3484 solver.cpp:237] Iteration 250, loss = 0.776468
I0204 16:33:21.713166  3484 solver.cpp:253]     Train net output #0: loss = 0.776468 (* 1 = 0.776468 loss)
I0204 16:33:21.713181  3484 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:33:27.519037  3484 solver.cpp:237] Iteration 260, loss = 0.681063
I0204 16:33:27.519120  3484 solver.cpp:253]     Train net output #0: loss = 0.681063 (* 1 = 0.681063 loss)
I0204 16:33:27.519139  3484 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:33:33.278118  3484 solver.cpp:237] Iteration 270, loss = 0.743528
I0204 16:33:33.278332  3484 solver.cpp:253]     Train net output #0: loss = 0.743528 (* 1 = 0.743528 loss)
I0204 16:33:33.278345  3484 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:33:38.978597  3484 solver.cpp:237] Iteration 280, loss = 0.753872
I0204 16:33:38.978662  3484 solver.cpp:253]     Train net output #0: loss = 0.753872 (* 1 = 0.753872 loss)
I0204 16:33:38.978675  3484 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:33:44.662341  3484 solver.cpp:237] Iteration 290, loss = 0.732616
I0204 16:33:44.662398  3484 solver.cpp:253]     Train net output #0: loss = 0.732616 (* 1 = 0.732616 loss)
I0204 16:33:44.662411  3484 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:33:49.915030  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_300.caffemodel
I0204 16:33:49.917453  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_300.solverstate
I0204 16:33:49.918501  3484 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:33:52.635555  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:33:52.635601  3484 solver.cpp:409]     Test net output #1: loss = 0.704859 (* 1 = 0.704859 loss)
I0204 16:33:53.195390  3484 solver.cpp:237] Iteration 300, loss = 0.788368
I0204 16:33:53.195441  3484 solver.cpp:253]     Train net output #0: loss = 0.788368 (* 1 = 0.788368 loss)
I0204 16:33:53.195452  3484 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:33:59.002277  3484 solver.cpp:237] Iteration 310, loss = 0.725669
I0204 16:33:59.002332  3484 solver.cpp:253]     Train net output #0: loss = 0.725669 (* 1 = 0.725669 loss)
I0204 16:33:59.002344  3484 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:34:04.794515  3484 solver.cpp:237] Iteration 320, loss = 0.715379
I0204 16:34:04.794670  3484 solver.cpp:253]     Train net output #0: loss = 0.715379 (* 1 = 0.715379 loss)
I0204 16:34:04.794684  3484 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:34:10.679361  3484 solver.cpp:237] Iteration 330, loss = 0.713114
I0204 16:34:10.679415  3484 solver.cpp:253]     Train net output #0: loss = 0.713114 (* 1 = 0.713114 loss)
I0204 16:34:10.679427  3484 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:34:16.418869  3484 solver.cpp:237] Iteration 340, loss = 0.728491
I0204 16:34:16.418922  3484 solver.cpp:253]     Train net output #0: loss = 0.728491 (* 1 = 0.728491 loss)
I0204 16:34:16.418936  3484 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:34:22.160893  3484 solver.cpp:237] Iteration 350, loss = 0.708445
I0204 16:34:22.160953  3484 solver.cpp:253]     Train net output #0: loss = 0.708445 (* 1 = 0.708445 loss)
I0204 16:34:22.160966  3484 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:34:27.932134  3484 solver.cpp:237] Iteration 360, loss = 0.704116
I0204 16:34:27.932186  3484 solver.cpp:253]     Train net output #0: loss = 0.704116 (* 1 = 0.704116 loss)
I0204 16:34:27.932199  3484 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:34:33.842144  3484 solver.cpp:237] Iteration 370, loss = 0.704457
I0204 16:34:33.842200  3484 solver.cpp:253]     Train net output #0: loss = 0.704457 (* 1 = 0.704457 loss)
I0204 16:34:33.842213  3484 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:34:39.686301  3484 solver.cpp:237] Iteration 380, loss = 0.813859
I0204 16:34:39.686424  3484 solver.cpp:253]     Train net output #0: loss = 0.813859 (* 1 = 0.813859 loss)
I0204 16:34:39.686437  3484 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:34:45.405185  3484 solver.cpp:237] Iteration 390, loss = 0.708355
I0204 16:34:45.405246  3484 solver.cpp:253]     Train net output #0: loss = 0.708355 (* 1 = 0.708355 loss)
I0204 16:34:45.405257  3484 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:34:50.574535  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_400.caffemodel
I0204 16:34:50.576912  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_400.solverstate
I0204 16:34:50.578018  3484 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:34:53.498527  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:34:53.498577  3484 solver.cpp:409]     Test net output #1: loss = 0.712445 (* 1 = 0.712445 loss)
I0204 16:34:54.080463  3484 solver.cpp:237] Iteration 400, loss = 0.698379
I0204 16:34:54.080514  3484 solver.cpp:253]     Train net output #0: loss = 0.698379 (* 1 = 0.698379 loss)
I0204 16:34:54.080528  3484 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:34:59.884258  3484 solver.cpp:237] Iteration 410, loss = 0.729825
I0204 16:34:59.884311  3484 solver.cpp:253]     Train net output #0: loss = 0.729825 (* 1 = 0.729825 loss)
I0204 16:34:59.884322  3484 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:35:05.529275  3484 solver.cpp:237] Iteration 420, loss = 0.691064
I0204 16:35:05.529336  3484 solver.cpp:253]     Train net output #0: loss = 0.691064 (* 1 = 0.691064 loss)
I0204 16:35:05.529350  3484 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:35:11.199477  3484 solver.cpp:237] Iteration 430, loss = 0.736778
I0204 16:35:11.199661  3484 solver.cpp:253]     Train net output #0: loss = 0.736778 (* 1 = 0.736778 loss)
I0204 16:35:11.199673  3484 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:35:16.839143  3484 solver.cpp:237] Iteration 440, loss = 0.690856
I0204 16:35:16.839196  3484 solver.cpp:253]     Train net output #0: loss = 0.690856 (* 1 = 0.690856 loss)
I0204 16:35:16.839207  3484 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:35:22.645766  3484 solver.cpp:237] Iteration 450, loss = 0.710344
I0204 16:35:22.645833  3484 solver.cpp:253]     Train net output #0: loss = 0.710344 (* 1 = 0.710344 loss)
I0204 16:35:22.645845  3484 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:35:28.415218  3484 solver.cpp:237] Iteration 460, loss = 0.782202
I0204 16:35:28.415285  3484 solver.cpp:253]     Train net output #0: loss = 0.782202 (* 1 = 0.782202 loss)
I0204 16:35:28.415297  3484 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:35:34.116482  3484 solver.cpp:237] Iteration 470, loss = 0.699284
I0204 16:35:34.116545  3484 solver.cpp:253]     Train net output #0: loss = 0.699284 (* 1 = 0.699284 loss)
I0204 16:35:34.116557  3484 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:35:39.831902  3484 solver.cpp:237] Iteration 480, loss = 0.690007
I0204 16:35:39.831972  3484 solver.cpp:253]     Train net output #0: loss = 0.690007 (* 1 = 0.690007 loss)
I0204 16:35:39.831984  3484 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:35:45.558804  3484 solver.cpp:237] Iteration 490, loss = 0.758595
I0204 16:35:45.558980  3484 solver.cpp:253]     Train net output #0: loss = 0.758595 (* 1 = 0.758595 loss)
I0204 16:35:45.558993  3484 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:35:50.712774  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_500.caffemodel
I0204 16:35:50.715085  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_500.solverstate
I0204 16:35:50.716034  3484 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:35:53.493983  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:35:53.494045  3484 solver.cpp:409]     Test net output #1: loss = 0.706847 (* 1 = 0.706847 loss)
I0204 16:35:54.084786  3484 solver.cpp:237] Iteration 500, loss = 0.716824
I0204 16:35:54.084843  3484 solver.cpp:253]     Train net output #0: loss = 0.716824 (* 1 = 0.716824 loss)
I0204 16:35:54.084856  3484 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:35:59.816447  3484 solver.cpp:237] Iteration 510, loss = 0.728586
I0204 16:35:59.816504  3484 solver.cpp:253]     Train net output #0: loss = 0.728586 (* 1 = 0.728586 loss)
I0204 16:35:59.816515  3484 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:36:05.609325  3484 solver.cpp:237] Iteration 520, loss = 0.706138
I0204 16:36:05.609381  3484 solver.cpp:253]     Train net output #0: loss = 0.706138 (* 1 = 0.706138 loss)
I0204 16:36:05.609393  3484 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:36:11.382064  3484 solver.cpp:237] Iteration 530, loss = 0.713742
I0204 16:36:11.382136  3484 solver.cpp:253]     Train net output #0: loss = 0.713742 (* 1 = 0.713742 loss)
I0204 16:36:11.382148  3484 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:36:17.192106  3484 solver.cpp:237] Iteration 540, loss = 0.76732
I0204 16:36:17.192296  3484 solver.cpp:253]     Train net output #0: loss = 0.76732 (* 1 = 0.76732 loss)
I0204 16:36:17.192308  3484 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:36:22.964309  3484 solver.cpp:237] Iteration 550, loss = 0.738138
I0204 16:36:22.964364  3484 solver.cpp:253]     Train net output #0: loss = 0.738138 (* 1 = 0.738138 loss)
I0204 16:36:22.964375  3484 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:36:28.773401  3484 solver.cpp:237] Iteration 560, loss = 0.722096
I0204 16:36:28.773466  3484 solver.cpp:253]     Train net output #0: loss = 0.722096 (* 1 = 0.722096 loss)
I0204 16:36:28.773478  3484 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:36:34.582149  3484 solver.cpp:237] Iteration 570, loss = 0.717996
I0204 16:36:34.582214  3484 solver.cpp:253]     Train net output #0: loss = 0.717996 (* 1 = 0.717996 loss)
I0204 16:36:34.582226  3484 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:36:40.422056  3484 solver.cpp:237] Iteration 580, loss = 0.681027
I0204 16:36:40.422123  3484 solver.cpp:253]     Train net output #0: loss = 0.681027 (* 1 = 0.681027 loss)
I0204 16:36:40.422135  3484 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:36:46.243535  3484 solver.cpp:237] Iteration 590, loss = 0.711086
I0204 16:36:46.243599  3484 solver.cpp:253]     Train net output #0: loss = 0.711086 (* 1 = 0.711086 loss)
I0204 16:36:46.243613  3484 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:36:51.620262  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_600.caffemodel
I0204 16:36:51.624634  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_600.solverstate
I0204 16:36:51.626413  3484 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:36:54.520012  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:36:54.520068  3484 solver.cpp:409]     Test net output #1: loss = 0.69429 (* 1 = 0.69429 loss)
I0204 16:36:55.098170  3484 solver.cpp:237] Iteration 600, loss = 0.699901
I0204 16:36:55.098219  3484 solver.cpp:253]     Train net output #0: loss = 0.699901 (* 1 = 0.699901 loss)
I0204 16:36:55.098232  3484 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:37:00.857933  3484 solver.cpp:237] Iteration 610, loss = 0.674926
I0204 16:37:00.857995  3484 solver.cpp:253]     Train net output #0: loss = 0.674926 (* 1 = 0.674926 loss)
I0204 16:37:00.858007  3484 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:37:06.573918  3484 solver.cpp:237] Iteration 620, loss = 0.771299
I0204 16:37:06.573976  3484 solver.cpp:253]     Train net output #0: loss = 0.771299 (* 1 = 0.771299 loss)
I0204 16:37:06.573990  3484 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:37:12.343443  3484 solver.cpp:237] Iteration 630, loss = 0.72948
I0204 16:37:12.343495  3484 solver.cpp:253]     Train net output #0: loss = 0.72948 (* 1 = 0.72948 loss)
I0204 16:37:12.343507  3484 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:37:18.124585  3484 solver.cpp:237] Iteration 640, loss = 0.683306
I0204 16:37:18.124652  3484 solver.cpp:253]     Train net output #0: loss = 0.683306 (* 1 = 0.683306 loss)
I0204 16:37:18.124665  3484 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:37:23.894067  3484 solver.cpp:237] Iteration 650, loss = 0.740254
I0204 16:37:23.894276  3484 solver.cpp:253]     Train net output #0: loss = 0.740254 (* 1 = 0.740254 loss)
I0204 16:37:23.894289  3484 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:37:29.641335  3484 solver.cpp:237] Iteration 660, loss = 0.69869
I0204 16:37:29.641404  3484 solver.cpp:253]     Train net output #0: loss = 0.69869 (* 1 = 0.69869 loss)
I0204 16:37:29.641427  3484 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:37:35.414582  3484 solver.cpp:237] Iteration 670, loss = 0.704768
I0204 16:37:35.414639  3484 solver.cpp:253]     Train net output #0: loss = 0.704768 (* 1 = 0.704768 loss)
I0204 16:37:35.414652  3484 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:37:41.010356  3484 solver.cpp:237] Iteration 680, loss = 0.668544
I0204 16:37:41.010416  3484 solver.cpp:253]     Train net output #0: loss = 0.668544 (* 1 = 0.668544 loss)
I0204 16:37:41.010426  3484 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:37:46.570621  3484 solver.cpp:237] Iteration 690, loss = 0.702181
I0204 16:37:46.570672  3484 solver.cpp:253]     Train net output #0: loss = 0.702181 (* 1 = 0.702181 loss)
I0204 16:37:46.570683  3484 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:37:51.593904  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_700.caffemodel
I0204 16:37:51.596161  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_700.solverstate
I0204 16:37:51.597100  3484 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:37:54.368726  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:37:54.368896  3484 solver.cpp:409]     Test net output #1: loss = 0.702862 (* 1 = 0.702862 loss)
I0204 16:37:54.953685  3484 solver.cpp:237] Iteration 700, loss = 0.759633
I0204 16:37:54.953738  3484 solver.cpp:253]     Train net output #0: loss = 0.759633 (* 1 = 0.759633 loss)
I0204 16:37:54.953750  3484 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:38:00.739694  3484 solver.cpp:237] Iteration 710, loss = 0.720559
I0204 16:38:00.739766  3484 solver.cpp:253]     Train net output #0: loss = 0.720559 (* 1 = 0.720559 loss)
I0204 16:38:00.739779  3484 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:38:06.518324  3484 solver.cpp:237] Iteration 720, loss = 0.722917
I0204 16:38:06.518380  3484 solver.cpp:253]     Train net output #0: loss = 0.722917 (* 1 = 0.722917 loss)
I0204 16:38:06.518393  3484 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:38:12.152797  3484 solver.cpp:237] Iteration 730, loss = 0.760776
I0204 16:38:12.152853  3484 solver.cpp:253]     Train net output #0: loss = 0.760776 (* 1 = 0.760776 loss)
I0204 16:38:12.152865  3484 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:38:17.808046  3484 solver.cpp:237] Iteration 740, loss = 0.690596
I0204 16:38:17.808118  3484 solver.cpp:253]     Train net output #0: loss = 0.690596 (* 1 = 0.690596 loss)
I0204 16:38:17.808131  3484 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 16:38:23.441808  3484 solver.cpp:237] Iteration 750, loss = 0.707961
I0204 16:38:23.441867  3484 solver.cpp:253]     Train net output #0: loss = 0.707961 (* 1 = 0.707961 loss)
I0204 16:38:23.441879  3484 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 16:38:29.054915  3484 solver.cpp:237] Iteration 760, loss = 0.711996
I0204 16:38:29.055088  3484 solver.cpp:253]     Train net output #0: loss = 0.711996 (* 1 = 0.711996 loss)
I0204 16:38:29.055101  3484 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 16:38:34.762560  3484 solver.cpp:237] Iteration 770, loss = 0.703165
I0204 16:38:34.762617  3484 solver.cpp:253]     Train net output #0: loss = 0.703165 (* 1 = 0.703165 loss)
I0204 16:38:34.762645  3484 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 16:38:40.612196  3484 solver.cpp:237] Iteration 780, loss = 0.735943
I0204 16:38:40.612251  3484 solver.cpp:253]     Train net output #0: loss = 0.735943 (* 1 = 0.735943 loss)
I0204 16:38:40.612263  3484 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 16:38:46.419198  3484 solver.cpp:237] Iteration 790, loss = 0.726412
I0204 16:38:46.419267  3484 solver.cpp:253]     Train net output #0: loss = 0.726412 (* 1 = 0.726412 loss)
I0204 16:38:46.419280  3484 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 16:38:51.621089  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_800.caffemodel
I0204 16:38:51.623343  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_800.solverstate
I0204 16:38:51.624274  3484 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 16:38:54.443529  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:38:54.443581  3484 solver.cpp:409]     Test net output #1: loss = 0.694756 (* 1 = 0.694756 loss)
I0204 16:38:55.027101  3484 solver.cpp:237] Iteration 800, loss = 0.713568
I0204 16:38:55.027148  3484 solver.cpp:253]     Train net output #0: loss = 0.713568 (* 1 = 0.713568 loss)
I0204 16:38:55.027160  3484 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 16:39:00.803874  3484 solver.cpp:237] Iteration 810, loss = 0.719854
I0204 16:39:00.804098  3484 solver.cpp:253]     Train net output #0: loss = 0.719854 (* 1 = 0.719854 loss)
I0204 16:39:00.804111  3484 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 16:39:06.589861  3484 solver.cpp:237] Iteration 820, loss = 0.701048
I0204 16:39:06.589925  3484 solver.cpp:253]     Train net output #0: loss = 0.701048 (* 1 = 0.701048 loss)
I0204 16:39:06.589936  3484 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 16:39:12.337440  3484 solver.cpp:237] Iteration 830, loss = 0.728486
I0204 16:39:12.337502  3484 solver.cpp:253]     Train net output #0: loss = 0.728486 (* 1 = 0.728486 loss)
I0204 16:39:12.337514  3484 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 16:39:18.112857  3484 solver.cpp:237] Iteration 840, loss = 0.685185
I0204 16:39:18.112931  3484 solver.cpp:253]     Train net output #0: loss = 0.685185 (* 1 = 0.685185 loss)
I0204 16:39:18.112947  3484 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 16:39:23.828774  3484 solver.cpp:237] Iteration 850, loss = 0.706326
I0204 16:39:23.828841  3484 solver.cpp:253]     Train net output #0: loss = 0.706326 (* 1 = 0.706326 loss)
I0204 16:39:23.828853  3484 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 16:39:29.695524  3484 solver.cpp:237] Iteration 860, loss = 0.740796
I0204 16:39:29.695585  3484 solver.cpp:253]     Train net output #0: loss = 0.740796 (* 1 = 0.740796 loss)
I0204 16:39:29.695598  3484 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 16:39:35.386170  3484 solver.cpp:237] Iteration 870, loss = 0.719357
I0204 16:39:35.386320  3484 solver.cpp:253]     Train net output #0: loss = 0.719357 (* 1 = 0.719357 loss)
I0204 16:39:35.386333  3484 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 16:39:41.173419  3484 solver.cpp:237] Iteration 880, loss = 0.680094
I0204 16:39:41.173480  3484 solver.cpp:253]     Train net output #0: loss = 0.680094 (* 1 = 0.680094 loss)
I0204 16:39:41.173492  3484 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 16:39:47.079427  3484 solver.cpp:237] Iteration 890, loss = 0.757226
I0204 16:39:47.079484  3484 solver.cpp:253]     Train net output #0: loss = 0.757226 (* 1 = 0.757226 loss)
I0204 16:39:47.079496  3484 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 16:39:52.390635  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_900.caffemodel
I0204 16:39:52.392794  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_900.solverstate
I0204 16:39:52.393698  3484 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 16:39:55.171228  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:39:55.171278  3484 solver.cpp:409]     Test net output #1: loss = 0.701719 (* 1 = 0.701719 loss)
I0204 16:39:55.777720  3484 solver.cpp:237] Iteration 900, loss = 0.701754
I0204 16:39:55.777773  3484 solver.cpp:253]     Train net output #0: loss = 0.701754 (* 1 = 0.701754 loss)
I0204 16:39:55.777786  3484 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 16:40:01.621384  3484 solver.cpp:237] Iteration 910, loss = 0.733392
I0204 16:40:01.621450  3484 solver.cpp:253]     Train net output #0: loss = 0.733392 (* 1 = 0.733392 loss)
I0204 16:40:01.621462  3484 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 16:40:07.262617  3484 solver.cpp:237] Iteration 920, loss = 0.732648
I0204 16:40:07.262831  3484 solver.cpp:253]     Train net output #0: loss = 0.732648 (* 1 = 0.732648 loss)
I0204 16:40:07.262843  3484 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 16:40:12.813805  3484 solver.cpp:237] Iteration 930, loss = 0.716447
I0204 16:40:12.813863  3484 solver.cpp:253]     Train net output #0: loss = 0.716447 (* 1 = 0.716447 loss)
I0204 16:40:12.813875  3484 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 16:40:18.445510  3484 solver.cpp:237] Iteration 940, loss = 0.720409
I0204 16:40:18.445574  3484 solver.cpp:253]     Train net output #0: loss = 0.720409 (* 1 = 0.720409 loss)
I0204 16:40:18.445586  3484 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 16:40:24.233757  3484 solver.cpp:237] Iteration 950, loss = 0.702628
I0204 16:40:24.233815  3484 solver.cpp:253]     Train net output #0: loss = 0.702628 (* 1 = 0.702628 loss)
I0204 16:40:24.233827  3484 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 16:40:29.975792  3484 solver.cpp:237] Iteration 960, loss = 0.702992
I0204 16:40:29.975847  3484 solver.cpp:253]     Train net output #0: loss = 0.702992 (* 1 = 0.702992 loss)
I0204 16:40:29.975859  3484 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 16:40:35.759338  3484 solver.cpp:237] Iteration 970, loss = 0.718207
I0204 16:40:35.759394  3484 solver.cpp:253]     Train net output #0: loss = 0.718207 (* 1 = 0.718207 loss)
I0204 16:40:35.759407  3484 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 16:40:41.570379  3484 solver.cpp:237] Iteration 980, loss = 0.695716
I0204 16:40:41.570555  3484 solver.cpp:253]     Train net output #0: loss = 0.695716 (* 1 = 0.695716 loss)
I0204 16:40:41.570569  3484 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 16:40:47.301268  3484 solver.cpp:237] Iteration 990, loss = 0.711181
I0204 16:40:47.301334  3484 solver.cpp:253]     Train net output #0: loss = 0.711181 (* 1 = 0.711181 loss)
I0204 16:40:47.301347  3484 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 16:40:52.430335  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1000.caffemodel
I0204 16:40:52.432565  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1000.solverstate
I0204 16:40:52.433449  3484 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 16:40:55.187108  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:40:55.187170  3484 solver.cpp:409]     Test net output #1: loss = 0.696597 (* 1 = 0.696597 loss)
I0204 16:40:55.755269  3484 solver.cpp:237] Iteration 1000, loss = 0.729954
I0204 16:40:55.755323  3484 solver.cpp:253]     Train net output #0: loss = 0.729954 (* 1 = 0.729954 loss)
I0204 16:40:55.755336  3484 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 16:41:01.475049  3484 solver.cpp:237] Iteration 1010, loss = 0.701564
I0204 16:41:01.475126  3484 solver.cpp:253]     Train net output #0: loss = 0.701564 (* 1 = 0.701564 loss)
I0204 16:41:01.475137  3484 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 16:41:07.176887  3484 solver.cpp:237] Iteration 1020, loss = 0.75073
I0204 16:41:07.176946  3484 solver.cpp:253]     Train net output #0: loss = 0.75073 (* 1 = 0.75073 loss)
I0204 16:41:07.176959  3484 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 16:41:12.962395  3484 solver.cpp:237] Iteration 1030, loss = 0.683615
I0204 16:41:12.962611  3484 solver.cpp:253]     Train net output #0: loss = 0.683615 (* 1 = 0.683615 loss)
I0204 16:41:12.962625  3484 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 16:41:18.721173  3484 solver.cpp:237] Iteration 1040, loss = 0.685293
I0204 16:41:18.721242  3484 solver.cpp:253]     Train net output #0: loss = 0.685293 (* 1 = 0.685293 loss)
I0204 16:41:18.721254  3484 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 16:41:24.451704  3484 solver.cpp:237] Iteration 1050, loss = 0.704546
I0204 16:41:24.451767  3484 solver.cpp:253]     Train net output #0: loss = 0.704546 (* 1 = 0.704546 loss)
I0204 16:41:24.451779  3484 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 16:41:30.228062  3484 solver.cpp:237] Iteration 1060, loss = 0.688245
I0204 16:41:30.228140  3484 solver.cpp:253]     Train net output #0: loss = 0.688245 (* 1 = 0.688245 loss)
I0204 16:41:30.228154  3484 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 16:41:36.030161  3484 solver.cpp:237] Iteration 1070, loss = 0.717843
I0204 16:41:36.030235  3484 solver.cpp:253]     Train net output #0: loss = 0.717843 (* 1 = 0.717843 loss)
I0204 16:41:36.030247  3484 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 16:41:41.750879  3484 solver.cpp:237] Iteration 1080, loss = 0.718796
I0204 16:41:41.750946  3484 solver.cpp:253]     Train net output #0: loss = 0.718796 (* 1 = 0.718796 loss)
I0204 16:41:41.750959  3484 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 16:41:47.483819  3484 solver.cpp:237] Iteration 1090, loss = 0.73114
I0204 16:41:47.483975  3484 solver.cpp:253]     Train net output #0: loss = 0.73114 (* 1 = 0.73114 loss)
I0204 16:41:47.483989  3484 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 16:41:52.634120  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1100.caffemodel
I0204 16:41:52.636430  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1100.solverstate
I0204 16:41:52.637428  3484 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 16:41:55.425541  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:41:55.425600  3484 solver.cpp:409]     Test net output #1: loss = 0.694887 (* 1 = 0.694887 loss)
I0204 16:41:56.007134  3484 solver.cpp:237] Iteration 1100, loss = 0.725424
I0204 16:41:56.007194  3484 solver.cpp:253]     Train net output #0: loss = 0.725424 (* 1 = 0.725424 loss)
I0204 16:41:56.007205  3484 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 16:42:01.777310  3484 solver.cpp:237] Iteration 1110, loss = 0.70637
I0204 16:42:01.777371  3484 solver.cpp:253]     Train net output #0: loss = 0.70637 (* 1 = 0.70637 loss)
I0204 16:42:01.777384  3484 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 16:42:07.568912  3484 solver.cpp:237] Iteration 1120, loss = 0.699504
I0204 16:42:07.568974  3484 solver.cpp:253]     Train net output #0: loss = 0.699504 (* 1 = 0.699504 loss)
I0204 16:42:07.568989  3484 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 16:42:13.378962  3484 solver.cpp:237] Iteration 1130, loss = 0.728443
I0204 16:42:13.379025  3484 solver.cpp:253]     Train net output #0: loss = 0.728443 (* 1 = 0.728443 loss)
I0204 16:42:13.379037  3484 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 16:42:19.142134  3484 solver.cpp:237] Iteration 1140, loss = 0.707735
I0204 16:42:19.142335  3484 solver.cpp:253]     Train net output #0: loss = 0.707735 (* 1 = 0.707735 loss)
I0204 16:42:19.142354  3484 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 16:42:24.887014  3484 solver.cpp:237] Iteration 1150, loss = 0.703303
I0204 16:42:24.887085  3484 solver.cpp:253]     Train net output #0: loss = 0.703303 (* 1 = 0.703303 loss)
I0204 16:42:24.887099  3484 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 16:42:30.659699  3484 solver.cpp:237] Iteration 1160, loss = 0.702352
I0204 16:42:30.659761  3484 solver.cpp:253]     Train net output #0: loss = 0.702352 (* 1 = 0.702352 loss)
I0204 16:42:30.659772  3484 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 16:42:36.379192  3484 solver.cpp:237] Iteration 1170, loss = 0.70081
I0204 16:42:36.379252  3484 solver.cpp:253]     Train net output #0: loss = 0.70081 (* 1 = 0.70081 loss)
I0204 16:42:36.379264  3484 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 16:42:42.177083  3484 solver.cpp:237] Iteration 1180, loss = 0.715931
I0204 16:42:42.177148  3484 solver.cpp:253]     Train net output #0: loss = 0.715931 (* 1 = 0.715931 loss)
I0204 16:42:42.177161  3484 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 16:42:47.915841  3484 solver.cpp:237] Iteration 1190, loss = 0.729088
I0204 16:42:47.915899  3484 solver.cpp:253]     Train net output #0: loss = 0.729088 (* 1 = 0.729088 loss)
I0204 16:42:47.915910  3484 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 16:42:53.053313  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1200.caffemodel
I0204 16:42:53.055716  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1200.solverstate
I0204 16:42:53.056761  3484 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 16:42:55.939782  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:42:55.939847  3484 solver.cpp:409]     Test net output #1: loss = 0.695965 (* 1 = 0.695965 loss)
I0204 16:42:56.515092  3484 solver.cpp:237] Iteration 1200, loss = 0.691077
I0204 16:42:56.515161  3484 solver.cpp:253]     Train net output #0: loss = 0.691077 (* 1 = 0.691077 loss)
I0204 16:42:56.515173  3484 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 16:43:02.260697  3484 solver.cpp:237] Iteration 1210, loss = 0.742808
I0204 16:43:02.260771  3484 solver.cpp:253]     Train net output #0: loss = 0.742808 (* 1 = 0.742808 loss)
I0204 16:43:02.260785  3484 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 16:43:07.989960  3484 solver.cpp:237] Iteration 1220, loss = 0.69196
I0204 16:43:07.990028  3484 solver.cpp:253]     Train net output #0: loss = 0.69196 (* 1 = 0.69196 loss)
I0204 16:43:07.990041  3484 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 16:43:13.699947  3484 solver.cpp:237] Iteration 1230, loss = 0.724445
I0204 16:43:13.700011  3484 solver.cpp:253]     Train net output #0: loss = 0.724445 (* 1 = 0.724445 loss)
I0204 16:43:13.700022  3484 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 16:43:19.431433  3484 solver.cpp:237] Iteration 1240, loss = 0.689091
I0204 16:43:19.431509  3484 solver.cpp:253]     Train net output #0: loss = 0.689091 (* 1 = 0.689091 loss)
I0204 16:43:19.431521  3484 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 16:43:25.176723  3484 solver.cpp:237] Iteration 1250, loss = 0.688084
I0204 16:43:25.176887  3484 solver.cpp:253]     Train net output #0: loss = 0.688084 (* 1 = 0.688084 loss)
I0204 16:43:25.176899  3484 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 16:43:30.927253  3484 solver.cpp:237] Iteration 1260, loss = 0.735152
I0204 16:43:30.927323  3484 solver.cpp:253]     Train net output #0: loss = 0.735152 (* 1 = 0.735152 loss)
I0204 16:43:30.927337  3484 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 16:43:36.800935  3484 solver.cpp:237] Iteration 1270, loss = 0.726918
I0204 16:43:36.800998  3484 solver.cpp:253]     Train net output #0: loss = 0.726918 (* 1 = 0.726918 loss)
I0204 16:43:36.801023  3484 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 16:43:42.556347  3484 solver.cpp:237] Iteration 1280, loss = 0.708427
I0204 16:43:42.556412  3484 solver.cpp:253]     Train net output #0: loss = 0.708427 (* 1 = 0.708427 loss)
I0204 16:43:42.556423  3484 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 16:43:48.280637  3484 solver.cpp:237] Iteration 1290, loss = 0.726887
I0204 16:43:48.280694  3484 solver.cpp:253]     Train net output #0: loss = 0.726887 (* 1 = 0.726887 loss)
I0204 16:43:48.280704  3484 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 16:43:53.443738  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1300.caffemodel
I0204 16:43:53.445955  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1300.solverstate
I0204 16:43:53.446853  3484 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 16:43:56.223574  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:43:56.223779  3484 solver.cpp:409]     Test net output #1: loss = 0.702253 (* 1 = 0.702253 loss)
I0204 16:43:56.797711  3484 solver.cpp:237] Iteration 1300, loss = 0.674187
I0204 16:43:56.797770  3484 solver.cpp:253]     Train net output #0: loss = 0.674187 (* 1 = 0.674187 loss)
I0204 16:43:56.797781  3484 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 16:44:02.693342  3484 solver.cpp:237] Iteration 1310, loss = 0.716688
I0204 16:44:02.693397  3484 solver.cpp:253]     Train net output #0: loss = 0.716688 (* 1 = 0.716688 loss)
I0204 16:44:02.693409  3484 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 16:44:08.432399  3484 solver.cpp:237] Iteration 1320, loss = 0.707845
I0204 16:44:08.432464  3484 solver.cpp:253]     Train net output #0: loss = 0.707845 (* 1 = 0.707845 loss)
I0204 16:44:08.432476  3484 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 16:44:14.127841  3484 solver.cpp:237] Iteration 1330, loss = 0.711818
I0204 16:44:14.127903  3484 solver.cpp:253]     Train net output #0: loss = 0.711818 (* 1 = 0.711818 loss)
I0204 16:44:14.127915  3484 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 16:44:19.911591  3484 solver.cpp:237] Iteration 1340, loss = 0.723655
I0204 16:44:19.911658  3484 solver.cpp:253]     Train net output #0: loss = 0.723655 (* 1 = 0.723655 loss)
I0204 16:44:19.911669  3484 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 16:44:25.672186  3484 solver.cpp:237] Iteration 1350, loss = 0.716147
I0204 16:44:25.672252  3484 solver.cpp:253]     Train net output #0: loss = 0.716147 (* 1 = 0.716147 loss)
I0204 16:44:25.672265  3484 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 16:44:31.598229  3484 solver.cpp:237] Iteration 1360, loss = 0.698385
I0204 16:44:31.598420  3484 solver.cpp:253]     Train net output #0: loss = 0.698385 (* 1 = 0.698385 loss)
I0204 16:44:31.598433  3484 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 16:44:37.420980  3484 solver.cpp:237] Iteration 1370, loss = 0.76089
I0204 16:44:37.421046  3484 solver.cpp:253]     Train net output #0: loss = 0.76089 (* 1 = 0.76089 loss)
I0204 16:44:37.421057  3484 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 16:44:43.120882  3484 solver.cpp:237] Iteration 1380, loss = 0.696377
I0204 16:44:43.120946  3484 solver.cpp:253]     Train net output #0: loss = 0.696377 (* 1 = 0.696377 loss)
I0204 16:44:43.120959  3484 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 16:44:48.891518  3484 solver.cpp:237] Iteration 1390, loss = 0.715663
I0204 16:44:48.891580  3484 solver.cpp:253]     Train net output #0: loss = 0.715663 (* 1 = 0.715663 loss)
I0204 16:44:48.891592  3484 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 16:44:54.025707  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1400.caffemodel
I0204 16:44:54.028076  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1400.solverstate
I0204 16:44:54.029114  3484 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 16:44:56.792970  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:44:56.793030  3484 solver.cpp:409]     Test net output #1: loss = 0.698756 (* 1 = 0.698756 loss)
I0204 16:44:57.367732  3484 solver.cpp:237] Iteration 1400, loss = 0.710855
I0204 16:44:57.367781  3484 solver.cpp:253]     Train net output #0: loss = 0.710855 (* 1 = 0.710855 loss)
I0204 16:44:57.367792  3484 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 16:45:03.112265  3484 solver.cpp:237] Iteration 1410, loss = 0.707483
I0204 16:45:03.112474  3484 solver.cpp:253]     Train net output #0: loss = 0.707483 (* 1 = 0.707483 loss)
I0204 16:45:03.112491  3484 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 16:45:08.858862  3484 solver.cpp:237] Iteration 1420, loss = 0.742537
I0204 16:45:08.858921  3484 solver.cpp:253]     Train net output #0: loss = 0.742537 (* 1 = 0.742537 loss)
I0204 16:45:08.858933  3484 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 16:45:14.689488  3484 solver.cpp:237] Iteration 1430, loss = 0.713929
I0204 16:45:14.689548  3484 solver.cpp:253]     Train net output #0: loss = 0.713929 (* 1 = 0.713929 loss)
I0204 16:45:14.689560  3484 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 16:45:20.455955  3484 solver.cpp:237] Iteration 1440, loss = 0.685541
I0204 16:45:20.456019  3484 solver.cpp:253]     Train net output #0: loss = 0.685541 (* 1 = 0.685541 loss)
I0204 16:45:20.456032  3484 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 16:45:26.217386  3484 solver.cpp:237] Iteration 1450, loss = 0.726584
I0204 16:45:26.217442  3484 solver.cpp:253]     Train net output #0: loss = 0.726584 (* 1 = 0.726584 loss)
I0204 16:45:26.217455  3484 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 16:45:32.019484  3484 solver.cpp:237] Iteration 1460, loss = 0.668109
I0204 16:45:32.019546  3484 solver.cpp:253]     Train net output #0: loss = 0.668109 (* 1 = 0.668109 loss)
I0204 16:45:32.019557  3484 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 16:45:37.847200  3484 solver.cpp:237] Iteration 1470, loss = 0.700761
I0204 16:45:37.847925  3484 solver.cpp:253]     Train net output #0: loss = 0.700761 (* 1 = 0.700761 loss)
I0204 16:45:37.847944  3484 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 16:45:43.638533  3484 solver.cpp:237] Iteration 1480, loss = 0.733125
I0204 16:45:43.638602  3484 solver.cpp:253]     Train net output #0: loss = 0.733125 (* 1 = 0.733125 loss)
I0204 16:45:43.638613  3484 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 16:45:49.421206  3484 solver.cpp:237] Iteration 1490, loss = 0.707217
I0204 16:45:49.421273  3484 solver.cpp:253]     Train net output #0: loss = 0.707217 (* 1 = 0.707217 loss)
I0204 16:45:49.421285  3484 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 16:45:54.583950  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1500.caffemodel
I0204 16:45:54.586189  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1500.solverstate
I0204 16:45:54.587173  3484 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 16:45:57.365142  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:45:57.365206  3484 solver.cpp:409]     Test net output #1: loss = 0.693913 (* 1 = 0.693913 loss)
I0204 16:45:57.939335  3484 solver.cpp:237] Iteration 1500, loss = 0.712395
I0204 16:45:57.939389  3484 solver.cpp:253]     Train net output #0: loss = 0.712395 (* 1 = 0.712395 loss)
I0204 16:45:57.939400  3484 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 16:46:03.652037  3484 solver.cpp:237] Iteration 1510, loss = 0.695611
I0204 16:46:03.652117  3484 solver.cpp:253]     Train net output #0: loss = 0.695611 (* 1 = 0.695611 loss)
I0204 16:46:03.652129  3484 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 16:46:09.420789  3484 solver.cpp:237] Iteration 1520, loss = 0.696466
I0204 16:46:09.421031  3484 solver.cpp:253]     Train net output #0: loss = 0.696466 (* 1 = 0.696466 loss)
I0204 16:46:09.421046  3484 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 16:46:15.170279  3484 solver.cpp:237] Iteration 1530, loss = 0.721638
I0204 16:46:15.170346  3484 solver.cpp:253]     Train net output #0: loss = 0.721638 (* 1 = 0.721638 loss)
I0204 16:46:15.170357  3484 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 16:46:20.929877  3484 solver.cpp:237] Iteration 1540, loss = 0.691778
I0204 16:46:20.929937  3484 solver.cpp:253]     Train net output #0: loss = 0.691778 (* 1 = 0.691778 loss)
I0204 16:46:20.929950  3484 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 16:46:26.586421  3484 solver.cpp:237] Iteration 1550, loss = 0.690288
I0204 16:46:26.586485  3484 solver.cpp:253]     Train net output #0: loss = 0.690288 (* 1 = 0.690288 loss)
I0204 16:46:26.586498  3484 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 16:46:32.189688  3484 solver.cpp:237] Iteration 1560, loss = 0.703254
I0204 16:46:32.189759  3484 solver.cpp:253]     Train net output #0: loss = 0.703254 (* 1 = 0.703254 loss)
I0204 16:46:32.189769  3484 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 16:46:37.807629  3484 solver.cpp:237] Iteration 1570, loss = 0.697867
I0204 16:46:37.807693  3484 solver.cpp:253]     Train net output #0: loss = 0.697867 (* 1 = 0.697867 loss)
I0204 16:46:37.807704  3484 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 16:46:43.665921  3484 solver.cpp:237] Iteration 1580, loss = 0.720961
I0204 16:46:43.666103  3484 solver.cpp:253]     Train net output #0: loss = 0.720961 (* 1 = 0.720961 loss)
I0204 16:46:43.666118  3484 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 16:46:49.430805  3484 solver.cpp:237] Iteration 1590, loss = 0.70282
I0204 16:46:49.430872  3484 solver.cpp:253]     Train net output #0: loss = 0.70282 (* 1 = 0.70282 loss)
I0204 16:46:49.430884  3484 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 16:46:54.636780  3484 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1600.caffemodel
I0204 16:46:54.639073  3484 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed3/snaps/snap__iter_1600.solverstate
I0204 16:46:54.918992  3484 solver.cpp:321] Iteration 1600, loss = 0.70439
I0204 16:46:54.919055  3484 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 16:46:57.724735  3484 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:46:57.724798  3484 solver.cpp:409]     Test net output #1: loss = 0.69441 (* 1 = 0.69441 loss)
I0204 16:46:57.724808  3484 solver.cpp:326] Optimization Done.
I0204 16:46:57.724814  3484 caffe.cpp:215] Optimization Done.
