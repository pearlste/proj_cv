Log file created at: 2016/02/05 02:45:44
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0205 02:45:44.435255 11512 caffe.cpp:177] Use CPU.
I0205 02:45:44.436204 11512 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap_"
solver_mode: CPU
random_seed: 23
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/train_val.prototxt"
I0205 02:45:44.436383 11512 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/train_val.prototxt
I0205 02:45:44.437002 11512 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0205 02:45:44.437047 11512 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0205 02:45:44.437309 11512 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 02:45:44.437464 11512 layer_factory.hpp:77] Creating layer data
I0205 02:45:44.437671 11512 net.cpp:106] Creating Layer data
I0205 02:45:44.437691 11512 net.cpp:411] data -> data
I0205 02:45:44.437786 11512 net.cpp:411] data -> label
I0205 02:45:44.437814 11512 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0205 02:45:44.437979 11513 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0205 02:45:44.439007 11512 data_layer.cpp:41] output data size: 100,1,227,227
I0205 02:45:44.470763 11512 net.cpp:150] Setting up data
I0205 02:45:44.470857 11512 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 02:45:44.470868 11512 net.cpp:157] Top shape: 100 (100)
I0205 02:45:44.470875 11512 net.cpp:165] Memory required for data: 20612000
I0205 02:45:44.470897 11512 layer_factory.hpp:77] Creating layer conv1
I0205 02:45:44.470927 11512 net.cpp:106] Creating Layer conv1
I0205 02:45:44.470935 11512 net.cpp:454] conv1 <- data
I0205 02:45:44.470957 11512 net.cpp:411] conv1 -> conv1
I0205 02:45:44.471108 11512 net.cpp:150] Setting up conv1
I0205 02:45:44.471122 11512 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 02:45:44.471129 11512 net.cpp:165] Memory required for data: 59332000
I0205 02:45:44.471148 11512 layer_factory.hpp:77] Creating layer relu1
I0205 02:45:44.471160 11512 net.cpp:106] Creating Layer relu1
I0205 02:45:44.471166 11512 net.cpp:454] relu1 <- conv1
I0205 02:45:44.471179 11512 net.cpp:397] relu1 -> conv1 (in-place)
I0205 02:45:44.471194 11512 net.cpp:150] Setting up relu1
I0205 02:45:44.471200 11512 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 02:45:44.471206 11512 net.cpp:165] Memory required for data: 98052000
I0205 02:45:44.471212 11512 layer_factory.hpp:77] Creating layer pool1
I0205 02:45:44.471225 11512 net.cpp:106] Creating Layer pool1
I0205 02:45:44.471230 11512 net.cpp:454] pool1 <- conv1
I0205 02:45:44.471238 11512 net.cpp:411] pool1 -> pool1
I0205 02:45:44.471264 11512 net.cpp:150] Setting up pool1
I0205 02:45:44.471273 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.471278 11512 net.cpp:165] Memory required for data: 107383200
I0205 02:45:44.471284 11512 layer_factory.hpp:77] Creating layer norm1
I0205 02:45:44.471319 11512 net.cpp:106] Creating Layer norm1
I0205 02:45:44.471325 11512 net.cpp:454] norm1 <- pool1
I0205 02:45:44.471335 11512 net.cpp:411] norm1 -> norm1
I0205 02:45:44.471354 11512 net.cpp:150] Setting up norm1
I0205 02:45:44.471362 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.471367 11512 net.cpp:165] Memory required for data: 116714400
I0205 02:45:44.471374 11512 layer_factory.hpp:77] Creating layer conv2
I0205 02:45:44.471385 11512 net.cpp:106] Creating Layer conv2
I0205 02:45:44.471391 11512 net.cpp:454] conv2 <- norm1
I0205 02:45:44.471400 11512 net.cpp:411] conv2 -> conv2
I0205 02:45:44.471534 11512 net.cpp:150] Setting up conv2
I0205 02:45:44.471544 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.471549 11512 net.cpp:165] Memory required for data: 126045600
I0205 02:45:44.471562 11512 layer_factory.hpp:77] Creating layer relu2
I0205 02:45:44.471571 11512 net.cpp:106] Creating Layer relu2
I0205 02:45:44.471577 11512 net.cpp:454] relu2 <- conv2
I0205 02:45:44.471602 11512 net.cpp:397] relu2 -> conv2 (in-place)
I0205 02:45:44.471614 11512 net.cpp:150] Setting up relu2
I0205 02:45:44.471621 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.471626 11512 net.cpp:165] Memory required for data: 135376800
I0205 02:45:44.471632 11512 layer_factory.hpp:77] Creating layer pool2
I0205 02:45:44.471642 11512 net.cpp:106] Creating Layer pool2
I0205 02:45:44.471647 11512 net.cpp:454] pool2 <- conv2
I0205 02:45:44.471655 11512 net.cpp:411] pool2 -> pool2
I0205 02:45:44.471668 11512 net.cpp:150] Setting up pool2
I0205 02:45:44.471674 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.471679 11512 net.cpp:165] Memory required for data: 137540000
I0205 02:45:44.471684 11512 layer_factory.hpp:77] Creating layer norm2
I0205 02:45:44.471695 11512 net.cpp:106] Creating Layer norm2
I0205 02:45:44.471703 11512 net.cpp:454] norm2 <- pool2
I0205 02:45:44.471714 11512 net.cpp:411] norm2 -> norm2
I0205 02:45:44.471724 11512 net.cpp:150] Setting up norm2
I0205 02:45:44.471730 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.471736 11512 net.cpp:165] Memory required for data: 139703200
I0205 02:45:44.471741 11512 layer_factory.hpp:77] Creating layer conv3
I0205 02:45:44.471752 11512 net.cpp:106] Creating Layer conv3
I0205 02:45:44.471758 11512 net.cpp:454] conv3 <- norm2
I0205 02:45:44.471766 11512 net.cpp:411] conv3 -> conv3
I0205 02:45:44.471882 11512 net.cpp:150] Setting up conv3
I0205 02:45:44.471892 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.471899 11512 net.cpp:165] Memory required for data: 141866400
I0205 02:45:44.471909 11512 layer_factory.hpp:77] Creating layer relu3
I0205 02:45:44.471920 11512 net.cpp:106] Creating Layer relu3
I0205 02:45:44.471926 11512 net.cpp:454] relu3 <- conv3
I0205 02:45:44.471933 11512 net.cpp:397] relu3 -> conv3 (in-place)
I0205 02:45:44.471943 11512 net.cpp:150] Setting up relu3
I0205 02:45:44.471951 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.471958 11512 net.cpp:165] Memory required for data: 144029600
I0205 02:45:44.471964 11512 layer_factory.hpp:77] Creating layer conv4
I0205 02:45:44.471977 11512 net.cpp:106] Creating Layer conv4
I0205 02:45:44.471982 11512 net.cpp:454] conv4 <- conv3
I0205 02:45:44.471993 11512 net.cpp:411] conv4 -> conv4
I0205 02:45:44.472065 11512 net.cpp:150] Setting up conv4
I0205 02:45:44.472074 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.472079 11512 net.cpp:165] Memory required for data: 146192800
I0205 02:45:44.472087 11512 layer_factory.hpp:77] Creating layer relu4
I0205 02:45:44.472105 11512 net.cpp:106] Creating Layer relu4
I0205 02:45:44.472110 11512 net.cpp:454] relu4 <- conv4
I0205 02:45:44.472117 11512 net.cpp:397] relu4 -> conv4 (in-place)
I0205 02:45:44.472126 11512 net.cpp:150] Setting up relu4
I0205 02:45:44.472133 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.472139 11512 net.cpp:165] Memory required for data: 148356000
I0205 02:45:44.472151 11512 layer_factory.hpp:77] Creating layer conv5
I0205 02:45:44.472170 11512 net.cpp:106] Creating Layer conv5
I0205 02:45:44.472177 11512 net.cpp:454] conv5 <- conv4
I0205 02:45:44.472185 11512 net.cpp:411] conv5 -> conv5
I0205 02:45:44.472234 11512 net.cpp:150] Setting up conv5
I0205 02:45:44.472244 11512 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 02:45:44.472249 11512 net.cpp:165] Memory required for data: 149437600
I0205 02:45:44.472259 11512 layer_factory.hpp:77] Creating layer relu5
I0205 02:45:44.472268 11512 net.cpp:106] Creating Layer relu5
I0205 02:45:44.472273 11512 net.cpp:454] relu5 <- conv5
I0205 02:45:44.472283 11512 net.cpp:397] relu5 -> conv5 (in-place)
I0205 02:45:44.472292 11512 net.cpp:150] Setting up relu5
I0205 02:45:44.472301 11512 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 02:45:44.472306 11512 net.cpp:165] Memory required for data: 150519200
I0205 02:45:44.472311 11512 layer_factory.hpp:77] Creating layer pool5
I0205 02:45:44.472319 11512 net.cpp:106] Creating Layer pool5
I0205 02:45:44.472326 11512 net.cpp:454] pool5 <- conv5
I0205 02:45:44.472335 11512 net.cpp:411] pool5 -> pool5
I0205 02:45:44.472347 11512 net.cpp:150] Setting up pool5
I0205 02:45:44.472355 11512 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0205 02:45:44.472362 11512 net.cpp:165] Memory required for data: 150749600
I0205 02:45:44.472367 11512 layer_factory.hpp:77] Creating layer fc6
I0205 02:45:44.472383 11512 net.cpp:106] Creating Layer fc6
I0205 02:45:44.472388 11512 net.cpp:454] fc6 <- pool5
I0205 02:45:44.472399 11512 net.cpp:411] fc6 -> fc6
I0205 02:45:44.473987 11512 net.cpp:150] Setting up fc6
I0205 02:45:44.474001 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474006 11512 net.cpp:165] Memory required for data: 150852000
I0205 02:45:44.474015 11512 layer_factory.hpp:77] Creating layer relu6
I0205 02:45:44.474027 11512 net.cpp:106] Creating Layer relu6
I0205 02:45:44.474033 11512 net.cpp:454] relu6 <- fc6
I0205 02:45:44.474040 11512 net.cpp:397] relu6 -> fc6 (in-place)
I0205 02:45:44.474050 11512 net.cpp:150] Setting up relu6
I0205 02:45:44.474056 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474062 11512 net.cpp:165] Memory required for data: 150954400
I0205 02:45:44.474069 11512 layer_factory.hpp:77] Creating layer drop6
I0205 02:45:44.474081 11512 net.cpp:106] Creating Layer drop6
I0205 02:45:44.474086 11512 net.cpp:454] drop6 <- fc6
I0205 02:45:44.474099 11512 net.cpp:397] drop6 -> fc6 (in-place)
I0205 02:45:44.474117 11512 net.cpp:150] Setting up drop6
I0205 02:45:44.474124 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474130 11512 net.cpp:165] Memory required for data: 151056800
I0205 02:45:44.474136 11512 layer_factory.hpp:77] Creating layer fc7
I0205 02:45:44.474145 11512 net.cpp:106] Creating Layer fc7
I0205 02:45:44.474151 11512 net.cpp:454] fc7 <- fc6
I0205 02:45:44.474161 11512 net.cpp:411] fc7 -> fc7
I0205 02:45:44.474856 11512 net.cpp:150] Setting up fc7
I0205 02:45:44.474870 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474875 11512 net.cpp:165] Memory required for data: 151159200
I0205 02:45:44.474884 11512 layer_factory.hpp:77] Creating layer relu7
I0205 02:45:44.474892 11512 net.cpp:106] Creating Layer relu7
I0205 02:45:44.474897 11512 net.cpp:454] relu7 <- fc7
I0205 02:45:44.474907 11512 net.cpp:397] relu7 -> fc7 (in-place)
I0205 02:45:44.474917 11512 net.cpp:150] Setting up relu7
I0205 02:45:44.474923 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474930 11512 net.cpp:165] Memory required for data: 151261600
I0205 02:45:44.474934 11512 layer_factory.hpp:77] Creating layer drop7
I0205 02:45:44.474942 11512 net.cpp:106] Creating Layer drop7
I0205 02:45:44.474949 11512 net.cpp:454] drop7 <- fc7
I0205 02:45:44.474959 11512 net.cpp:397] drop7 -> fc7 (in-place)
I0205 02:45:44.474969 11512 net.cpp:150] Setting up drop7
I0205 02:45:44.474977 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.474982 11512 net.cpp:165] Memory required for data: 151364000
I0205 02:45:44.474987 11512 layer_factory.hpp:77] Creating layer fc8
I0205 02:45:44.475004 11512 net.cpp:106] Creating Layer fc8
I0205 02:45:44.475018 11512 net.cpp:454] fc8 <- fc7
I0205 02:45:44.475028 11512 net.cpp:411] fc8 -> fc8
I0205 02:45:44.475052 11512 net.cpp:150] Setting up fc8
I0205 02:45:44.475059 11512 net.cpp:157] Top shape: 100 2 (200)
I0205 02:45:44.475065 11512 net.cpp:165] Memory required for data: 151364800
I0205 02:45:44.475074 11512 layer_factory.hpp:77] Creating layer loss
I0205 02:45:44.475085 11512 net.cpp:106] Creating Layer loss
I0205 02:45:44.475106 11512 net.cpp:454] loss <- fc8
I0205 02:45:44.475112 11512 net.cpp:454] loss <- label
I0205 02:45:44.475122 11512 net.cpp:411] loss -> loss
I0205 02:45:44.475138 11512 layer_factory.hpp:77] Creating layer loss
I0205 02:45:44.475172 11512 net.cpp:150] Setting up loss
I0205 02:45:44.475179 11512 net.cpp:157] Top shape: (1)
I0205 02:45:44.475185 11512 net.cpp:160]     with loss weight 1
I0205 02:45:44.475215 11512 net.cpp:165] Memory required for data: 151364804
I0205 02:45:44.475224 11512 net.cpp:226] loss needs backward computation.
I0205 02:45:44.475230 11512 net.cpp:226] fc8 needs backward computation.
I0205 02:45:44.475236 11512 net.cpp:226] drop7 needs backward computation.
I0205 02:45:44.475241 11512 net.cpp:226] relu7 needs backward computation.
I0205 02:45:44.475246 11512 net.cpp:226] fc7 needs backward computation.
I0205 02:45:44.475252 11512 net.cpp:226] drop6 needs backward computation.
I0205 02:45:44.475258 11512 net.cpp:226] relu6 needs backward computation.
I0205 02:45:44.475263 11512 net.cpp:226] fc6 needs backward computation.
I0205 02:45:44.475270 11512 net.cpp:226] pool5 needs backward computation.
I0205 02:45:44.475278 11512 net.cpp:226] relu5 needs backward computation.
I0205 02:45:44.475283 11512 net.cpp:226] conv5 needs backward computation.
I0205 02:45:44.475289 11512 net.cpp:226] relu4 needs backward computation.
I0205 02:45:44.475294 11512 net.cpp:226] conv4 needs backward computation.
I0205 02:45:44.475301 11512 net.cpp:226] relu3 needs backward computation.
I0205 02:45:44.475306 11512 net.cpp:226] conv3 needs backward computation.
I0205 02:45:44.475316 11512 net.cpp:226] norm2 needs backward computation.
I0205 02:45:44.475322 11512 net.cpp:226] pool2 needs backward computation.
I0205 02:45:44.475327 11512 net.cpp:226] relu2 needs backward computation.
I0205 02:45:44.475333 11512 net.cpp:226] conv2 needs backward computation.
I0205 02:45:44.475338 11512 net.cpp:226] norm1 needs backward computation.
I0205 02:45:44.475344 11512 net.cpp:226] pool1 needs backward computation.
I0205 02:45:44.475350 11512 net.cpp:226] relu1 needs backward computation.
I0205 02:45:44.475355 11512 net.cpp:226] conv1 needs backward computation.
I0205 02:45:44.475363 11512 net.cpp:228] data does not need backward computation.
I0205 02:45:44.475368 11512 net.cpp:270] This network produces output loss
I0205 02:45:44.475399 11512 net.cpp:283] Network initialization done.
I0205 02:45:44.476186 11512 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/train_val.prototxt
I0205 02:45:44.476245 11512 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0205 02:45:44.476548 11512 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0205 02:45:44.476727 11512 layer_factory.hpp:77] Creating layer data
I0205 02:45:44.476884 11512 net.cpp:106] Creating Layer data
I0205 02:45:44.476909 11512 net.cpp:411] data -> data
I0205 02:45:44.476924 11512 net.cpp:411] data -> label
I0205 02:45:44.476935 11512 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0205 02:45:44.477165 11516 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0205 02:45:44.477951 11512 data_layer.cpp:41] output data size: 100,1,227,227
I0205 02:45:44.507693 11512 net.cpp:150] Setting up data
I0205 02:45:44.507721 11512 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0205 02:45:44.507730 11512 net.cpp:157] Top shape: 100 (100)
I0205 02:45:44.507735 11512 net.cpp:165] Memory required for data: 20612000
I0205 02:45:44.507745 11512 layer_factory.hpp:77] Creating layer label_data_1_split
I0205 02:45:44.507762 11512 net.cpp:106] Creating Layer label_data_1_split
I0205 02:45:44.507771 11512 net.cpp:454] label_data_1_split <- label
I0205 02:45:44.507782 11512 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0205 02:45:44.507797 11512 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0205 02:45:44.507809 11512 net.cpp:150] Setting up label_data_1_split
I0205 02:45:44.507817 11512 net.cpp:157] Top shape: 100 (100)
I0205 02:45:44.507824 11512 net.cpp:157] Top shape: 100 (100)
I0205 02:45:44.507829 11512 net.cpp:165] Memory required for data: 20612800
I0205 02:45:44.507835 11512 layer_factory.hpp:77] Creating layer conv1
I0205 02:45:44.507850 11512 net.cpp:106] Creating Layer conv1
I0205 02:45:44.507858 11512 net.cpp:454] conv1 <- data
I0205 02:45:44.507868 11512 net.cpp:411] conv1 -> conv1
I0205 02:45:44.507938 11512 net.cpp:150] Setting up conv1
I0205 02:45:44.507951 11512 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 02:45:44.507957 11512 net.cpp:165] Memory required for data: 59332800
I0205 02:45:44.507972 11512 layer_factory.hpp:77] Creating layer relu1
I0205 02:45:44.507982 11512 net.cpp:106] Creating Layer relu1
I0205 02:45:44.507989 11512 net.cpp:454] relu1 <- conv1
I0205 02:45:44.507997 11512 net.cpp:397] relu1 -> conv1 (in-place)
I0205 02:45:44.508008 11512 net.cpp:150] Setting up relu1
I0205 02:45:44.508014 11512 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0205 02:45:44.508019 11512 net.cpp:165] Memory required for data: 98052800
I0205 02:45:44.508025 11512 layer_factory.hpp:77] Creating layer pool1
I0205 02:45:44.508035 11512 net.cpp:106] Creating Layer pool1
I0205 02:45:44.508041 11512 net.cpp:454] pool1 <- conv1
I0205 02:45:44.508049 11512 net.cpp:411] pool1 -> pool1
I0205 02:45:44.508064 11512 net.cpp:150] Setting up pool1
I0205 02:45:44.508070 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.508075 11512 net.cpp:165] Memory required for data: 107384000
I0205 02:45:44.508081 11512 layer_factory.hpp:77] Creating layer norm1
I0205 02:45:44.508098 11512 net.cpp:106] Creating Layer norm1
I0205 02:45:44.508105 11512 net.cpp:454] norm1 <- pool1
I0205 02:45:44.508115 11512 net.cpp:411] norm1 -> norm1
I0205 02:45:44.508126 11512 net.cpp:150] Setting up norm1
I0205 02:45:44.508133 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.508138 11512 net.cpp:165] Memory required for data: 116715200
I0205 02:45:44.508144 11512 layer_factory.hpp:77] Creating layer conv2
I0205 02:45:44.508157 11512 net.cpp:106] Creating Layer conv2
I0205 02:45:44.508163 11512 net.cpp:454] conv2 <- norm1
I0205 02:45:44.508172 11512 net.cpp:411] conv2 -> conv2
I0205 02:45:44.508322 11512 net.cpp:150] Setting up conv2
I0205 02:45:44.508332 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.508337 11512 net.cpp:165] Memory required for data: 126046400
I0205 02:45:44.508348 11512 layer_factory.hpp:77] Creating layer relu2
I0205 02:45:44.508358 11512 net.cpp:106] Creating Layer relu2
I0205 02:45:44.508363 11512 net.cpp:454] relu2 <- conv2
I0205 02:45:44.508379 11512 net.cpp:397] relu2 -> conv2 (in-place)
I0205 02:45:44.508399 11512 net.cpp:150] Setting up relu2
I0205 02:45:44.508406 11512 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0205 02:45:44.508411 11512 net.cpp:165] Memory required for data: 135377600
I0205 02:45:44.508417 11512 layer_factory.hpp:77] Creating layer pool2
I0205 02:45:44.508427 11512 net.cpp:106] Creating Layer pool2
I0205 02:45:44.508432 11512 net.cpp:454] pool2 <- conv2
I0205 02:45:44.508455 11512 net.cpp:411] pool2 -> pool2
I0205 02:45:44.508467 11512 net.cpp:150] Setting up pool2
I0205 02:45:44.508474 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508479 11512 net.cpp:165] Memory required for data: 137540800
I0205 02:45:44.508486 11512 layer_factory.hpp:77] Creating layer norm2
I0205 02:45:44.508493 11512 net.cpp:106] Creating Layer norm2
I0205 02:45:44.508499 11512 net.cpp:454] norm2 <- pool2
I0205 02:45:44.508507 11512 net.cpp:411] norm2 -> norm2
I0205 02:45:44.508518 11512 net.cpp:150] Setting up norm2
I0205 02:45:44.508527 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508532 11512 net.cpp:165] Memory required for data: 139704000
I0205 02:45:44.508536 11512 layer_factory.hpp:77] Creating layer conv3
I0205 02:45:44.508548 11512 net.cpp:106] Creating Layer conv3
I0205 02:45:44.508553 11512 net.cpp:454] conv3 <- norm2
I0205 02:45:44.508561 11512 net.cpp:411] conv3 -> conv3
I0205 02:45:44.508661 11512 net.cpp:150] Setting up conv3
I0205 02:45:44.508669 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508676 11512 net.cpp:165] Memory required for data: 141867200
I0205 02:45:44.508685 11512 layer_factory.hpp:77] Creating layer relu3
I0205 02:45:44.508694 11512 net.cpp:106] Creating Layer relu3
I0205 02:45:44.508699 11512 net.cpp:454] relu3 <- conv3
I0205 02:45:44.508708 11512 net.cpp:397] relu3 -> conv3 (in-place)
I0205 02:45:44.508718 11512 net.cpp:150] Setting up relu3
I0205 02:45:44.508724 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508729 11512 net.cpp:165] Memory required for data: 144030400
I0205 02:45:44.508735 11512 layer_factory.hpp:77] Creating layer conv4
I0205 02:45:44.508745 11512 net.cpp:106] Creating Layer conv4
I0205 02:45:44.508751 11512 net.cpp:454] conv4 <- conv3
I0205 02:45:44.508760 11512 net.cpp:411] conv4 -> conv4
I0205 02:45:44.508821 11512 net.cpp:150] Setting up conv4
I0205 02:45:44.508831 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508837 11512 net.cpp:165] Memory required for data: 146193600
I0205 02:45:44.508846 11512 layer_factory.hpp:77] Creating layer relu4
I0205 02:45:44.508853 11512 net.cpp:106] Creating Layer relu4
I0205 02:45:44.508859 11512 net.cpp:454] relu4 <- conv4
I0205 02:45:44.508867 11512 net.cpp:397] relu4 -> conv4 (in-place)
I0205 02:45:44.508875 11512 net.cpp:150] Setting up relu4
I0205 02:45:44.508882 11512 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0205 02:45:44.508888 11512 net.cpp:165] Memory required for data: 148356800
I0205 02:45:44.508893 11512 layer_factory.hpp:77] Creating layer conv5
I0205 02:45:44.508903 11512 net.cpp:106] Creating Layer conv5
I0205 02:45:44.508908 11512 net.cpp:454] conv5 <- conv4
I0205 02:45:44.508918 11512 net.cpp:411] conv5 -> conv5
I0205 02:45:44.508957 11512 net.cpp:150] Setting up conv5
I0205 02:45:44.508965 11512 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 02:45:44.508971 11512 net.cpp:165] Memory required for data: 149438400
I0205 02:45:44.508981 11512 layer_factory.hpp:77] Creating layer relu5
I0205 02:45:44.508991 11512 net.cpp:106] Creating Layer relu5
I0205 02:45:44.508998 11512 net.cpp:454] relu5 <- conv5
I0205 02:45:44.509006 11512 net.cpp:397] relu5 -> conv5 (in-place)
I0205 02:45:44.509014 11512 net.cpp:150] Setting up relu5
I0205 02:45:44.509021 11512 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0205 02:45:44.509027 11512 net.cpp:165] Memory required for data: 150520000
I0205 02:45:44.509032 11512 layer_factory.hpp:77] Creating layer pool5
I0205 02:45:44.509042 11512 net.cpp:106] Creating Layer pool5
I0205 02:45:44.509052 11512 net.cpp:454] pool5 <- conv5
I0205 02:45:44.509070 11512 net.cpp:411] pool5 -> pool5
I0205 02:45:44.509083 11512 net.cpp:150] Setting up pool5
I0205 02:45:44.509094 11512 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0205 02:45:44.509100 11512 net.cpp:165] Memory required for data: 150750400
I0205 02:45:44.509109 11512 layer_factory.hpp:77] Creating layer fc6
I0205 02:45:44.509120 11512 net.cpp:106] Creating Layer fc6
I0205 02:45:44.509126 11512 net.cpp:454] fc6 <- pool5
I0205 02:45:44.509135 11512 net.cpp:411] fc6 -> fc6
I0205 02:45:44.510810 11512 net.cpp:150] Setting up fc6
I0205 02:45:44.510823 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.510828 11512 net.cpp:165] Memory required for data: 150852800
I0205 02:45:44.510838 11512 layer_factory.hpp:77] Creating layer relu6
I0205 02:45:44.510846 11512 net.cpp:106] Creating Layer relu6
I0205 02:45:44.510853 11512 net.cpp:454] relu6 <- fc6
I0205 02:45:44.510860 11512 net.cpp:397] relu6 -> fc6 (in-place)
I0205 02:45:44.510871 11512 net.cpp:150] Setting up relu6
I0205 02:45:44.510879 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.510884 11512 net.cpp:165] Memory required for data: 150955200
I0205 02:45:44.510890 11512 layer_factory.hpp:77] Creating layer drop6
I0205 02:45:44.510900 11512 net.cpp:106] Creating Layer drop6
I0205 02:45:44.510905 11512 net.cpp:454] drop6 <- fc6
I0205 02:45:44.510913 11512 net.cpp:397] drop6 -> fc6 (in-place)
I0205 02:45:44.510924 11512 net.cpp:150] Setting up drop6
I0205 02:45:44.510934 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.510941 11512 net.cpp:165] Memory required for data: 151057600
I0205 02:45:44.510946 11512 layer_factory.hpp:77] Creating layer fc7
I0205 02:45:44.510956 11512 net.cpp:106] Creating Layer fc7
I0205 02:45:44.510962 11512 net.cpp:454] fc7 <- fc6
I0205 02:45:44.510969 11512 net.cpp:411] fc7 -> fc7
I0205 02:45:44.511692 11512 net.cpp:150] Setting up fc7
I0205 02:45:44.511703 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.511708 11512 net.cpp:165] Memory required for data: 151160000
I0205 02:45:44.511716 11512 layer_factory.hpp:77] Creating layer relu7
I0205 02:45:44.511724 11512 net.cpp:106] Creating Layer relu7
I0205 02:45:44.511730 11512 net.cpp:454] relu7 <- fc7
I0205 02:45:44.511760 11512 net.cpp:397] relu7 -> fc7 (in-place)
I0205 02:45:44.511770 11512 net.cpp:150] Setting up relu7
I0205 02:45:44.511777 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.511783 11512 net.cpp:165] Memory required for data: 151262400
I0205 02:45:44.511788 11512 layer_factory.hpp:77] Creating layer drop7
I0205 02:45:44.511797 11512 net.cpp:106] Creating Layer drop7
I0205 02:45:44.511802 11512 net.cpp:454] drop7 <- fc7
I0205 02:45:44.511812 11512 net.cpp:397] drop7 -> fc7 (in-place)
I0205 02:45:44.511822 11512 net.cpp:150] Setting up drop7
I0205 02:45:44.511831 11512 net.cpp:157] Top shape: 100 256 (25600)
I0205 02:45:44.511837 11512 net.cpp:165] Memory required for data: 151364800
I0205 02:45:44.511842 11512 layer_factory.hpp:77] Creating layer fc8
I0205 02:45:44.511852 11512 net.cpp:106] Creating Layer fc8
I0205 02:45:44.511857 11512 net.cpp:454] fc8 <- fc7
I0205 02:45:44.511864 11512 net.cpp:411] fc8 -> fc8
I0205 02:45:44.511904 11512 net.cpp:150] Setting up fc8
I0205 02:45:44.511914 11512 net.cpp:157] Top shape: 100 2 (200)
I0205 02:45:44.511919 11512 net.cpp:165] Memory required for data: 151365600
I0205 02:45:44.511926 11512 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0205 02:45:44.511937 11512 net.cpp:106] Creating Layer fc8_fc8_0_split
I0205 02:45:44.511943 11512 net.cpp:454] fc8_fc8_0_split <- fc8
I0205 02:45:44.511953 11512 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0205 02:45:44.511965 11512 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0205 02:45:44.511975 11512 net.cpp:150] Setting up fc8_fc8_0_split
I0205 02:45:44.511981 11512 net.cpp:157] Top shape: 100 2 (200)
I0205 02:45:44.511989 11512 net.cpp:157] Top shape: 100 2 (200)
I0205 02:45:44.511996 11512 net.cpp:165] Memory required for data: 151367200
I0205 02:45:44.512001 11512 layer_factory.hpp:77] Creating layer accuracy
I0205 02:45:44.512025 11512 net.cpp:106] Creating Layer accuracy
I0205 02:45:44.512032 11512 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0205 02:45:44.512039 11512 net.cpp:454] accuracy <- label_data_1_split_0
I0205 02:45:44.512047 11512 net.cpp:411] accuracy -> accuracy
I0205 02:45:44.512074 11512 net.cpp:150] Setting up accuracy
I0205 02:45:44.512082 11512 net.cpp:157] Top shape: (1)
I0205 02:45:44.512087 11512 net.cpp:165] Memory required for data: 151367204
I0205 02:45:44.512099 11512 layer_factory.hpp:77] Creating layer loss
I0205 02:45:44.512114 11512 net.cpp:106] Creating Layer loss
I0205 02:45:44.512120 11512 net.cpp:454] loss <- fc8_fc8_0_split_1
I0205 02:45:44.512126 11512 net.cpp:454] loss <- label_data_1_split_1
I0205 02:45:44.512135 11512 net.cpp:411] loss -> loss
I0205 02:45:44.512148 11512 layer_factory.hpp:77] Creating layer loss
I0205 02:45:44.512171 11512 net.cpp:150] Setting up loss
I0205 02:45:44.512177 11512 net.cpp:157] Top shape: (1)
I0205 02:45:44.512183 11512 net.cpp:160]     with loss weight 1
I0205 02:45:44.512198 11512 net.cpp:165] Memory required for data: 151367208
I0205 02:45:44.512204 11512 net.cpp:226] loss needs backward computation.
I0205 02:45:44.512210 11512 net.cpp:228] accuracy does not need backward computation.
I0205 02:45:44.512217 11512 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0205 02:45:44.512225 11512 net.cpp:226] fc8 needs backward computation.
I0205 02:45:44.512231 11512 net.cpp:226] drop7 needs backward computation.
I0205 02:45:44.512236 11512 net.cpp:226] relu7 needs backward computation.
I0205 02:45:44.512243 11512 net.cpp:226] fc7 needs backward computation.
I0205 02:45:44.512248 11512 net.cpp:226] drop6 needs backward computation.
I0205 02:45:44.512253 11512 net.cpp:226] relu6 needs backward computation.
I0205 02:45:44.512259 11512 net.cpp:226] fc6 needs backward computation.
I0205 02:45:44.512264 11512 net.cpp:226] pool5 needs backward computation.
I0205 02:45:44.512269 11512 net.cpp:226] relu5 needs backward computation.
I0205 02:45:44.512275 11512 net.cpp:226] conv5 needs backward computation.
I0205 02:45:44.512280 11512 net.cpp:226] relu4 needs backward computation.
I0205 02:45:44.512286 11512 net.cpp:226] conv4 needs backward computation.
I0205 02:45:44.512291 11512 net.cpp:226] relu3 needs backward computation.
I0205 02:45:44.512297 11512 net.cpp:226] conv3 needs backward computation.
I0205 02:45:44.512303 11512 net.cpp:226] norm2 needs backward computation.
I0205 02:45:44.512312 11512 net.cpp:226] pool2 needs backward computation.
I0205 02:45:44.512317 11512 net.cpp:226] relu2 needs backward computation.
I0205 02:45:44.512323 11512 net.cpp:226] conv2 needs backward computation.
I0205 02:45:44.512329 11512 net.cpp:226] norm1 needs backward computation.
I0205 02:45:44.512334 11512 net.cpp:226] pool1 needs backward computation.
I0205 02:45:44.512341 11512 net.cpp:226] relu1 needs backward computation.
I0205 02:45:44.512346 11512 net.cpp:226] conv1 needs backward computation.
I0205 02:45:44.512352 11512 net.cpp:228] label_data_1_split does not need backward computation.
I0205 02:45:44.512359 11512 net.cpp:228] data does not need backward computation.
I0205 02:45:44.512367 11512 net.cpp:270] This network produces output accuracy
I0205 02:45:44.512373 11512 net.cpp:270] This network produces output loss
I0205 02:45:44.512403 11512 net.cpp:283] Network initialization done.
I0205 02:45:44.512516 11512 solver.cpp:60] Solver scaffolding done.
I0205 02:45:44.512576 11512 caffe.cpp:212] Starting Optimization
I0205 02:45:44.512583 11512 solver.cpp:288] Solving CaffeNet
I0205 02:45:44.512589 11512 solver.cpp:289] Learning Rate Policy: step
I0205 02:45:44.513504 11512 solver.cpp:341] Iteration 0, Testing net (#0)
I0205 02:45:44.513629 11512 blocking_queue.cpp:50] Data layer prefetch queue empty
I0205 02:45:51.756801 11512 solver.cpp:409]     Test net output #0: accuracy = 0.536
I0205 02:45:51.756872 11512 solver.cpp:409]     Test net output #1: loss = 1.6838 (* 1 = 1.6838 loss)
I0205 02:45:53.386915 11512 solver.cpp:237] Iteration 0, loss = 8.54434
I0205 02:45:53.386991 11512 solver.cpp:253]     Train net output #0: loss = 8.54434 (* 1 = 8.54434 loss)
I0205 02:45:53.387006 11512 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0205 02:46:10.983264 11512 solver.cpp:237] Iteration 10, loss = 1.32019
I0205 02:46:10.983340 11512 solver.cpp:253]     Train net output #0: loss = 1.32019 (* 1 = 1.32019 loss)
I0205 02:46:10.983352 11512 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0205 02:46:32.981755 11512 solver.cpp:237] Iteration 20, loss = 0.986718
I0205 02:46:32.981894 11512 solver.cpp:253]     Train net output #0: loss = 0.986718 (* 1 = 0.986718 loss)
I0205 02:46:32.981907 11512 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0205 02:46:55.982507 11512 solver.cpp:237] Iteration 30, loss = 0.968885
I0205 02:46:55.982573 11512 solver.cpp:253]     Train net output #0: loss = 0.968886 (* 1 = 0.968886 loss)
I0205 02:46:55.982586 11512 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0205 02:47:18.614404 11512 solver.cpp:237] Iteration 40, loss = 0.877862
I0205 02:47:18.614598 11512 solver.cpp:253]     Train net output #0: loss = 0.877862 (* 1 = 0.877862 loss)
I0205 02:47:18.614614 11512 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0205 02:47:41.551205 11512 solver.cpp:237] Iteration 50, loss = 0.773862
I0205 02:47:41.551270 11512 solver.cpp:253]     Train net output #0: loss = 0.773863 (* 1 = 0.773863 loss)
I0205 02:47:41.551282 11512 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0205 02:48:04.822352 11512 solver.cpp:237] Iteration 60, loss = 0.815573
I0205 02:48:04.822551 11512 solver.cpp:253]     Train net output #0: loss = 0.815573 (* 1 = 0.815573 loss)
I0205 02:48:04.822566 11512 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0205 02:48:28.289948 11512 solver.cpp:237] Iteration 70, loss = 0.705817
I0205 02:48:28.290014 11512 solver.cpp:253]     Train net output #0: loss = 0.705817 (* 1 = 0.705817 loss)
I0205 02:48:28.290027 11512 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0205 02:48:51.654158 11512 solver.cpp:237] Iteration 80, loss = 0.762787
I0205 02:48:51.654364 11512 solver.cpp:253]     Train net output #0: loss = 0.762787 (* 1 = 0.762787 loss)
I0205 02:48:51.654379 11512 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0205 02:49:14.997964 11512 solver.cpp:237] Iteration 90, loss = 0.739928
I0205 02:49:14.998031 11512 solver.cpp:253]     Train net output #0: loss = 0.739929 (* 1 = 0.739929 loss)
I0205 02:49:14.998045 11512 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0205 02:49:35.940870 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_100.caffemodel
I0205 02:49:35.945071 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_100.solverstate
I0205 02:49:35.946485 11512 solver.cpp:341] Iteration 100, Testing net (#0)
I0205 02:49:46.870872 11512 solver.cpp:409]     Test net output #0: accuracy = 0.844
I0205 02:49:46.870929 11512 solver.cpp:409]     Test net output #1: loss = 0.529914 (* 1 = 0.529914 loss)
I0205 02:49:49.205375 11512 solver.cpp:237] Iteration 100, loss = 0.639485
I0205 02:49:49.205435 11512 solver.cpp:253]     Train net output #0: loss = 0.639485 (* 1 = 0.639485 loss)
I0205 02:49:49.205449 11512 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0205 02:50:11.975347 11512 solver.cpp:237] Iteration 110, loss = 0.619852
I0205 02:50:11.975533 11512 solver.cpp:253]     Train net output #0: loss = 0.619852 (* 1 = 0.619852 loss)
I0205 02:50:11.975548 11512 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0205 02:50:34.538269 11512 solver.cpp:237] Iteration 120, loss = 0.495312
I0205 02:50:34.538332 11512 solver.cpp:253]     Train net output #0: loss = 0.495312 (* 1 = 0.495312 loss)
I0205 02:50:34.538346 11512 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0205 02:50:57.463824 11512 solver.cpp:237] Iteration 130, loss = 0.442572
I0205 02:50:57.464046 11512 solver.cpp:253]     Train net output #0: loss = 0.442572 (* 1 = 0.442572 loss)
I0205 02:50:57.464066 11512 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0205 02:51:20.702560 11512 solver.cpp:237] Iteration 140, loss = 0.250867
I0205 02:51:20.702628 11512 solver.cpp:253]     Train net output #0: loss = 0.250868 (* 1 = 0.250868 loss)
I0205 02:51:20.702641 11512 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0205 02:51:44.147941 11512 solver.cpp:237] Iteration 150, loss = 0.195768
I0205 02:51:44.148144 11512 solver.cpp:253]     Train net output #0: loss = 0.195769 (* 1 = 0.195769 loss)
I0205 02:51:44.148159 11512 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0205 02:52:07.569640 11512 solver.cpp:237] Iteration 160, loss = 0.225687
I0205 02:52:07.569707 11512 solver.cpp:253]     Train net output #0: loss = 0.225687 (* 1 = 0.225687 loss)
I0205 02:52:07.569720 11512 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0205 02:52:31.103823 11512 solver.cpp:237] Iteration 170, loss = 0.174218
I0205 02:52:31.104032 11512 solver.cpp:253]     Train net output #0: loss = 0.174218 (* 1 = 0.174218 loss)
I0205 02:52:31.104046 11512 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0205 02:52:54.745967 11512 solver.cpp:237] Iteration 180, loss = 0.144715
I0205 02:52:54.746037 11512 solver.cpp:253]     Train net output #0: loss = 0.144715 (* 1 = 0.144715 loss)
I0205 02:52:54.746050 11512 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0205 02:53:18.064379 11512 solver.cpp:237] Iteration 190, loss = 0.12997
I0205 02:53:18.064570 11512 solver.cpp:253]     Train net output #0: loss = 0.12997 (* 1 = 0.12997 loss)
I0205 02:53:18.064585 11512 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0205 02:53:38.655614 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_200.caffemodel
I0205 02:53:38.659206 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_200.solverstate
I0205 02:53:38.660603 11512 solver.cpp:341] Iteration 200, Testing net (#0)
I0205 02:53:49.376766 11512 solver.cpp:409]     Test net output #0: accuracy = 0.993
I0205 02:53:49.376957 11512 solver.cpp:409]     Test net output #1: loss = 0.0349079 (* 1 = 0.0349079 loss)
I0205 02:53:51.650985 11512 solver.cpp:237] Iteration 200, loss = 0.0802028
I0205 02:53:51.651042 11512 solver.cpp:253]     Train net output #0: loss = 0.080203 (* 1 = 0.080203 loss)
I0205 02:53:51.651056 11512 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0205 02:54:14.269495 11512 solver.cpp:237] Iteration 210, loss = 0.124713
I0205 02:54:14.269553 11512 solver.cpp:253]     Train net output #0: loss = 0.124713 (* 1 = 0.124713 loss)
I0205 02:54:14.269567 11512 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0205 02:54:36.830668 11512 solver.cpp:237] Iteration 220, loss = 0.0952139
I0205 02:54:36.830840 11512 solver.cpp:253]     Train net output #0: loss = 0.0952142 (* 1 = 0.0952142 loss)
I0205 02:54:36.830857 11512 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0205 02:54:59.491966 11512 solver.cpp:237] Iteration 230, loss = 0.0283933
I0205 02:54:59.492029 11512 solver.cpp:253]     Train net output #0: loss = 0.0283936 (* 1 = 0.0283936 loss)
I0205 02:54:59.492041 11512 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0205 02:55:21.716800 11512 solver.cpp:237] Iteration 240, loss = 0.0821361
I0205 02:55:21.716997 11512 solver.cpp:253]     Train net output #0: loss = 0.0821363 (* 1 = 0.0821363 loss)
I0205 02:55:21.717012 11512 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0205 02:55:43.309365 11512 solver.cpp:237] Iteration 250, loss = 0.0740629
I0205 02:55:43.309432 11512 solver.cpp:253]     Train net output #0: loss = 0.0740632 (* 1 = 0.0740632 loss)
I0205 02:55:43.309444 11512 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0205 02:56:03.910696 11512 solver.cpp:237] Iteration 260, loss = 0.0609228
I0205 02:56:03.910909 11512 solver.cpp:253]     Train net output #0: loss = 0.060923 (* 1 = 0.060923 loss)
I0205 02:56:03.910936 11512 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0205 02:56:24.286695 11512 solver.cpp:237] Iteration 270, loss = 0.0414211
I0205 02:56:24.286756 11512 solver.cpp:253]     Train net output #0: loss = 0.0414214 (* 1 = 0.0414214 loss)
I0205 02:56:24.286769 11512 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0205 02:56:44.849192 11512 solver.cpp:237] Iteration 280, loss = 0.0517002
I0205 02:56:44.849395 11512 solver.cpp:253]     Train net output #0: loss = 0.0517005 (* 1 = 0.0517005 loss)
I0205 02:56:44.849409 11512 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0205 02:57:05.687348 11512 solver.cpp:237] Iteration 290, loss = 0.113151
I0205 02:57:05.687414 11512 solver.cpp:253]     Train net output #0: loss = 0.113152 (* 1 = 0.113152 loss)
I0205 02:57:05.687427 11512 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0205 02:57:24.517951 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_300.caffemodel
I0205 02:57:25.045702 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_300.solverstate
I0205 02:57:25.047353 11512 solver.cpp:341] Iteration 300, Testing net (#0)
I0205 02:57:34.844112 11512 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0205 02:57:34.844172 11512 solver.cpp:409]     Test net output #1: loss = 0.0143839 (* 1 = 0.0143839 loss)
I0205 02:57:36.958962 11512 solver.cpp:237] Iteration 300, loss = 0.0188328
I0205 02:57:36.959018 11512 solver.cpp:253]     Train net output #0: loss = 0.0188331 (* 1 = 0.0188331 loss)
I0205 02:57:36.959031 11512 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0205 02:57:57.960968 11512 solver.cpp:237] Iteration 310, loss = 0.0147874
I0205 02:57:57.961164 11512 solver.cpp:253]     Train net output #0: loss = 0.0147876 (* 1 = 0.0147876 loss)
I0205 02:57:57.961179 11512 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0205 02:58:18.829732 11512 solver.cpp:237] Iteration 320, loss = 0.00780205
I0205 02:58:18.829797 11512 solver.cpp:253]     Train net output #0: loss = 0.00780232 (* 1 = 0.00780232 loss)
I0205 02:58:18.829810 11512 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0205 02:58:39.436835 11512 solver.cpp:237] Iteration 330, loss = 0.0622035
I0205 02:58:39.437032 11512 solver.cpp:253]     Train net output #0: loss = 0.0622038 (* 1 = 0.0622038 loss)
I0205 02:58:39.437047 11512 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0205 02:58:59.804071 11512 solver.cpp:237] Iteration 340, loss = 0.0126209
I0205 02:58:59.804136 11512 solver.cpp:253]     Train net output #0: loss = 0.0126211 (* 1 = 0.0126211 loss)
I0205 02:58:59.804148 11512 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0205 02:59:20.297549 11512 solver.cpp:237] Iteration 350, loss = 0.0102118
I0205 02:59:20.297734 11512 solver.cpp:253]     Train net output #0: loss = 0.0102121 (* 1 = 0.0102121 loss)
I0205 02:59:20.297749 11512 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0205 02:59:40.799423 11512 solver.cpp:237] Iteration 360, loss = 0.0365834
I0205 02:59:40.799487 11512 solver.cpp:253]     Train net output #0: loss = 0.0365836 (* 1 = 0.0365836 loss)
I0205 02:59:40.799500 11512 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0205 03:00:01.199295 11512 solver.cpp:237] Iteration 370, loss = 0.040962
I0205 03:00:01.199491 11512 solver.cpp:253]     Train net output #0: loss = 0.0409623 (* 1 = 0.0409623 loss)
I0205 03:00:01.199506 11512 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0205 03:00:21.679802 11512 solver.cpp:237] Iteration 380, loss = 0.0666615
I0205 03:00:21.679873 11512 solver.cpp:253]     Train net output #0: loss = 0.0666618 (* 1 = 0.0666618 loss)
I0205 03:00:21.679886 11512 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0205 03:00:42.077354 11512 solver.cpp:237] Iteration 390, loss = 0.0154441
I0205 03:00:42.077561 11512 solver.cpp:253]     Train net output #0: loss = 0.0154444 (* 1 = 0.0154444 loss)
I0205 03:00:42.077581 11512 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0205 03:01:00.358603 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_400.caffemodel
I0205 03:01:00.362174 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_400.solverstate
I0205 03:01:00.363548 11512 solver.cpp:341] Iteration 400, Testing net (#0)
I0205 03:01:09.625625 11512 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0205 03:01:09.625684 11512 solver.cpp:409]     Test net output #1: loss = 0.0144416 (* 1 = 0.0144416 loss)
I0205 03:01:11.620164 11512 solver.cpp:237] Iteration 400, loss = 0.0370685
I0205 03:01:11.620215 11512 solver.cpp:253]     Train net output #0: loss = 0.0370688 (* 1 = 0.0370688 loss)
I0205 03:01:11.620228 11512 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0205 03:01:31.306763 11512 solver.cpp:237] Iteration 410, loss = 0.00767659
I0205 03:01:31.306965 11512 solver.cpp:253]     Train net output #0: loss = 0.00767685 (* 1 = 0.00767685 loss)
I0205 03:01:31.306980 11512 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0205 03:01:50.907544 11512 solver.cpp:237] Iteration 420, loss = 0.00642069
I0205 03:01:50.907606 11512 solver.cpp:253]     Train net output #0: loss = 0.00642095 (* 1 = 0.00642095 loss)
I0205 03:01:50.907618 11512 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0205 03:02:10.601562 11512 solver.cpp:237] Iteration 430, loss = 0.0249983
I0205 03:02:10.601748 11512 solver.cpp:253]     Train net output #0: loss = 0.0249985 (* 1 = 0.0249985 loss)
I0205 03:02:10.601763 11512 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0205 03:02:30.588423 11512 solver.cpp:237] Iteration 440, loss = 0.00619066
I0205 03:02:30.588487 11512 solver.cpp:253]     Train net output #0: loss = 0.00619093 (* 1 = 0.00619093 loss)
I0205 03:02:30.588500 11512 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0205 03:02:50.725486 11512 solver.cpp:237] Iteration 450, loss = 0.00657237
I0205 03:02:50.725836 11512 solver.cpp:253]     Train net output #0: loss = 0.00657263 (* 1 = 0.00657263 loss)
I0205 03:02:50.725850 11512 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0205 03:03:10.862452 11512 solver.cpp:237] Iteration 460, loss = 0.0234766
I0205 03:03:10.862515 11512 solver.cpp:253]     Train net output #0: loss = 0.0234769 (* 1 = 0.0234769 loss)
I0205 03:03:10.862529 11512 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0205 03:03:30.883828 11512 solver.cpp:237] Iteration 470, loss = 0.00523055
I0205 03:03:30.884003 11512 solver.cpp:253]     Train net output #0: loss = 0.00523081 (* 1 = 0.00523081 loss)
I0205 03:03:30.884018 11512 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0205 03:03:51.059849 11512 solver.cpp:237] Iteration 480, loss = 0.0840857
I0205 03:03:51.059937 11512 solver.cpp:253]     Train net output #0: loss = 0.084086 (* 1 = 0.084086 loss)
I0205 03:03:51.059952 11512 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0205 03:04:11.295405 11512 solver.cpp:237] Iteration 490, loss = 0.0149661
I0205 03:04:11.295621 11512 solver.cpp:253]     Train net output #0: loss = 0.0149663 (* 1 = 0.0149663 loss)
I0205 03:04:11.295639 11512 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0205 03:04:30.166244 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_500.caffemodel
I0205 03:04:30.170112 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_500.solverstate
I0205 03:04:30.171720 11512 solver.cpp:341] Iteration 500, Testing net (#0)
I0205 03:04:40.111696 11512 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 03:04:40.111765 11512 solver.cpp:409]     Test net output #1: loss = 0.00651762 (* 1 = 0.00651762 loss)
I0205 03:04:42.199028 11512 solver.cpp:237] Iteration 500, loss = 0.0194155
I0205 03:04:42.199280 11512 solver.cpp:253]     Train net output #0: loss = 0.0194158 (* 1 = 0.0194158 loss)
I0205 03:04:42.199297 11512 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0205 03:05:02.993432 11512 solver.cpp:237] Iteration 510, loss = 0.00721211
I0205 03:05:02.993507 11512 solver.cpp:253]     Train net output #0: loss = 0.00721237 (* 1 = 0.00721237 loss)
I0205 03:05:02.993520 11512 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0205 03:05:23.504092 11512 solver.cpp:237] Iteration 520, loss = 0.00156488
I0205 03:05:23.504312 11512 solver.cpp:253]     Train net output #0: loss = 0.00156513 (* 1 = 0.00156513 loss)
I0205 03:05:23.504328 11512 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0205 03:05:43.931593 11512 solver.cpp:237] Iteration 530, loss = 0.00578571
I0205 03:05:43.931663 11512 solver.cpp:253]     Train net output #0: loss = 0.00578596 (* 1 = 0.00578596 loss)
I0205 03:05:43.931675 11512 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0205 03:06:04.368944 11512 solver.cpp:237] Iteration 540, loss = 0.00593801
I0205 03:06:04.369168 11512 solver.cpp:253]     Train net output #0: loss = 0.00593827 (* 1 = 0.00593827 loss)
I0205 03:06:04.369184 11512 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0205 03:06:24.675876 11512 solver.cpp:237] Iteration 550, loss = 0.00140621
I0205 03:06:24.675948 11512 solver.cpp:253]     Train net output #0: loss = 0.00140647 (* 1 = 0.00140647 loss)
I0205 03:06:24.675961 11512 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0205 03:06:44.812698 11512 solver.cpp:237] Iteration 560, loss = 0.00216537
I0205 03:06:44.812899 11512 solver.cpp:253]     Train net output #0: loss = 0.00216564 (* 1 = 0.00216564 loss)
I0205 03:06:44.812914 11512 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0205 03:07:04.492799 11512 solver.cpp:237] Iteration 570, loss = 0.00227384
I0205 03:07:04.492866 11512 solver.cpp:253]     Train net output #0: loss = 0.00227411 (* 1 = 0.00227411 loss)
I0205 03:07:04.492878 11512 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0205 03:07:24.142309 11512 solver.cpp:237] Iteration 580, loss = 0.0583482
I0205 03:07:24.142537 11512 solver.cpp:253]     Train net output #0: loss = 0.0583484 (* 1 = 0.0583484 loss)
I0205 03:07:24.142554 11512 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0205 03:07:44.396082 11512 solver.cpp:237] Iteration 590, loss = 0.00573625
I0205 03:07:44.396162 11512 solver.cpp:253]     Train net output #0: loss = 0.00573653 (* 1 = 0.00573653 loss)
I0205 03:07:44.396174 11512 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0205 03:08:03.388118 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_600.caffemodel
I0205 03:08:03.391927 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_600.solverstate
I0205 03:08:03.393318 11512 solver.cpp:341] Iteration 600, Testing net (#0)
I0205 03:08:13.294637 11512 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0205 03:08:13.294698 11512 solver.cpp:409]     Test net output #1: loss = 0.0227065 (* 1 = 0.0227065 loss)
I0205 03:08:15.390353 11512 solver.cpp:237] Iteration 600, loss = 0.0597534
I0205 03:08:15.390410 11512 solver.cpp:253]     Train net output #0: loss = 0.0597537 (* 1 = 0.0597537 loss)
I0205 03:08:15.390424 11512 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0205 03:08:36.880059 11512 solver.cpp:237] Iteration 610, loss = 0.0166567
I0205 03:08:36.880260 11512 solver.cpp:253]     Train net output #0: loss = 0.016657 (* 1 = 0.016657 loss)
I0205 03:08:36.880276 11512 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0205 03:08:58.604495 11512 solver.cpp:237] Iteration 620, loss = 0.021351
I0205 03:08:58.604557 11512 solver.cpp:253]     Train net output #0: loss = 0.0213513 (* 1 = 0.0213513 loss)
I0205 03:08:58.604569 11512 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0205 03:09:20.399536 11512 solver.cpp:237] Iteration 630, loss = 0.00187621
I0205 03:09:20.399768 11512 solver.cpp:253]     Train net output #0: loss = 0.00187648 (* 1 = 0.00187648 loss)
I0205 03:09:20.399785 11512 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0205 03:09:42.130311 11512 solver.cpp:237] Iteration 640, loss = 0.00157569
I0205 03:09:42.130378 11512 solver.cpp:253]     Train net output #0: loss = 0.00157596 (* 1 = 0.00157596 loss)
I0205 03:09:42.130390 11512 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0205 03:10:03.593783 11512 solver.cpp:237] Iteration 650, loss = 0.0290632
I0205 03:10:03.593971 11512 solver.cpp:253]     Train net output #0: loss = 0.0290634 (* 1 = 0.0290634 loss)
I0205 03:10:03.593986 11512 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0205 03:10:24.817946 11512 solver.cpp:237] Iteration 660, loss = 0.00221147
I0205 03:10:24.818009 11512 solver.cpp:253]     Train net output #0: loss = 0.00221174 (* 1 = 0.00221174 loss)
I0205 03:10:24.818022 11512 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0205 03:10:45.726707 11512 solver.cpp:237] Iteration 670, loss = 0.0255474
I0205 03:10:45.726897 11512 solver.cpp:253]     Train net output #0: loss = 0.0255477 (* 1 = 0.0255477 loss)
I0205 03:10:45.726912 11512 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0205 03:11:06.265529 11512 solver.cpp:237] Iteration 680, loss = 0.00142684
I0205 03:11:06.265594 11512 solver.cpp:253]     Train net output #0: loss = 0.0014271 (* 1 = 0.0014271 loss)
I0205 03:11:06.265606 11512 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0205 03:11:26.986229 11512 solver.cpp:237] Iteration 690, loss = 0.00530165
I0205 03:11:26.986415 11512 solver.cpp:253]     Train net output #0: loss = 0.00530191 (* 1 = 0.00530191 loss)
I0205 03:11:26.986430 11512 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0205 03:11:45.711588 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_700.caffemodel
I0205 03:11:45.715148 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_700.solverstate
I0205 03:11:45.716542 11512 solver.cpp:341] Iteration 700, Testing net (#0)
I0205 03:11:55.221508 11512 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0205 03:11:55.221566 11512 solver.cpp:409]     Test net output #1: loss = 0.0147512 (* 1 = 0.0147512 loss)
I0205 03:11:57.277498 11512 solver.cpp:237] Iteration 700, loss = 0.00149228
I0205 03:11:57.277678 11512 solver.cpp:253]     Train net output #0: loss = 0.00149255 (* 1 = 0.00149255 loss)
I0205 03:11:57.277693 11512 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0205 03:12:18.120029 11512 solver.cpp:237] Iteration 710, loss = 0.00769844
I0205 03:12:18.120092 11512 solver.cpp:253]     Train net output #0: loss = 0.0076987 (* 1 = 0.0076987 loss)
I0205 03:12:18.120105 11512 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0205 03:12:38.734313 11512 solver.cpp:237] Iteration 720, loss = 0.0111251
I0205 03:12:38.734488 11512 solver.cpp:253]     Train net output #0: loss = 0.0111254 (* 1 = 0.0111254 loss)
I0205 03:12:38.734503 11512 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0205 03:12:59.131546 11512 solver.cpp:237] Iteration 730, loss = 0.00571876
I0205 03:12:59.131610 11512 solver.cpp:253]     Train net output #0: loss = 0.00571902 (* 1 = 0.00571902 loss)
I0205 03:12:59.131621 11512 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0205 03:13:19.973812 11512 solver.cpp:237] Iteration 740, loss = 0.000965618
I0205 03:13:19.973997 11512 solver.cpp:253]     Train net output #0: loss = 0.000965877 (* 1 = 0.000965877 loss)
I0205 03:13:19.974011 11512 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0205 03:13:41.070030 11512 solver.cpp:237] Iteration 750, loss = 0.0191651
I0205 03:13:41.070096 11512 solver.cpp:253]     Train net output #0: loss = 0.0191654 (* 1 = 0.0191654 loss)
I0205 03:13:41.070123 11512 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0205 03:14:02.309551 11512 solver.cpp:237] Iteration 760, loss = 0.0175927
I0205 03:14:02.309773 11512 solver.cpp:253]     Train net output #0: loss = 0.0175929 (* 1 = 0.0175929 loss)
I0205 03:14:02.309788 11512 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0205 03:14:23.170495 11512 solver.cpp:237] Iteration 770, loss = 0.0592388
I0205 03:14:23.170560 11512 solver.cpp:253]     Train net output #0: loss = 0.059239 (* 1 = 0.059239 loss)
I0205 03:14:23.170572 11512 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0205 03:14:43.933346 11512 solver.cpp:237] Iteration 780, loss = 0.0304144
I0205 03:14:43.933524 11512 solver.cpp:253]     Train net output #0: loss = 0.0304147 (* 1 = 0.0304147 loss)
I0205 03:14:43.933538 11512 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0205 03:15:04.846256 11512 solver.cpp:237] Iteration 790, loss = 0.00205112
I0205 03:15:04.846318 11512 solver.cpp:253]     Train net output #0: loss = 0.00205137 (* 1 = 0.00205137 loss)
I0205 03:15:04.846329 11512 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0205 03:15:23.903223 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_800.caffemodel
I0205 03:15:23.906961 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_800.solverstate
I0205 03:15:23.908359 11512 solver.cpp:341] Iteration 800, Testing net (#0)
I0205 03:15:33.838551 11512 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 03:15:33.838609 11512 solver.cpp:409]     Test net output #1: loss = 0.0111889 (* 1 = 0.0111889 loss)
I0205 03:15:35.937232 11512 solver.cpp:237] Iteration 800, loss = 0.00082781
I0205 03:15:35.937280 11512 solver.cpp:253]     Train net output #0: loss = 0.000828059 (* 1 = 0.000828059 loss)
I0205 03:15:35.937293 11512 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0205 03:15:57.136559 11512 solver.cpp:237] Iteration 810, loss = 0.0419812
I0205 03:15:57.136750 11512 solver.cpp:253]     Train net output #0: loss = 0.0419814 (* 1 = 0.0419814 loss)
I0205 03:15:57.136765 11512 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0205 03:16:18.590936 11512 solver.cpp:237] Iteration 820, loss = 0.00174294
I0205 03:16:18.591001 11512 solver.cpp:253]     Train net output #0: loss = 0.0017432 (* 1 = 0.0017432 loss)
I0205 03:16:18.591014 11512 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0205 03:16:39.973690 11512 solver.cpp:237] Iteration 830, loss = 0.0255602
I0205 03:16:39.973871 11512 solver.cpp:253]     Train net output #0: loss = 0.0255605 (* 1 = 0.0255605 loss)
I0205 03:16:39.973886 11512 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0205 03:17:01.587424 11512 solver.cpp:237] Iteration 840, loss = 0.00400625
I0205 03:17:01.587489 11512 solver.cpp:253]     Train net output #0: loss = 0.00400651 (* 1 = 0.00400651 loss)
I0205 03:17:01.587503 11512 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0205 03:17:23.561022 11512 solver.cpp:237] Iteration 850, loss = 0.0381988
I0205 03:17:23.561213 11512 solver.cpp:253]     Train net output #0: loss = 0.0381991 (* 1 = 0.0381991 loss)
I0205 03:17:23.561226 11512 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0205 03:17:45.432183 11512 solver.cpp:237] Iteration 860, loss = 0.0229031
I0205 03:17:45.432256 11512 solver.cpp:253]     Train net output #0: loss = 0.0229034 (* 1 = 0.0229034 loss)
I0205 03:17:45.432268 11512 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0205 03:18:07.727644 11512 solver.cpp:237] Iteration 870, loss = 0.00210757
I0205 03:18:07.727831 11512 solver.cpp:253]     Train net output #0: loss = 0.00210782 (* 1 = 0.00210782 loss)
I0205 03:18:07.727846 11512 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0205 03:18:29.359818 11512 solver.cpp:237] Iteration 880, loss = 0.00639791
I0205 03:18:29.359884 11512 solver.cpp:253]     Train net output #0: loss = 0.00639816 (* 1 = 0.00639816 loss)
I0205 03:18:29.359910 11512 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0205 03:18:51.114795 11512 solver.cpp:237] Iteration 890, loss = 0.00713533
I0205 03:18:51.115018 11512 solver.cpp:253]     Train net output #0: loss = 0.00713558 (* 1 = 0.00713558 loss)
I0205 03:18:51.115033 11512 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0205 03:19:10.840301 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_900.caffemodel
I0205 03:19:10.844518 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_900.solverstate
I0205 03:19:10.845939 11512 solver.cpp:341] Iteration 900, Testing net (#0)
I0205 03:19:21.148077 11512 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 03:19:21.148267 11512 solver.cpp:409]     Test net output #1: loss = 0.00581024 (* 1 = 0.00581024 loss)
I0205 03:19:23.358036 11512 solver.cpp:237] Iteration 900, loss = 0.0064567
I0205 03:19:23.358108 11512 solver.cpp:253]     Train net output #0: loss = 0.00645695 (* 1 = 0.00645695 loss)
I0205 03:19:23.358120 11512 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0205 03:19:45.126273 11512 solver.cpp:237] Iteration 910, loss = 0.0031549
I0205 03:19:45.126338 11512 solver.cpp:253]     Train net output #0: loss = 0.00315515 (* 1 = 0.00315515 loss)
I0205 03:19:45.126351 11512 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0205 03:20:07.207804 11512 solver.cpp:237] Iteration 920, loss = 0.00153196
I0205 03:20:07.207986 11512 solver.cpp:253]     Train net output #0: loss = 0.00153221 (* 1 = 0.00153221 loss)
I0205 03:20:07.208000 11512 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0205 03:20:29.166424 11512 solver.cpp:237] Iteration 930, loss = 0.00167921
I0205 03:20:29.166488 11512 solver.cpp:253]     Train net output #0: loss = 0.00167945 (* 1 = 0.00167945 loss)
I0205 03:20:29.166501 11512 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0205 03:20:50.982429 11512 solver.cpp:237] Iteration 940, loss = 0.00151668
I0205 03:20:50.982614 11512 solver.cpp:253]     Train net output #0: loss = 0.00151693 (* 1 = 0.00151693 loss)
I0205 03:20:50.982628 11512 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0205 03:21:12.586213 11512 solver.cpp:237] Iteration 950, loss = 0.013286
I0205 03:21:12.586278 11512 solver.cpp:253]     Train net output #0: loss = 0.0132862 (* 1 = 0.0132862 loss)
I0205 03:21:12.586292 11512 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0205 03:21:33.993785 11512 solver.cpp:237] Iteration 960, loss = 0.000419179
I0205 03:21:33.993980 11512 solver.cpp:253]     Train net output #0: loss = 0.000419426 (* 1 = 0.000419426 loss)
I0205 03:21:33.993995 11512 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0205 03:21:55.372467 11512 solver.cpp:237] Iteration 970, loss = 0.0583231
I0205 03:21:55.372532 11512 solver.cpp:253]     Train net output #0: loss = 0.0583233 (* 1 = 0.0583233 loss)
I0205 03:21:55.372545 11512 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0205 03:22:16.659909 11512 solver.cpp:237] Iteration 980, loss = 0.00273593
I0205 03:22:16.660107 11512 solver.cpp:253]     Train net output #0: loss = 0.00273618 (* 1 = 0.00273618 loss)
I0205 03:22:16.660121 11512 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0205 03:22:38.241701 11512 solver.cpp:237] Iteration 990, loss = 0.0278231
I0205 03:22:38.241763 11512 solver.cpp:253]     Train net output #0: loss = 0.0278233 (* 1 = 0.0278233 loss)
I0205 03:22:38.241776 11512 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0205 03:22:57.815986 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1000.caffemodel
I0205 03:22:57.819773 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1000.solverstate
I0205 03:22:57.821169 11512 solver.cpp:341] Iteration 1000, Testing net (#0)
I0205 03:23:07.897440 11512 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 03:23:07.897510 11512 solver.cpp:409]     Test net output #1: loss = 0.00501779 (* 1 = 0.00501779 loss)
I0205 03:23:10.024955 11512 solver.cpp:237] Iteration 1000, loss = 0.00394236
I0205 03:23:10.025025 11512 solver.cpp:253]     Train net output #0: loss = 0.00394261 (* 1 = 0.00394261 loss)
I0205 03:23:10.025038 11512 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0205 03:23:30.929630 11512 solver.cpp:237] Iteration 1010, loss = 0.00378989
I0205 03:23:30.929888 11512 solver.cpp:253]     Train net output #0: loss = 0.00379014 (* 1 = 0.00379014 loss)
I0205 03:23:30.929904 11512 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0205 03:23:51.633457 11512 solver.cpp:237] Iteration 1020, loss = 0.000960376
I0205 03:23:51.633543 11512 solver.cpp:253]     Train net output #0: loss = 0.000960631 (* 1 = 0.000960631 loss)
I0205 03:23:51.633556 11512 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0205 03:24:12.149948 11512 solver.cpp:237] Iteration 1030, loss = 0.00186101
I0205 03:24:12.150187 11512 solver.cpp:253]     Train net output #0: loss = 0.00186127 (* 1 = 0.00186127 loss)
I0205 03:24:12.150203 11512 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0205 03:24:32.333489 11512 solver.cpp:237] Iteration 1040, loss = 0.00498001
I0205 03:24:32.333567 11512 solver.cpp:253]     Train net output #0: loss = 0.00498026 (* 1 = 0.00498026 loss)
I0205 03:24:32.333580 11512 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0205 03:24:52.329797 11512 solver.cpp:237] Iteration 1050, loss = 0.000490991
I0205 03:24:52.330055 11512 solver.cpp:253]     Train net output #0: loss = 0.000491248 (* 1 = 0.000491248 loss)
I0205 03:24:52.330072 11512 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0205 03:25:12.393263 11512 solver.cpp:237] Iteration 1060, loss = 0.0324913
I0205 03:25:12.393345 11512 solver.cpp:253]     Train net output #0: loss = 0.0324916 (* 1 = 0.0324916 loss)
I0205 03:25:12.393358 11512 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0205 03:25:32.771109 11512 solver.cpp:237] Iteration 1070, loss = 0.00561782
I0205 03:25:32.771342 11512 solver.cpp:253]     Train net output #0: loss = 0.00561808 (* 1 = 0.00561808 loss)
I0205 03:25:32.771358 11512 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0205 03:25:53.486997 11512 solver.cpp:237] Iteration 1080, loss = 0.00450359
I0205 03:25:53.487087 11512 solver.cpp:253]     Train net output #0: loss = 0.00450384 (* 1 = 0.00450384 loss)
I0205 03:25:53.487099 11512 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0205 03:26:14.063210 11512 solver.cpp:237] Iteration 1090, loss = 0.00138213
I0205 03:26:14.063432 11512 solver.cpp:253]     Train net output #0: loss = 0.00138238 (* 1 = 0.00138238 loss)
I0205 03:26:14.063451 11512 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0205 03:26:32.753986 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1100.caffemodel
I0205 03:26:32.757580 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1100.solverstate
I0205 03:26:32.758934 11512 solver.cpp:341] Iteration 1100, Testing net (#0)
I0205 03:26:42.256484 11512 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0205 03:26:42.256551 11512 solver.cpp:409]     Test net output #1: loss = 0.0202595 (* 1 = 0.0202595 loss)
I0205 03:26:44.273072 11512 solver.cpp:237] Iteration 1100, loss = 0.0585859
I0205 03:26:44.273581 11512 solver.cpp:253]     Train net output #0: loss = 0.0585862 (* 1 = 0.0585862 loss)
I0205 03:26:44.273607 11512 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0205 03:27:05.313096 11512 solver.cpp:237] Iteration 1110, loss = 0.0167643
I0205 03:27:05.313177 11512 solver.cpp:253]     Train net output #0: loss = 0.0167646 (* 1 = 0.0167646 loss)
I0205 03:27:05.313207 11512 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0205 03:27:26.243470 11512 solver.cpp:237] Iteration 1120, loss = 0.00242756
I0205 03:27:26.243733 11512 solver.cpp:253]     Train net output #0: loss = 0.00242781 (* 1 = 0.00242781 loss)
I0205 03:27:26.243751 11512 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0205 03:27:47.161726 11512 solver.cpp:237] Iteration 1130, loss = 0.00212613
I0205 03:27:47.161803 11512 solver.cpp:253]     Train net output #0: loss = 0.00212639 (* 1 = 0.00212639 loss)
I0205 03:27:47.161818 11512 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0205 03:28:08.388660 11512 solver.cpp:237] Iteration 1140, loss = 0.00362859
I0205 03:28:08.388876 11512 solver.cpp:253]     Train net output #0: loss = 0.00362885 (* 1 = 0.00362885 loss)
I0205 03:28:08.388892 11512 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0205 03:28:29.461583 11512 solver.cpp:237] Iteration 1150, loss = 0.0521884
I0205 03:28:29.461665 11512 solver.cpp:253]     Train net output #0: loss = 0.0521887 (* 1 = 0.0521887 loss)
I0205 03:28:29.461678 11512 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0205 03:28:50.956470 11512 solver.cpp:237] Iteration 1160, loss = 0.00912135
I0205 03:28:50.956681 11512 solver.cpp:253]     Train net output #0: loss = 0.00912161 (* 1 = 0.00912161 loss)
I0205 03:28:50.956697 11512 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0205 03:29:12.600383 11512 solver.cpp:237] Iteration 1170, loss = 0.017542
I0205 03:29:12.600468 11512 solver.cpp:253]     Train net output #0: loss = 0.0175423 (* 1 = 0.0175423 loss)
I0205 03:29:12.600482 11512 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0205 03:29:34.095206 11512 solver.cpp:237] Iteration 1180, loss = 0.000905895
I0205 03:29:34.095440 11512 solver.cpp:253]     Train net output #0: loss = 0.000906157 (* 1 = 0.000906157 loss)
I0205 03:29:34.095456 11512 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0205 03:29:55.282124 11512 solver.cpp:237] Iteration 1190, loss = 0.000261669
I0205 03:29:55.282207 11512 solver.cpp:253]     Train net output #0: loss = 0.000261935 (* 1 = 0.000261935 loss)
I0205 03:29:55.282219 11512 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0205 03:30:15.086099 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1200.caffemodel
I0205 03:30:15.089799 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1200.solverstate
I0205 03:30:15.091179 11512 solver.cpp:341] Iteration 1200, Testing net (#0)
I0205 03:30:25.185366 11512 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0205 03:30:25.185431 11512 solver.cpp:409]     Test net output #1: loss = 0.027173 (* 1 = 0.027173 loss)
I0205 03:30:27.311658 11512 solver.cpp:237] Iteration 1200, loss = 0.00241238
I0205 03:30:27.311736 11512 solver.cpp:253]     Train net output #0: loss = 0.00241262 (* 1 = 0.00241262 loss)
I0205 03:30:27.311749 11512 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0205 03:30:49.213377 11512 solver.cpp:237] Iteration 1210, loss = 0.00097464
I0205 03:30:49.213584 11512 solver.cpp:253]     Train net output #0: loss = 0.000974897 (* 1 = 0.000974897 loss)
I0205 03:30:49.213599 11512 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0205 03:31:11.030848 11512 solver.cpp:237] Iteration 1220, loss = 0.000553691
I0205 03:31:11.030925 11512 solver.cpp:253]     Train net output #0: loss = 0.000553949 (* 1 = 0.000553949 loss)
I0205 03:31:11.030938 11512 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0205 03:31:32.941082 11512 solver.cpp:237] Iteration 1230, loss = 0.000280078
I0205 03:31:32.941274 11512 solver.cpp:253]     Train net output #0: loss = 0.000280334 (* 1 = 0.000280334 loss)
I0205 03:31:32.941290 11512 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0205 03:31:54.811679 11512 solver.cpp:237] Iteration 1240, loss = 0.00432353
I0205 03:31:54.811764 11512 solver.cpp:253]     Train net output #0: loss = 0.00432379 (* 1 = 0.00432379 loss)
I0205 03:31:54.811792 11512 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0205 03:32:15.763847 11512 solver.cpp:237] Iteration 1250, loss = 0.0123274
I0205 03:32:15.764125 11512 solver.cpp:253]     Train net output #0: loss = 0.0123277 (* 1 = 0.0123277 loss)
I0205 03:32:15.764142 11512 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0205 03:32:36.346968 11512 solver.cpp:237] Iteration 1260, loss = 0.00114831
I0205 03:32:36.347054 11512 solver.cpp:253]     Train net output #0: loss = 0.00114857 (* 1 = 0.00114857 loss)
I0205 03:32:36.347069 11512 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0205 03:32:56.946226 11512 solver.cpp:237] Iteration 1270, loss = 0.000377794
I0205 03:32:56.946447 11512 solver.cpp:253]     Train net output #0: loss = 0.000378054 (* 1 = 0.000378054 loss)
I0205 03:32:56.946465 11512 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0205 03:33:17.433161 11512 solver.cpp:237] Iteration 1280, loss = 0.00092167
I0205 03:33:17.433245 11512 solver.cpp:253]     Train net output #0: loss = 0.000921931 (* 1 = 0.000921931 loss)
I0205 03:33:17.433259 11512 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0205 03:33:38.020860 11512 solver.cpp:237] Iteration 1290, loss = 0.019912
I0205 03:33:38.021091 11512 solver.cpp:253]     Train net output #0: loss = 0.0199123 (* 1 = 0.0199123 loss)
I0205 03:33:38.021107 11512 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0205 03:33:56.581375 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1300.caffemodel
I0205 03:33:56.585643 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1300.solverstate
I0205 03:33:56.587010 11512 solver.cpp:341] Iteration 1300, Testing net (#0)
I0205 03:34:06.701436 11512 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0205 03:34:06.701511 11512 solver.cpp:409]     Test net output #1: loss = 0.0137626 (* 1 = 0.0137626 loss)
I0205 03:34:08.840829 11512 solver.cpp:237] Iteration 1300, loss = 0.00383572
I0205 03:34:08.841083 11512 solver.cpp:253]     Train net output #0: loss = 0.00383598 (* 1 = 0.00383598 loss)
I0205 03:34:08.841099 11512 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0205 03:34:29.898476 11512 solver.cpp:237] Iteration 1310, loss = 0.00387532
I0205 03:34:29.898566 11512 solver.cpp:253]     Train net output #0: loss = 0.00387559 (* 1 = 0.00387559 loss)
I0205 03:34:29.898579 11512 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0205 03:34:50.753207 11512 solver.cpp:237] Iteration 1320, loss = 0.000518556
I0205 03:34:50.753419 11512 solver.cpp:253]     Train net output #0: loss = 0.00051882 (* 1 = 0.00051882 loss)
I0205 03:34:50.753435 11512 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0205 03:35:11.383885 11512 solver.cpp:237] Iteration 1330, loss = 0.000785413
I0205 03:35:11.383965 11512 solver.cpp:253]     Train net output #0: loss = 0.000785678 (* 1 = 0.000785678 loss)
I0205 03:35:11.383977 11512 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0205 03:35:31.906355 11512 solver.cpp:237] Iteration 1340, loss = 0.000840622
I0205 03:35:31.906563 11512 solver.cpp:253]     Train net output #0: loss = 0.000840887 (* 1 = 0.000840887 loss)
I0205 03:35:31.906577 11512 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0205 03:35:52.132648 11512 solver.cpp:237] Iteration 1350, loss = 0.00233739
I0205 03:35:52.132731 11512 solver.cpp:253]     Train net output #0: loss = 0.00233766 (* 1 = 0.00233766 loss)
I0205 03:35:52.132745 11512 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0205 03:36:12.377131 11512 solver.cpp:237] Iteration 1360, loss = 0.000166169
I0205 03:36:12.377367 11512 solver.cpp:253]     Train net output #0: loss = 0.000166433 (* 1 = 0.000166433 loss)
I0205 03:36:12.377382 11512 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0205 03:36:32.724328 11512 solver.cpp:237] Iteration 1370, loss = 0.00119695
I0205 03:36:32.724423 11512 solver.cpp:253]     Train net output #0: loss = 0.00119722 (* 1 = 0.00119722 loss)
I0205 03:36:32.724436 11512 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0205 03:36:53.520510 11512 solver.cpp:237] Iteration 1380, loss = 0.0305752
I0205 03:36:53.520759 11512 solver.cpp:253]     Train net output #0: loss = 0.0305754 (* 1 = 0.0305754 loss)
I0205 03:36:53.520776 11512 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0205 03:37:14.095204 11512 solver.cpp:237] Iteration 1390, loss = 0.00395229
I0205 03:37:14.095288 11512 solver.cpp:253]     Train net output #0: loss = 0.00395256 (* 1 = 0.00395256 loss)
I0205 03:37:14.095301 11512 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0205 03:37:33.094099 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1400.caffemodel
I0205 03:37:33.097820 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1400.solverstate
I0205 03:37:33.099181 11512 solver.cpp:341] Iteration 1400, Testing net (#0)
I0205 03:37:42.977668 11512 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0205 03:37:42.977737 11512 solver.cpp:409]     Test net output #1: loss = 0.00403363 (* 1 = 0.00403363 loss)
I0205 03:37:45.056742 11512 solver.cpp:237] Iteration 1400, loss = 0.00152233
I0205 03:37:45.056821 11512 solver.cpp:253]     Train net output #0: loss = 0.00152259 (* 1 = 0.00152259 loss)
I0205 03:37:45.056835 11512 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0205 03:38:06.006485 11512 solver.cpp:237] Iteration 1410, loss = 0.0010789
I0205 03:38:06.006700 11512 solver.cpp:253]     Train net output #0: loss = 0.00107916 (* 1 = 0.00107916 loss)
I0205 03:38:06.006716 11512 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0205 03:38:27.269991 11512 solver.cpp:237] Iteration 1420, loss = 0.00663941
I0205 03:38:27.270079 11512 solver.cpp:253]     Train net output #0: loss = 0.00663967 (* 1 = 0.00663967 loss)
I0205 03:38:27.270093 11512 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0205 03:38:48.814148 11512 solver.cpp:237] Iteration 1430, loss = 0.00565935
I0205 03:38:48.814381 11512 solver.cpp:253]     Train net output #0: loss = 0.00565961 (* 1 = 0.00565961 loss)
I0205 03:38:48.814396 11512 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0205 03:39:10.239167 11512 solver.cpp:237] Iteration 1440, loss = 0.000687938
I0205 03:39:10.239256 11512 solver.cpp:253]     Train net output #0: loss = 0.000688203 (* 1 = 0.000688203 loss)
I0205 03:39:10.239269 11512 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0205 03:39:31.531034 11512 solver.cpp:237] Iteration 1450, loss = 0.031894
I0205 03:39:31.531252 11512 solver.cpp:253]     Train net output #0: loss = 0.0318942 (* 1 = 0.0318942 loss)
I0205 03:39:31.531268 11512 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0205 03:39:52.759701 11512 solver.cpp:237] Iteration 1460, loss = 0.0508364
I0205 03:39:52.759783 11512 solver.cpp:253]     Train net output #0: loss = 0.0508366 (* 1 = 0.0508366 loss)
I0205 03:39:52.759798 11512 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0205 03:40:14.175858 11512 solver.cpp:237] Iteration 1470, loss = 0.00026644
I0205 03:40:14.176082 11512 solver.cpp:253]     Train net output #0: loss = 0.000266701 (* 1 = 0.000266701 loss)
I0205 03:40:14.176098 11512 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0205 03:40:35.351876 11512 solver.cpp:237] Iteration 1480, loss = 0.00286828
I0205 03:40:35.351961 11512 solver.cpp:253]     Train net output #0: loss = 0.00286854 (* 1 = 0.00286854 loss)
I0205 03:40:35.351975 11512 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0205 03:40:56.498230 11512 solver.cpp:237] Iteration 1490, loss = 0.000457453
I0205 03:40:56.498441 11512 solver.cpp:253]     Train net output #0: loss = 0.000457713 (* 1 = 0.000457713 loss)
I0205 03:40:56.498457 11512 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0205 03:41:15.627671 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1500.caffemodel
I0205 03:41:15.631198 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1500.solverstate
I0205 03:41:15.632560 11512 solver.cpp:341] Iteration 1500, Testing net (#0)
I0205 03:41:25.245589 11512 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0205 03:41:25.245656 11512 solver.cpp:409]     Test net output #1: loss = 0.0182222 (* 1 = 0.0182222 loss)
I0205 03:41:27.327946 11512 solver.cpp:237] Iteration 1500, loss = 0.00333786
I0205 03:41:27.328197 11512 solver.cpp:253]     Train net output #0: loss = 0.00333812 (* 1 = 0.00333812 loss)
I0205 03:41:27.328213 11512 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0205 03:41:48.064606 11512 solver.cpp:237] Iteration 1510, loss = 0.0870598
I0205 03:41:48.064689 11512 solver.cpp:253]     Train net output #0: loss = 0.08706 (* 1 = 0.08706 loss)
I0205 03:41:48.064703 11512 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0205 03:42:08.700104 11512 solver.cpp:237] Iteration 1520, loss = 0.00024572
I0205 03:42:08.700346 11512 solver.cpp:253]     Train net output #0: loss = 0.00024598 (* 1 = 0.00024598 loss)
I0205 03:42:08.700361 11512 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0205 03:42:30.364527 11512 solver.cpp:237] Iteration 1530, loss = 0.00430381
I0205 03:42:30.364609 11512 solver.cpp:253]     Train net output #0: loss = 0.00430407 (* 1 = 0.00430407 loss)
I0205 03:42:30.364624 11512 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0205 03:42:52.139152 11512 solver.cpp:237] Iteration 1540, loss = 0.00206944
I0205 03:42:52.139374 11512 solver.cpp:253]     Train net output #0: loss = 0.0020697 (* 1 = 0.0020697 loss)
I0205 03:42:52.139389 11512 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0205 03:43:13.827805 11512 solver.cpp:237] Iteration 1550, loss = 0.0580172
I0205 03:43:13.827884 11512 solver.cpp:253]     Train net output #0: loss = 0.0580175 (* 1 = 0.0580175 loss)
I0205 03:43:13.827898 11512 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0205 03:43:35.990314 11512 solver.cpp:237] Iteration 1560, loss = 0.00190923
I0205 03:43:35.990520 11512 solver.cpp:253]     Train net output #0: loss = 0.00190948 (* 1 = 0.00190948 loss)
I0205 03:43:35.990535 11512 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0205 03:43:58.299347 11512 solver.cpp:237] Iteration 1570, loss = 0.00143001
I0205 03:43:58.299428 11512 solver.cpp:253]     Train net output #0: loss = 0.00143026 (* 1 = 0.00143026 loss)
I0205 03:43:58.299442 11512 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0205 03:44:20.297704 11512 solver.cpp:237] Iteration 1580, loss = 0.000342626
I0205 03:44:20.297943 11512 solver.cpp:253]     Train net output #0: loss = 0.000342877 (* 1 = 0.000342877 loss)
I0205 03:44:20.297960 11512 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0205 03:44:42.565975 11512 solver.cpp:237] Iteration 1590, loss = 0.0109282
I0205 03:44:42.566066 11512 solver.cpp:253]     Train net output #0: loss = 0.0109284 (* 1 = 0.0109284 loss)
I0205 03:44:42.566079 11512 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0205 03:45:02.658295 11512 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1600.caffemodel
I0205 03:45:02.662011 11512 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed23/snaps/snap__iter_1600.solverstate
I0205 03:45:03.707854 11512 solver.cpp:321] Iteration 1600, loss = 0.00146515
I0205 03:45:03.707916 11512 solver.cpp:341] Iteration 1600, Testing net (#0)
I0205 03:45:14.219734 11512 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0205 03:45:14.219807 11512 solver.cpp:409]     Test net output #1: loss = 0.00428783 (* 1 = 0.00428783 loss)
I0205 03:45:14.219830 11512 solver.cpp:326] Optimization Done.
I0205 03:45:14.219835 11512 caffe.cpp:215] Optimization Done.
