Log file created at: 2016/02/04 21:47:44
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 21:47:44.405323  9913 caffe.cpp:177] Use CPU.
I0204 21:47:44.406087  9913 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap_"
solver_mode: CPU
random_seed: 14
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/train_val.prototxt"
I0204 21:47:44.406256  9913 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/train_val.prototxt
I0204 21:47:44.406853  9913 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 21:47:44.406886  9913 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 21:47:44.407142  9913 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 21:47:44.407280  9913 layer_factory.hpp:77] Creating layer data
I0204 21:47:44.407454  9913 net.cpp:106] Creating Layer data
I0204 21:47:44.407472  9913 net.cpp:411] data -> data
I0204 21:47:44.407557  9913 net.cpp:411] data -> label
I0204 21:47:44.407580  9913 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 21:47:44.407737  9914 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 21:47:44.408586  9913 data_layer.cpp:41] output data size: 100,1,227,227
I0204 21:47:44.440847  9913 net.cpp:150] Setting up data
I0204 21:47:44.440877  9913 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 21:47:44.440886  9913 net.cpp:157] Top shape: 100 (100)
I0204 21:47:44.440893  9913 net.cpp:165] Memory required for data: 20612000
I0204 21:47:44.440908  9913 layer_factory.hpp:77] Creating layer conv1
I0204 21:47:44.440954  9913 net.cpp:106] Creating Layer conv1
I0204 21:47:44.440973  9913 net.cpp:454] conv1 <- data
I0204 21:47:44.440991  9913 net.cpp:411] conv1 -> conv1
I0204 21:47:44.441115  9913 net.cpp:150] Setting up conv1
I0204 21:47:44.441126  9913 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 21:47:44.441133  9913 net.cpp:165] Memory required for data: 59332000
I0204 21:47:44.441149  9913 layer_factory.hpp:77] Creating layer relu1
I0204 21:47:44.441161  9913 net.cpp:106] Creating Layer relu1
I0204 21:47:44.441167  9913 net.cpp:454] relu1 <- conv1
I0204 21:47:44.441176  9913 net.cpp:397] relu1 -> conv1 (in-place)
I0204 21:47:44.441191  9913 net.cpp:150] Setting up relu1
I0204 21:47:44.441200  9913 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 21:47:44.441205  9913 net.cpp:165] Memory required for data: 98052000
I0204 21:47:44.441210  9913 layer_factory.hpp:77] Creating layer pool1
I0204 21:47:44.441221  9913 net.cpp:106] Creating Layer pool1
I0204 21:47:44.441227  9913 net.cpp:454] pool1 <- conv1
I0204 21:47:44.441236  9913 net.cpp:411] pool1 -> pool1
I0204 21:47:44.441259  9913 net.cpp:150] Setting up pool1
I0204 21:47:44.441267  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.441273  9913 net.cpp:165] Memory required for data: 107383200
I0204 21:47:44.441279  9913 layer_factory.hpp:77] Creating layer norm1
I0204 21:47:44.441309  9913 net.cpp:106] Creating Layer norm1
I0204 21:47:44.441318  9913 net.cpp:454] norm1 <- pool1
I0204 21:47:44.441326  9913 net.cpp:411] norm1 -> norm1
I0204 21:47:44.441344  9913 net.cpp:150] Setting up norm1
I0204 21:47:44.441352  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.441357  9913 net.cpp:165] Memory required for data: 116714400
I0204 21:47:44.441364  9913 layer_factory.hpp:77] Creating layer conv2
I0204 21:47:44.441375  9913 net.cpp:106] Creating Layer conv2
I0204 21:47:44.441380  9913 net.cpp:454] conv2 <- norm1
I0204 21:47:44.441390  9913 net.cpp:411] conv2 -> conv2
I0204 21:47:44.441519  9913 net.cpp:150] Setting up conv2
I0204 21:47:44.441529  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.441534  9913 net.cpp:165] Memory required for data: 126045600
I0204 21:47:44.441545  9913 layer_factory.hpp:77] Creating layer relu2
I0204 21:47:44.441553  9913 net.cpp:106] Creating Layer relu2
I0204 21:47:44.441560  9913 net.cpp:454] relu2 <- conv2
I0204 21:47:44.441578  9913 net.cpp:397] relu2 -> conv2 (in-place)
I0204 21:47:44.441589  9913 net.cpp:150] Setting up relu2
I0204 21:47:44.441596  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.441601  9913 net.cpp:165] Memory required for data: 135376800
I0204 21:47:44.441607  9913 layer_factory.hpp:77] Creating layer pool2
I0204 21:47:44.441615  9913 net.cpp:106] Creating Layer pool2
I0204 21:47:44.441622  9913 net.cpp:454] pool2 <- conv2
I0204 21:47:44.441628  9913 net.cpp:411] pool2 -> pool2
I0204 21:47:44.441639  9913 net.cpp:150] Setting up pool2
I0204 21:47:44.441647  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.441651  9913 net.cpp:165] Memory required for data: 137540000
I0204 21:47:44.441656  9913 layer_factory.hpp:77] Creating layer norm2
I0204 21:47:44.441666  9913 net.cpp:106] Creating Layer norm2
I0204 21:47:44.441673  9913 net.cpp:454] norm2 <- pool2
I0204 21:47:44.441682  9913 net.cpp:411] norm2 -> norm2
I0204 21:47:44.441692  9913 net.cpp:150] Setting up norm2
I0204 21:47:44.441701  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.441706  9913 net.cpp:165] Memory required for data: 139703200
I0204 21:47:44.441712  9913 layer_factory.hpp:77] Creating layer conv3
I0204 21:47:44.441722  9913 net.cpp:106] Creating Layer conv3
I0204 21:47:44.441728  9913 net.cpp:454] conv3 <- norm2
I0204 21:47:44.441740  9913 net.cpp:411] conv3 -> conv3
I0204 21:47:44.441848  9913 net.cpp:150] Setting up conv3
I0204 21:47:44.441859  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.441864  9913 net.cpp:165] Memory required for data: 141866400
I0204 21:47:44.441874  9913 layer_factory.hpp:77] Creating layer relu3
I0204 21:47:44.441882  9913 net.cpp:106] Creating Layer relu3
I0204 21:47:44.441889  9913 net.cpp:454] relu3 <- conv3
I0204 21:47:44.441898  9913 net.cpp:397] relu3 -> conv3 (in-place)
I0204 21:47:44.441906  9913 net.cpp:150] Setting up relu3
I0204 21:47:44.441913  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.441918  9913 net.cpp:165] Memory required for data: 144029600
I0204 21:47:44.441923  9913 layer_factory.hpp:77] Creating layer conv4
I0204 21:47:44.441933  9913 net.cpp:106] Creating Layer conv4
I0204 21:47:44.441939  9913 net.cpp:454] conv4 <- conv3
I0204 21:47:44.441948  9913 net.cpp:411] conv4 -> conv4
I0204 21:47:44.442030  9913 net.cpp:150] Setting up conv4
I0204 21:47:44.442040  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.442045  9913 net.cpp:165] Memory required for data: 146192800
I0204 21:47:44.442054  9913 layer_factory.hpp:77] Creating layer relu4
I0204 21:47:44.442061  9913 net.cpp:106] Creating Layer relu4
I0204 21:47:44.442067  9913 net.cpp:454] relu4 <- conv4
I0204 21:47:44.442075  9913 net.cpp:397] relu4 -> conv4 (in-place)
I0204 21:47:44.442083  9913 net.cpp:150] Setting up relu4
I0204 21:47:44.442092  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.442098  9913 net.cpp:165] Memory required for data: 148356000
I0204 21:47:44.442109  9913 layer_factory.hpp:77] Creating layer conv5
I0204 21:47:44.442129  9913 net.cpp:106] Creating Layer conv5
I0204 21:47:44.442136  9913 net.cpp:454] conv5 <- conv4
I0204 21:47:44.442143  9913 net.cpp:411] conv5 -> conv5
I0204 21:47:44.442189  9913 net.cpp:150] Setting up conv5
I0204 21:47:44.442198  9913 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 21:47:44.442203  9913 net.cpp:165] Memory required for data: 149437600
I0204 21:47:44.442215  9913 layer_factory.hpp:77] Creating layer relu5
I0204 21:47:44.442226  9913 net.cpp:106] Creating Layer relu5
I0204 21:47:44.442232  9913 net.cpp:454] relu5 <- conv5
I0204 21:47:44.442240  9913 net.cpp:397] relu5 -> conv5 (in-place)
I0204 21:47:44.442248  9913 net.cpp:150] Setting up relu5
I0204 21:47:44.442255  9913 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 21:47:44.442260  9913 net.cpp:165] Memory required for data: 150519200
I0204 21:47:44.442266  9913 layer_factory.hpp:77] Creating layer pool5
I0204 21:47:44.442275  9913 net.cpp:106] Creating Layer pool5
I0204 21:47:44.442281  9913 net.cpp:454] pool5 <- conv5
I0204 21:47:44.442291  9913 net.cpp:411] pool5 -> pool5
I0204 21:47:44.442301  9913 net.cpp:150] Setting up pool5
I0204 21:47:44.442308  9913 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 21:47:44.442313  9913 net.cpp:165] Memory required for data: 150749600
I0204 21:47:44.442318  9913 layer_factory.hpp:77] Creating layer fc6
I0204 21:47:44.442337  9913 net.cpp:106] Creating Layer fc6
I0204 21:47:44.442345  9913 net.cpp:454] fc6 <- pool5
I0204 21:47:44.442354  9913 net.cpp:411] fc6 -> fc6
I0204 21:47:44.443919  9913 net.cpp:150] Setting up fc6
I0204 21:47:44.443933  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.443938  9913 net.cpp:165] Memory required for data: 150852000
I0204 21:47:44.443946  9913 layer_factory.hpp:77] Creating layer relu6
I0204 21:47:44.443958  9913 net.cpp:106] Creating Layer relu6
I0204 21:47:44.443974  9913 net.cpp:454] relu6 <- fc6
I0204 21:47:44.443981  9913 net.cpp:397] relu6 -> fc6 (in-place)
I0204 21:47:44.443991  9913 net.cpp:150] Setting up relu6
I0204 21:47:44.443997  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.444003  9913 net.cpp:165] Memory required for data: 150954400
I0204 21:47:44.444008  9913 layer_factory.hpp:77] Creating layer drop6
I0204 21:47:44.444018  9913 net.cpp:106] Creating Layer drop6
I0204 21:47:44.444025  9913 net.cpp:454] drop6 <- fc6
I0204 21:47:44.444031  9913 net.cpp:397] drop6 -> fc6 (in-place)
I0204 21:47:44.444051  9913 net.cpp:150] Setting up drop6
I0204 21:47:44.444058  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.444063  9913 net.cpp:165] Memory required for data: 151056800
I0204 21:47:44.444068  9913 layer_factory.hpp:77] Creating layer fc7
I0204 21:47:44.444079  9913 net.cpp:106] Creating Layer fc7
I0204 21:47:44.444084  9913 net.cpp:454] fc7 <- fc6
I0204 21:47:44.444094  9913 net.cpp:411] fc7 -> fc7
I0204 21:47:44.444795  9913 net.cpp:150] Setting up fc7
I0204 21:47:44.444808  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.444813  9913 net.cpp:165] Memory required for data: 151159200
I0204 21:47:44.444823  9913 layer_factory.hpp:77] Creating layer relu7
I0204 21:47:44.444830  9913 net.cpp:106] Creating Layer relu7
I0204 21:47:44.444836  9913 net.cpp:454] relu7 <- fc7
I0204 21:47:44.444846  9913 net.cpp:397] relu7 -> fc7 (in-place)
I0204 21:47:44.444855  9913 net.cpp:150] Setting up relu7
I0204 21:47:44.444861  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.444867  9913 net.cpp:165] Memory required for data: 151261600
I0204 21:47:44.444872  9913 layer_factory.hpp:77] Creating layer drop7
I0204 21:47:44.444880  9913 net.cpp:106] Creating Layer drop7
I0204 21:47:44.444886  9913 net.cpp:454] drop7 <- fc7
I0204 21:47:44.444896  9913 net.cpp:397] drop7 -> fc7 (in-place)
I0204 21:47:44.444905  9913 net.cpp:150] Setting up drop7
I0204 21:47:44.444912  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.444917  9913 net.cpp:165] Memory required for data: 151364000
I0204 21:47:44.444923  9913 layer_factory.hpp:77] Creating layer fc8
I0204 21:47:44.444939  9913 net.cpp:106] Creating Layer fc8
I0204 21:47:44.444952  9913 net.cpp:454] fc8 <- fc7
I0204 21:47:44.444978  9913 net.cpp:411] fc8 -> fc8
I0204 21:47:44.445005  9913 net.cpp:150] Setting up fc8
I0204 21:47:44.445013  9913 net.cpp:157] Top shape: 100 2 (200)
I0204 21:47:44.445019  9913 net.cpp:165] Memory required for data: 151364800
I0204 21:47:44.445027  9913 layer_factory.hpp:77] Creating layer loss
I0204 21:47:44.445039  9913 net.cpp:106] Creating Layer loss
I0204 21:47:44.445045  9913 net.cpp:454] loss <- fc8
I0204 21:47:44.445051  9913 net.cpp:454] loss <- label
I0204 21:47:44.445060  9913 net.cpp:411] loss -> loss
I0204 21:47:44.445076  9913 layer_factory.hpp:77] Creating layer loss
I0204 21:47:44.445104  9913 net.cpp:150] Setting up loss
I0204 21:47:44.445112  9913 net.cpp:157] Top shape: (1)
I0204 21:47:44.445118  9913 net.cpp:160]     with loss weight 1
I0204 21:47:44.445145  9913 net.cpp:165] Memory required for data: 151364804
I0204 21:47:44.445153  9913 net.cpp:226] loss needs backward computation.
I0204 21:47:44.445160  9913 net.cpp:226] fc8 needs backward computation.
I0204 21:47:44.445166  9913 net.cpp:226] drop7 needs backward computation.
I0204 21:47:44.445171  9913 net.cpp:226] relu7 needs backward computation.
I0204 21:47:44.445176  9913 net.cpp:226] fc7 needs backward computation.
I0204 21:47:44.445183  9913 net.cpp:226] drop6 needs backward computation.
I0204 21:47:44.445188  9913 net.cpp:226] relu6 needs backward computation.
I0204 21:47:44.445194  9913 net.cpp:226] fc6 needs backward computation.
I0204 21:47:44.445199  9913 net.cpp:226] pool5 needs backward computation.
I0204 21:47:44.445206  9913 net.cpp:226] relu5 needs backward computation.
I0204 21:47:44.445211  9913 net.cpp:226] conv5 needs backward computation.
I0204 21:47:44.445217  9913 net.cpp:226] relu4 needs backward computation.
I0204 21:47:44.445222  9913 net.cpp:226] conv4 needs backward computation.
I0204 21:47:44.445228  9913 net.cpp:226] relu3 needs backward computation.
I0204 21:47:44.445233  9913 net.cpp:226] conv3 needs backward computation.
I0204 21:47:44.445243  9913 net.cpp:226] norm2 needs backward computation.
I0204 21:47:44.445250  9913 net.cpp:226] pool2 needs backward computation.
I0204 21:47:44.445255  9913 net.cpp:226] relu2 needs backward computation.
I0204 21:47:44.445261  9913 net.cpp:226] conv2 needs backward computation.
I0204 21:47:44.445266  9913 net.cpp:226] norm1 needs backward computation.
I0204 21:47:44.445271  9913 net.cpp:226] pool1 needs backward computation.
I0204 21:47:44.445277  9913 net.cpp:226] relu1 needs backward computation.
I0204 21:47:44.445283  9913 net.cpp:226] conv1 needs backward computation.
I0204 21:47:44.445289  9913 net.cpp:228] data does not need backward computation.
I0204 21:47:44.445294  9913 net.cpp:270] This network produces output loss
I0204 21:47:44.445322  9913 net.cpp:283] Network initialization done.
I0204 21:47:44.446087  9913 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/train_val.prototxt
I0204 21:47:44.446143  9913 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 21:47:44.446436  9913 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 21:47:44.446625  9913 layer_factory.hpp:77] Creating layer data
I0204 21:47:44.446765  9913 net.cpp:106] Creating Layer data
I0204 21:47:44.446781  9913 net.cpp:411] data -> data
I0204 21:47:44.446794  9913 net.cpp:411] data -> label
I0204 21:47:44.446805  9913 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 21:47:44.446992  9918 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 21:47:44.447679  9913 data_layer.cpp:41] output data size: 100,1,227,227
I0204 21:47:44.482775  9913 net.cpp:150] Setting up data
I0204 21:47:44.482812  9913 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 21:47:44.482821  9913 net.cpp:157] Top shape: 100 (100)
I0204 21:47:44.482826  9913 net.cpp:165] Memory required for data: 20612000
I0204 21:47:44.482837  9913 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 21:47:44.482857  9913 net.cpp:106] Creating Layer label_data_1_split
I0204 21:47:44.482866  9913 net.cpp:454] label_data_1_split <- label
I0204 21:47:44.482877  9913 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 21:47:44.482900  9913 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 21:47:44.482913  9913 net.cpp:150] Setting up label_data_1_split
I0204 21:47:44.482921  9913 net.cpp:157] Top shape: 100 (100)
I0204 21:47:44.482928  9913 net.cpp:157] Top shape: 100 (100)
I0204 21:47:44.482934  9913 net.cpp:165] Memory required for data: 20612800
I0204 21:47:44.482940  9913 layer_factory.hpp:77] Creating layer conv1
I0204 21:47:44.482959  9913 net.cpp:106] Creating Layer conv1
I0204 21:47:44.482972  9913 net.cpp:454] conv1 <- data
I0204 21:47:44.482986  9913 net.cpp:411] conv1 -> conv1
I0204 21:47:44.483060  9913 net.cpp:150] Setting up conv1
I0204 21:47:44.483073  9913 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 21:47:44.483078  9913 net.cpp:165] Memory required for data: 59332800
I0204 21:47:44.483093  9913 layer_factory.hpp:77] Creating layer relu1
I0204 21:47:44.483103  9913 net.cpp:106] Creating Layer relu1
I0204 21:47:44.483109  9913 net.cpp:454] relu1 <- conv1
I0204 21:47:44.483117  9913 net.cpp:397] relu1 -> conv1 (in-place)
I0204 21:47:44.483129  9913 net.cpp:150] Setting up relu1
I0204 21:47:44.483136  9913 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 21:47:44.483142  9913 net.cpp:165] Memory required for data: 98052800
I0204 21:47:44.483149  9913 layer_factory.hpp:77] Creating layer pool1
I0204 21:47:44.483160  9913 net.cpp:106] Creating Layer pool1
I0204 21:47:44.483165  9913 net.cpp:454] pool1 <- conv1
I0204 21:47:44.483173  9913 net.cpp:411] pool1 -> pool1
I0204 21:47:44.483187  9913 net.cpp:150] Setting up pool1
I0204 21:47:44.483196  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.483201  9913 net.cpp:165] Memory required for data: 107384000
I0204 21:47:44.483206  9913 layer_factory.hpp:77] Creating layer norm1
I0204 21:47:44.483218  9913 net.cpp:106] Creating Layer norm1
I0204 21:47:44.483225  9913 net.cpp:454] norm1 <- pool1
I0204 21:47:44.483234  9913 net.cpp:411] norm1 -> norm1
I0204 21:47:44.483247  9913 net.cpp:150] Setting up norm1
I0204 21:47:44.483253  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.483259  9913 net.cpp:165] Memory required for data: 116715200
I0204 21:47:44.483264  9913 layer_factory.hpp:77] Creating layer conv2
I0204 21:47:44.483278  9913 net.cpp:106] Creating Layer conv2
I0204 21:47:44.483284  9913 net.cpp:454] conv2 <- norm1
I0204 21:47:44.483294  9913 net.cpp:411] conv2 -> conv2
I0204 21:47:44.483425  9913 net.cpp:150] Setting up conv2
I0204 21:47:44.483435  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.483441  9913 net.cpp:165] Memory required for data: 126046400
I0204 21:47:44.483451  9913 layer_factory.hpp:77] Creating layer relu2
I0204 21:47:44.483461  9913 net.cpp:106] Creating Layer relu2
I0204 21:47:44.483467  9913 net.cpp:454] relu2 <- conv2
I0204 21:47:44.483485  9913 net.cpp:397] relu2 -> conv2 (in-place)
I0204 21:47:44.483503  9913 net.cpp:150] Setting up relu2
I0204 21:47:44.483510  9913 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 21:47:44.483516  9913 net.cpp:165] Memory required for data: 135377600
I0204 21:47:44.483521  9913 layer_factory.hpp:77] Creating layer pool2
I0204 21:47:44.483533  9913 net.cpp:106] Creating Layer pool2
I0204 21:47:44.483541  9913 net.cpp:454] pool2 <- conv2
I0204 21:47:44.483548  9913 net.cpp:411] pool2 -> pool2
I0204 21:47:44.483561  9913 net.cpp:150] Setting up pool2
I0204 21:47:44.483568  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483574  9913 net.cpp:165] Memory required for data: 137540800
I0204 21:47:44.483582  9913 layer_factory.hpp:77] Creating layer norm2
I0204 21:47:44.483592  9913 net.cpp:106] Creating Layer norm2
I0204 21:47:44.483597  9913 net.cpp:454] norm2 <- pool2
I0204 21:47:44.483606  9913 net.cpp:411] norm2 -> norm2
I0204 21:47:44.483616  9913 net.cpp:150] Setting up norm2
I0204 21:47:44.483623  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483628  9913 net.cpp:165] Memory required for data: 139704000
I0204 21:47:44.483634  9913 layer_factory.hpp:77] Creating layer conv3
I0204 21:47:44.483646  9913 net.cpp:106] Creating Layer conv3
I0204 21:47:44.483652  9913 net.cpp:454] conv3 <- norm2
I0204 21:47:44.483660  9913 net.cpp:411] conv3 -> conv3
I0204 21:47:44.483760  9913 net.cpp:150] Setting up conv3
I0204 21:47:44.483769  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483774  9913 net.cpp:165] Memory required for data: 141867200
I0204 21:47:44.483785  9913 layer_factory.hpp:77] Creating layer relu3
I0204 21:47:44.483793  9913 net.cpp:106] Creating Layer relu3
I0204 21:47:44.483799  9913 net.cpp:454] relu3 <- conv3
I0204 21:47:44.483808  9913 net.cpp:397] relu3 -> conv3 (in-place)
I0204 21:47:44.483817  9913 net.cpp:150] Setting up relu3
I0204 21:47:44.483824  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483829  9913 net.cpp:165] Memory required for data: 144030400
I0204 21:47:44.483834  9913 layer_factory.hpp:77] Creating layer conv4
I0204 21:47:44.483845  9913 net.cpp:106] Creating Layer conv4
I0204 21:47:44.483850  9913 net.cpp:454] conv4 <- conv3
I0204 21:47:44.483860  9913 net.cpp:411] conv4 -> conv4
I0204 21:47:44.483922  9913 net.cpp:150] Setting up conv4
I0204 21:47:44.483929  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483934  9913 net.cpp:165] Memory required for data: 146193600
I0204 21:47:44.483942  9913 layer_factory.hpp:77] Creating layer relu4
I0204 21:47:44.483952  9913 net.cpp:106] Creating Layer relu4
I0204 21:47:44.483958  9913 net.cpp:454] relu4 <- conv4
I0204 21:47:44.483970  9913 net.cpp:397] relu4 -> conv4 (in-place)
I0204 21:47:44.483978  9913 net.cpp:150] Setting up relu4
I0204 21:47:44.483986  9913 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 21:47:44.483991  9913 net.cpp:165] Memory required for data: 148356800
I0204 21:47:44.483997  9913 layer_factory.hpp:77] Creating layer conv5
I0204 21:47:44.484010  9913 net.cpp:106] Creating Layer conv5
I0204 21:47:44.484019  9913 net.cpp:454] conv5 <- conv4
I0204 21:47:44.484027  9913 net.cpp:411] conv5 -> conv5
I0204 21:47:44.484071  9913 net.cpp:150] Setting up conv5
I0204 21:47:44.484079  9913 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 21:47:44.484084  9913 net.cpp:165] Memory required for data: 149438400
I0204 21:47:44.484097  9913 layer_factory.hpp:77] Creating layer relu5
I0204 21:47:44.484105  9913 net.cpp:106] Creating Layer relu5
I0204 21:47:44.484112  9913 net.cpp:454] relu5 <- conv5
I0204 21:47:44.484118  9913 net.cpp:397] relu5 -> conv5 (in-place)
I0204 21:47:44.484127  9913 net.cpp:150] Setting up relu5
I0204 21:47:44.484134  9913 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 21:47:44.484139  9913 net.cpp:165] Memory required for data: 150520000
I0204 21:47:44.484144  9913 layer_factory.hpp:77] Creating layer pool5
I0204 21:47:44.484155  9913 net.cpp:106] Creating Layer pool5
I0204 21:47:44.484168  9913 net.cpp:454] pool5 <- conv5
I0204 21:47:44.484187  9913 net.cpp:411] pool5 -> pool5
I0204 21:47:44.484201  9913 net.cpp:150] Setting up pool5
I0204 21:47:44.484210  9913 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 21:47:44.484215  9913 net.cpp:165] Memory required for data: 150750400
I0204 21:47:44.484220  9913 layer_factory.hpp:77] Creating layer fc6
I0204 21:47:44.484232  9913 net.cpp:106] Creating Layer fc6
I0204 21:47:44.484237  9913 net.cpp:454] fc6 <- pool5
I0204 21:47:44.484246  9913 net.cpp:411] fc6 -> fc6
I0204 21:47:44.485878  9913 net.cpp:150] Setting up fc6
I0204 21:47:44.485891  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.485898  9913 net.cpp:165] Memory required for data: 150852800
I0204 21:47:44.485908  9913 layer_factory.hpp:77] Creating layer relu6
I0204 21:47:44.485916  9913 net.cpp:106] Creating Layer relu6
I0204 21:47:44.485924  9913 net.cpp:454] relu6 <- fc6
I0204 21:47:44.485936  9913 net.cpp:397] relu6 -> fc6 (in-place)
I0204 21:47:44.485945  9913 net.cpp:150] Setting up relu6
I0204 21:47:44.485952  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.485959  9913 net.cpp:165] Memory required for data: 150955200
I0204 21:47:44.485963  9913 layer_factory.hpp:77] Creating layer drop6
I0204 21:47:44.485988  9913 net.cpp:106] Creating Layer drop6
I0204 21:47:44.485994  9913 net.cpp:454] drop6 <- fc6
I0204 21:47:44.486003  9913 net.cpp:397] drop6 -> fc6 (in-place)
I0204 21:47:44.486016  9913 net.cpp:150] Setting up drop6
I0204 21:47:44.486021  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.486027  9913 net.cpp:165] Memory required for data: 151057600
I0204 21:47:44.486032  9913 layer_factory.hpp:77] Creating layer fc7
I0204 21:47:44.486042  9913 net.cpp:106] Creating Layer fc7
I0204 21:47:44.486048  9913 net.cpp:454] fc7 <- fc6
I0204 21:47:44.486057  9913 net.cpp:411] fc7 -> fc7
I0204 21:47:44.486760  9913 net.cpp:150] Setting up fc7
I0204 21:47:44.486771  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.486776  9913 net.cpp:165] Memory required for data: 151160000
I0204 21:47:44.486785  9913 layer_factory.hpp:77] Creating layer relu7
I0204 21:47:44.486793  9913 net.cpp:106] Creating Layer relu7
I0204 21:47:44.486799  9913 net.cpp:454] relu7 <- fc7
I0204 21:47:44.486807  9913 net.cpp:397] relu7 -> fc7 (in-place)
I0204 21:47:44.486815  9913 net.cpp:150] Setting up relu7
I0204 21:47:44.486822  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.486827  9913 net.cpp:165] Memory required for data: 151262400
I0204 21:47:44.486834  9913 layer_factory.hpp:77] Creating layer drop7
I0204 21:47:44.486845  9913 net.cpp:106] Creating Layer drop7
I0204 21:47:44.486850  9913 net.cpp:454] drop7 <- fc7
I0204 21:47:44.486857  9913 net.cpp:397] drop7 -> fc7 (in-place)
I0204 21:47:44.486868  9913 net.cpp:150] Setting up drop7
I0204 21:47:44.486876  9913 net.cpp:157] Top shape: 100 256 (25600)
I0204 21:47:44.486881  9913 net.cpp:165] Memory required for data: 151364800
I0204 21:47:44.486886  9913 layer_factory.hpp:77] Creating layer fc8
I0204 21:47:44.486899  9913 net.cpp:106] Creating Layer fc8
I0204 21:47:44.486907  9913 net.cpp:454] fc8 <- fc7
I0204 21:47:44.486913  9913 net.cpp:411] fc8 -> fc8
I0204 21:47:44.486940  9913 net.cpp:150] Setting up fc8
I0204 21:47:44.486948  9913 net.cpp:157] Top shape: 100 2 (200)
I0204 21:47:44.486953  9913 net.cpp:165] Memory required for data: 151365600
I0204 21:47:44.486961  9913 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 21:47:44.486979  9913 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 21:47:44.486984  9913 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 21:47:44.486991  9913 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 21:47:44.487000  9913 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 21:47:44.487010  9913 net.cpp:150] Setting up fc8_fc8_0_split
I0204 21:47:44.487021  9913 net.cpp:157] Top shape: 100 2 (200)
I0204 21:47:44.487028  9913 net.cpp:157] Top shape: 100 2 (200)
I0204 21:47:44.487033  9913 net.cpp:165] Memory required for data: 151367200
I0204 21:47:44.487040  9913 layer_factory.hpp:77] Creating layer accuracy
I0204 21:47:44.487066  9913 net.cpp:106] Creating Layer accuracy
I0204 21:47:44.487072  9913 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 21:47:44.487079  9913 net.cpp:454] accuracy <- label_data_1_split_0
I0204 21:47:44.487087  9913 net.cpp:411] accuracy -> accuracy
I0204 21:47:44.487098  9913 net.cpp:150] Setting up accuracy
I0204 21:47:44.487105  9913 net.cpp:157] Top shape: (1)
I0204 21:47:44.487112  9913 net.cpp:165] Memory required for data: 151367204
I0204 21:47:44.487118  9913 layer_factory.hpp:77] Creating layer loss
I0204 21:47:44.487129  9913 net.cpp:106] Creating Layer loss
I0204 21:47:44.487136  9913 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 21:47:44.487143  9913 net.cpp:454] loss <- label_data_1_split_1
I0204 21:47:44.487150  9913 net.cpp:411] loss -> loss
I0204 21:47:44.487161  9913 layer_factory.hpp:77] Creating layer loss
I0204 21:47:44.487185  9913 net.cpp:150] Setting up loss
I0204 21:47:44.487191  9913 net.cpp:157] Top shape: (1)
I0204 21:47:44.487198  9913 net.cpp:160]     with loss weight 1
I0204 21:47:44.487213  9913 net.cpp:165] Memory required for data: 151367208
I0204 21:47:44.487221  9913 net.cpp:226] loss needs backward computation.
I0204 21:47:44.487226  9913 net.cpp:228] accuracy does not need backward computation.
I0204 21:47:44.487233  9913 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 21:47:44.487239  9913 net.cpp:226] fc8 needs backward computation.
I0204 21:47:44.487244  9913 net.cpp:226] drop7 needs backward computation.
I0204 21:47:44.487251  9913 net.cpp:226] relu7 needs backward computation.
I0204 21:47:44.487256  9913 net.cpp:226] fc7 needs backward computation.
I0204 21:47:44.487262  9913 net.cpp:226] drop6 needs backward computation.
I0204 21:47:44.487267  9913 net.cpp:226] relu6 needs backward computation.
I0204 21:47:44.487272  9913 net.cpp:226] fc6 needs backward computation.
I0204 21:47:44.487277  9913 net.cpp:226] pool5 needs backward computation.
I0204 21:47:44.487283  9913 net.cpp:226] relu5 needs backward computation.
I0204 21:47:44.487288  9913 net.cpp:226] conv5 needs backward computation.
I0204 21:47:44.487294  9913 net.cpp:226] relu4 needs backward computation.
I0204 21:47:44.487299  9913 net.cpp:226] conv4 needs backward computation.
I0204 21:47:44.487305  9913 net.cpp:226] relu3 needs backward computation.
I0204 21:47:44.487311  9913 net.cpp:226] conv3 needs backward computation.
I0204 21:47:44.487319  9913 net.cpp:226] norm2 needs backward computation.
I0204 21:47:44.487325  9913 net.cpp:226] pool2 needs backward computation.
I0204 21:47:44.487331  9913 net.cpp:226] relu2 needs backward computation.
I0204 21:47:44.487337  9913 net.cpp:226] conv2 needs backward computation.
I0204 21:47:44.487344  9913 net.cpp:226] norm1 needs backward computation.
I0204 21:47:44.487350  9913 net.cpp:226] pool1 needs backward computation.
I0204 21:47:44.487356  9913 net.cpp:226] relu1 needs backward computation.
I0204 21:47:44.487362  9913 net.cpp:226] conv1 needs backward computation.
I0204 21:47:44.487370  9913 net.cpp:228] label_data_1_split does not need backward computation.
I0204 21:47:44.487375  9913 net.cpp:228] data does not need backward computation.
I0204 21:47:44.487381  9913 net.cpp:270] This network produces output accuracy
I0204 21:47:44.487387  9913 net.cpp:270] This network produces output loss
I0204 21:47:44.487416  9913 net.cpp:283] Network initialization done.
I0204 21:47:44.487534  9913 solver.cpp:60] Solver scaffolding done.
I0204 21:47:44.487588  9913 caffe.cpp:212] Starting Optimization
I0204 21:47:44.487596  9913 solver.cpp:288] Solving CaffeNet
I0204 21:47:44.487602  9913 solver.cpp:289] Learning Rate Policy: step
I0204 21:47:44.488458  9913 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 21:47:44.488584  9913 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 21:47:51.828819  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:47:51.828871  9913 solver.cpp:409]     Test net output #1: loss = 7.00992 (* 1 = 7.00992 loss)
I0204 21:47:53.519325  9913 solver.cpp:237] Iteration 0, loss = 9.77065
I0204 21:47:53.519428  9913 solver.cpp:253]     Train net output #0: loss = 9.77065 (* 1 = 9.77065 loss)
I0204 21:47:53.519448  9913 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 21:48:08.988044  9913 solver.cpp:237] Iteration 10, loss = 1.2879
I0204 21:48:08.988133  9913 solver.cpp:253]     Train net output #0: loss = 1.2879 (* 1 = 1.2879 loss)
I0204 21:48:08.988147  9913 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 21:48:24.676693  9913 solver.cpp:237] Iteration 20, loss = 0.859644
I0204 21:48:24.676867  9913 solver.cpp:253]     Train net output #0: loss = 0.859644 (* 1 = 0.859644 loss)
I0204 21:48:24.676882  9913 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 21:48:40.343706  9913 solver.cpp:237] Iteration 30, loss = 0.94815
I0204 21:48:40.343796  9913 solver.cpp:253]     Train net output #0: loss = 0.94815 (* 1 = 0.94815 loss)
I0204 21:48:40.343811  9913 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 21:48:55.939458  9913 solver.cpp:237] Iteration 40, loss = 0.934205
I0204 21:48:55.939685  9913 solver.cpp:253]     Train net output #0: loss = 0.934205 (* 1 = 0.934205 loss)
I0204 21:48:55.939702  9913 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 21:49:11.506505  9913 solver.cpp:237] Iteration 50, loss = 0.863142
I0204 21:49:11.506598  9913 solver.cpp:253]     Train net output #0: loss = 0.863142 (* 1 = 0.863142 loss)
I0204 21:49:11.506613  9913 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 21:49:27.089498  9913 solver.cpp:237] Iteration 60, loss = 0.85135
I0204 21:49:27.089710  9913 solver.cpp:253]     Train net output #0: loss = 0.85135 (* 1 = 0.85135 loss)
I0204 21:49:27.089728  9913 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 21:49:42.677952  9913 solver.cpp:237] Iteration 70, loss = 0.843922
I0204 21:49:42.678041  9913 solver.cpp:253]     Train net output #0: loss = 0.843922 (* 1 = 0.843922 loss)
I0204 21:49:42.678062  9913 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 21:49:58.263686  9913 solver.cpp:237] Iteration 80, loss = 0.739002
I0204 21:49:58.263916  9913 solver.cpp:253]     Train net output #0: loss = 0.739002 (* 1 = 0.739002 loss)
I0204 21:49:58.263933  9913 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 21:50:13.829099  9913 solver.cpp:237] Iteration 90, loss = 0.847538
I0204 21:50:13.829188  9913 solver.cpp:253]     Train net output #0: loss = 0.847538 (* 1 = 0.847538 loss)
I0204 21:50:13.829203  9913 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 21:50:27.837468  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_100.caffemodel
I0204 21:50:27.840948  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_100.solverstate
I0204 21:50:27.842370  9913 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 21:50:35.006850  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:50:35.007086  9913 solver.cpp:409]     Test net output #1: loss = 0.693577 (* 1 = 0.693577 loss)
I0204 21:50:36.561256  9913 solver.cpp:237] Iteration 100, loss = 0.732008
I0204 21:50:36.561341  9913 solver.cpp:253]     Train net output #0: loss = 0.732008 (* 1 = 0.732008 loss)
I0204 21:50:36.561355  9913 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 21:50:52.112886  9913 solver.cpp:237] Iteration 110, loss = 0.745903
I0204 21:50:52.112983  9913 solver.cpp:253]     Train net output #0: loss = 0.745903 (* 1 = 0.745903 loss)
I0204 21:50:52.112999  9913 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 21:51:07.653246  9913 solver.cpp:237] Iteration 120, loss = 0.73877
I0204 21:51:07.653476  9913 solver.cpp:253]     Train net output #0: loss = 0.73877 (* 1 = 0.73877 loss)
I0204 21:51:07.653494  9913 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 21:51:23.195818  9913 solver.cpp:237] Iteration 130, loss = 0.771906
I0204 21:51:23.195912  9913 solver.cpp:253]     Train net output #0: loss = 0.771906 (* 1 = 0.771906 loss)
I0204 21:51:23.195942  9913 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 21:51:38.830938  9913 solver.cpp:237] Iteration 140, loss = 0.739767
I0204 21:51:38.831217  9913 solver.cpp:253]     Train net output #0: loss = 0.739767 (* 1 = 0.739767 loss)
I0204 21:51:38.831234  9913 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 21:51:54.472929  9913 solver.cpp:237] Iteration 150, loss = 0.740642
I0204 21:51:54.473017  9913 solver.cpp:253]     Train net output #0: loss = 0.740642 (* 1 = 0.740642 loss)
I0204 21:51:54.473033  9913 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 21:52:10.104244  9913 solver.cpp:237] Iteration 160, loss = 0.700139
I0204 21:52:10.104501  9913 solver.cpp:253]     Train net output #0: loss = 0.700139 (* 1 = 0.700139 loss)
I0204 21:52:10.104518  9913 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 21:52:25.636557  9913 solver.cpp:237] Iteration 170, loss = 0.727045
I0204 21:52:25.636644  9913 solver.cpp:253]     Train net output #0: loss = 0.727045 (* 1 = 0.727045 loss)
I0204 21:52:25.636661  9913 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 21:52:41.186292  9913 solver.cpp:237] Iteration 180, loss = 0.714443
I0204 21:52:41.186506  9913 solver.cpp:253]     Train net output #0: loss = 0.714443 (* 1 = 0.714443 loss)
I0204 21:52:41.186523  9913 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 21:52:56.708264  9913 solver.cpp:237] Iteration 190, loss = 0.805399
I0204 21:52:56.708349  9913 solver.cpp:253]     Train net output #0: loss = 0.805399 (* 1 = 0.805399 loss)
I0204 21:52:56.708364  9913 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 21:53:10.687415  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_200.caffemodel
I0204 21:53:10.691087  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_200.solverstate
I0204 21:53:10.692481  9913 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 21:53:17.842911  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:53:17.843132  9913 solver.cpp:409]     Test net output #1: loss = 0.697008 (* 1 = 0.697008 loss)
I0204 21:53:19.398249  9913 solver.cpp:237] Iteration 200, loss = 0.757996
I0204 21:53:19.398321  9913 solver.cpp:253]     Train net output #0: loss = 0.757996 (* 1 = 0.757996 loss)
I0204 21:53:19.398336  9913 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 21:53:34.921061  9913 solver.cpp:237] Iteration 210, loss = 0.712456
I0204 21:53:34.921149  9913 solver.cpp:253]     Train net output #0: loss = 0.712456 (* 1 = 0.712456 loss)
I0204 21:53:34.921164  9913 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 21:53:50.448043  9913 solver.cpp:237] Iteration 220, loss = 0.759246
I0204 21:53:50.448268  9913 solver.cpp:253]     Train net output #0: loss = 0.759246 (* 1 = 0.759246 loss)
I0204 21:53:50.448284  9913 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 21:54:05.967417  9913 solver.cpp:237] Iteration 230, loss = 0.695891
I0204 21:54:05.967514  9913 solver.cpp:253]     Train net output #0: loss = 0.695891 (* 1 = 0.695891 loss)
I0204 21:54:05.967530  9913 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 21:54:21.503796  9913 solver.cpp:237] Iteration 240, loss = 0.694071
I0204 21:54:21.504027  9913 solver.cpp:253]     Train net output #0: loss = 0.694071 (* 1 = 0.694071 loss)
I0204 21:54:21.504045  9913 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 21:54:37.053100  9913 solver.cpp:237] Iteration 250, loss = 0.731916
I0204 21:54:37.053194  9913 solver.cpp:253]     Train net output #0: loss = 0.731916 (* 1 = 0.731916 loss)
I0204 21:54:37.053208  9913 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 21:54:52.597638  9913 solver.cpp:237] Iteration 260, loss = 0.735041
I0204 21:54:52.597903  9913 solver.cpp:253]     Train net output #0: loss = 0.735041 (* 1 = 0.735041 loss)
I0204 21:54:52.597926  9913 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 21:55:08.131166  9913 solver.cpp:237] Iteration 270, loss = 0.762332
I0204 21:55:08.131258  9913 solver.cpp:253]     Train net output #0: loss = 0.762332 (* 1 = 0.762332 loss)
I0204 21:55:08.131273  9913 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 21:55:23.668603  9913 solver.cpp:237] Iteration 280, loss = 0.706533
I0204 21:55:23.668836  9913 solver.cpp:253]     Train net output #0: loss = 0.706533 (* 1 = 0.706533 loss)
I0204 21:55:23.668853  9913 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 21:55:39.204663  9913 solver.cpp:237] Iteration 290, loss = 0.711997
I0204 21:55:39.204751  9913 solver.cpp:253]     Train net output #0: loss = 0.711997 (* 1 = 0.711997 loss)
I0204 21:55:39.204766  9913 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 21:55:53.179009  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_300.caffemodel
I0204 21:55:53.182651  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_300.solverstate
I0204 21:55:53.184046  9913 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 21:56:00.334017  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:56:00.334247  9913 solver.cpp:409]     Test net output #1: loss = 0.712548 (* 1 = 0.712548 loss)
I0204 21:56:01.887346  9913 solver.cpp:237] Iteration 300, loss = 0.77453
I0204 21:56:01.887426  9913 solver.cpp:253]     Train net output #0: loss = 0.77453 (* 1 = 0.77453 loss)
I0204 21:56:01.887441  9913 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 21:56:17.420270  9913 solver.cpp:237] Iteration 310, loss = 0.675185
I0204 21:56:17.420366  9913 solver.cpp:253]     Train net output #0: loss = 0.675185 (* 1 = 0.675185 loss)
I0204 21:56:17.420380  9913 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 21:56:32.953958  9913 solver.cpp:237] Iteration 320, loss = 0.669084
I0204 21:56:32.954218  9913 solver.cpp:253]     Train net output #0: loss = 0.669084 (* 1 = 0.669084 loss)
I0204 21:56:32.954236  9913 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 21:56:48.477032  9913 solver.cpp:237] Iteration 330, loss = 0.767694
I0204 21:56:48.477130  9913 solver.cpp:253]     Train net output #0: loss = 0.767694 (* 1 = 0.767694 loss)
I0204 21:56:48.477145  9913 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 21:57:04.009660  9913 solver.cpp:237] Iteration 340, loss = 0.694036
I0204 21:57:04.009893  9913 solver.cpp:253]     Train net output #0: loss = 0.694036 (* 1 = 0.694036 loss)
I0204 21:57:04.009910  9913 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 21:57:19.538674  9913 solver.cpp:237] Iteration 350, loss = 0.727593
I0204 21:57:19.538758  9913 solver.cpp:253]     Train net output #0: loss = 0.727593 (* 1 = 0.727593 loss)
I0204 21:57:19.538774  9913 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 21:57:35.065520  9913 solver.cpp:237] Iteration 360, loss = 0.670155
I0204 21:57:35.065742  9913 solver.cpp:253]     Train net output #0: loss = 0.670155 (* 1 = 0.670155 loss)
I0204 21:57:35.065760  9913 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 21:57:50.595033  9913 solver.cpp:237] Iteration 370, loss = 0.685665
I0204 21:57:50.595131  9913 solver.cpp:253]     Train net output #0: loss = 0.685665 (* 1 = 0.685665 loss)
I0204 21:57:50.595146  9913 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 21:58:06.126363  9913 solver.cpp:237] Iteration 380, loss = 0.763912
I0204 21:58:06.126592  9913 solver.cpp:253]     Train net output #0: loss = 0.763912 (* 1 = 0.763912 loss)
I0204 21:58:06.126610  9913 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 21:58:21.643407  9913 solver.cpp:237] Iteration 390, loss = 0.715066
I0204 21:58:21.643498  9913 solver.cpp:253]     Train net output #0: loss = 0.715066 (* 1 = 0.715066 loss)
I0204 21:58:21.643513  9913 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 21:58:35.643474  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_400.caffemodel
I0204 21:58:35.647145  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_400.solverstate
I0204 21:58:35.648533  9913 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 21:58:42.803010  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 21:58:42.803268  9913 solver.cpp:409]     Test net output #1: loss = 0.702263 (* 1 = 0.702263 loss)
I0204 21:58:44.357298  9913 solver.cpp:237] Iteration 400, loss = 0.720776
I0204 21:58:44.357384  9913 solver.cpp:253]     Train net output #0: loss = 0.720776 (* 1 = 0.720776 loss)
I0204 21:58:44.357400  9913 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 21:58:59.911260  9913 solver.cpp:237] Iteration 410, loss = 0.741729
I0204 21:58:59.911350  9913 solver.cpp:253]     Train net output #0: loss = 0.741729 (* 1 = 0.741729 loss)
I0204 21:58:59.911366  9913 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 21:59:15.458034  9913 solver.cpp:237] Iteration 420, loss = 0.706912
I0204 21:59:15.458272  9913 solver.cpp:253]     Train net output #0: loss = 0.706912 (* 1 = 0.706912 loss)
I0204 21:59:15.458289  9913 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 21:59:31.010627  9913 solver.cpp:237] Iteration 430, loss = 0.707148
I0204 21:59:31.010723  9913 solver.cpp:253]     Train net output #0: loss = 0.707148 (* 1 = 0.707148 loss)
I0204 21:59:31.010738  9913 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 21:59:46.608338  9913 solver.cpp:237] Iteration 440, loss = 0.670729
I0204 21:59:46.608563  9913 solver.cpp:253]     Train net output #0: loss = 0.670729 (* 1 = 0.670729 loss)
I0204 21:59:46.608582  9913 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 22:00:02.170816  9913 solver.cpp:237] Iteration 450, loss = 0.705077
I0204 22:00:02.170907  9913 solver.cpp:253]     Train net output #0: loss = 0.705077 (* 1 = 0.705077 loss)
I0204 22:00:02.170923  9913 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 22:00:17.881053  9913 solver.cpp:237] Iteration 460, loss = 0.77884
I0204 22:00:17.881255  9913 solver.cpp:253]     Train net output #0: loss = 0.77884 (* 1 = 0.77884 loss)
I0204 22:00:17.881270  9913 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 22:00:33.580634  9913 solver.cpp:237] Iteration 470, loss = 0.718158
I0204 22:00:33.580695  9913 solver.cpp:253]     Train net output #0: loss = 0.718158 (* 1 = 0.718158 loss)
I0204 22:00:33.580708  9913 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 22:00:49.324268  9913 solver.cpp:237] Iteration 480, loss = 0.730266
I0204 22:00:49.324492  9913 solver.cpp:253]     Train net output #0: loss = 0.730266 (* 1 = 0.730266 loss)
I0204 22:00:49.324512  9913 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 22:01:05.042248  9913 solver.cpp:237] Iteration 490, loss = 0.737935
I0204 22:01:05.042309  9913 solver.cpp:253]     Train net output #0: loss = 0.737935 (* 1 = 0.737935 loss)
I0204 22:01:05.042322  9913 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 22:01:19.145706  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_500.caffemodel
I0204 22:01:19.149274  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_500.solverstate
I0204 22:01:19.150679  9913 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 22:01:26.347368  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 22:01:26.347555  9913 solver.cpp:409]     Test net output #1: loss = 0.695367 (* 1 = 0.695367 loss)
I0204 22:01:27.911873  9913 solver.cpp:237] Iteration 500, loss = 0.684526
I0204 22:01:27.911945  9913 solver.cpp:253]     Train net output #0: loss = 0.684526 (* 1 = 0.684526 loss)
I0204 22:01:27.911957  9913 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 22:01:43.587031  9913 solver.cpp:237] Iteration 510, loss = 0.711115
I0204 22:01:43.587091  9913 solver.cpp:253]     Train net output #0: loss = 0.711115 (* 1 = 0.711115 loss)
I0204 22:01:43.587103  9913 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 22:01:59.260835  9913 solver.cpp:237] Iteration 520, loss = 0.697588
I0204 22:01:59.261039  9913 solver.cpp:253]     Train net output #0: loss = 0.697588 (* 1 = 0.697588 loss)
I0204 22:01:59.261052  9913 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 22:02:14.921931  9913 solver.cpp:237] Iteration 530, loss = 0.703521
I0204 22:02:14.921991  9913 solver.cpp:253]     Train net output #0: loss = 0.703521 (* 1 = 0.703521 loss)
I0204 22:02:14.922003  9913 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 22:02:30.576360  9913 solver.cpp:237] Iteration 540, loss = 0.7997
I0204 22:02:30.576551  9913 solver.cpp:253]     Train net output #0: loss = 0.7997 (* 1 = 0.7997 loss)
I0204 22:02:30.576565  9913 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 22:02:46.235110  9913 solver.cpp:237] Iteration 550, loss = 0.699196
I0204 22:02:46.235168  9913 solver.cpp:253]     Train net output #0: loss = 0.699196 (* 1 = 0.699196 loss)
I0204 22:02:46.235180  9913 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 22:03:01.903283  9913 solver.cpp:237] Iteration 560, loss = 0.70741
I0204 22:03:01.903470  9913 solver.cpp:253]     Train net output #0: loss = 0.70741 (* 1 = 0.70741 loss)
I0204 22:03:01.903483  9913 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 22:03:17.662791  9913 solver.cpp:237] Iteration 570, loss = 0.760605
I0204 22:03:17.662847  9913 solver.cpp:253]     Train net output #0: loss = 0.760605 (* 1 = 0.760605 loss)
I0204 22:03:17.662859  9913 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 22:03:33.424268  9913 solver.cpp:237] Iteration 580, loss = 0.69442
I0204 22:03:33.424445  9913 solver.cpp:253]     Train net output #0: loss = 0.69442 (* 1 = 0.69442 loss)
I0204 22:03:33.424459  9913 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 22:03:49.179394  9913 solver.cpp:237] Iteration 590, loss = 0.714911
I0204 22:03:49.179453  9913 solver.cpp:253]     Train net output #0: loss = 0.714911 (* 1 = 0.714911 loss)
I0204 22:03:49.179464  9913 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 22:04:03.354956  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_600.caffemodel
I0204 22:04:03.358505  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_600.solverstate
I0204 22:04:03.359892  9913 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 22:04:10.594966  9913 solver.cpp:409]     Test net output #0: accuracy = 0.499
I0204 22:04:10.595204  9913 solver.cpp:409]     Test net output #1: loss = 0.692574 (* 1 = 0.692574 loss)
I0204 22:04:12.157608  9913 solver.cpp:237] Iteration 600, loss = 0.688329
I0204 22:04:12.157692  9913 solver.cpp:253]     Train net output #0: loss = 0.688329 (* 1 = 0.688329 loss)
I0204 22:04:12.157707  9913 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 22:04:27.798925  9913 solver.cpp:237] Iteration 610, loss = 0.691993
I0204 22:04:27.799006  9913 solver.cpp:253]     Train net output #0: loss = 0.691993 (* 1 = 0.691993 loss)
I0204 22:04:27.799022  9913 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 22:04:43.464612  9913 solver.cpp:237] Iteration 620, loss = 0.799114
I0204 22:04:43.464809  9913 solver.cpp:253]     Train net output #0: loss = 0.799114 (* 1 = 0.799114 loss)
I0204 22:04:43.464823  9913 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 22:04:59.096307  9913 solver.cpp:237] Iteration 630, loss = 0.693588
I0204 22:04:59.096366  9913 solver.cpp:253]     Train net output #0: loss = 0.693588 (* 1 = 0.693588 loss)
I0204 22:04:59.096395  9913 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 22:05:14.738247  9913 solver.cpp:237] Iteration 640, loss = 0.712082
I0204 22:05:14.738448  9913 solver.cpp:253]     Train net output #0: loss = 0.712082 (* 1 = 0.712082 loss)
I0204 22:05:14.738462  9913 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 22:05:30.379434  9913 solver.cpp:237] Iteration 650, loss = 0.729292
I0204 22:05:30.379484  9913 solver.cpp:253]     Train net output #0: loss = 0.729292 (* 1 = 0.729292 loss)
I0204 22:05:30.379495  9913 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 22:05:46.035346  9913 solver.cpp:237] Iteration 660, loss = 0.708953
I0204 22:05:46.035540  9913 solver.cpp:253]     Train net output #0: loss = 0.708953 (* 1 = 0.708953 loss)
I0204 22:05:46.035553  9913 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 22:06:01.669069  9913 solver.cpp:237] Iteration 670, loss = 0.702469
I0204 22:06:01.669129  9913 solver.cpp:253]     Train net output #0: loss = 0.702469 (* 1 = 0.702469 loss)
I0204 22:06:01.669140  9913 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 22:06:17.298008  9913 solver.cpp:237] Iteration 680, loss = 0.698194
I0204 22:06:17.298218  9913 solver.cpp:253]     Train net output #0: loss = 0.698194 (* 1 = 0.698194 loss)
I0204 22:06:17.298230  9913 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 22:06:32.928558  9913 solver.cpp:237] Iteration 690, loss = 0.698364
I0204 22:06:32.928619  9913 solver.cpp:253]     Train net output #0: loss = 0.698364 (* 1 = 0.698364 loss)
I0204 22:06:32.928632  9913 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 22:06:46.983033  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_700.caffemodel
I0204 22:06:46.987143  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_700.solverstate
I0204 22:06:46.988564  9913 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 22:06:54.156358  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 22:06:54.156530  9913 solver.cpp:409]     Test net output #1: loss = 0.703567 (* 1 = 0.703567 loss)
I0204 22:06:55.718708  9913 solver.cpp:237] Iteration 700, loss = 0.754965
I0204 22:06:55.718763  9913 solver.cpp:253]     Train net output #0: loss = 0.754965 (* 1 = 0.754965 loss)
I0204 22:06:55.718775  9913 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 22:07:11.343379  9913 solver.cpp:237] Iteration 710, loss = 0.705349
I0204 22:07:11.343437  9913 solver.cpp:253]     Train net output #0: loss = 0.705349 (* 1 = 0.705349 loss)
I0204 22:07:11.343448  9913 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 22:07:26.967999  9913 solver.cpp:237] Iteration 720, loss = 0.69399
I0204 22:07:26.968180  9913 solver.cpp:253]     Train net output #0: loss = 0.69399 (* 1 = 0.69399 loss)
I0204 22:07:26.968194  9913 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 22:07:42.581889  9913 solver.cpp:237] Iteration 730, loss = 0.744132
I0204 22:07:42.581962  9913 solver.cpp:253]     Train net output #0: loss = 0.744132 (* 1 = 0.744132 loss)
I0204 22:07:42.581974  9913 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 22:07:58.195277  9913 solver.cpp:237] Iteration 740, loss = 0.686266
I0204 22:07:58.195451  9913 solver.cpp:253]     Train net output #0: loss = 0.686266 (* 1 = 0.686266 loss)
I0204 22:07:58.195466  9913 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 22:08:13.813997  9913 solver.cpp:237] Iteration 750, loss = 0.715131
I0204 22:08:13.814060  9913 solver.cpp:253]     Train net output #0: loss = 0.715131 (* 1 = 0.715131 loss)
I0204 22:08:13.814071  9913 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 22:08:29.422811  9913 solver.cpp:237] Iteration 760, loss = 0.693971
I0204 22:08:29.423022  9913 solver.cpp:253]     Train net output #0: loss = 0.693971 (* 1 = 0.693971 loss)
I0204 22:08:29.423037  9913 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 22:08:45.036429  9913 solver.cpp:237] Iteration 770, loss = 0.689672
I0204 22:08:45.036491  9913 solver.cpp:253]     Train net output #0: loss = 0.689672 (* 1 = 0.689672 loss)
I0204 22:08:45.036502  9913 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 22:09:00.647227  9913 solver.cpp:237] Iteration 780, loss = 0.770069
I0204 22:09:00.647414  9913 solver.cpp:253]     Train net output #0: loss = 0.770069 (* 1 = 0.770069 loss)
I0204 22:09:00.647428  9913 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 22:09:16.244737  9913 solver.cpp:237] Iteration 790, loss = 0.70819
I0204 22:09:16.244796  9913 solver.cpp:253]     Train net output #0: loss = 0.70819 (* 1 = 0.70819 loss)
I0204 22:09:16.244807  9913 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 22:09:30.280769  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_800.caffemodel
I0204 22:09:30.284309  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_800.solverstate
I0204 22:09:30.285686  9913 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 22:09:37.444541  9913 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 22:09:37.444726  9913 solver.cpp:409]     Test net output #1: loss = 0.692403 (* 1 = 0.692403 loss)
I0204 22:09:39.003537  9913 solver.cpp:237] Iteration 800, loss = 0.70423
I0204 22:09:39.003597  9913 solver.cpp:253]     Train net output #0: loss = 0.70423 (* 1 = 0.70423 loss)
I0204 22:09:39.003608  9913 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 22:09:54.612438  9913 solver.cpp:237] Iteration 810, loss = 0.726612
I0204 22:09:54.612496  9913 solver.cpp:253]     Train net output #0: loss = 0.726612 (* 1 = 0.726612 loss)
I0204 22:09:54.612506  9913 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 22:10:10.214970  9913 solver.cpp:237] Iteration 820, loss = 0.697767
I0204 22:10:10.215164  9913 solver.cpp:253]     Train net output #0: loss = 0.697767 (* 1 = 0.697767 loss)
I0204 22:10:10.215178  9913 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 22:10:25.818222  9913 solver.cpp:237] Iteration 830, loss = 0.768892
I0204 22:10:25.818282  9913 solver.cpp:253]     Train net output #0: loss = 0.768892 (* 1 = 0.768892 loss)
I0204 22:10:25.818295  9913 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 22:10:41.417291  9913 solver.cpp:237] Iteration 840, loss = 0.691533
I0204 22:10:41.417479  9913 solver.cpp:253]     Train net output #0: loss = 0.691533 (* 1 = 0.691533 loss)
I0204 22:10:41.417493  9913 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 22:10:57.010910  9913 solver.cpp:237] Iteration 850, loss = 0.684382
I0204 22:10:57.010974  9913 solver.cpp:253]     Train net output #0: loss = 0.684382 (* 1 = 0.684382 loss)
I0204 22:10:57.010987  9913 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 22:11:12.606006  9913 solver.cpp:237] Iteration 860, loss = 0.803636
I0204 22:11:12.606204  9913 solver.cpp:253]     Train net output #0: loss = 0.803636 (* 1 = 0.803636 loss)
I0204 22:11:12.606216  9913 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 22:11:28.198415  9913 solver.cpp:237] Iteration 870, loss = 0.726106
I0204 22:11:28.198477  9913 solver.cpp:253]     Train net output #0: loss = 0.726106 (* 1 = 0.726106 loss)
I0204 22:11:28.198488  9913 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 22:11:43.786839  9913 solver.cpp:237] Iteration 880, loss = 0.688662
I0204 22:11:43.787045  9913 solver.cpp:253]     Train net output #0: loss = 0.688662 (* 1 = 0.688662 loss)
I0204 22:11:43.787057  9913 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 22:11:59.376057  9913 solver.cpp:237] Iteration 890, loss = 0.714134
I0204 22:11:59.376116  9913 solver.cpp:253]     Train net output #0: loss = 0.714134 (* 1 = 0.714134 loss)
I0204 22:11:59.376127  9913 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 22:12:13.402762  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_900.caffemodel
I0204 22:12:13.406466  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_900.solverstate
I0204 22:12:13.407886  9913 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 22:12:20.557950  9913 solver.cpp:409]     Test net output #0: accuracy = 0.558
I0204 22:12:20.558153  9913 solver.cpp:409]     Test net output #1: loss = 0.681932 (* 1 = 0.681932 loss)
I0204 22:12:22.116030  9913 solver.cpp:237] Iteration 900, loss = 0.670569
I0204 22:12:22.116085  9913 solver.cpp:253]     Train net output #0: loss = 0.670569 (* 1 = 0.670569 loss)
I0204 22:12:22.116096  9913 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 22:12:37.689918  9913 solver.cpp:237] Iteration 910, loss = 0.67279
I0204 22:12:37.689980  9913 solver.cpp:253]     Train net output #0: loss = 0.67279 (* 1 = 0.67279 loss)
I0204 22:12:37.689992  9913 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 22:12:53.299877  9913 solver.cpp:237] Iteration 920, loss = 0.70733
I0204 22:12:53.300086  9913 solver.cpp:253]     Train net output #0: loss = 0.70733 (* 1 = 0.70733 loss)
I0204 22:12:53.300101  9913 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 22:13:08.880586  9913 solver.cpp:237] Iteration 930, loss = 0.640372
I0204 22:13:08.880647  9913 solver.cpp:253]     Train net output #0: loss = 0.640372 (* 1 = 0.640372 loss)
I0204 22:13:08.880659  9913 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 22:13:24.473122  9913 solver.cpp:237] Iteration 940, loss = 0.672868
I0204 22:13:24.473315  9913 solver.cpp:253]     Train net output #0: loss = 0.672868 (* 1 = 0.672868 loss)
I0204 22:13:24.473328  9913 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 22:13:40.017282  9913 solver.cpp:237] Iteration 950, loss = 0.612649
I0204 22:13:40.017340  9913 solver.cpp:253]     Train net output #0: loss = 0.612649 (* 1 = 0.612649 loss)
I0204 22:13:40.017351  9913 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 22:13:55.542023  9913 solver.cpp:237] Iteration 960, loss = 0.640345
I0204 22:13:55.542212  9913 solver.cpp:253]     Train net output #0: loss = 0.640345 (* 1 = 0.640345 loss)
I0204 22:13:55.542225  9913 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 22:14:11.068773  9913 solver.cpp:237] Iteration 970, loss = 0.682946
I0204 22:14:11.068833  9913 solver.cpp:253]     Train net output #0: loss = 0.682946 (* 1 = 0.682946 loss)
I0204 22:14:11.068845  9913 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 22:14:26.600569  9913 solver.cpp:237] Iteration 980, loss = 0.720876
I0204 22:14:26.600762  9913 solver.cpp:253]     Train net output #0: loss = 0.720876 (* 1 = 0.720876 loss)
I0204 22:14:26.600775  9913 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 22:14:42.121229  9913 solver.cpp:237] Iteration 990, loss = 0.675188
I0204 22:14:42.121290  9913 solver.cpp:253]     Train net output #0: loss = 0.675188 (* 1 = 0.675188 loss)
I0204 22:14:42.121302  9913 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 22:14:56.101999  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1000.caffemodel
I0204 22:14:56.105561  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1000.solverstate
I0204 22:14:56.106967  9913 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 22:15:03.228598  9913 solver.cpp:409]     Test net output #0: accuracy = 0.594
I0204 22:15:03.228770  9913 solver.cpp:409]     Test net output #1: loss = 0.660505 (* 1 = 0.660505 loss)
I0204 22:15:04.778821  9913 solver.cpp:237] Iteration 1000, loss = 0.682731
I0204 22:15:04.778874  9913 solver.cpp:253]     Train net output #0: loss = 0.682731 (* 1 = 0.682731 loss)
I0204 22:15:04.778898  9913 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 22:15:20.306462  9913 solver.cpp:237] Iteration 1010, loss = 0.655028
I0204 22:15:20.306519  9913 solver.cpp:253]     Train net output #0: loss = 0.655028 (* 1 = 0.655028 loss)
I0204 22:15:20.306530  9913 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 22:15:35.826795  9913 solver.cpp:237] Iteration 1020, loss = 0.746
I0204 22:15:35.827025  9913 solver.cpp:253]     Train net output #0: loss = 0.746 (* 1 = 0.746 loss)
I0204 22:15:35.827039  9913 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 22:15:51.365787  9913 solver.cpp:237] Iteration 1030, loss = 0.616577
I0204 22:15:51.365847  9913 solver.cpp:253]     Train net output #0: loss = 0.616577 (* 1 = 0.616577 loss)
I0204 22:15:51.365859  9913 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 22:16:06.886418  9913 solver.cpp:237] Iteration 1040, loss = 0.616905
I0204 22:16:06.886612  9913 solver.cpp:253]     Train net output #0: loss = 0.616905 (* 1 = 0.616905 loss)
I0204 22:16:06.886626  9913 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 22:16:22.407524  9913 solver.cpp:237] Iteration 1050, loss = 0.707655
I0204 22:16:22.407583  9913 solver.cpp:253]     Train net output #0: loss = 0.707655 (* 1 = 0.707655 loss)
I0204 22:16:22.407595  9913 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 22:16:37.923324  9913 solver.cpp:237] Iteration 1060, loss = 0.609128
I0204 22:16:37.923511  9913 solver.cpp:253]     Train net output #0: loss = 0.609128 (* 1 = 0.609128 loss)
I0204 22:16:37.923523  9913 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 22:16:53.495805  9913 solver.cpp:237] Iteration 1070, loss = 0.592677
I0204 22:16:53.495862  9913 solver.cpp:253]     Train net output #0: loss = 0.592677 (* 1 = 0.592677 loss)
I0204 22:16:53.495873  9913 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 22:17:09.126916  9913 solver.cpp:237] Iteration 1080, loss = 0.673732
I0204 22:17:09.127120  9913 solver.cpp:253]     Train net output #0: loss = 0.673732 (* 1 = 0.673732 loss)
I0204 22:17:09.127133  9913 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 22:17:24.772080  9913 solver.cpp:237] Iteration 1090, loss = 0.597521
I0204 22:17:24.772140  9913 solver.cpp:253]     Train net output #0: loss = 0.597521 (* 1 = 0.597521 loss)
I0204 22:17:24.772151  9913 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 22:17:38.755983  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1100.caffemodel
I0204 22:17:38.759529  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1100.solverstate
I0204 22:17:38.760934  9913 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 22:17:45.880988  9913 solver.cpp:409]     Test net output #0: accuracy = 0.7
I0204 22:17:45.881199  9913 solver.cpp:409]     Test net output #1: loss = 0.580373 (* 1 = 0.580373 loss)
I0204 22:17:47.431416  9913 solver.cpp:237] Iteration 1100, loss = 0.639862
I0204 22:17:47.431470  9913 solver.cpp:253]     Train net output #0: loss = 0.639862 (* 1 = 0.639862 loss)
I0204 22:17:47.431481  9913 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 22:18:02.955677  9913 solver.cpp:237] Iteration 1110, loss = 0.605259
I0204 22:18:02.955734  9913 solver.cpp:253]     Train net output #0: loss = 0.605259 (* 1 = 0.605259 loss)
I0204 22:18:02.955745  9913 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 22:18:18.488056  9913 solver.cpp:237] Iteration 1120, loss = 0.611396
I0204 22:18:18.488242  9913 solver.cpp:253]     Train net output #0: loss = 0.611396 (* 1 = 0.611396 loss)
I0204 22:18:18.488255  9913 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 22:18:34.017256  9913 solver.cpp:237] Iteration 1130, loss = 0.539962
I0204 22:18:34.017318  9913 solver.cpp:253]     Train net output #0: loss = 0.539962 (* 1 = 0.539962 loss)
I0204 22:18:34.017341  9913 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 22:18:49.539304  9913 solver.cpp:237] Iteration 1140, loss = 0.61658
I0204 22:18:49.539540  9913 solver.cpp:253]     Train net output #0: loss = 0.61658 (* 1 = 0.61658 loss)
I0204 22:18:49.539552  9913 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 22:19:05.186939  9913 solver.cpp:237] Iteration 1150, loss = 0.580229
I0204 22:19:05.187028  9913 solver.cpp:253]     Train net output #0: loss = 0.580229 (* 1 = 0.580229 loss)
I0204 22:19:05.187042  9913 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 22:19:20.707527  9913 solver.cpp:237] Iteration 1160, loss = 0.623588
I0204 22:19:21.253217  9913 solver.cpp:253]     Train net output #0: loss = 0.623588 (* 1 = 0.623588 loss)
I0204 22:19:21.253252  9913 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 22:19:36.778471  9913 solver.cpp:237] Iteration 1170, loss = 0.634448
I0204 22:19:36.778532  9913 solver.cpp:253]     Train net output #0: loss = 0.634448 (* 1 = 0.634448 loss)
I0204 22:19:36.778543  9913 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 22:19:52.291076  9913 solver.cpp:237] Iteration 1180, loss = 0.868216
I0204 22:19:52.291260  9913 solver.cpp:253]     Train net output #0: loss = 0.868216 (* 1 = 0.868216 loss)
I0204 22:19:52.291272  9913 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 22:20:07.810552  9913 solver.cpp:237] Iteration 1190, loss = 0.598863
I0204 22:20:07.810611  9913 solver.cpp:253]     Train net output #0: loss = 0.598863 (* 1 = 0.598863 loss)
I0204 22:20:07.810622  9913 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 22:20:21.777987  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1200.caffemodel
I0204 22:20:21.781508  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1200.solverstate
I0204 22:20:21.782902  9913 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 22:20:28.903318  9913 solver.cpp:409]     Test net output #0: accuracy = 0.808
I0204 22:20:28.903467  9913 solver.cpp:409]     Test net output #1: loss = 0.500056 (* 1 = 0.500056 loss)
I0204 22:20:30.453558  9913 solver.cpp:237] Iteration 1200, loss = 0.503055
I0204 22:20:30.453604  9913 solver.cpp:253]     Train net output #0: loss = 0.503055 (* 1 = 0.503055 loss)
I0204 22:20:30.453615  9913 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 22:20:45.963892  9913 solver.cpp:237] Iteration 1210, loss = 0.511307
I0204 22:20:45.963965  9913 solver.cpp:253]     Train net output #0: loss = 0.511307 (* 1 = 0.511307 loss)
I0204 22:20:45.963976  9913 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 22:21:01.498358  9913 solver.cpp:237] Iteration 1220, loss = 0.455114
I0204 22:21:01.498541  9913 solver.cpp:253]     Train net output #0: loss = 0.455114 (* 1 = 0.455114 loss)
I0204 22:21:01.498555  9913 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 22:21:17.019482  9913 solver.cpp:237] Iteration 1230, loss = 0.413728
I0204 22:21:17.019544  9913 solver.cpp:253]     Train net output #0: loss = 0.413728 (* 1 = 0.413728 loss)
I0204 22:21:17.019556  9913 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 22:21:32.536345  9913 solver.cpp:237] Iteration 1240, loss = 0.377147
I0204 22:21:32.536536  9913 solver.cpp:253]     Train net output #0: loss = 0.377147 (* 1 = 0.377147 loss)
I0204 22:21:32.536550  9913 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 22:21:48.055717  9913 solver.cpp:237] Iteration 1250, loss = 0.209257
I0204 22:21:48.055778  9913 solver.cpp:253]     Train net output #0: loss = 0.209257 (* 1 = 0.209257 loss)
I0204 22:21:48.055789  9913 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 22:22:03.571949  9913 solver.cpp:237] Iteration 1260, loss = 0.133002
I0204 22:22:03.572212  9913 solver.cpp:253]     Train net output #0: loss = 0.133002 (* 1 = 0.133002 loss)
I0204 22:22:03.572232  9913 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 22:22:19.090112  9913 solver.cpp:237] Iteration 1270, loss = 0.122451
I0204 22:22:19.090170  9913 solver.cpp:253]     Train net output #0: loss = 0.122451 (* 1 = 0.122451 loss)
I0204 22:22:19.090181  9913 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 22:22:34.601582  9913 solver.cpp:237] Iteration 1280, loss = 0.202095
I0204 22:22:34.601778  9913 solver.cpp:253]     Train net output #0: loss = 0.202095 (* 1 = 0.202095 loss)
I0204 22:22:34.601790  9913 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 22:22:50.128342  9913 solver.cpp:237] Iteration 1290, loss = 0.220083
I0204 22:22:50.128407  9913 solver.cpp:253]     Train net output #0: loss = 0.220083 (* 1 = 0.220083 loss)
I0204 22:22:50.128418  9913 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 22:23:04.096402  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1300.caffemodel
I0204 22:23:04.100021  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1300.solverstate
I0204 22:23:04.101366  9913 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 22:23:11.220715  9913 solver.cpp:409]     Test net output #0: accuracy = 0.945
I0204 22:23:11.220898  9913 solver.cpp:409]     Test net output #1: loss = 0.13479 (* 1 = 0.13479 loss)
I0204 22:23:12.772029  9913 solver.cpp:237] Iteration 1300, loss = 0.281949
I0204 22:23:12.772083  9913 solver.cpp:253]     Train net output #0: loss = 0.281949 (* 1 = 0.281949 loss)
I0204 22:23:12.772095  9913 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 22:23:28.295164  9913 solver.cpp:237] Iteration 1310, loss = 0.0849096
I0204 22:23:28.295228  9913 solver.cpp:253]     Train net output #0: loss = 0.0849096 (* 1 = 0.0849096 loss)
I0204 22:23:28.295239  9913 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 22:23:43.819756  9913 solver.cpp:237] Iteration 1320, loss = 0.0991211
I0204 22:23:43.819942  9913 solver.cpp:253]     Train net output #0: loss = 0.0991211 (* 1 = 0.0991211 loss)
I0204 22:23:43.819957  9913 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 22:23:59.347101  9913 solver.cpp:237] Iteration 1330, loss = 0.103792
I0204 22:23:59.347159  9913 solver.cpp:253]     Train net output #0: loss = 0.103792 (* 1 = 0.103792 loss)
I0204 22:23:59.347170  9913 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 22:24:14.892307  9913 solver.cpp:237] Iteration 1340, loss = 0.1672
I0204 22:24:14.892490  9913 solver.cpp:253]     Train net output #0: loss = 0.1672 (* 1 = 0.1672 loss)
I0204 22:24:14.892504  9913 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 22:24:30.432178  9913 solver.cpp:237] Iteration 1350, loss = 0.0838129
I0204 22:24:30.432238  9913 solver.cpp:253]     Train net output #0: loss = 0.0838128 (* 1 = 0.0838128 loss)
I0204 22:24:30.432250  9913 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 22:24:45.968451  9913 solver.cpp:237] Iteration 1360, loss = 0.0787108
I0204 22:24:45.968639  9913 solver.cpp:253]     Train net output #0: loss = 0.0787108 (* 1 = 0.0787108 loss)
I0204 22:24:45.968652  9913 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 22:25:01.518389  9913 solver.cpp:237] Iteration 1370, loss = 0.0480347
I0204 22:25:01.518448  9913 solver.cpp:253]     Train net output #0: loss = 0.0480346 (* 1 = 0.0480346 loss)
I0204 22:25:01.518460  9913 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 22:25:17.067944  9913 solver.cpp:237] Iteration 1380, loss = 0.108267
I0204 22:25:17.068141  9913 solver.cpp:253]     Train net output #0: loss = 0.108267 (* 1 = 0.108267 loss)
I0204 22:25:17.068155  9913 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 22:25:32.604228  9913 solver.cpp:237] Iteration 1390, loss = 0.12521
I0204 22:25:32.604285  9913 solver.cpp:253]     Train net output #0: loss = 0.12521 (* 1 = 0.12521 loss)
I0204 22:25:32.604310  9913 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 22:25:46.565737  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1400.caffemodel
I0204 22:25:46.569308  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1400.solverstate
I0204 22:25:46.570703  9913 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 22:25:53.690361  9913 solver.cpp:409]     Test net output #0: accuracy = 0.965
I0204 22:25:53.690567  9913 solver.cpp:409]     Test net output #1: loss = 0.120604 (* 1 = 0.120604 loss)
I0204 22:25:55.242836  9913 solver.cpp:237] Iteration 1400, loss = 0.314452
I0204 22:25:55.242889  9913 solver.cpp:253]     Train net output #0: loss = 0.314452 (* 1 = 0.314452 loss)
I0204 22:25:55.242900  9913 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 22:26:10.756081  9913 solver.cpp:237] Iteration 1410, loss = 0.0555868
I0204 22:26:10.756147  9913 solver.cpp:253]     Train net output #0: loss = 0.0555867 (* 1 = 0.0555867 loss)
I0204 22:26:10.756158  9913 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 22:26:26.272929  9913 solver.cpp:237] Iteration 1420, loss = 0.0352312
I0204 22:26:26.273144  9913 solver.cpp:253]     Train net output #0: loss = 0.0352311 (* 1 = 0.0352311 loss)
I0204 22:26:26.273156  9913 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 22:26:41.787283  9913 solver.cpp:237] Iteration 1430, loss = 0.0159423
I0204 22:26:41.787340  9913 solver.cpp:253]     Train net output #0: loss = 0.0159422 (* 1 = 0.0159422 loss)
I0204 22:26:41.787351  9913 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 22:26:57.305330  9913 solver.cpp:237] Iteration 1440, loss = 0.0864362
I0204 22:26:57.305506  9913 solver.cpp:253]     Train net output #0: loss = 0.0864361 (* 1 = 0.0864361 loss)
I0204 22:26:57.305519  9913 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 22:27:12.844413  9913 solver.cpp:237] Iteration 1450, loss = 0.0296077
I0204 22:27:12.844472  9913 solver.cpp:253]     Train net output #0: loss = 0.0296075 (* 1 = 0.0296075 loss)
I0204 22:27:12.844483  9913 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 22:27:28.397521  9913 solver.cpp:237] Iteration 1460, loss = 0.1241
I0204 22:27:28.397702  9913 solver.cpp:253]     Train net output #0: loss = 0.1241 (* 1 = 0.1241 loss)
I0204 22:27:28.397716  9913 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 22:27:43.941280  9913 solver.cpp:237] Iteration 1470, loss = 0.0539194
I0204 22:27:43.941340  9913 solver.cpp:253]     Train net output #0: loss = 0.0539193 (* 1 = 0.0539193 loss)
I0204 22:27:43.941352  9913 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 22:27:59.472729  9913 solver.cpp:237] Iteration 1480, loss = 0.0125441
I0204 22:27:59.472904  9913 solver.cpp:253]     Train net output #0: loss = 0.012544 (* 1 = 0.012544 loss)
I0204 22:27:59.472918  9913 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 22:28:15.000423  9913 solver.cpp:237] Iteration 1490, loss = 0.0253673
I0204 22:28:15.000483  9913 solver.cpp:253]     Train net output #0: loss = 0.0253672 (* 1 = 0.0253672 loss)
I0204 22:28:15.000494  9913 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 22:28:28.972203  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1500.caffemodel
I0204 22:28:28.975744  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1500.solverstate
I0204 22:28:28.977147  9913 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 22:28:36.111035  9913 solver.cpp:409]     Test net output #0: accuracy = 0.993
I0204 22:28:36.111243  9913 solver.cpp:409]     Test net output #1: loss = 0.0240501 (* 1 = 0.0240501 loss)
I0204 22:28:37.662504  9913 solver.cpp:237] Iteration 1500, loss = 0.0280241
I0204 22:28:37.662557  9913 solver.cpp:253]     Train net output #0: loss = 0.028024 (* 1 = 0.028024 loss)
I0204 22:28:37.662569  9913 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 22:28:53.202764  9913 solver.cpp:237] Iteration 1510, loss = 0.00865887
I0204 22:28:53.202821  9913 solver.cpp:253]     Train net output #0: loss = 0.00865877 (* 1 = 0.00865877 loss)
I0204 22:28:53.202832  9913 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 22:29:08.762209  9913 solver.cpp:237] Iteration 1520, loss = 0.0331547
I0204 22:29:08.762403  9913 solver.cpp:253]     Train net output #0: loss = 0.0331546 (* 1 = 0.0331546 loss)
I0204 22:29:08.762416  9913 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 22:29:24.309454  9913 solver.cpp:237] Iteration 1530, loss = 0.0231271
I0204 22:29:24.309514  9913 solver.cpp:253]     Train net output #0: loss = 0.023127 (* 1 = 0.023127 loss)
I0204 22:29:24.309525  9913 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 22:29:39.847321  9913 solver.cpp:237] Iteration 1540, loss = 0.109349
I0204 22:29:39.847494  9913 solver.cpp:253]     Train net output #0: loss = 0.109349 (* 1 = 0.109349 loss)
I0204 22:29:39.847507  9913 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 22:29:55.392174  9913 solver.cpp:237] Iteration 1550, loss = 0.0396419
I0204 22:29:55.392231  9913 solver.cpp:253]     Train net output #0: loss = 0.0396418 (* 1 = 0.0396418 loss)
I0204 22:29:55.392242  9913 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 22:30:10.939036  9913 solver.cpp:237] Iteration 1560, loss = 0.00764196
I0204 22:30:10.939229  9913 solver.cpp:253]     Train net output #0: loss = 0.00764185 (* 1 = 0.00764185 loss)
I0204 22:30:10.939242  9913 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 22:30:26.492449  9913 solver.cpp:237] Iteration 1570, loss = 0.0210625
I0204 22:30:26.492511  9913 solver.cpp:253]     Train net output #0: loss = 0.0210624 (* 1 = 0.0210624 loss)
I0204 22:30:26.492522  9913 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 22:30:42.093626  9913 solver.cpp:237] Iteration 1580, loss = 0.00790416
I0204 22:30:42.093817  9913 solver.cpp:253]     Train net output #0: loss = 0.00790405 (* 1 = 0.00790405 loss)
I0204 22:30:42.093832  9913 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 22:30:57.779250  9913 solver.cpp:237] Iteration 1590, loss = 0.0113961
I0204 22:30:57.779307  9913 solver.cpp:253]     Train net output #0: loss = 0.011396 (* 1 = 0.011396 loss)
I0204 22:30:57.779320  9913 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 22:31:11.897439  9913 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1600.caffemodel
I0204 22:31:11.901001  9913 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed14/snaps/snap__iter_1600.solverstate
I0204 22:31:12.618475  9913 solver.cpp:321] Iteration 1600, loss = 0.0147039
I0204 22:31:12.618659  9913 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 22:31:19.829370  9913 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 22:31:19.829419  9913 solver.cpp:409]     Test net output #1: loss = 0.0107234 (* 1 = 0.0107234 loss)
I0204 22:31:19.829428  9913 solver.cpp:326] Optimization Done.
I0204 22:31:19.829434  9913 caffe.cpp:215] Optimization Done.
