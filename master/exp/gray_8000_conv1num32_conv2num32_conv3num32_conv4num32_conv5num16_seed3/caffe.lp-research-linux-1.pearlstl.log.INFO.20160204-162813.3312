Log file created at: 2016/02/04 16:28:13
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 16:28:13.685678  3312 caffe.cpp:177] Use CPU.
I0204 16:28:13.686311  3312 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap_"
solver_mode: CPU
random_seed: 3
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/train_val.prototxt"
I0204 16:28:13.686467  3312 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/train_val.prototxt
I0204 16:28:13.687088  3312 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:28:13.687119  3312 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:28:13.687362  3312 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.687511  3312 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.687716  3312 net.cpp:106] Creating Layer data
I0204 16:28:13.687734  3312 net.cpp:411] data -> data
I0204 16:28:13.687777  3312 net.cpp:411] data -> label
I0204 16:28:13.687798  3312 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:28:13.687834  3317 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:28:13.688868  3312 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.727141  3312 net.cpp:150] Setting up data
I0204 16:28:13.727304  3312 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.727330  3312 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.727342  3312 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.727371  3312 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.727421  3312 net.cpp:106] Creating Layer conv1
I0204 16:28:13.727438  3312 net.cpp:454] conv1 <- data
I0204 16:28:13.727471  3312 net.cpp:411] conv1 -> conv1
I0204 16:28:13.727685  3312 net.cpp:150] Setting up conv1
I0204 16:28:13.727708  3312 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.727718  3312 net.cpp:165] Memory required for data: 59332000
I0204 16:28:13.727754  3312 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.727778  3312 net.cpp:106] Creating Layer relu1
I0204 16:28:13.727790  3312 net.cpp:454] relu1 <- conv1
I0204 16:28:13.727807  3312 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.727831  3312 net.cpp:150] Setting up relu1
I0204 16:28:13.727851  3312 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.727862  3312 net.cpp:165] Memory required for data: 98052000
I0204 16:28:13.727874  3312 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.727892  3312 net.cpp:106] Creating Layer pool1
I0204 16:28:13.727903  3312 net.cpp:454] pool1 <- conv1
I0204 16:28:13.727919  3312 net.cpp:411] pool1 -> pool1
I0204 16:28:13.727964  3312 net.cpp:150] Setting up pool1
I0204 16:28:13.727988  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.727998  3312 net.cpp:165] Memory required for data: 107383200
I0204 16:28:13.728010  3312 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.728077  3312 net.cpp:106] Creating Layer norm1
I0204 16:28:13.728091  3312 net.cpp:454] norm1 <- pool1
I0204 16:28:13.728107  3312 net.cpp:411] norm1 -> norm1
I0204 16:28:13.728140  3312 net.cpp:150] Setting up norm1
I0204 16:28:13.728157  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.728168  3312 net.cpp:165] Memory required for data: 116714400
I0204 16:28:13.728183  3312 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.728205  3312 net.cpp:106] Creating Layer conv2
I0204 16:28:13.728216  3312 net.cpp:454] conv2 <- norm1
I0204 16:28:13.728234  3312 net.cpp:411] conv2 -> conv2
I0204 16:28:13.728507  3312 net.cpp:150] Setting up conv2
I0204 16:28:13.728525  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.728534  3312 net.cpp:165] Memory required for data: 126045600
I0204 16:28:13.728555  3312 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.728572  3312 net.cpp:106] Creating Layer relu2
I0204 16:28:13.728585  3312 net.cpp:454] relu2 <- conv2
I0204 16:28:13.728617  3312 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.728639  3312 net.cpp:150] Setting up relu2
I0204 16:28:13.728653  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.728663  3312 net.cpp:165] Memory required for data: 135376800
I0204 16:28:13.728675  3312 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.728691  3312 net.cpp:106] Creating Layer pool2
I0204 16:28:13.728701  3312 net.cpp:454] pool2 <- conv2
I0204 16:28:13.728723  3312 net.cpp:411] pool2 -> pool2
I0204 16:28:13.728745  3312 net.cpp:150] Setting up pool2
I0204 16:28:13.728760  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.728770  3312 net.cpp:165] Memory required for data: 137540000
I0204 16:28:13.728780  3312 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.728797  3312 net.cpp:106] Creating Layer norm2
I0204 16:28:13.728812  3312 net.cpp:454] norm2 <- pool2
I0204 16:28:13.728832  3312 net.cpp:411] norm2 -> norm2
I0204 16:28:13.728852  3312 net.cpp:150] Setting up norm2
I0204 16:28:13.728866  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.728875  3312 net.cpp:165] Memory required for data: 139703200
I0204 16:28:13.728885  3312 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.728905  3312 net.cpp:106] Creating Layer conv3
I0204 16:28:13.728921  3312 net.cpp:454] conv3 <- norm2
I0204 16:28:13.728940  3312 net.cpp:411] conv3 -> conv3
I0204 16:28:13.729183  3312 net.cpp:150] Setting up conv3
I0204 16:28:13.729204  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.729214  3312 net.cpp:165] Memory required for data: 141866400
I0204 16:28:13.729234  3312 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.729264  3312 net.cpp:106] Creating Layer relu3
I0204 16:28:13.729276  3312 net.cpp:454] relu3 <- conv3
I0204 16:28:13.729291  3312 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.729310  3312 net.cpp:150] Setting up relu3
I0204 16:28:13.729323  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.729333  3312 net.cpp:165] Memory required for data: 144029600
I0204 16:28:13.729343  3312 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.729370  3312 net.cpp:106] Creating Layer conv4
I0204 16:28:13.729383  3312 net.cpp:454] conv4 <- conv3
I0204 16:28:13.729405  3312 net.cpp:411] conv4 -> conv4
I0204 16:28:13.729542  3312 net.cpp:150] Setting up conv4
I0204 16:28:13.729558  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.729573  3312 net.cpp:165] Memory required for data: 146192800
I0204 16:28:13.729591  3312 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.729607  3312 net.cpp:106] Creating Layer relu4
I0204 16:28:13.729619  3312 net.cpp:454] relu4 <- conv4
I0204 16:28:13.729635  3312 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.729651  3312 net.cpp:150] Setting up relu4
I0204 16:28:13.729666  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.729681  3312 net.cpp:165] Memory required for data: 148356000
I0204 16:28:13.729703  3312 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.729740  3312 net.cpp:106] Creating Layer conv5
I0204 16:28:13.729753  3312 net.cpp:454] conv5 <- conv4
I0204 16:28:13.729769  3312 net.cpp:411] conv5 -> conv5
I0204 16:28:13.729861  3312 net.cpp:150] Setting up conv5
I0204 16:28:13.729877  3312 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.729892  3312 net.cpp:165] Memory required for data: 149437600
I0204 16:28:13.729913  3312 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.729928  3312 net.cpp:106] Creating Layer relu5
I0204 16:28:13.729939  3312 net.cpp:454] relu5 <- conv5
I0204 16:28:13.729957  3312 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.729974  3312 net.cpp:150] Setting up relu5
I0204 16:28:13.729991  3312 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.730002  3312 net.cpp:165] Memory required for data: 150519200
I0204 16:28:13.730013  3312 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.730029  3312 net.cpp:106] Creating Layer pool5
I0204 16:28:13.730041  3312 net.cpp:454] pool5 <- conv5
I0204 16:28:13.730069  3312 net.cpp:411] pool5 -> pool5
I0204 16:28:13.730093  3312 net.cpp:150] Setting up pool5
I0204 16:28:13.730113  3312 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.730123  3312 net.cpp:165] Memory required for data: 150749600
I0204 16:28:13.730134  3312 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.730164  3312 net.cpp:106] Creating Layer fc6
I0204 16:28:13.730177  3312 net.cpp:454] fc6 <- pool5
I0204 16:28:13.730202  3312 net.cpp:411] fc6 -> fc6
I0204 16:28:13.735285  3312 net.cpp:150] Setting up fc6
I0204 16:28:13.735328  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.735340  3312 net.cpp:165] Memory required for data: 150852000
I0204 16:28:13.735363  3312 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.735389  3312 net.cpp:106] Creating Layer relu6
I0204 16:28:13.735404  3312 net.cpp:454] relu6 <- fc6
I0204 16:28:13.735425  3312 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.735450  3312 net.cpp:150] Setting up relu6
I0204 16:28:13.735468  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.735479  3312 net.cpp:165] Memory required for data: 150954400
I0204 16:28:13.735491  3312 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.735509  3312 net.cpp:106] Creating Layer drop6
I0204 16:28:13.735520  3312 net.cpp:454] drop6 <- fc6
I0204 16:28:13.735539  3312 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.735574  3312 net.cpp:150] Setting up drop6
I0204 16:28:13.735589  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.735599  3312 net.cpp:165] Memory required for data: 151056800
I0204 16:28:13.735610  3312 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.735638  3312 net.cpp:106] Creating Layer fc7
I0204 16:28:13.735651  3312 net.cpp:454] fc7 <- fc6
I0204 16:28:13.735671  3312 net.cpp:411] fc7 -> fc7
I0204 16:28:13.738548  3312 net.cpp:150] Setting up fc7
I0204 16:28:13.738618  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.738628  3312 net.cpp:165] Memory required for data: 151159200
I0204 16:28:13.738659  3312 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.738692  3312 net.cpp:106] Creating Layer relu7
I0204 16:28:13.738708  3312 net.cpp:454] relu7 <- fc7
I0204 16:28:13.738728  3312 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.738756  3312 net.cpp:150] Setting up relu7
I0204 16:28:13.738770  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.738780  3312 net.cpp:165] Memory required for data: 151261600
I0204 16:28:13.738792  3312 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.738823  3312 net.cpp:106] Creating Layer drop7
I0204 16:28:13.738836  3312 net.cpp:454] drop7 <- fc7
I0204 16:28:13.738847  3312 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.738867  3312 net.cpp:150] Setting up drop7
I0204 16:28:13.738878  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.738885  3312 net.cpp:165] Memory required for data: 151364000
I0204 16:28:13.738898  3312 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.738930  3312 net.cpp:106] Creating Layer fc8
I0204 16:28:13.738953  3312 net.cpp:454] fc8 <- fc7
I0204 16:28:13.738966  3312 net.cpp:411] fc8 -> fc8
I0204 16:28:13.739012  3312 net.cpp:150] Setting up fc8
I0204 16:28:13.739025  3312 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.739032  3312 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.739044  3312 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.739061  3312 net.cpp:106] Creating Layer loss
I0204 16:28:13.739085  3312 net.cpp:454] loss <- fc8
I0204 16:28:13.739095  3312 net.cpp:454] loss <- label
I0204 16:28:13.739110  3312 net.cpp:411] loss -> loss
I0204 16:28:13.739132  3312 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.739168  3312 net.cpp:150] Setting up loss
I0204 16:28:13.739181  3312 net.cpp:157] Top shape: (1)
I0204 16:28:13.739188  3312 net.cpp:160]     with loss weight 1
I0204 16:28:13.739238  3312 net.cpp:165] Memory required for data: 151364804
I0204 16:28:13.739251  3312 net.cpp:226] loss needs backward computation.
I0204 16:28:13.739261  3312 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.739272  3312 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.739280  3312 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.739289  3312 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.739296  3312 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.739305  3312 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.739313  3312 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.739321  3312 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.739333  3312 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.739342  3312 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.739351  3312 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.739361  3312 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.739372  3312 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.739380  3312 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.739401  3312 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.739413  3312 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.739423  3312 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.739433  3312 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.739444  3312 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.739454  3312 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.739462  3312 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.739473  3312 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.739485  3312 net.cpp:228] data does not need backward computation.
I0204 16:28:13.739493  3312 net.cpp:270] This network produces output loss
I0204 16:28:13.739542  3312 net.cpp:283] Network initialization done.
I0204 16:28:13.740806  3312 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/train_val.prototxt
I0204 16:28:13.740897  3312 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:28:13.741415  3312 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.741695  3312 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.741971  3312 net.cpp:106] Creating Layer data
I0204 16:28:13.741999  3312 net.cpp:411] data -> data
I0204 16:28:13.742025  3312 net.cpp:411] data -> label
I0204 16:28:13.742054  3312 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:28:13.743438  3336 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:28:13.743669  3312 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.803560  3312 net.cpp:150] Setting up data
I0204 16:28:13.803633  3312 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.803649  3312 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.803660  3312 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.803678  3312 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:28:13.803731  3312 net.cpp:106] Creating Layer label_data_1_split
I0204 16:28:13.803748  3312 net.cpp:454] label_data_1_split <- label
I0204 16:28:13.803769  3312 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:28:13.803800  3312 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:28:13.803829  3312 net.cpp:150] Setting up label_data_1_split
I0204 16:28:13.803844  3312 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.803859  3312 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.803869  3312 net.cpp:165] Memory required for data: 20612800
I0204 16:28:13.803879  3312 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.803906  3312 net.cpp:106] Creating Layer conv1
I0204 16:28:13.803918  3312 net.cpp:454] conv1 <- data
I0204 16:28:13.803936  3312 net.cpp:411] conv1 -> conv1
I0204 16:28:13.804071  3312 net.cpp:150] Setting up conv1
I0204 16:28:13.804091  3312 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.804101  3312 net.cpp:165] Memory required for data: 59332800
I0204 16:28:13.804126  3312 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.804146  3312 net.cpp:106] Creating Layer relu1
I0204 16:28:13.804165  3312 net.cpp:454] relu1 <- conv1
I0204 16:28:13.804180  3312 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.804198  3312 net.cpp:150] Setting up relu1
I0204 16:28:13.804211  3312 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.804221  3312 net.cpp:165] Memory required for data: 98052800
I0204 16:28:13.804232  3312 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.804250  3312 net.cpp:106] Creating Layer pool1
I0204 16:28:13.804261  3312 net.cpp:454] pool1 <- conv1
I0204 16:28:13.804275  3312 net.cpp:411] pool1 -> pool1
I0204 16:28:13.804299  3312 net.cpp:150] Setting up pool1
I0204 16:28:13.804312  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.804322  3312 net.cpp:165] Memory required for data: 107384000
I0204 16:28:13.804332  3312 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.804348  3312 net.cpp:106] Creating Layer norm1
I0204 16:28:13.804359  3312 net.cpp:454] norm1 <- pool1
I0204 16:28:13.804376  3312 net.cpp:411] norm1 -> norm1
I0204 16:28:13.804396  3312 net.cpp:150] Setting up norm1
I0204 16:28:13.804409  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.804419  3312 net.cpp:165] Memory required for data: 116715200
I0204 16:28:13.804430  3312 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.804450  3312 net.cpp:106] Creating Layer conv2
I0204 16:28:13.804461  3312 net.cpp:454] conv2 <- norm1
I0204 16:28:13.804474  3312 net.cpp:411] conv2 -> conv2
I0204 16:28:13.804736  3312 net.cpp:150] Setting up conv2
I0204 16:28:13.804752  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.804762  3312 net.cpp:165] Memory required for data: 126046400
I0204 16:28:13.804786  3312 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.804802  3312 net.cpp:106] Creating Layer relu2
I0204 16:28:13.804813  3312 net.cpp:454] relu2 <- conv2
I0204 16:28:13.804843  3312 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.804879  3312 net.cpp:150] Setting up relu2
I0204 16:28:13.804893  3312 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.804901  3312 net.cpp:165] Memory required for data: 135377600
I0204 16:28:13.804911  3312 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.804932  3312 net.cpp:106] Creating Layer pool2
I0204 16:28:13.804944  3312 net.cpp:454] pool2 <- conv2
I0204 16:28:13.804960  3312 net.cpp:411] pool2 -> pool2
I0204 16:28:13.804980  3312 net.cpp:150] Setting up pool2
I0204 16:28:13.804993  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805003  3312 net.cpp:165] Memory required for data: 137540800
I0204 16:28:13.805012  3312 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.805027  3312 net.cpp:106] Creating Layer norm2
I0204 16:28:13.805037  3312 net.cpp:454] norm2 <- pool2
I0204 16:28:13.805050  3312 net.cpp:411] norm2 -> norm2
I0204 16:28:13.805073  3312 net.cpp:150] Setting up norm2
I0204 16:28:13.805085  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805095  3312 net.cpp:165] Memory required for data: 139704000
I0204 16:28:13.805104  3312 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.805122  3312 net.cpp:106] Creating Layer conv3
I0204 16:28:13.805132  3312 net.cpp:454] conv3 <- norm2
I0204 16:28:13.805147  3312 net.cpp:411] conv3 -> conv3
I0204 16:28:13.805367  3312 net.cpp:150] Setting up conv3
I0204 16:28:13.805383  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805393  3312 net.cpp:165] Memory required for data: 141867200
I0204 16:28:13.805413  3312 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.805428  3312 net.cpp:106] Creating Layer relu3
I0204 16:28:13.805438  3312 net.cpp:454] relu3 <- conv3
I0204 16:28:13.805452  3312 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.805469  3312 net.cpp:150] Setting up relu3
I0204 16:28:13.805481  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805490  3312 net.cpp:165] Memory required for data: 144030400
I0204 16:28:13.805503  3312 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.805524  3312 net.cpp:106] Creating Layer conv4
I0204 16:28:13.805536  3312 net.cpp:454] conv4 <- conv3
I0204 16:28:13.805551  3312 net.cpp:411] conv4 -> conv4
I0204 16:28:13.805675  3312 net.cpp:150] Setting up conv4
I0204 16:28:13.805691  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805699  3312 net.cpp:165] Memory required for data: 146193600
I0204 16:28:13.805716  3312 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.805730  3312 net.cpp:106] Creating Layer relu4
I0204 16:28:13.805742  3312 net.cpp:454] relu4 <- conv4
I0204 16:28:13.805755  3312 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.805771  3312 net.cpp:150] Setting up relu4
I0204 16:28:13.805784  3312 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.805794  3312 net.cpp:165] Memory required for data: 148356800
I0204 16:28:13.805804  3312 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.805824  3312 net.cpp:106] Creating Layer conv5
I0204 16:28:13.805835  3312 net.cpp:454] conv5 <- conv4
I0204 16:28:13.805850  3312 net.cpp:411] conv5 -> conv5
I0204 16:28:13.805923  3312 net.cpp:150] Setting up conv5
I0204 16:28:13.805938  3312 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.805946  3312 net.cpp:165] Memory required for data: 149438400
I0204 16:28:13.805969  3312 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.805985  3312 net.cpp:106] Creating Layer relu5
I0204 16:28:13.805996  3312 net.cpp:454] relu5 <- conv5
I0204 16:28:13.806010  3312 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.806025  3312 net.cpp:150] Setting up relu5
I0204 16:28:13.806036  3312 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.806046  3312 net.cpp:165] Memory required for data: 150520000
I0204 16:28:13.806056  3312 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.806074  3312 net.cpp:106] Creating Layer pool5
I0204 16:28:13.806087  3312 net.cpp:454] pool5 <- conv5
I0204 16:28:13.806120  3312 net.cpp:411] pool5 -> pool5
I0204 16:28:13.806143  3312 net.cpp:150] Setting up pool5
I0204 16:28:13.806162  3312 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.806172  3312 net.cpp:165] Memory required for data: 150750400
I0204 16:28:13.806182  3312 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.806201  3312 net.cpp:106] Creating Layer fc6
I0204 16:28:13.806212  3312 net.cpp:454] fc6 <- pool5
I0204 16:28:13.806231  3312 net.cpp:411] fc6 -> fc6
I0204 16:28:13.808540  3312 net.cpp:150] Setting up fc6
I0204 16:28:13.808590  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.808600  3312 net.cpp:165] Memory required for data: 150852800
I0204 16:28:13.808619  3312 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.808642  3312 net.cpp:106] Creating Layer relu6
I0204 16:28:13.808653  3312 net.cpp:454] relu6 <- fc6
I0204 16:28:13.808670  3312 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.808691  3312 net.cpp:150] Setting up relu6
I0204 16:28:13.808703  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.808712  3312 net.cpp:165] Memory required for data: 150955200
I0204 16:28:13.808719  3312 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.808737  3312 net.cpp:106] Creating Layer drop6
I0204 16:28:13.808745  3312 net.cpp:454] drop6 <- fc6
I0204 16:28:13.808758  3312 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.808775  3312 net.cpp:150] Setting up drop6
I0204 16:28:13.808784  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.808792  3312 net.cpp:165] Memory required for data: 151057600
I0204 16:28:13.808800  3312 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.808820  3312 net.cpp:106] Creating Layer fc7
I0204 16:28:13.808828  3312 net.cpp:454] fc7 <- fc6
I0204 16:28:13.808841  3312 net.cpp:411] fc7 -> fc7
I0204 16:28:13.809895  3312 net.cpp:150] Setting up fc7
I0204 16:28:13.809911  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.809919  3312 net.cpp:165] Memory required for data: 151160000
I0204 16:28:13.809931  3312 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.809947  3312 net.cpp:106] Creating Layer relu7
I0204 16:28:13.809955  3312 net.cpp:454] relu7 <- fc7
I0204 16:28:13.809967  3312 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.809989  3312 net.cpp:150] Setting up relu7
I0204 16:28:13.810000  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.810008  3312 net.cpp:165] Memory required for data: 151262400
I0204 16:28:13.810015  3312 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.810027  3312 net.cpp:106] Creating Layer drop7
I0204 16:28:13.810037  3312 net.cpp:454] drop7 <- fc7
I0204 16:28:13.810047  3312 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.810061  3312 net.cpp:150] Setting up drop7
I0204 16:28:13.810070  3312 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.810078  3312 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.810086  3312 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.810108  3312 net.cpp:106] Creating Layer fc8
I0204 16:28:13.810117  3312 net.cpp:454] fc8 <- fc7
I0204 16:28:13.810128  3312 net.cpp:411] fc8 -> fc8
I0204 16:28:13.810169  3312 net.cpp:150] Setting up fc8
I0204 16:28:13.810181  3312 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.810189  3312 net.cpp:165] Memory required for data: 151365600
I0204 16:28:13.810200  3312 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:28:13.810216  3312 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:28:13.810225  3312 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:28:13.810235  3312 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:28:13.810247  3312 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:28:13.810261  3312 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:28:13.810271  3312 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.810281  3312 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.810288  3312 net.cpp:165] Memory required for data: 151367200
I0204 16:28:13.810295  3312 layer_factory.hpp:77] Creating layer accuracy
I0204 16:28:13.810364  3312 net.cpp:106] Creating Layer accuracy
I0204 16:28:13.810372  3312 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:28:13.810382  3312 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:28:13.810392  3312 net.cpp:411] accuracy -> accuracy
I0204 16:28:13.810410  3312 net.cpp:150] Setting up accuracy
I0204 16:28:13.810420  3312 net.cpp:157] Top shape: (1)
I0204 16:28:13.810426  3312 net.cpp:165] Memory required for data: 151367204
I0204 16:28:13.810434  3312 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.810448  3312 net.cpp:106] Creating Layer loss
I0204 16:28:13.810456  3312 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:28:13.810467  3312 net.cpp:454] loss <- label_data_1_split_1
I0204 16:28:13.810478  3312 net.cpp:411] loss -> loss
I0204 16:28:13.810495  3312 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.810528  3312 net.cpp:150] Setting up loss
I0204 16:28:13.810539  3312 net.cpp:157] Top shape: (1)
I0204 16:28:13.810547  3312 net.cpp:160]     with loss weight 1
I0204 16:28:13.810569  3312 net.cpp:165] Memory required for data: 151367208
I0204 16:28:13.810577  3312 net.cpp:226] loss needs backward computation.
I0204 16:28:13.810586  3312 net.cpp:228] accuracy does not need backward computation.
I0204 16:28:13.810596  3312 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:28:13.810605  3312 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.810612  3312 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.810619  3312 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.810627  3312 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.810636  3312 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.810642  3312 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.810649  3312 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.810657  3312 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.810667  3312 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.810675  3312 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.810683  3312 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.810693  3312 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.810700  3312 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.810708  3312 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.810717  3312 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.810725  3312 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.810734  3312 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.810742  3312 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.810750  3312 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.810758  3312 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.810766  3312 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.810775  3312 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.810783  3312 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:28:13.810793  3312 net.cpp:228] data does not need backward computation.
I0204 16:28:13.810801  3312 net.cpp:270] This network produces output accuracy
I0204 16:28:13.810809  3312 net.cpp:270] This network produces output loss
I0204 16:28:13.810850  3312 net.cpp:283] Network initialization done.
I0204 16:28:13.811008  3312 solver.cpp:60] Solver scaffolding done.
I0204 16:28:13.811082  3312 caffe.cpp:212] Starting Optimization
I0204 16:28:13.811100  3312 solver.cpp:288] Solving CaffeNet
I0204 16:28:13.811107  3312 solver.cpp:289] Learning Rate Policy: step
I0204 16:28:13.812978  3312 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:28:13.813218  3312 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:28:21.878479  3312 solver.cpp:409]     Test net output #0: accuracy = 0.499
I0204 16:28:21.878522  3312 solver.cpp:409]     Test net output #1: loss = 3.403 (* 1 = 3.403 loss)
I0204 16:28:23.666103  3312 solver.cpp:237] Iteration 0, loss = 7.86061
I0204 16:28:23.666172  3312 solver.cpp:253]     Train net output #0: loss = 7.86061 (* 1 = 7.86061 loss)
I0204 16:28:23.666198  3312 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:28:41.137581  3312 solver.cpp:237] Iteration 10, loss = 1.13164
I0204 16:28:41.137644  3312 solver.cpp:253]     Train net output #0: loss = 1.13164 (* 1 = 1.13164 loss)
I0204 16:28:41.137655  3312 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:29:00.792632  3312 solver.cpp:237] Iteration 20, loss = 1.11522
I0204 16:29:00.792760  3312 solver.cpp:253]     Train net output #0: loss = 1.11522 (* 1 = 1.11522 loss)
I0204 16:29:00.792773  3312 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:29:20.400328  3312 solver.cpp:237] Iteration 30, loss = 0.807919
I0204 16:29:20.400393  3312 solver.cpp:253]     Train net output #0: loss = 0.807919 (* 1 = 0.807919 loss)
I0204 16:29:20.400405  3312 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:29:39.901937  3312 solver.cpp:237] Iteration 40, loss = 0.945959
I0204 16:29:39.902137  3312 solver.cpp:253]     Train net output #0: loss = 0.945959 (* 1 = 0.945959 loss)
I0204 16:29:39.902151  3312 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:29:59.715225  3312 solver.cpp:237] Iteration 50, loss = 0.92616
I0204 16:29:59.715293  3312 solver.cpp:253]     Train net output #0: loss = 0.92616 (* 1 = 0.92616 loss)
I0204 16:29:59.715306  3312 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:30:19.549612  3312 solver.cpp:237] Iteration 60, loss = 0.823718
I0204 16:30:20.074921  3312 solver.cpp:253]     Train net output #0: loss = 0.823718 (* 1 = 0.823718 loss)
I0204 16:30:20.074964  3312 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:30:39.806851  3312 solver.cpp:237] Iteration 70, loss = 0.733494
I0204 16:30:39.806913  3312 solver.cpp:253]     Train net output #0: loss = 0.733494 (* 1 = 0.733494 loss)
I0204 16:30:39.806926  3312 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:31:00.543134  3312 solver.cpp:237] Iteration 80, loss = 0.72509
I0204 16:31:00.543330  3312 solver.cpp:253]     Train net output #0: loss = 0.72509 (* 1 = 0.72509 loss)
I0204 16:31:00.543345  3312 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:21.930990  3312 solver.cpp:237] Iteration 90, loss = 0.505508
I0204 16:31:21.931061  3312 solver.cpp:253]     Train net output #0: loss = 0.505508 (* 1 = 0.505508 loss)
I0204 16:31:21.931073  3312 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:31:41.062449  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_100.caffemodel
I0204 16:31:41.066874  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_100.solverstate
I0204 16:31:41.068794  3312 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:31:51.007880  3312 solver.cpp:409]     Test net output #0: accuracy = 0.822
I0204 16:31:51.007935  3312 solver.cpp:409]     Test net output #1: loss = 0.478464 (* 1 = 0.478464 loss)
I0204 16:31:53.145531  3312 solver.cpp:237] Iteration 100, loss = 0.662319
I0204 16:31:53.145589  3312 solver.cpp:253]     Train net output #0: loss = 0.662319 (* 1 = 0.662319 loss)
I0204 16:31:53.145601  3312 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:14.720681  3312 solver.cpp:237] Iteration 110, loss = 0.659559
I0204 16:32:14.720839  3312 solver.cpp:253]     Train net output #0: loss = 0.659559 (* 1 = 0.659559 loss)
I0204 16:32:14.720851  3312 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:32:36.279301  3312 solver.cpp:237] Iteration 120, loss = 0.510291
I0204 16:32:36.279369  3312 solver.cpp:253]     Train net output #0: loss = 0.510291 (* 1 = 0.510291 loss)
I0204 16:32:36.279381  3312 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:32:57.774518  3312 solver.cpp:237] Iteration 130, loss = 0.488646
I0204 16:32:57.774739  3312 solver.cpp:253]     Train net output #0: loss = 0.488646 (* 1 = 0.488646 loss)
I0204 16:32:57.774755  3312 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:33:19.293406  3312 solver.cpp:237] Iteration 140, loss = 0.424483
I0204 16:33:19.293459  3312 solver.cpp:253]     Train net output #0: loss = 0.424483 (* 1 = 0.424483 loss)
I0204 16:33:19.293472  3312 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:33:40.966169  3312 solver.cpp:237] Iteration 150, loss = 0.420328
I0204 16:33:40.966339  3312 solver.cpp:253]     Train net output #0: loss = 0.420328 (* 1 = 0.420328 loss)
I0204 16:33:40.966351  3312 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:34:02.660967  3312 solver.cpp:237] Iteration 160, loss = 0.386675
I0204 16:34:02.661022  3312 solver.cpp:253]     Train net output #0: loss = 0.386675 (* 1 = 0.386675 loss)
I0204 16:34:02.661038  3312 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:34:24.172703  3312 solver.cpp:237] Iteration 170, loss = 0.528628
I0204 16:34:24.172865  3312 solver.cpp:253]     Train net output #0: loss = 0.528628 (* 1 = 0.528628 loss)
I0204 16:34:24.172878  3312 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:34:46.131904  3312 solver.cpp:237] Iteration 180, loss = 0.38509
I0204 16:34:46.131976  3312 solver.cpp:253]     Train net output #0: loss = 0.38509 (* 1 = 0.38509 loss)
I0204 16:34:46.131989  3312 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:35:07.912726  3312 solver.cpp:237] Iteration 190, loss = 0.320759
I0204 16:35:07.912842  3312 solver.cpp:253]     Train net output #0: loss = 0.320759 (* 1 = 0.320759 loss)
I0204 16:35:07.912853  3312 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:35:27.325953  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_200.caffemodel
I0204 16:35:27.329886  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_200.solverstate
I0204 16:35:27.331549  3312 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:35:37.657680  3312 solver.cpp:409]     Test net output #0: accuracy = 0.934
I0204 16:35:37.657734  3312 solver.cpp:409]     Test net output #1: loss = 0.198382 (* 1 = 0.198382 loss)
I0204 16:35:39.842212  3312 solver.cpp:237] Iteration 200, loss = 0.321499
I0204 16:35:39.842336  3312 solver.cpp:253]     Train net output #0: loss = 0.321499 (* 1 = 0.321499 loss)
I0204 16:35:39.842350  3312 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:36:01.539178  3312 solver.cpp:237] Iteration 210, loss = 0.273302
I0204 16:36:01.539232  3312 solver.cpp:253]     Train net output #0: loss = 0.273302 (* 1 = 0.273302 loss)
I0204 16:36:01.539244  3312 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:36:23.183964  3312 solver.cpp:237] Iteration 220, loss = 0.3146
I0204 16:36:23.184123  3312 solver.cpp:253]     Train net output #0: loss = 0.3146 (* 1 = 0.3146 loss)
I0204 16:36:23.184136  3312 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:36:45.155760  3312 solver.cpp:237] Iteration 230, loss = 0.218208
I0204 16:36:45.155834  3312 solver.cpp:253]     Train net output #0: loss = 0.218208 (* 1 = 0.218208 loss)
I0204 16:36:45.155848  3312 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:37:06.961870  3312 solver.cpp:237] Iteration 240, loss = 0.2297
I0204 16:37:06.962054  3312 solver.cpp:253]     Train net output #0: loss = 0.2297 (* 1 = 0.2297 loss)
I0204 16:37:06.962069  3312 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:37:28.867038  3312 solver.cpp:237] Iteration 250, loss = 0.147885
I0204 16:37:28.867120  3312 solver.cpp:253]     Train net output #0: loss = 0.147885 (* 1 = 0.147885 loss)
I0204 16:37:28.867135  3312 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:37:50.691675  3312 solver.cpp:237] Iteration 260, loss = 0.11454
I0204 16:37:50.691905  3312 solver.cpp:253]     Train net output #0: loss = 0.11454 (* 1 = 0.11454 loss)
I0204 16:37:50.691920  3312 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:38:12.191203  3312 solver.cpp:237] Iteration 270, loss = 0.165117
I0204 16:38:12.191270  3312 solver.cpp:253]     Train net output #0: loss = 0.165117 (* 1 = 0.165117 loss)
I0204 16:38:12.191283  3312 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:38:34.376298  3312 solver.cpp:237] Iteration 280, loss = 0.0974745
I0204 16:38:34.376466  3312 solver.cpp:253]     Train net output #0: loss = 0.0974745 (* 1 = 0.0974745 loss)
I0204 16:38:34.376479  3312 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:38:56.414834  3312 solver.cpp:237] Iteration 290, loss = 0.100596
I0204 16:38:56.414901  3312 solver.cpp:253]     Train net output #0: loss = 0.100596 (* 1 = 0.100596 loss)
I0204 16:38:56.414914  3312 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:39:16.176384  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_300.caffemodel
I0204 16:39:16.180444  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_300.solverstate
I0204 16:39:16.182067  3312 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:39:26.431614  3312 solver.cpp:409]     Test net output #0: accuracy = 0.987
I0204 16:39:26.431679  3312 solver.cpp:409]     Test net output #1: loss = 0.033968 (* 1 = 0.033968 loss)
I0204 16:39:28.603440  3312 solver.cpp:237] Iteration 300, loss = 0.123349
I0204 16:39:28.603504  3312 solver.cpp:253]     Train net output #0: loss = 0.123349 (* 1 = 0.123349 loss)
I0204 16:39:28.603518  3312 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:39:50.617209  3312 solver.cpp:237] Iteration 310, loss = 0.0248843
I0204 16:39:50.617385  3312 solver.cpp:253]     Train net output #0: loss = 0.0248843 (* 1 = 0.0248843 loss)
I0204 16:39:50.617400  3312 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:40:12.938169  3312 solver.cpp:237] Iteration 320, loss = 0.0318463
I0204 16:40:12.938225  3312 solver.cpp:253]     Train net output #0: loss = 0.0318463 (* 1 = 0.0318463 loss)
I0204 16:40:12.938235  3312 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:40:34.939568  3312 solver.cpp:237] Iteration 330, loss = 0.0147483
I0204 16:40:34.939720  3312 solver.cpp:253]     Train net output #0: loss = 0.0147483 (* 1 = 0.0147483 loss)
I0204 16:40:34.939733  3312 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:40:57.035514  3312 solver.cpp:237] Iteration 340, loss = 0.0438605
I0204 16:40:57.035583  3312 solver.cpp:253]     Train net output #0: loss = 0.0438605 (* 1 = 0.0438605 loss)
I0204 16:40:57.035596  3312 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:41:19.117645  3312 solver.cpp:237] Iteration 350, loss = 0.0478734
I0204 16:41:19.117835  3312 solver.cpp:253]     Train net output #0: loss = 0.0478735 (* 1 = 0.0478735 loss)
I0204 16:41:19.117848  3312 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:41:41.004550  3312 solver.cpp:237] Iteration 360, loss = 0.230285
I0204 16:41:41.004616  3312 solver.cpp:253]     Train net output #0: loss = 0.230285 (* 1 = 0.230285 loss)
I0204 16:41:41.004629  3312 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:42:02.681790  3312 solver.cpp:237] Iteration 370, loss = 0.117034
I0204 16:42:02.685186  3312 solver.cpp:253]     Train net output #0: loss = 0.117034 (* 1 = 0.117034 loss)
I0204 16:42:02.685207  3312 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:42:24.522330  3312 solver.cpp:237] Iteration 380, loss = 0.592455
I0204 16:42:24.522399  3312 solver.cpp:253]     Train net output #0: loss = 0.592455 (* 1 = 0.592455 loss)
I0204 16:42:24.522413  3312 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:42:46.155758  3312 solver.cpp:237] Iteration 390, loss = 0.143677
I0204 16:42:46.156078  3312 solver.cpp:253]     Train net output #0: loss = 0.143677 (* 1 = 0.143677 loss)
I0204 16:42:46.156093  3312 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:43:05.818264  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_400.caffemodel
I0204 16:43:05.822219  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_400.solverstate
I0204 16:43:05.823990  3312 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:43:15.942165  3312 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:43:15.942231  3312 solver.cpp:409]     Test net output #1: loss = 0.0344044 (* 1 = 0.0344044 loss)
I0204 16:43:18.131489  3312 solver.cpp:237] Iteration 400, loss = 0.0860073
I0204 16:43:18.131638  3312 solver.cpp:253]     Train net output #0: loss = 0.0860073 (* 1 = 0.0860073 loss)
I0204 16:43:18.131650  3312 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:43:40.163592  3312 solver.cpp:237] Iteration 410, loss = 0.0609355
I0204 16:43:40.163651  3312 solver.cpp:253]     Train net output #0: loss = 0.0609355 (* 1 = 0.0609355 loss)
I0204 16:43:40.163663  3312 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:44:01.884943  3312 solver.cpp:237] Iteration 420, loss = 0.0418156
I0204 16:44:01.885134  3312 solver.cpp:253]     Train net output #0: loss = 0.0418156 (* 1 = 0.0418156 loss)
I0204 16:44:01.885148  3312 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:44:24.441792  3312 solver.cpp:237] Iteration 430, loss = 0.0743349
I0204 16:44:24.441848  3312 solver.cpp:253]     Train net output #0: loss = 0.0743349 (* 1 = 0.0743349 loss)
I0204 16:44:24.441860  3312 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:44:46.799602  3312 solver.cpp:237] Iteration 440, loss = 0.0321686
I0204 16:44:46.799767  3312 solver.cpp:253]     Train net output #0: loss = 0.0321686 (* 1 = 0.0321686 loss)
I0204 16:44:46.799778  3312 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:45:09.903489  3312 solver.cpp:237] Iteration 450, loss = 0.125891
I0204 16:45:09.903544  3312 solver.cpp:253]     Train net output #0: loss = 0.125891 (* 1 = 0.125891 loss)
I0204 16:45:09.903556  3312 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:45:33.136008  3312 solver.cpp:237] Iteration 460, loss = 0.0260661
I0204 16:45:33.136176  3312 solver.cpp:253]     Train net output #0: loss = 0.0260661 (* 1 = 0.0260661 loss)
I0204 16:45:33.136188  3312 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:45:56.622277  3312 solver.cpp:237] Iteration 470, loss = 0.0146546
I0204 16:45:56.622334  3312 solver.cpp:253]     Train net output #0: loss = 0.0146546 (* 1 = 0.0146546 loss)
I0204 16:45:56.622345  3312 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:46:19.268504  3312 solver.cpp:237] Iteration 480, loss = 0.040616
I0204 16:46:19.268682  3312 solver.cpp:253]     Train net output #0: loss = 0.040616 (* 1 = 0.040616 loss)
I0204 16:46:19.268697  3312 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:46:42.004458  3312 solver.cpp:237] Iteration 490, loss = 0.028644
I0204 16:46:42.004531  3312 solver.cpp:253]     Train net output #0: loss = 0.028644 (* 1 = 0.028644 loss)
I0204 16:46:42.004545  3312 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:47:02.450265  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_500.caffemodel
I0204 16:47:02.454358  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_500.solverstate
I0204 16:47:02.456007  3312 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:47:12.728247  3312 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:47:12.728307  3312 solver.cpp:409]     Test net output #1: loss = 0.0266811 (* 1 = 0.0266811 loss)
I0204 16:47:14.935662  3312 solver.cpp:237] Iteration 500, loss = 0.0535441
I0204 16:47:14.935731  3312 solver.cpp:253]     Train net output #0: loss = 0.0535441 (* 1 = 0.0535441 loss)
I0204 16:47:14.935744  3312 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:47:36.864855  3312 solver.cpp:237] Iteration 510, loss = 0.0998059
I0204 16:47:36.871105  3312 solver.cpp:253]     Train net output #0: loss = 0.0998059 (* 1 = 0.0998059 loss)
I0204 16:47:36.871181  3312 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:47:59.245677  3312 solver.cpp:237] Iteration 520, loss = 0.0389256
I0204 16:47:59.245745  3312 solver.cpp:253]     Train net output #0: loss = 0.0389256 (* 1 = 0.0389256 loss)
I0204 16:47:59.245759  3312 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:48:21.650354  3312 solver.cpp:237] Iteration 530, loss = 0.0717131
I0204 16:48:21.650568  3312 solver.cpp:253]     Train net output #0: loss = 0.0717131 (* 1 = 0.0717131 loss)
I0204 16:48:21.650583  3312 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:48:44.188645  3312 solver.cpp:237] Iteration 540, loss = 0.0118233
I0204 16:48:44.188711  3312 solver.cpp:253]     Train net output #0: loss = 0.0118233 (* 1 = 0.0118233 loss)
I0204 16:48:44.188724  3312 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:49:06.770040  3312 solver.cpp:237] Iteration 550, loss = 0.0157939
I0204 16:49:06.770238  3312 solver.cpp:253]     Train net output #0: loss = 0.0157939 (* 1 = 0.0157939 loss)
I0204 16:49:06.770252  3312 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:49:29.130177  3312 solver.cpp:237] Iteration 560, loss = 0.020773
I0204 16:49:29.130249  3312 solver.cpp:253]     Train net output #0: loss = 0.020773 (* 1 = 0.020773 loss)
I0204 16:49:29.130261  3312 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:49:51.647214  3312 solver.cpp:237] Iteration 570, loss = 0.0247626
I0204 16:49:51.647518  3312 solver.cpp:253]     Train net output #0: loss = 0.0247626 (* 1 = 0.0247626 loss)
I0204 16:49:51.647533  3312 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:50:14.147919  3312 solver.cpp:237] Iteration 580, loss = 0.0123387
I0204 16:50:14.147989  3312 solver.cpp:253]     Train net output #0: loss = 0.0123387 (* 1 = 0.0123387 loss)
I0204 16:50:14.148001  3312 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:50:36.480167  3312 solver.cpp:237] Iteration 590, loss = 0.0524132
I0204 16:50:36.480346  3312 solver.cpp:253]     Train net output #0: loss = 0.0524132 (* 1 = 0.0524132 loss)
I0204 16:50:36.480361  3312 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:50:56.493391  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_600.caffemodel
I0204 16:50:56.497122  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_600.solverstate
I0204 16:50:56.498713  3312 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:51:06.666298  3312 solver.cpp:409]     Test net output #0: accuracy = 0.995
I0204 16:51:06.666496  3312 solver.cpp:409]     Test net output #1: loss = 0.0136259 (* 1 = 0.0136259 loss)
I0204 16:51:08.821712  3312 solver.cpp:237] Iteration 600, loss = 0.0100755
I0204 16:51:08.821779  3312 solver.cpp:253]     Train net output #0: loss = 0.0100755 (* 1 = 0.0100755 loss)
I0204 16:51:08.821791  3312 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:51:30.432816  3312 solver.cpp:237] Iteration 610, loss = 0.0090736
I0204 16:51:30.432878  3312 solver.cpp:253]     Train net output #0: loss = 0.0090736 (* 1 = 0.0090736 loss)
I0204 16:51:30.432889  3312 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:51:52.055451  3312 solver.cpp:237] Iteration 620, loss = 0.0055234
I0204 16:51:52.055662  3312 solver.cpp:253]     Train net output #0: loss = 0.0055234 (* 1 = 0.0055234 loss)
I0204 16:51:52.055675  3312 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:52:13.660272  3312 solver.cpp:237] Iteration 630, loss = 0.0237333
I0204 16:52:13.660356  3312 solver.cpp:253]     Train net output #0: loss = 0.0237333 (* 1 = 0.0237333 loss)
I0204 16:52:13.660367  3312 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:52:35.339409  3312 solver.cpp:237] Iteration 640, loss = 0.0682544
I0204 16:52:35.339684  3312 solver.cpp:253]     Train net output #0: loss = 0.0682544 (* 1 = 0.0682544 loss)
I0204 16:52:35.339700  3312 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:52:56.969833  3312 solver.cpp:237] Iteration 650, loss = 0.0116341
I0204 16:52:56.969897  3312 solver.cpp:253]     Train net output #0: loss = 0.0116341 (* 1 = 0.0116341 loss)
I0204 16:52:56.969908  3312 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:53:17.732079  3312 solver.cpp:237] Iteration 660, loss = 0.0105737
I0204 16:53:17.732306  3312 solver.cpp:253]     Train net output #0: loss = 0.0105737 (* 1 = 0.0105737 loss)
I0204 16:53:17.732318  3312 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:53:39.214076  3312 solver.cpp:237] Iteration 670, loss = 0.0350927
I0204 16:53:39.214148  3312 solver.cpp:253]     Train net output #0: loss = 0.0350927 (* 1 = 0.0350927 loss)
I0204 16:53:39.214160  3312 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:54:00.960912  3312 solver.cpp:237] Iteration 680, loss = 0.00375487
I0204 16:54:00.961122  3312 solver.cpp:253]     Train net output #0: loss = 0.00375487 (* 1 = 0.00375487 loss)
I0204 16:54:00.961141  3312 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:54:22.558607  3312 solver.cpp:237] Iteration 690, loss = 0.0357199
I0204 16:54:22.558670  3312 solver.cpp:253]     Train net output #0: loss = 0.0357199 (* 1 = 0.0357199 loss)
I0204 16:54:22.558681  3312 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:54:41.928783  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_700.caffemodel
I0204 16:54:41.932799  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_700.solverstate
I0204 16:54:41.934315  3312 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:54:52.041805  3312 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 16:54:52.041865  3312 solver.cpp:409]     Test net output #1: loss = 0.00881078 (* 1 = 0.00881078 loss)
I0204 16:54:54.202834  3312 solver.cpp:237] Iteration 700, loss = 0.0111743
I0204 16:54:54.202898  3312 solver.cpp:253]     Train net output #0: loss = 0.0111743 (* 1 = 0.0111743 loss)
I0204 16:54:54.202910  3312 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:55:15.830950  3312 solver.cpp:237] Iteration 710, loss = 0.00122589
I0204 16:55:15.831154  3312 solver.cpp:253]     Train net output #0: loss = 0.00122589 (* 1 = 0.00122589 loss)
I0204 16:55:15.831168  3312 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:55:37.482863  3312 solver.cpp:237] Iteration 720, loss = 0.00157952
I0204 16:55:37.482933  3312 solver.cpp:253]     Train net output #0: loss = 0.00157952 (* 1 = 0.00157952 loss)
I0204 16:55:37.482945  3312 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:55:59.163259  3312 solver.cpp:237] Iteration 730, loss = 0.000720449
I0204 16:55:59.163466  3312 solver.cpp:253]     Train net output #0: loss = 0.00072045 (* 1 = 0.00072045 loss)
I0204 16:55:59.163481  3312 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:56:20.746618  3312 solver.cpp:237] Iteration 740, loss = 0.0129721
I0204 16:56:20.746681  3312 solver.cpp:253]     Train net output #0: loss = 0.0129721 (* 1 = 0.0129721 loss)
I0204 16:56:20.746693  3312 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 16:56:42.402359  3312 solver.cpp:237] Iteration 750, loss = 0.0085041
I0204 16:56:42.402549  3312 solver.cpp:253]     Train net output #0: loss = 0.00850409 (* 1 = 0.00850409 loss)
I0204 16:56:42.402562  3312 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 16:57:04.137538  3312 solver.cpp:237] Iteration 760, loss = 0.160694
I0204 16:57:04.137621  3312 solver.cpp:253]     Train net output #0: loss = 0.160694 (* 1 = 0.160694 loss)
I0204 16:57:04.137634  3312 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 16:57:26.078928  3312 solver.cpp:237] Iteration 770, loss = 0.0984201
I0204 16:57:26.079180  3312 solver.cpp:253]     Train net output #0: loss = 0.0984201 (* 1 = 0.0984201 loss)
I0204 16:57:26.079193  3312 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 16:57:48.066671  3312 solver.cpp:237] Iteration 780, loss = 0.00245604
I0204 16:57:48.066730  3312 solver.cpp:253]     Train net output #0: loss = 0.00245603 (* 1 = 0.00245603 loss)
I0204 16:57:48.066740  3312 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 16:58:10.085763  3312 solver.cpp:237] Iteration 790, loss = 0.000947866
I0204 16:58:10.085973  3312 solver.cpp:253]     Train net output #0: loss = 0.000947855 (* 1 = 0.000947855 loss)
I0204 16:58:10.085986  3312 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 16:58:29.781508  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_800.caffemodel
I0204 16:58:29.785205  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_800.solverstate
I0204 16:58:29.786679  3312 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 16:58:40.115809  3312 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 16:58:40.116021  3312 solver.cpp:409]     Test net output #1: loss = 0.0119056 (* 1 = 0.0119056 loss)
I0204 16:58:42.325486  3312 solver.cpp:237] Iteration 800, loss = 0.0027709
I0204 16:58:42.325547  3312 solver.cpp:253]     Train net output #0: loss = 0.00277089 (* 1 = 0.00277089 loss)
I0204 16:58:42.325559  3312 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 16:59:04.231780  3312 solver.cpp:237] Iteration 810, loss = 0.0210808
I0204 16:59:04.231848  3312 solver.cpp:253]     Train net output #0: loss = 0.0210807 (* 1 = 0.0210807 loss)
I0204 16:59:04.231860  3312 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 16:59:26.114606  3312 solver.cpp:237] Iteration 820, loss = 0.0464731
I0204 16:59:26.114823  3312 solver.cpp:253]     Train net output #0: loss = 0.0464731 (* 1 = 0.0464731 loss)
I0204 16:59:26.114836  3312 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 16:59:48.003562  3312 solver.cpp:237] Iteration 830, loss = 0.129567
I0204 16:59:48.003623  3312 solver.cpp:253]     Train net output #0: loss = 0.129567 (* 1 = 0.129567 loss)
I0204 16:59:48.003636  3312 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 17:00:10.006356  3312 solver.cpp:237] Iteration 840, loss = 0.007741
I0204 17:00:10.006548  3312 solver.cpp:253]     Train net output #0: loss = 0.007741 (* 1 = 0.007741 loss)
I0204 17:00:10.006561  3312 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 17:00:31.887037  3312 solver.cpp:237] Iteration 850, loss = 0.035818
I0204 17:00:31.887100  3312 solver.cpp:253]     Train net output #0: loss = 0.035818 (* 1 = 0.035818 loss)
I0204 17:00:31.887114  3312 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 17:00:53.791409  3312 solver.cpp:237] Iteration 860, loss = 0.00388089
I0204 17:00:53.791596  3312 solver.cpp:253]     Train net output #0: loss = 0.00388089 (* 1 = 0.00388089 loss)
I0204 17:00:53.791610  3312 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 17:01:15.622097  3312 solver.cpp:237] Iteration 870, loss = 0.000839982
I0204 17:01:15.622165  3312 solver.cpp:253]     Train net output #0: loss = 0.000839983 (* 1 = 0.000839983 loss)
I0204 17:01:15.622176  3312 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 17:01:37.530203  3312 solver.cpp:237] Iteration 880, loss = 0.00165385
I0204 17:01:37.530400  3312 solver.cpp:253]     Train net output #0: loss = 0.00165385 (* 1 = 0.00165385 loss)
I0204 17:01:37.530412  3312 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 17:01:59.393666  3312 solver.cpp:237] Iteration 890, loss = 0.00330173
I0204 17:01:59.393746  3312 solver.cpp:253]     Train net output #0: loss = 0.00330173 (* 1 = 0.00330173 loss)
I0204 17:01:59.393759  3312 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 17:02:19.112931  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_900.caffemodel
I0204 17:02:19.116904  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_900.solverstate
I0204 17:02:19.118444  3312 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 17:02:29.344501  3312 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:02:29.344559  3312 solver.cpp:409]     Test net output #1: loss = 0.00349544 (* 1 = 0.00349544 loss)
I0204 17:02:31.553874  3312 solver.cpp:237] Iteration 900, loss = 0.0101565
I0204 17:02:31.553930  3312 solver.cpp:253]     Train net output #0: loss = 0.0101565 (* 1 = 0.0101565 loss)
I0204 17:02:31.553942  3312 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 17:02:53.693773  3312 solver.cpp:237] Iteration 910, loss = 0.000889555
I0204 17:02:53.693972  3312 solver.cpp:253]     Train net output #0: loss = 0.000889554 (* 1 = 0.000889554 loss)
I0204 17:02:53.693986  3312 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 17:03:15.754125  3312 solver.cpp:237] Iteration 920, loss = 0.0099799
I0204 17:03:15.754209  3312 solver.cpp:253]     Train net output #0: loss = 0.0099799 (* 1 = 0.0099799 loss)
I0204 17:03:15.754220  3312 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 17:03:36.045454  3312 solver.cpp:237] Iteration 930, loss = 0.00564976
I0204 17:03:36.045647  3312 solver.cpp:253]     Train net output #0: loss = 0.00564976 (* 1 = 0.00564976 loss)
I0204 17:03:36.045661  3312 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 17:03:56.466974  3312 solver.cpp:237] Iteration 940, loss = 0.000268597
I0204 17:03:56.467046  3312 solver.cpp:253]     Train net output #0: loss = 0.000268599 (* 1 = 0.000268599 loss)
I0204 17:03:56.467058  3312 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 17:04:16.842427  3312 solver.cpp:237] Iteration 950, loss = 0.000597146
I0204 17:04:16.842628  3312 solver.cpp:253]     Train net output #0: loss = 0.00059715 (* 1 = 0.00059715 loss)
I0204 17:04:16.842643  3312 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 17:04:37.237458  3312 solver.cpp:237] Iteration 960, loss = 0.00363479
I0204 17:04:37.237532  3312 solver.cpp:253]     Train net output #0: loss = 0.00363479 (* 1 = 0.00363479 loss)
I0204 17:04:37.237545  3312 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 17:04:57.656498  3312 solver.cpp:237] Iteration 970, loss = 0.00361272
I0204 17:04:57.656690  3312 solver.cpp:253]     Train net output #0: loss = 0.00361272 (* 1 = 0.00361272 loss)
I0204 17:04:57.656703  3312 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 17:05:18.076135  3312 solver.cpp:237] Iteration 980, loss = 0.00148696
I0204 17:05:18.076210  3312 solver.cpp:253]     Train net output #0: loss = 0.00148696 (* 1 = 0.00148696 loss)
I0204 17:05:18.076220  3312 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 17:05:38.268723  3312 solver.cpp:237] Iteration 990, loss = 0.024941
I0204 17:05:38.268914  3312 solver.cpp:253]     Train net output #0: loss = 0.024941 (* 1 = 0.024941 loss)
I0204 17:05:38.268929  3312 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 17:05:56.137493  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1000.caffemodel
I0204 17:05:56.140899  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1000.solverstate
I0204 17:05:56.142273  3312 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 17:06:05.401628  3312 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:06:05.401695  3312 solver.cpp:409]     Test net output #1: loss = 0.00774104 (* 1 = 0.00774104 loss)
I0204 17:06:07.399749  3312 solver.cpp:237] Iteration 1000, loss = 0.00170976
I0204 17:06:07.399804  3312 solver.cpp:253]     Train net output #0: loss = 0.00170976 (* 1 = 0.00170976 loss)
I0204 17:06:07.399816  3312 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 17:06:27.240407  3312 solver.cpp:237] Iteration 1010, loss = 0.0271358
I0204 17:06:27.240624  3312 solver.cpp:253]     Train net output #0: loss = 0.0271358 (* 1 = 0.0271358 loss)
I0204 17:06:27.240638  3312 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 17:06:47.130512  3312 solver.cpp:237] Iteration 1020, loss = 0.152984
I0204 17:06:47.130578  3312 solver.cpp:253]     Train net output #0: loss = 0.152984 (* 1 = 0.152984 loss)
I0204 17:06:47.130589  3312 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 17:07:07.424461  3312 solver.cpp:237] Iteration 1030, loss = 0.00282422
I0204 17:07:07.424681  3312 solver.cpp:253]     Train net output #0: loss = 0.00282422 (* 1 = 0.00282422 loss)
I0204 17:07:07.424695  3312 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 17:07:27.455116  3312 solver.cpp:237] Iteration 1040, loss = 0.00173642
I0204 17:07:27.455178  3312 solver.cpp:253]     Train net output #0: loss = 0.00173642 (* 1 = 0.00173642 loss)
I0204 17:07:27.455189  3312 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 17:07:47.856189  3312 solver.cpp:237] Iteration 1050, loss = 0.0103043
I0204 17:07:47.856394  3312 solver.cpp:253]     Train net output #0: loss = 0.0103043 (* 1 = 0.0103043 loss)
I0204 17:07:47.856407  3312 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 17:08:07.814473  3312 solver.cpp:237] Iteration 1060, loss = 0.00758966
I0204 17:08:07.814544  3312 solver.cpp:253]     Train net output #0: loss = 0.00758966 (* 1 = 0.00758966 loss)
I0204 17:08:07.814555  3312 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 17:08:27.604377  3312 solver.cpp:237] Iteration 1070, loss = 0.000584839
I0204 17:08:27.604564  3312 solver.cpp:253]     Train net output #0: loss = 0.000584839 (* 1 = 0.000584839 loss)
I0204 17:08:27.604578  3312 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 17:08:47.559690  3312 solver.cpp:237] Iteration 1080, loss = 0.0458507
I0204 17:08:47.559754  3312 solver.cpp:253]     Train net output #0: loss = 0.0458507 (* 1 = 0.0458507 loss)
I0204 17:08:47.559765  3312 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 17:09:08.336565  3312 solver.cpp:237] Iteration 1090, loss = 0.000493776
I0204 17:09:08.397266  3312 solver.cpp:253]     Train net output #0: loss = 0.000493777 (* 1 = 0.000493777 loss)
I0204 17:09:08.397299  3312 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 17:09:27.325645  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1100.caffemodel
I0204 17:09:27.329385  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1100.solverstate
I0204 17:09:27.330818  3312 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 17:09:37.506274  3312 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:09:37.506325  3312 solver.cpp:409]     Test net output #1: loss = 0.00552865 (* 1 = 0.00552865 loss)
I0204 17:09:39.735865  3312 solver.cpp:237] Iteration 1100, loss = 0.000844628
I0204 17:09:39.736052  3312 solver.cpp:253]     Train net output #0: loss = 0.000844628 (* 1 = 0.000844628 loss)
I0204 17:09:39.736066  3312 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 17:10:01.566957  3312 solver.cpp:237] Iteration 1110, loss = 0.00456924
I0204 17:10:01.567020  3312 solver.cpp:253]     Train net output #0: loss = 0.00456924 (* 1 = 0.00456924 loss)
I0204 17:10:01.567033  3312 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 17:10:23.286730  3312 solver.cpp:237] Iteration 1120, loss = 0.0130515
I0204 17:10:23.286968  3312 solver.cpp:253]     Train net output #0: loss = 0.0130515 (* 1 = 0.0130515 loss)
I0204 17:10:23.286981  3312 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 17:10:44.957098  3312 solver.cpp:237] Iteration 1130, loss = 0.0012705
I0204 17:10:44.957167  3312 solver.cpp:253]     Train net output #0: loss = 0.0012705 (* 1 = 0.0012705 loss)
I0204 17:10:44.957180  3312 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 17:11:05.043891  3312 solver.cpp:237] Iteration 1140, loss = 0.0022553
I0204 17:11:05.044111  3312 solver.cpp:253]     Train net output #0: loss = 0.0022553 (* 1 = 0.0022553 loss)
I0204 17:11:05.044124  3312 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 17:11:25.971582  3312 solver.cpp:237] Iteration 1150, loss = 0.055374
I0204 17:11:25.971645  3312 solver.cpp:253]     Train net output #0: loss = 0.055374 (* 1 = 0.055374 loss)
I0204 17:11:25.971657  3312 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 17:11:46.196214  3312 solver.cpp:237] Iteration 1160, loss = 0.00892324
I0204 17:11:46.196403  3312 solver.cpp:253]     Train net output #0: loss = 0.00892323 (* 1 = 0.00892323 loss)
I0204 17:11:46.196418  3312 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 17:12:07.535043  3312 solver.cpp:237] Iteration 1170, loss = 0.00141387
I0204 17:12:07.535120  3312 solver.cpp:253]     Train net output #0: loss = 0.00141386 (* 1 = 0.00141386 loss)
I0204 17:12:07.535133  3312 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 17:12:29.120159  3312 solver.cpp:237] Iteration 1180, loss = 0.000267651
I0204 17:12:29.120355  3312 solver.cpp:253]     Train net output #0: loss = 0.000267646 (* 1 = 0.000267646 loss)
I0204 17:12:29.120368  3312 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 17:12:50.649719  3312 solver.cpp:237] Iteration 1190, loss = 0.00169295
I0204 17:12:50.649791  3312 solver.cpp:253]     Train net output #0: loss = 0.00169295 (* 1 = 0.00169295 loss)
I0204 17:12:50.649802  3312 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 17:13:10.082262  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1200.caffemodel
I0204 17:13:10.086160  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1200.solverstate
I0204 17:13:10.087662  3312 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 17:13:20.221645  3312 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:13:20.221704  3312 solver.cpp:409]     Test net output #1: loss = 0.00310865 (* 1 = 0.00310865 loss)
I0204 17:13:22.373483  3312 solver.cpp:237] Iteration 1200, loss = 0.00191964
I0204 17:13:22.373533  3312 solver.cpp:253]     Train net output #0: loss = 0.00191963 (* 1 = 0.00191963 loss)
I0204 17:13:22.373543  3312 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 17:13:43.924537  3312 solver.cpp:237] Iteration 1210, loss = 0.0320021
I0204 17:13:43.924742  3312 solver.cpp:253]     Train net output #0: loss = 0.0320021 (* 1 = 0.0320021 loss)
I0204 17:13:43.924756  3312 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 17:14:05.058853  3312 solver.cpp:237] Iteration 1220, loss = 0.00789244
I0204 17:14:05.058918  3312 solver.cpp:253]     Train net output #0: loss = 0.00789244 (* 1 = 0.00789244 loss)
I0204 17:14:05.058929  3312 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 17:14:26.655820  3312 solver.cpp:237] Iteration 1230, loss = 0.00623418
I0204 17:14:26.656023  3312 solver.cpp:253]     Train net output #0: loss = 0.00623418 (* 1 = 0.00623418 loss)
I0204 17:14:26.656035  3312 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 17:14:48.344756  3312 solver.cpp:237] Iteration 1240, loss = 0.000269169
I0204 17:14:48.344822  3312 solver.cpp:253]     Train net output #0: loss = 0.000269167 (* 1 = 0.000269167 loss)
I0204 17:14:48.344835  3312 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 17:15:09.115244  3312 solver.cpp:237] Iteration 1250, loss = 0.0541782
I0204 17:15:09.115471  3312 solver.cpp:253]     Train net output #0: loss = 0.0541782 (* 1 = 0.0541782 loss)
I0204 17:15:09.115484  3312 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 17:15:29.302405  3312 solver.cpp:237] Iteration 1260, loss = 0.000899008
I0204 17:15:29.302466  3312 solver.cpp:253]     Train net output #0: loss = 0.000899005 (* 1 = 0.000899005 loss)
I0204 17:15:29.302476  3312 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 17:15:49.476064  3312 solver.cpp:237] Iteration 1270, loss = 0.000404673
I0204 17:15:49.476300  3312 solver.cpp:253]     Train net output #0: loss = 0.00040467 (* 1 = 0.00040467 loss)
I0204 17:15:49.476315  3312 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 17:16:09.647372  3312 solver.cpp:237] Iteration 1280, loss = 0.000941801
I0204 17:16:09.647439  3312 solver.cpp:253]     Train net output #0: loss = 0.000941798 (* 1 = 0.000941798 loss)
I0204 17:16:09.647450  3312 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 17:16:29.759521  3312 solver.cpp:237] Iteration 1290, loss = 0.00062594
I0204 17:16:29.759709  3312 solver.cpp:253]     Train net output #0: loss = 0.000625936 (* 1 = 0.000625936 loss)
I0204 17:16:29.759722  3312 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 17:16:47.800737  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1300.caffemodel
I0204 17:16:47.804203  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1300.solverstate
I0204 17:16:47.805553  3312 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 17:16:57.300175  3312 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:16:57.300233  3312 solver.cpp:409]     Test net output #1: loss = 0.00372295 (* 1 = 0.00372295 loss)
I0204 17:16:59.308698  3312 solver.cpp:237] Iteration 1300, loss = 0.00485976
I0204 17:16:59.308758  3312 solver.cpp:253]     Train net output #0: loss = 0.00485975 (* 1 = 0.00485975 loss)
I0204 17:16:59.308769  3312 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 17:17:19.520369  3312 solver.cpp:237] Iteration 1310, loss = 0.0160966
I0204 17:17:19.520553  3312 solver.cpp:253]     Train net output #0: loss = 0.0160966 (* 1 = 0.0160966 loss)
I0204 17:17:19.520566  3312 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 17:17:39.572382  3312 solver.cpp:237] Iteration 1320, loss = 0.00235302
I0204 17:17:39.572444  3312 solver.cpp:253]     Train net output #0: loss = 0.00235302 (* 1 = 0.00235302 loss)
I0204 17:17:39.572455  3312 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 17:17:59.787732  3312 solver.cpp:237] Iteration 1330, loss = 0.00151852
I0204 17:17:59.787925  3312 solver.cpp:253]     Train net output #0: loss = 0.00151852 (* 1 = 0.00151852 loss)
I0204 17:17:59.787938  3312 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 17:18:20.039180  3312 solver.cpp:237] Iteration 1340, loss = 0.00063305
I0204 17:18:20.039247  3312 solver.cpp:253]     Train net output #0: loss = 0.00063305 (* 1 = 0.00063305 loss)
I0204 17:18:20.039258  3312 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 17:18:40.239823  3312 solver.cpp:237] Iteration 1350, loss = 0.0015817
I0204 17:18:40.240012  3312 solver.cpp:253]     Train net output #0: loss = 0.0015817 (* 1 = 0.0015817 loss)
I0204 17:18:40.240025  3312 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 17:19:00.403882  3312 solver.cpp:237] Iteration 1360, loss = 0.00090342
I0204 17:19:00.403946  3312 solver.cpp:253]     Train net output #0: loss = 0.00090342 (* 1 = 0.00090342 loss)
I0204 17:19:00.403959  3312 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 17:19:20.509258  3312 solver.cpp:237] Iteration 1370, loss = 0.0074357
I0204 17:19:20.509474  3312 solver.cpp:253]     Train net output #0: loss = 0.00743571 (* 1 = 0.00743571 loss)
I0204 17:19:20.509488  3312 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 17:19:40.829383  3312 solver.cpp:237] Iteration 1380, loss = 0.0307358
I0204 17:19:40.829450  3312 solver.cpp:253]     Train net output #0: loss = 0.0307358 (* 1 = 0.0307358 loss)
I0204 17:19:40.829462  3312 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 17:20:01.245254  3312 solver.cpp:237] Iteration 1390, loss = 0.00887548
I0204 17:20:01.245455  3312 solver.cpp:253]     Train net output #0: loss = 0.00887548 (* 1 = 0.00887548 loss)
I0204 17:20:01.245470  3312 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 17:20:19.522856  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1400.caffemodel
I0204 17:20:19.526379  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1400.solverstate
I0204 17:20:19.527729  3312 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 17:20:28.984171  3312 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 17:20:28.984230  3312 solver.cpp:409]     Test net output #1: loss = 0.0172928 (* 1 = 0.0172928 loss)
I0204 17:20:31.030138  3312 solver.cpp:237] Iteration 1400, loss = 0.00347888
I0204 17:20:31.030197  3312 solver.cpp:253]     Train net output #0: loss = 0.00347888 (* 1 = 0.00347888 loss)
I0204 17:20:31.030207  3312 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 17:20:51.232718  3312 solver.cpp:237] Iteration 1410, loss = 0.00695138
I0204 17:20:51.232923  3312 solver.cpp:253]     Train net output #0: loss = 0.00695138 (* 1 = 0.00695138 loss)
I0204 17:20:51.232936  3312 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 17:21:11.581488  3312 solver.cpp:237] Iteration 1420, loss = 0.00530645
I0204 17:21:11.581565  3312 solver.cpp:253]     Train net output #0: loss = 0.00530645 (* 1 = 0.00530645 loss)
I0204 17:21:11.581578  3312 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 17:21:32.168829  3312 solver.cpp:237] Iteration 1430, loss = 0.0137259
I0204 17:21:32.169011  3312 solver.cpp:253]     Train net output #0: loss = 0.0137259 (* 1 = 0.0137259 loss)
I0204 17:21:32.169024  3312 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 17:21:52.521692  3312 solver.cpp:237] Iteration 1440, loss = 0.0382385
I0204 17:21:52.521759  3312 solver.cpp:253]     Train net output #0: loss = 0.0382385 (* 1 = 0.0382385 loss)
I0204 17:21:52.521770  3312 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 17:22:12.988247  3312 solver.cpp:237] Iteration 1450, loss = 0.000816286
I0204 17:22:12.988451  3312 solver.cpp:253]     Train net output #0: loss = 0.000816285 (* 1 = 0.000816285 loss)
I0204 17:22:12.988463  3312 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 17:22:33.437350  3312 solver.cpp:237] Iteration 1460, loss = 0.00492502
I0204 17:22:33.437415  3312 solver.cpp:253]     Train net output #0: loss = 0.00492502 (* 1 = 0.00492502 loss)
I0204 17:22:33.437427  3312 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 17:22:53.902750  3312 solver.cpp:237] Iteration 1470, loss = 0.00428493
I0204 17:22:53.902966  3312 solver.cpp:253]     Train net output #0: loss = 0.00428493 (* 1 = 0.00428493 loss)
I0204 17:22:53.902978  3312 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 17:23:14.263677  3312 solver.cpp:237] Iteration 1480, loss = 0.000182313
I0204 17:23:14.263741  3312 solver.cpp:253]     Train net output #0: loss = 0.000182315 (* 1 = 0.000182315 loss)
I0204 17:23:14.263751  3312 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 17:23:34.652657  3312 solver.cpp:237] Iteration 1490, loss = 0.00645027
I0204 17:23:34.652842  3312 solver.cpp:253]     Train net output #0: loss = 0.00645027 (* 1 = 0.00645027 loss)
I0204 17:23:34.652856  3312 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 17:23:52.982843  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1500.caffemodel
I0204 17:23:52.986354  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1500.solverstate
I0204 17:23:52.987732  3312 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 17:24:02.547308  3312 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:24:02.547369  3312 solver.cpp:409]     Test net output #1: loss = 0.00491269 (* 1 = 0.00491269 loss)
I0204 17:24:04.604631  3312 solver.cpp:237] Iteration 1500, loss = 0.000542641
I0204 17:24:04.604687  3312 solver.cpp:253]     Train net output #0: loss = 0.000542646 (* 1 = 0.000542646 loss)
I0204 17:24:04.604699  3312 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 17:24:24.961639  3312 solver.cpp:237] Iteration 1510, loss = 0.000615759
I0204 17:24:24.961838  3312 solver.cpp:253]     Train net output #0: loss = 0.000615764 (* 1 = 0.000615764 loss)
I0204 17:24:24.961851  3312 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 17:24:45.378332  3312 solver.cpp:237] Iteration 1520, loss = 0.0400531
I0204 17:24:45.378398  3312 solver.cpp:253]     Train net output #0: loss = 0.0400531 (* 1 = 0.0400531 loss)
I0204 17:24:45.378409  3312 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 17:25:05.687301  3312 solver.cpp:237] Iteration 1530, loss = 0.0012904
I0204 17:25:05.687525  3312 solver.cpp:253]     Train net output #0: loss = 0.00129041 (* 1 = 0.00129041 loss)
I0204 17:25:05.687537  3312 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 17:25:25.963318  3312 solver.cpp:237] Iteration 1540, loss = 0.000751328
I0204 17:25:25.963382  3312 solver.cpp:253]     Train net output #0: loss = 0.000751346 (* 1 = 0.000751346 loss)
I0204 17:25:25.963393  3312 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 17:25:46.273087  3312 solver.cpp:237] Iteration 1550, loss = 0.0167441
I0204 17:25:46.273298  3312 solver.cpp:253]     Train net output #0: loss = 0.0167441 (* 1 = 0.0167441 loss)
I0204 17:25:46.273318  3312 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 17:26:06.437271  3312 solver.cpp:237] Iteration 1560, loss = 0.00461625
I0204 17:26:06.437337  3312 solver.cpp:253]     Train net output #0: loss = 0.00461627 (* 1 = 0.00461627 loss)
I0204 17:26:06.437348  3312 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 17:26:26.656983  3312 solver.cpp:237] Iteration 1570, loss = 0.0624719
I0204 17:26:26.657162  3312 solver.cpp:253]     Train net output #0: loss = 0.0624719 (* 1 = 0.0624719 loss)
I0204 17:26:26.657176  3312 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 17:26:46.732257  3312 solver.cpp:237] Iteration 1580, loss = 0.000320888
I0204 17:26:46.732324  3312 solver.cpp:253]     Train net output #0: loss = 0.000320907 (* 1 = 0.000320907 loss)
I0204 17:26:46.732336  3312 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 17:27:06.764484  3312 solver.cpp:237] Iteration 1590, loss = 0.000397716
I0204 17:27:06.764696  3312 solver.cpp:253]     Train net output #0: loss = 0.000397737 (* 1 = 0.000397737 loss)
I0204 17:27:06.764709  3312 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 17:27:24.739056  3312 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1600.caffemodel
I0204 17:27:24.742501  3312 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed3/snaps/snap__iter_1600.solverstate
I0204 17:27:25.667326  3312 solver.cpp:321] Iteration 1600, loss = 0.00347332
I0204 17:27:25.667376  3312 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 17:27:35.292232  3312 solver.cpp:409]     Test net output #0: accuracy = 0.993
I0204 17:27:35.292289  3312 solver.cpp:409]     Test net output #1: loss = 0.0241859 (* 1 = 0.0241859 loss)
I0204 17:27:35.292297  3312 solver.cpp:326] Optimization Done.
I0204 17:27:35.292304  3312 caffe.cpp:215] Optimization Done.
