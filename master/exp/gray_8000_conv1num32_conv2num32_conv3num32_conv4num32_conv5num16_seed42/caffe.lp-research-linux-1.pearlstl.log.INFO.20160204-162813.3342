Log file created at: 2016/02/04 16:28:13
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 16:28:13.778309  3342 caffe.cpp:177] Use CPU.
I0204 16:28:13.778921  3342 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap_"
solver_mode: CPU
random_seed: 42
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/train_val.prototxt"
I0204 16:28:13.779104  3342 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/train_val.prototxt
I0204 16:28:13.779736  3342 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:28:13.779769  3342 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:28:13.780025  3342 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.780176  3342 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.780397  3342 net.cpp:106] Creating Layer data
I0204 16:28:13.780428  3342 net.cpp:411] data -> data
I0204 16:28:13.780503  3342 net.cpp:411] data -> label
I0204 16:28:13.780529  3342 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:28:13.780591  3344 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:28:13.781638  3342 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.816289  3342 net.cpp:150] Setting up data
I0204 16:28:13.816387  3342 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.816454  3342 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.816462  3342 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.816485  3342 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.816545  3342 net.cpp:106] Creating Layer conv1
I0204 16:28:13.816555  3342 net.cpp:454] conv1 <- data
I0204 16:28:13.816576  3342 net.cpp:411] conv1 -> conv1
I0204 16:28:13.825255  3342 net.cpp:150] Setting up conv1
I0204 16:28:13.825311  3342 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.825317  3342 net.cpp:165] Memory required for data: 59332000
I0204 16:28:13.825346  3342 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.825368  3342 net.cpp:106] Creating Layer relu1
I0204 16:28:13.825378  3342 net.cpp:454] relu1 <- conv1
I0204 16:28:13.825390  3342 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.825410  3342 net.cpp:150] Setting up relu1
I0204 16:28:13.825419  3342 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.825425  3342 net.cpp:165] Memory required for data: 98052000
I0204 16:28:13.825435  3342 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.825448  3342 net.cpp:106] Creating Layer pool1
I0204 16:28:13.825454  3342 net.cpp:454] pool1 <- conv1
I0204 16:28:13.825464  3342 net.cpp:411] pool1 -> pool1
I0204 16:28:13.825491  3342 net.cpp:150] Setting up pool1
I0204 16:28:13.825502  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.825522  3342 net.cpp:165] Memory required for data: 107383200
I0204 16:28:13.825530  3342 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.825570  3342 net.cpp:106] Creating Layer norm1
I0204 16:28:13.825577  3342 net.cpp:454] norm1 <- pool1
I0204 16:28:13.825587  3342 net.cpp:411] norm1 -> norm1
I0204 16:28:13.825749  3342 net.cpp:150] Setting up norm1
I0204 16:28:13.825763  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.825769  3342 net.cpp:165] Memory required for data: 116714400
I0204 16:28:13.825776  3342 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.825793  3342 net.cpp:106] Creating Layer conv2
I0204 16:28:13.825800  3342 net.cpp:454] conv2 <- norm1
I0204 16:28:13.825811  3342 net.cpp:411] conv2 -> conv2
I0204 16:28:13.825975  3342 net.cpp:150] Setting up conv2
I0204 16:28:13.825987  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.825992  3342 net.cpp:165] Memory required for data: 126045600
I0204 16:28:13.826006  3342 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.826035  3342 net.cpp:106] Creating Layer relu2
I0204 16:28:13.826043  3342 net.cpp:454] relu2 <- conv2
I0204 16:28:13.826063  3342 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.826074  3342 net.cpp:150] Setting up relu2
I0204 16:28:13.826083  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.826088  3342 net.cpp:165] Memory required for data: 135376800
I0204 16:28:13.826095  3342 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.826109  3342 net.cpp:106] Creating Layer pool2
I0204 16:28:13.826117  3342 net.cpp:454] pool2 <- conv2
I0204 16:28:13.826125  3342 net.cpp:411] pool2 -> pool2
I0204 16:28:13.826138  3342 net.cpp:150] Setting up pool2
I0204 16:28:13.826146  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826151  3342 net.cpp:165] Memory required for data: 137540000
I0204 16:28:13.826158  3342 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.826170  3342 net.cpp:106] Creating Layer norm2
I0204 16:28:13.826177  3342 net.cpp:454] norm2 <- pool2
I0204 16:28:13.826189  3342 net.cpp:411] norm2 -> norm2
I0204 16:28:13.826200  3342 net.cpp:150] Setting up norm2
I0204 16:28:13.826206  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826212  3342 net.cpp:165] Memory required for data: 139703200
I0204 16:28:13.826217  3342 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.826231  3342 net.cpp:106] Creating Layer conv3
I0204 16:28:13.826236  3342 net.cpp:454] conv3 <- norm2
I0204 16:28:13.826246  3342 net.cpp:411] conv3 -> conv3
I0204 16:28:13.826371  3342 net.cpp:150] Setting up conv3
I0204 16:28:13.826383  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826388  3342 net.cpp:165] Memory required for data: 141866400
I0204 16:28:13.826400  3342 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.826411  3342 net.cpp:106] Creating Layer relu3
I0204 16:28:13.826426  3342 net.cpp:454] relu3 <- conv3
I0204 16:28:13.826436  3342 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.826444  3342 net.cpp:150] Setting up relu3
I0204 16:28:13.826462  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826468  3342 net.cpp:165] Memory required for data: 144029600
I0204 16:28:13.826474  3342 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.826489  3342 net.cpp:106] Creating Layer conv4
I0204 16:28:13.826496  3342 net.cpp:454] conv4 <- conv3
I0204 16:28:13.826508  3342 net.cpp:411] conv4 -> conv4
I0204 16:28:13.826598  3342 net.cpp:150] Setting up conv4
I0204 16:28:13.826608  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826614  3342 net.cpp:165] Memory required for data: 146192800
I0204 16:28:13.826624  3342 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.826632  3342 net.cpp:106] Creating Layer relu4
I0204 16:28:13.826639  3342 net.cpp:454] relu4 <- conv4
I0204 16:28:13.826648  3342 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.826658  3342 net.cpp:150] Setting up relu4
I0204 16:28:13.826666  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.826673  3342 net.cpp:165] Memory required for data: 148356000
I0204 16:28:13.826689  3342 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.826712  3342 net.cpp:106] Creating Layer conv5
I0204 16:28:13.826719  3342 net.cpp:454] conv5 <- conv4
I0204 16:28:13.826730  3342 net.cpp:411] conv5 -> conv5
I0204 16:28:13.826802  3342 net.cpp:150] Setting up conv5
I0204 16:28:13.826817  3342 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.826824  3342 net.cpp:165] Memory required for data: 149437600
I0204 16:28:13.826838  3342 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.826848  3342 net.cpp:106] Creating Layer relu5
I0204 16:28:13.826855  3342 net.cpp:454] relu5 <- conv5
I0204 16:28:13.826869  3342 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.826879  3342 net.cpp:150] Setting up relu5
I0204 16:28:13.826889  3342 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.826894  3342 net.cpp:165] Memory required for data: 150519200
I0204 16:28:13.826900  3342 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.826910  3342 net.cpp:106] Creating Layer pool5
I0204 16:28:13.826917  3342 net.cpp:454] pool5 <- conv5
I0204 16:28:13.826951  3342 net.cpp:411] pool5 -> pool5
I0204 16:28:13.826968  3342 net.cpp:150] Setting up pool5
I0204 16:28:13.826977  3342 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.826983  3342 net.cpp:165] Memory required for data: 150749600
I0204 16:28:13.826990  3342 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.827009  3342 net.cpp:106] Creating Layer fc6
I0204 16:28:13.827031  3342 net.cpp:454] fc6 <- pool5
I0204 16:28:13.827045  3342 net.cpp:411] fc6 -> fc6
I0204 16:28:13.829094  3342 net.cpp:150] Setting up fc6
I0204 16:28:13.829118  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.829125  3342 net.cpp:165] Memory required for data: 150852000
I0204 16:28:13.829138  3342 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.829154  3342 net.cpp:106] Creating Layer relu6
I0204 16:28:13.829160  3342 net.cpp:454] relu6 <- fc6
I0204 16:28:13.829172  3342 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.829185  3342 net.cpp:150] Setting up relu6
I0204 16:28:13.829193  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.829200  3342 net.cpp:165] Memory required for data: 150954400
I0204 16:28:13.829206  3342 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.829218  3342 net.cpp:106] Creating Layer drop6
I0204 16:28:13.829226  3342 net.cpp:454] drop6 <- fc6
I0204 16:28:13.829234  3342 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.829259  3342 net.cpp:150] Setting up drop6
I0204 16:28:13.829285  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.829293  3342 net.cpp:165] Memory required for data: 151056800
I0204 16:28:13.829299  3342 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.829313  3342 net.cpp:106] Creating Layer fc7
I0204 16:28:13.829323  3342 net.cpp:454] fc7 <- fc6
I0204 16:28:13.829336  3342 net.cpp:411] fc7 -> fc7
I0204 16:28:13.830238  3342 net.cpp:150] Setting up fc7
I0204 16:28:13.830255  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.830260  3342 net.cpp:165] Memory required for data: 151159200
I0204 16:28:13.830286  3342 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.830299  3342 net.cpp:106] Creating Layer relu7
I0204 16:28:13.830307  3342 net.cpp:454] relu7 <- fc7
I0204 16:28:13.830319  3342 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.830330  3342 net.cpp:150] Setting up relu7
I0204 16:28:13.830339  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.830345  3342 net.cpp:165] Memory required for data: 151261600
I0204 16:28:13.830353  3342 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.830363  3342 net.cpp:106] Creating Layer drop7
I0204 16:28:13.830373  3342 net.cpp:454] drop7 <- fc7
I0204 16:28:13.830384  3342 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.830396  3342 net.cpp:150] Setting up drop7
I0204 16:28:13.830404  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.830411  3342 net.cpp:165] Memory required for data: 151364000
I0204 16:28:13.830418  3342 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.830440  3342 net.cpp:106] Creating Layer fc8
I0204 16:28:13.830458  3342 net.cpp:454] fc8 <- fc7
I0204 16:28:13.830476  3342 net.cpp:411] fc8 -> fc8
I0204 16:28:13.830503  3342 net.cpp:150] Setting up fc8
I0204 16:28:13.830513  3342 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.830519  3342 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.830531  3342 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.830546  3342 net.cpp:106] Creating Layer loss
I0204 16:28:13.830554  3342 net.cpp:454] loss <- fc8
I0204 16:28:13.830561  3342 net.cpp:454] loss <- label
I0204 16:28:13.830574  3342 net.cpp:411] loss -> loss
I0204 16:28:13.830591  3342 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.830626  3342 net.cpp:150] Setting up loss
I0204 16:28:13.830636  3342 net.cpp:157] Top shape: (1)
I0204 16:28:13.830642  3342 net.cpp:160]     with loss weight 1
I0204 16:28:13.830682  3342 net.cpp:165] Memory required for data: 151364804
I0204 16:28:13.830693  3342 net.cpp:226] loss needs backward computation.
I0204 16:28:13.830701  3342 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.830708  3342 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.830714  3342 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.830720  3342 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.830727  3342 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.830734  3342 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.830740  3342 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.830749  3342 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.830757  3342 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.830765  3342 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.830790  3342 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.830796  3342 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.830806  3342 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.830812  3342 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.830824  3342 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.830832  3342 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.830842  3342 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.830849  3342 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.830857  3342 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.830864  3342 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.830871  3342 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.830878  3342 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.830886  3342 net.cpp:228] data does not need backward computation.
I0204 16:28:13.830893  3342 net.cpp:270] This network produces output loss
I0204 16:28:13.830935  3342 net.cpp:283] Network initialization done.
I0204 16:28:13.831992  3342 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/train_val.prototxt
I0204 16:28:13.832082  3342 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:28:13.832489  3342 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:28:13.832731  3342 layer_factory.hpp:77] Creating layer data
I0204 16:28:13.832943  3342 net.cpp:106] Creating Layer data
I0204 16:28:13.832964  3342 net.cpp:411] data -> data
I0204 16:28:13.832983  3342 net.cpp:411] data -> label
I0204 16:28:13.832999  3342 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:28:13.834090  3349 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:28:13.834352  3342 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:28:13.881198  3342 net.cpp:150] Setting up data
I0204 16:28:13.881243  3342 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:28:13.881253  3342 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.881258  3342 net.cpp:165] Memory required for data: 20612000
I0204 16:28:13.881269  3342 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:28:13.881290  3342 net.cpp:106] Creating Layer label_data_1_split
I0204 16:28:13.881299  3342 net.cpp:454] label_data_1_split <- label
I0204 16:28:13.881309  3342 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:28:13.881327  3342 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:28:13.881340  3342 net.cpp:150] Setting up label_data_1_split
I0204 16:28:13.881348  3342 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.881356  3342 net.cpp:157] Top shape: 100 (100)
I0204 16:28:13.881361  3342 net.cpp:165] Memory required for data: 20612800
I0204 16:28:13.881366  3342 layer_factory.hpp:77] Creating layer conv1
I0204 16:28:13.881383  3342 net.cpp:106] Creating Layer conv1
I0204 16:28:13.881391  3342 net.cpp:454] conv1 <- data
I0204 16:28:13.881399  3342 net.cpp:411] conv1 -> conv1
I0204 16:28:13.881469  3342 net.cpp:150] Setting up conv1
I0204 16:28:13.881479  3342 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.881484  3342 net.cpp:165] Memory required for data: 59332800
I0204 16:28:13.881499  3342 layer_factory.hpp:77] Creating layer relu1
I0204 16:28:13.881508  3342 net.cpp:106] Creating Layer relu1
I0204 16:28:13.881515  3342 net.cpp:454] relu1 <- conv1
I0204 16:28:13.881523  3342 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:28:13.881532  3342 net.cpp:150] Setting up relu1
I0204 16:28:13.881541  3342 net.cpp:157] Top shape: 100 32 55 55 (9680000)
I0204 16:28:13.881546  3342 net.cpp:165] Memory required for data: 98052800
I0204 16:28:13.881551  3342 layer_factory.hpp:77] Creating layer pool1
I0204 16:28:13.881562  3342 net.cpp:106] Creating Layer pool1
I0204 16:28:13.881569  3342 net.cpp:454] pool1 <- conv1
I0204 16:28:13.881577  3342 net.cpp:411] pool1 -> pool1
I0204 16:28:13.881590  3342 net.cpp:150] Setting up pool1
I0204 16:28:13.881598  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.881603  3342 net.cpp:165] Memory required for data: 107384000
I0204 16:28:13.881609  3342 layer_factory.hpp:77] Creating layer norm1
I0204 16:28:13.881621  3342 net.cpp:106] Creating Layer norm1
I0204 16:28:13.881628  3342 net.cpp:454] norm1 <- pool1
I0204 16:28:13.881635  3342 net.cpp:411] norm1 -> norm1
I0204 16:28:13.881646  3342 net.cpp:150] Setting up norm1
I0204 16:28:13.881654  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.881659  3342 net.cpp:165] Memory required for data: 116715200
I0204 16:28:13.881664  3342 layer_factory.hpp:77] Creating layer conv2
I0204 16:28:13.881675  3342 net.cpp:106] Creating Layer conv2
I0204 16:28:13.881681  3342 net.cpp:454] conv2 <- norm1
I0204 16:28:13.881691  3342 net.cpp:411] conv2 -> conv2
I0204 16:28:13.881819  3342 net.cpp:150] Setting up conv2
I0204 16:28:13.881827  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.881834  3342 net.cpp:165] Memory required for data: 126046400
I0204 16:28:13.881844  3342 layer_factory.hpp:77] Creating layer relu2
I0204 16:28:13.881853  3342 net.cpp:106] Creating Layer relu2
I0204 16:28:13.881860  3342 net.cpp:454] relu2 <- conv2
I0204 16:28:13.881877  3342 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:28:13.881897  3342 net.cpp:150] Setting up relu2
I0204 16:28:13.881906  3342 net.cpp:157] Top shape: 100 32 27 27 (2332800)
I0204 16:28:13.881911  3342 net.cpp:165] Memory required for data: 135377600
I0204 16:28:13.881916  3342 layer_factory.hpp:77] Creating layer pool2
I0204 16:28:13.881927  3342 net.cpp:106] Creating Layer pool2
I0204 16:28:13.881933  3342 net.cpp:454] pool2 <- conv2
I0204 16:28:13.881942  3342 net.cpp:411] pool2 -> pool2
I0204 16:28:13.881954  3342 net.cpp:150] Setting up pool2
I0204 16:28:13.881963  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.881968  3342 net.cpp:165] Memory required for data: 137540800
I0204 16:28:13.881973  3342 layer_factory.hpp:77] Creating layer norm2
I0204 16:28:13.881983  3342 net.cpp:106] Creating Layer norm2
I0204 16:28:13.881988  3342 net.cpp:454] norm2 <- pool2
I0204 16:28:13.881995  3342 net.cpp:411] norm2 -> norm2
I0204 16:28:13.882004  3342 net.cpp:150] Setting up norm2
I0204 16:28:13.882011  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.882016  3342 net.cpp:165] Memory required for data: 139704000
I0204 16:28:13.882022  3342 layer_factory.hpp:77] Creating layer conv3
I0204 16:28:13.882038  3342 net.cpp:106] Creating Layer conv3
I0204 16:28:13.882045  3342 net.cpp:454] conv3 <- norm2
I0204 16:28:13.882055  3342 net.cpp:411] conv3 -> conv3
I0204 16:28:13.882151  3342 net.cpp:150] Setting up conv3
I0204 16:28:13.882159  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.882164  3342 net.cpp:165] Memory required for data: 141867200
I0204 16:28:13.882174  3342 layer_factory.hpp:77] Creating layer relu3
I0204 16:28:13.882184  3342 net.cpp:106] Creating Layer relu3
I0204 16:28:13.882189  3342 net.cpp:454] relu3 <- conv3
I0204 16:28:13.882197  3342 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:28:13.882205  3342 net.cpp:150] Setting up relu3
I0204 16:28:13.882212  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.882217  3342 net.cpp:165] Memory required for data: 144030400
I0204 16:28:13.882222  3342 layer_factory.hpp:77] Creating layer conv4
I0204 16:28:13.882233  3342 net.cpp:106] Creating Layer conv4
I0204 16:28:13.882238  3342 net.cpp:454] conv4 <- conv3
I0204 16:28:13.882247  3342 net.cpp:411] conv4 -> conv4
I0204 16:28:13.882305  3342 net.cpp:150] Setting up conv4
I0204 16:28:13.882313  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.882318  3342 net.cpp:165] Memory required for data: 146193600
I0204 16:28:13.882325  3342 layer_factory.hpp:77] Creating layer relu4
I0204 16:28:13.882334  3342 net.cpp:106] Creating Layer relu4
I0204 16:28:13.882340  3342 net.cpp:454] relu4 <- conv4
I0204 16:28:13.882349  3342 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:28:13.882356  3342 net.cpp:150] Setting up relu4
I0204 16:28:13.882364  3342 net.cpp:157] Top shape: 100 32 13 13 (540800)
I0204 16:28:13.882369  3342 net.cpp:165] Memory required for data: 148356800
I0204 16:28:13.882375  3342 layer_factory.hpp:77] Creating layer conv5
I0204 16:28:13.882385  3342 net.cpp:106] Creating Layer conv5
I0204 16:28:13.882390  3342 net.cpp:454] conv5 <- conv4
I0204 16:28:13.882398  3342 net.cpp:411] conv5 -> conv5
I0204 16:28:13.882443  3342 net.cpp:150] Setting up conv5
I0204 16:28:13.882450  3342 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.882455  3342 net.cpp:165] Memory required for data: 149438400
I0204 16:28:13.882467  3342 layer_factory.hpp:77] Creating layer relu5
I0204 16:28:13.882475  3342 net.cpp:106] Creating Layer relu5
I0204 16:28:13.882480  3342 net.cpp:454] relu5 <- conv5
I0204 16:28:13.882488  3342 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:28:13.882496  3342 net.cpp:150] Setting up relu5
I0204 16:28:13.882503  3342 net.cpp:157] Top shape: 100 16 13 13 (270400)
I0204 16:28:13.882508  3342 net.cpp:165] Memory required for data: 150520000
I0204 16:28:13.882513  3342 layer_factory.hpp:77] Creating layer pool5
I0204 16:28:13.882524  3342 net.cpp:106] Creating Layer pool5
I0204 16:28:13.882534  3342 net.cpp:454] pool5 <- conv5
I0204 16:28:13.882549  3342 net.cpp:411] pool5 -> pool5
I0204 16:28:13.882560  3342 net.cpp:150] Setting up pool5
I0204 16:28:13.882566  3342 net.cpp:157] Top shape: 100 16 6 6 (57600)
I0204 16:28:13.882571  3342 net.cpp:165] Memory required for data: 150750400
I0204 16:28:13.882577  3342 layer_factory.hpp:77] Creating layer fc6
I0204 16:28:13.882589  3342 net.cpp:106] Creating Layer fc6
I0204 16:28:13.882594  3342 net.cpp:454] fc6 <- pool5
I0204 16:28:13.882603  3342 net.cpp:411] fc6 -> fc6
I0204 16:28:13.884387  3342 net.cpp:150] Setting up fc6
I0204 16:28:13.884402  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.884407  3342 net.cpp:165] Memory required for data: 150852800
I0204 16:28:13.884416  3342 layer_factory.hpp:77] Creating layer relu6
I0204 16:28:13.884426  3342 net.cpp:106] Creating Layer relu6
I0204 16:28:13.884434  3342 net.cpp:454] relu6 <- fc6
I0204 16:28:13.884443  3342 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:28:13.884454  3342 net.cpp:150] Setting up relu6
I0204 16:28:13.884460  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.884465  3342 net.cpp:165] Memory required for data: 150955200
I0204 16:28:13.884470  3342 layer_factory.hpp:77] Creating layer drop6
I0204 16:28:13.884481  3342 net.cpp:106] Creating Layer drop6
I0204 16:28:13.884487  3342 net.cpp:454] drop6 <- fc6
I0204 16:28:13.884495  3342 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:28:13.884506  3342 net.cpp:150] Setting up drop6
I0204 16:28:13.884513  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.884519  3342 net.cpp:165] Memory required for data: 151057600
I0204 16:28:13.884526  3342 layer_factory.hpp:77] Creating layer fc7
I0204 16:28:13.884536  3342 net.cpp:106] Creating Layer fc7
I0204 16:28:13.884542  3342 net.cpp:454] fc7 <- fc6
I0204 16:28:13.884549  3342 net.cpp:411] fc7 -> fc7
I0204 16:28:13.885265  3342 net.cpp:150] Setting up fc7
I0204 16:28:13.885277  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.885283  3342 net.cpp:165] Memory required for data: 151160000
I0204 16:28:13.885292  3342 layer_factory.hpp:77] Creating layer relu7
I0204 16:28:13.885300  3342 net.cpp:106] Creating Layer relu7
I0204 16:28:13.885306  3342 net.cpp:454] relu7 <- fc7
I0204 16:28:13.885315  3342 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:28:13.885324  3342 net.cpp:150] Setting up relu7
I0204 16:28:13.885331  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.885336  3342 net.cpp:165] Memory required for data: 151262400
I0204 16:28:13.885342  3342 layer_factory.hpp:77] Creating layer drop7
I0204 16:28:13.885352  3342 net.cpp:106] Creating Layer drop7
I0204 16:28:13.885359  3342 net.cpp:454] drop7 <- fc7
I0204 16:28:13.885365  3342 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:28:13.885375  3342 net.cpp:150] Setting up drop7
I0204 16:28:13.885382  3342 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:28:13.885387  3342 net.cpp:165] Memory required for data: 151364800
I0204 16:28:13.885393  3342 layer_factory.hpp:77] Creating layer fc8
I0204 16:28:13.885408  3342 net.cpp:106] Creating Layer fc8
I0204 16:28:13.885414  3342 net.cpp:454] fc8 <- fc7
I0204 16:28:13.885422  3342 net.cpp:411] fc8 -> fc8
I0204 16:28:13.885448  3342 net.cpp:150] Setting up fc8
I0204 16:28:13.885457  3342 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.885465  3342 net.cpp:165] Memory required for data: 151365600
I0204 16:28:13.885473  3342 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:28:13.885484  3342 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:28:13.885490  3342 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:28:13.885498  3342 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:28:13.885506  3342 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:28:13.885516  3342 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:28:13.885525  3342 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.885531  3342 net.cpp:157] Top shape: 100 2 (200)
I0204 16:28:13.885538  3342 net.cpp:165] Memory required for data: 151367200
I0204 16:28:13.885545  3342 layer_factory.hpp:77] Creating layer accuracy
I0204 16:28:13.885576  3342 net.cpp:106] Creating Layer accuracy
I0204 16:28:13.885582  3342 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:28:13.885589  3342 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:28:13.885601  3342 net.cpp:411] accuracy -> accuracy
I0204 16:28:13.885612  3342 net.cpp:150] Setting up accuracy
I0204 16:28:13.885618  3342 net.cpp:157] Top shape: (1)
I0204 16:28:13.885624  3342 net.cpp:165] Memory required for data: 151367204
I0204 16:28:13.885629  3342 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.885640  3342 net.cpp:106] Creating Layer loss
I0204 16:28:13.885646  3342 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:28:13.885653  3342 net.cpp:454] loss <- label_data_1_split_1
I0204 16:28:13.885660  3342 net.cpp:411] loss -> loss
I0204 16:28:13.885676  3342 layer_factory.hpp:77] Creating layer loss
I0204 16:28:13.885695  3342 net.cpp:150] Setting up loss
I0204 16:28:13.885705  3342 net.cpp:157] Top shape: (1)
I0204 16:28:13.885710  3342 net.cpp:160]     with loss weight 1
I0204 16:28:13.885725  3342 net.cpp:165] Memory required for data: 151367208
I0204 16:28:13.885730  3342 net.cpp:226] loss needs backward computation.
I0204 16:28:13.885738  3342 net.cpp:228] accuracy does not need backward computation.
I0204 16:28:13.885746  3342 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:28:13.885751  3342 net.cpp:226] fc8 needs backward computation.
I0204 16:28:13.885757  3342 net.cpp:226] drop7 needs backward computation.
I0204 16:28:13.885762  3342 net.cpp:226] relu7 needs backward computation.
I0204 16:28:13.885767  3342 net.cpp:226] fc7 needs backward computation.
I0204 16:28:13.885773  3342 net.cpp:226] drop6 needs backward computation.
I0204 16:28:13.885778  3342 net.cpp:226] relu6 needs backward computation.
I0204 16:28:13.885783  3342 net.cpp:226] fc6 needs backward computation.
I0204 16:28:13.885789  3342 net.cpp:226] pool5 needs backward computation.
I0204 16:28:13.885795  3342 net.cpp:226] relu5 needs backward computation.
I0204 16:28:13.885802  3342 net.cpp:226] conv5 needs backward computation.
I0204 16:28:13.885807  3342 net.cpp:226] relu4 needs backward computation.
I0204 16:28:13.885812  3342 net.cpp:226] conv4 needs backward computation.
I0204 16:28:13.885820  3342 net.cpp:226] relu3 needs backward computation.
I0204 16:28:13.885825  3342 net.cpp:226] conv3 needs backward computation.
I0204 16:28:13.885833  3342 net.cpp:226] norm2 needs backward computation.
I0204 16:28:13.885838  3342 net.cpp:226] pool2 needs backward computation.
I0204 16:28:13.885843  3342 net.cpp:226] relu2 needs backward computation.
I0204 16:28:13.885849  3342 net.cpp:226] conv2 needs backward computation.
I0204 16:28:13.885854  3342 net.cpp:226] norm1 needs backward computation.
I0204 16:28:13.885860  3342 net.cpp:226] pool1 needs backward computation.
I0204 16:28:13.885866  3342 net.cpp:226] relu1 needs backward computation.
I0204 16:28:13.885874  3342 net.cpp:226] conv1 needs backward computation.
I0204 16:28:13.885880  3342 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:28:13.885887  3342 net.cpp:228] data does not need backward computation.
I0204 16:28:13.885892  3342 net.cpp:270] This network produces output accuracy
I0204 16:28:13.885898  3342 net.cpp:270] This network produces output loss
I0204 16:28:13.885926  3342 net.cpp:283] Network initialization done.
I0204 16:28:13.886056  3342 solver.cpp:60] Solver scaffolding done.
I0204 16:28:13.886114  3342 caffe.cpp:212] Starting Optimization
I0204 16:28:13.886121  3342 solver.cpp:288] Solving CaffeNet
I0204 16:28:13.886126  3342 solver.cpp:289] Learning Rate Policy: step
I0204 16:28:13.886932  3342 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:28:13.887080  3342 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:28:21.414043  3342 solver.cpp:409]     Test net output #0: accuracy = 0.52
I0204 16:28:21.414096  3342 solver.cpp:409]     Test net output #1: loss = 1.50945 (* 1 = 1.50945 loss)
I0204 16:28:23.040805  3342 solver.cpp:237] Iteration 0, loss = 9.79225
I0204 16:28:23.040874  3342 solver.cpp:253]     Train net output #0: loss = 9.79225 (* 1 = 9.79225 loss)
I0204 16:28:23.040885  3342 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:28:42.454767  3342 solver.cpp:237] Iteration 10, loss = 1.62766
I0204 16:28:42.454818  3342 solver.cpp:253]     Train net output #0: loss = 1.62766 (* 1 = 1.62766 loss)
I0204 16:28:42.454828  3342 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:29:04.018463  3342 solver.cpp:237] Iteration 20, loss = 1.0319
I0204 16:29:04.018559  3342 solver.cpp:253]     Train net output #0: loss = 1.0319 (* 1 = 1.0319 loss)
I0204 16:29:04.018570  3342 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:29:24.723852  3342 solver.cpp:237] Iteration 30, loss = 0.955991
I0204 16:29:24.723901  3342 solver.cpp:253]     Train net output #0: loss = 0.955991 (* 1 = 0.955991 loss)
I0204 16:29:24.723912  3342 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:29:45.498191  3342 solver.cpp:237] Iteration 40, loss = 0.821402
I0204 16:29:45.498519  3342 solver.cpp:253]     Train net output #0: loss = 0.821402 (* 1 = 0.821402 loss)
I0204 16:29:45.498533  3342 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:30:05.713340  3342 solver.cpp:237] Iteration 50, loss = 0.880073
I0204 16:30:05.713392  3342 solver.cpp:253]     Train net output #0: loss = 0.880073 (* 1 = 0.880073 loss)
I0204 16:30:05.713403  3342 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:30:26.063731  3342 solver.cpp:237] Iteration 60, loss = 0.786248
I0204 16:30:26.063912  3342 solver.cpp:253]     Train net output #0: loss = 0.786248 (* 1 = 0.786248 loss)
I0204 16:30:26.063926  3342 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:30:46.519651  3342 solver.cpp:237] Iteration 70, loss = 0.716674
I0204 16:30:46.519703  3342 solver.cpp:253]     Train net output #0: loss = 0.716674 (* 1 = 0.716674 loss)
I0204 16:30:46.519714  3342 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:31:10.052546  3342 solver.cpp:237] Iteration 80, loss = 0.755559
I0204 16:31:10.056219  3342 solver.cpp:253]     Train net output #0: loss = 0.755559 (* 1 = 0.755559 loss)
I0204 16:31:10.056248  3342 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:31:33.886447  3342 solver.cpp:237] Iteration 90, loss = 0.738596
I0204 16:31:33.886510  3342 solver.cpp:253]     Train net output #0: loss = 0.738596 (* 1 = 0.738596 loss)
I0204 16:31:33.886523  3342 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:31:55.487540  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_100.caffemodel
I0204 16:31:55.491511  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_100.solverstate
I0204 16:31:55.493397  3342 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:32:06.797335  3342 solver.cpp:409]     Test net output #0: accuracy = 0.501
I0204 16:32:06.797397  3342 solver.cpp:409]     Test net output #1: loss = 0.698273 (* 1 = 0.698273 loss)
I0204 16:32:09.171736  3342 solver.cpp:237] Iteration 100, loss = 0.720656
I0204 16:32:09.171798  3342 solver.cpp:253]     Train net output #0: loss = 0.720656 (* 1 = 0.720656 loss)
I0204 16:32:09.171811  3342 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:33.174499  3342 solver.cpp:237] Iteration 110, loss = 0.736822
I0204 16:32:33.174677  3342 solver.cpp:253]     Train net output #0: loss = 0.736822 (* 1 = 0.736822 loss)
I0204 16:32:33.174691  3342 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:32:56.915813  3342 solver.cpp:237] Iteration 120, loss = 0.715229
I0204 16:32:56.915874  3342 solver.cpp:253]     Train net output #0: loss = 0.715229 (* 1 = 0.715229 loss)
I0204 16:32:56.915886  3342 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:33:20.283025  3342 solver.cpp:237] Iteration 130, loss = 0.76686
I0204 16:33:20.283247  3342 solver.cpp:253]     Train net output #0: loss = 0.76686 (* 1 = 0.76686 loss)
I0204 16:33:20.283267  3342 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:33:43.629729  3342 solver.cpp:237] Iteration 140, loss = 0.782425
I0204 16:33:43.629801  3342 solver.cpp:253]     Train net output #0: loss = 0.782425 (* 1 = 0.782425 loss)
I0204 16:33:43.629813  3342 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:34:06.935752  3342 solver.cpp:237] Iteration 150, loss = 0.688057
I0204 16:34:06.935906  3342 solver.cpp:253]     Train net output #0: loss = 0.688057 (* 1 = 0.688057 loss)
I0204 16:34:06.935920  3342 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:34:30.241327  3342 solver.cpp:237] Iteration 160, loss = 0.696051
I0204 16:34:30.241387  3342 solver.cpp:253]     Train net output #0: loss = 0.696051 (* 1 = 0.696051 loss)
I0204 16:34:30.241400  3342 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:34:53.570709  3342 solver.cpp:237] Iteration 170, loss = 0.714947
I0204 16:34:53.570888  3342 solver.cpp:253]     Train net output #0: loss = 0.714947 (* 1 = 0.714947 loss)
I0204 16:34:53.570900  3342 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:35:16.903012  3342 solver.cpp:237] Iteration 180, loss = 0.703282
I0204 16:35:16.903074  3342 solver.cpp:253]     Train net output #0: loss = 0.703282 (* 1 = 0.703282 loss)
I0204 16:35:16.903086  3342 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:35:40.145658  3342 solver.cpp:237] Iteration 190, loss = 0.733244
I0204 16:35:40.145823  3342 solver.cpp:253]     Train net output #0: loss = 0.733244 (* 1 = 0.733244 loss)
I0204 16:35:40.145835  3342 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:36:01.188474  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_200.caffemodel
I0204 16:36:01.192585  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_200.solverstate
I0204 16:36:01.194344  3342 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:36:12.390786  3342 solver.cpp:409]     Test net output #0: accuracy = 0.542
I0204 16:36:12.390926  3342 solver.cpp:409]     Test net output #1: loss = 0.678637 (* 1 = 0.678637 loss)
I0204 16:36:14.722929  3342 solver.cpp:237] Iteration 200, loss = 0.699816
I0204 16:36:14.722996  3342 solver.cpp:253]     Train net output #0: loss = 0.699816 (* 1 = 0.699816 loss)
I0204 16:36:14.723008  3342 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:36:38.131597  3342 solver.cpp:237] Iteration 210, loss = 0.670452
I0204 16:36:38.131665  3342 solver.cpp:253]     Train net output #0: loss = 0.670452 (* 1 = 0.670452 loss)
I0204 16:36:38.131678  3342 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:37:01.671095  3342 solver.cpp:237] Iteration 220, loss = 0.723077
I0204 16:37:01.671275  3342 solver.cpp:253]     Train net output #0: loss = 0.723077 (* 1 = 0.723077 loss)
I0204 16:37:01.671289  3342 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:37:25.484145  3342 solver.cpp:237] Iteration 230, loss = 0.679751
I0204 16:37:25.484213  3342 solver.cpp:253]     Train net output #0: loss = 0.679751 (* 1 = 0.679751 loss)
I0204 16:37:25.484226  3342 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:37:49.556793  3342 solver.cpp:237] Iteration 240, loss = 0.637008
I0204 16:37:49.556960  3342 solver.cpp:253]     Train net output #0: loss = 0.637008 (* 1 = 0.637008 loss)
I0204 16:37:49.556974  3342 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:38:13.689543  3342 solver.cpp:237] Iteration 250, loss = 0.655201
I0204 16:38:13.689611  3342 solver.cpp:253]     Train net output #0: loss = 0.655201 (* 1 = 0.655201 loss)
I0204 16:38:13.689626  3342 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:38:37.695763  3342 solver.cpp:237] Iteration 260, loss = 0.661475
I0204 16:38:37.695935  3342 solver.cpp:253]     Train net output #0: loss = 0.661475 (* 1 = 0.661475 loss)
I0204 16:38:37.695960  3342 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:39:01.907290  3342 solver.cpp:237] Iteration 270, loss = 0.517383
I0204 16:39:01.907346  3342 solver.cpp:253]     Train net output #0: loss = 0.517383 (* 1 = 0.517383 loss)
I0204 16:39:01.907358  3342 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:39:26.087368  3342 solver.cpp:237] Iteration 280, loss = 0.563506
I0204 16:39:26.087530  3342 solver.cpp:253]     Train net output #0: loss = 0.563506 (* 1 = 0.563506 loss)
I0204 16:39:26.087544  3342 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:39:50.224599  3342 solver.cpp:237] Iteration 290, loss = 0.503402
I0204 16:39:50.224653  3342 solver.cpp:253]     Train net output #0: loss = 0.503402 (* 1 = 0.503402 loss)
I0204 16:39:50.224665  3342 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:40:12.089603  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_300.caffemodel
I0204 16:40:12.093737  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_300.solverstate
I0204 16:40:12.095470  3342 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:40:23.799357  3342 solver.cpp:409]     Test net output #0: accuracy = 0.882
I0204 16:40:23.799420  3342 solver.cpp:409]     Test net output #1: loss = 0.333098 (* 1 = 0.333098 loss)
I0204 16:40:26.258864  3342 solver.cpp:237] Iteration 300, loss = 0.393816
I0204 16:40:26.258914  3342 solver.cpp:253]     Train net output #0: loss = 0.393816 (* 1 = 0.393816 loss)
I0204 16:40:26.258927  3342 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:40:50.893563  3342 solver.cpp:237] Iteration 310, loss = 0.344226
I0204 16:40:50.893733  3342 solver.cpp:253]     Train net output #0: loss = 0.344226 (* 1 = 0.344226 loss)
I0204 16:40:50.893746  3342 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:41:15.851096  3342 solver.cpp:237] Iteration 320, loss = 0.365221
I0204 16:41:15.851153  3342 solver.cpp:253]     Train net output #0: loss = 0.365221 (* 1 = 0.365221 loss)
I0204 16:41:15.851166  3342 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:41:40.796322  3342 solver.cpp:237] Iteration 330, loss = 0.33522
I0204 16:41:40.796440  3342 solver.cpp:253]     Train net output #0: loss = 0.33522 (* 1 = 0.33522 loss)
I0204 16:41:40.796453  3342 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:42:05.384815  3342 solver.cpp:237] Iteration 340, loss = 0.246641
I0204 16:42:05.384876  3342 solver.cpp:253]     Train net output #0: loss = 0.246641 (* 1 = 0.246641 loss)
I0204 16:42:05.384888  3342 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:42:29.900660  3342 solver.cpp:237] Iteration 350, loss = 0.272463
I0204 16:42:29.901254  3342 solver.cpp:253]     Train net output #0: loss = 0.272463 (* 1 = 0.272463 loss)
I0204 16:42:29.901273  3342 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:42:54.552038  3342 solver.cpp:237] Iteration 360, loss = 0.194072
I0204 16:42:54.552093  3342 solver.cpp:253]     Train net output #0: loss = 0.194072 (* 1 = 0.194072 loss)
I0204 16:42:54.552104  3342 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:43:19.790166  3342 solver.cpp:237] Iteration 370, loss = 0.213901
I0204 16:43:19.790325  3342 solver.cpp:253]     Train net output #0: loss = 0.213901 (* 1 = 0.213901 loss)
I0204 16:43:19.790338  3342 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:43:45.552762  3342 solver.cpp:237] Iteration 380, loss = 0.097465
I0204 16:43:45.552817  3342 solver.cpp:253]     Train net output #0: loss = 0.097465 (* 1 = 0.097465 loss)
I0204 16:43:45.552830  3342 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:44:12.295855  3342 solver.cpp:237] Iteration 390, loss = 0.0776666
I0204 16:44:12.296075  3342 solver.cpp:253]     Train net output #0: loss = 0.0776666 (* 1 = 0.0776666 loss)
I0204 16:44:12.296090  3342 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:44:36.833052  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_400.caffemodel
I0204 16:44:36.836833  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_400.solverstate
I0204 16:44:36.838425  3342 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:44:49.684880  3342 solver.cpp:409]     Test net output #0: accuracy = 0.98
I0204 16:44:49.685075  3342 solver.cpp:409]     Test net output #1: loss = 0.0581016 (* 1 = 0.0581016 loss)
I0204 16:44:52.376670  3342 solver.cpp:237] Iteration 400, loss = 0.0769545
I0204 16:44:52.376720  3342 solver.cpp:253]     Train net output #0: loss = 0.0769545 (* 1 = 0.0769545 loss)
I0204 16:44:52.376734  3342 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:45:19.532088  3342 solver.cpp:237] Iteration 410, loss = 0.0671929
I0204 16:45:19.532145  3342 solver.cpp:253]     Train net output #0: loss = 0.0671929 (* 1 = 0.0671929 loss)
I0204 16:45:19.532157  3342 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:45:46.410362  3342 solver.cpp:237] Iteration 420, loss = 0.0679023
I0204 16:45:46.410534  3342 solver.cpp:253]     Train net output #0: loss = 0.0679023 (* 1 = 0.0679023 loss)
I0204 16:45:46.410548  3342 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:46:13.353291  3342 solver.cpp:237] Iteration 430, loss = 0.089463
I0204 16:46:13.353344  3342 solver.cpp:253]     Train net output #0: loss = 0.089463 (* 1 = 0.089463 loss)
I0204 16:46:13.353356  3342 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:46:39.955867  3342 solver.cpp:237] Iteration 440, loss = 0.0392713
I0204 16:46:39.956012  3342 solver.cpp:253]     Train net output #0: loss = 0.0392713 (* 1 = 0.0392713 loss)
I0204 16:46:39.956025  3342 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:47:06.251241  3342 solver.cpp:237] Iteration 450, loss = 0.0823764
I0204 16:47:06.251301  3342 solver.cpp:253]     Train net output #0: loss = 0.0823764 (* 1 = 0.0823764 loss)
I0204 16:47:06.251313  3342 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:47:32.064990  3342 solver.cpp:237] Iteration 460, loss = 0.0542959
I0204 16:47:32.065173  3342 solver.cpp:253]     Train net output #0: loss = 0.0542959 (* 1 = 0.0542959 loss)
I0204 16:47:32.065187  3342 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:47:57.835702  3342 solver.cpp:237] Iteration 470, loss = 0.0504153
I0204 16:47:57.835757  3342 solver.cpp:253]     Train net output #0: loss = 0.0504153 (* 1 = 0.0504153 loss)
I0204 16:47:57.835770  3342 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:48:23.764348  3342 solver.cpp:237] Iteration 480, loss = 0.0536921
I0204 16:48:23.764503  3342 solver.cpp:253]     Train net output #0: loss = 0.0536921 (* 1 = 0.0536921 loss)
I0204 16:48:23.764515  3342 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:48:49.921353  3342 solver.cpp:237] Iteration 490, loss = 0.0678968
I0204 16:48:49.921416  3342 solver.cpp:253]     Train net output #0: loss = 0.0678968 (* 1 = 0.0678968 loss)
I0204 16:48:49.921427  3342 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:49:13.408079  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_500.caffemodel
I0204 16:49:13.412045  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_500.solverstate
I0204 16:49:13.413594  3342 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:49:25.788054  3342 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 16:49:25.788120  3342 solver.cpp:409]     Test net output #1: loss = 0.0235697 (* 1 = 0.0235697 loss)
I0204 16:49:28.397827  3342 solver.cpp:237] Iteration 500, loss = 0.0546137
I0204 16:49:28.397898  3342 solver.cpp:253]     Train net output #0: loss = 0.0546137 (* 1 = 0.0546137 loss)
I0204 16:49:28.397910  3342 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:49:54.739331  3342 solver.cpp:237] Iteration 510, loss = 0.0976626
I0204 16:49:54.739578  3342 solver.cpp:253]     Train net output #0: loss = 0.0976626 (* 1 = 0.0976626 loss)
I0204 16:49:54.739593  3342 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:50:21.026669  3342 solver.cpp:237] Iteration 520, loss = 0.0139263
I0204 16:50:21.026728  3342 solver.cpp:253]     Train net output #0: loss = 0.0139263 (* 1 = 0.0139263 loss)
I0204 16:50:21.026741  3342 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:50:47.099340  3342 solver.cpp:237] Iteration 530, loss = 0.0557764
I0204 16:50:47.099515  3342 solver.cpp:253]     Train net output #0: loss = 0.0557764 (* 1 = 0.0557764 loss)
I0204 16:50:47.099529  3342 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:51:12.625663  3342 solver.cpp:237] Iteration 540, loss = 0.0176575
I0204 16:51:12.625725  3342 solver.cpp:253]     Train net output #0: loss = 0.0176576 (* 1 = 0.0176576 loss)
I0204 16:51:12.625736  3342 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:51:38.012809  3342 solver.cpp:237] Iteration 550, loss = 0.0145888
I0204 16:51:38.012992  3342 solver.cpp:253]     Train net output #0: loss = 0.0145888 (* 1 = 0.0145888 loss)
I0204 16:51:38.013006  3342 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:52:03.292065  3342 solver.cpp:237] Iteration 560, loss = 0.0531006
I0204 16:52:03.292124  3342 solver.cpp:253]     Train net output #0: loss = 0.0531006 (* 1 = 0.0531006 loss)
I0204 16:52:03.292140  3342 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:52:28.471029  3342 solver.cpp:237] Iteration 570, loss = 0.0134296
I0204 16:52:28.471246  3342 solver.cpp:253]     Train net output #0: loss = 0.0134296 (* 1 = 0.0134296 loss)
I0204 16:52:28.471261  3342 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:52:53.775961  3342 solver.cpp:237] Iteration 580, loss = 0.0636439
I0204 16:52:53.776022  3342 solver.cpp:253]     Train net output #0: loss = 0.0636439 (* 1 = 0.0636439 loss)
I0204 16:52:53.776036  3342 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:53:19.397656  3342 solver.cpp:237] Iteration 590, loss = 0.051397
I0204 16:53:19.398188  3342 solver.cpp:253]     Train net output #0: loss = 0.051397 (* 1 = 0.051397 loss)
I0204 16:53:19.398207  3342 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:53:42.279366  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_600.caffemodel
I0204 16:53:42.283120  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_600.solverstate
I0204 16:53:42.284606  3342 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:53:54.284317  3342 solver.cpp:409]     Test net output #0: accuracy = 0.973
I0204 16:53:54.284497  3342 solver.cpp:409]     Test net output #1: loss = 0.0771355 (* 1 = 0.0771355 loss)
I0204 16:53:56.854943  3342 solver.cpp:237] Iteration 600, loss = 0.107939
I0204 16:53:56.854993  3342 solver.cpp:253]     Train net output #0: loss = 0.107939 (* 1 = 0.107939 loss)
I0204 16:53:56.855005  3342 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:54:22.099853  3342 solver.cpp:237] Iteration 610, loss = 0.11394
I0204 16:54:22.099908  3342 solver.cpp:253]     Train net output #0: loss = 0.11394 (* 1 = 0.11394 loss)
I0204 16:54:22.099920  3342 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:54:47.315891  3342 solver.cpp:237] Iteration 620, loss = 0.00475502
I0204 16:54:47.316090  3342 solver.cpp:253]     Train net output #0: loss = 0.00475503 (* 1 = 0.00475503 loss)
I0204 16:54:47.316104  3342 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:55:12.720551  3342 solver.cpp:237] Iteration 630, loss = 0.00870559
I0204 16:55:12.720638  3342 solver.cpp:253]     Train net output #0: loss = 0.00870562 (* 1 = 0.00870562 loss)
I0204 16:55:12.720655  3342 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:55:38.139809  3342 solver.cpp:237] Iteration 640, loss = 0.0653375
I0204 16:55:38.140039  3342 solver.cpp:253]     Train net output #0: loss = 0.0653375 (* 1 = 0.0653375 loss)
I0204 16:55:38.140053  3342 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:56:03.588696  3342 solver.cpp:237] Iteration 650, loss = 0.081464
I0204 16:56:03.588752  3342 solver.cpp:253]     Train net output #0: loss = 0.081464 (* 1 = 0.081464 loss)
I0204 16:56:03.588764  3342 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:56:29.117791  3342 solver.cpp:237] Iteration 660, loss = 0.0495741
I0204 16:56:29.117985  3342 solver.cpp:253]     Train net output #0: loss = 0.0495741 (* 1 = 0.0495741 loss)
I0204 16:56:29.117998  3342 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:56:54.707715  3342 solver.cpp:237] Iteration 670, loss = 0.0669842
I0204 16:56:54.707767  3342 solver.cpp:253]     Train net output #0: loss = 0.0669842 (* 1 = 0.0669842 loss)
I0204 16:56:54.707777  3342 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:57:20.085757  3342 solver.cpp:237] Iteration 680, loss = 0.0121532
I0204 16:57:20.085945  3342 solver.cpp:253]     Train net output #0: loss = 0.0121533 (* 1 = 0.0121533 loss)
I0204 16:57:20.085960  3342 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:57:45.753795  3342 solver.cpp:237] Iteration 690, loss = 0.030588
I0204 16:57:45.753849  3342 solver.cpp:253]     Train net output #0: loss = 0.030588 (* 1 = 0.030588 loss)
I0204 16:57:45.753860  3342 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:58:08.834059  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_700.caffemodel
I0204 16:58:08.837829  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_700.solverstate
I0204 16:58:08.839352  3342 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:58:21.015262  3342 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:58:21.015316  3342 solver.cpp:409]     Test net output #1: loss = 0.023881 (* 1 = 0.023881 loss)
I0204 16:58:23.581377  3342 solver.cpp:237] Iteration 700, loss = 0.0117697
I0204 16:58:23.581425  3342 solver.cpp:253]     Train net output #0: loss = 0.0117697 (* 1 = 0.0117697 loss)
I0204 16:58:23.581436  3342 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:58:49.362097  3342 solver.cpp:237] Iteration 710, loss = 0.0524596
I0204 16:58:49.362258  3342 solver.cpp:253]     Train net output #0: loss = 0.0524596 (* 1 = 0.0524596 loss)
I0204 16:58:49.362272  3342 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:59:15.148537  3342 solver.cpp:237] Iteration 720, loss = 0.0248937
I0204 16:59:15.148591  3342 solver.cpp:253]     Train net output #0: loss = 0.0248937 (* 1 = 0.0248937 loss)
I0204 16:59:15.148603  3342 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:59:41.122303  3342 solver.cpp:237] Iteration 730, loss = 0.0619136
I0204 16:59:41.122485  3342 solver.cpp:253]     Train net output #0: loss = 0.0619137 (* 1 = 0.0619137 loss)
I0204 16:59:41.122498  3342 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 17:00:07.038236  3342 solver.cpp:237] Iteration 740, loss = 0.16736
I0204 17:00:07.038293  3342 solver.cpp:253]     Train net output #0: loss = 0.16736 (* 1 = 0.16736 loss)
I0204 17:00:07.038305  3342 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 17:00:33.058450  3342 solver.cpp:237] Iteration 750, loss = 0.0553601
I0204 17:00:33.058630  3342 solver.cpp:253]     Train net output #0: loss = 0.0553601 (* 1 = 0.0553601 loss)
I0204 17:00:33.058643  3342 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 17:00:58.954846  3342 solver.cpp:237] Iteration 760, loss = 0.0196638
I0204 17:00:58.954916  3342 solver.cpp:253]     Train net output #0: loss = 0.0196639 (* 1 = 0.0196639 loss)
I0204 17:00:58.954941  3342 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 17:01:24.896934  3342 solver.cpp:237] Iteration 770, loss = 0.0291123
I0204 17:01:24.897150  3342 solver.cpp:253]     Train net output #0: loss = 0.0291123 (* 1 = 0.0291123 loss)
I0204 17:01:24.897164  3342 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 17:01:50.922161  3342 solver.cpp:237] Iteration 780, loss = 0.00591704
I0204 17:01:50.922217  3342 solver.cpp:253]     Train net output #0: loss = 0.00591709 (* 1 = 0.00591709 loss)
I0204 17:01:50.922229  3342 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 17:02:16.947993  3342 solver.cpp:237] Iteration 790, loss = 0.0043294
I0204 17:02:16.948163  3342 solver.cpp:253]     Train net output #0: loss = 0.00432944 (* 1 = 0.00432944 loss)
I0204 17:02:16.948176  3342 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 17:02:40.422660  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_800.caffemodel
I0204 17:02:40.426390  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_800.solverstate
I0204 17:02:40.427889  3342 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 17:02:52.670393  3342 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 17:02:52.670583  3342 solver.cpp:409]     Test net output #1: loss = 0.0108413 (* 1 = 0.0108413 loss)
I0204 17:02:55.330245  3342 solver.cpp:237] Iteration 800, loss = 0.00429353
I0204 17:02:55.330312  3342 solver.cpp:253]     Train net output #0: loss = 0.00429357 (* 1 = 0.00429357 loss)
I0204 17:02:55.330324  3342 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 17:03:21.355940  3342 solver.cpp:237] Iteration 810, loss = 0.00780875
I0204 17:03:21.356008  3342 solver.cpp:253]     Train net output #0: loss = 0.0078088 (* 1 = 0.0078088 loss)
I0204 17:03:21.356020  3342 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 17:03:47.529484  3342 solver.cpp:237] Iteration 820, loss = 0.00604399
I0204 17:03:47.529672  3342 solver.cpp:253]     Train net output #0: loss = 0.00604403 (* 1 = 0.00604403 loss)
I0204 17:03:47.529686  3342 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 17:04:13.524715  3342 solver.cpp:237] Iteration 830, loss = 0.0532893
I0204 17:04:13.524785  3342 solver.cpp:253]     Train net output #0: loss = 0.0532893 (* 1 = 0.0532893 loss)
I0204 17:04:13.524801  3342 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 17:04:39.525101  3342 solver.cpp:237] Iteration 840, loss = 0.00508265
I0204 17:04:39.525284  3342 solver.cpp:253]     Train net output #0: loss = 0.0050827 (* 1 = 0.0050827 loss)
I0204 17:04:39.525296  3342 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 17:05:05.696220  3342 solver.cpp:237] Iteration 850, loss = 0.009884
I0204 17:05:05.696275  3342 solver.cpp:253]     Train net output #0: loss = 0.00988405 (* 1 = 0.00988405 loss)
I0204 17:05:05.696287  3342 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 17:05:31.859637  3342 solver.cpp:237] Iteration 860, loss = 0.00204116
I0204 17:05:31.859822  3342 solver.cpp:253]     Train net output #0: loss = 0.0020412 (* 1 = 0.0020412 loss)
I0204 17:05:31.859836  3342 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 17:05:57.807781  3342 solver.cpp:237] Iteration 870, loss = 0.0108494
I0204 17:05:57.807837  3342 solver.cpp:253]     Train net output #0: loss = 0.0108495 (* 1 = 0.0108495 loss)
I0204 17:05:57.807850  3342 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 17:06:23.919056  3342 solver.cpp:237] Iteration 880, loss = 0.0163255
I0204 17:06:23.919240  3342 solver.cpp:253]     Train net output #0: loss = 0.0163256 (* 1 = 0.0163256 loss)
I0204 17:06:23.919253  3342 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 17:06:49.714332  3342 solver.cpp:237] Iteration 890, loss = 0.00255408
I0204 17:06:49.714402  3342 solver.cpp:253]     Train net output #0: loss = 0.00255412 (* 1 = 0.00255412 loss)
I0204 17:06:49.714413  3342 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 17:07:13.335152  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_900.caffemodel
I0204 17:07:13.339103  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_900.solverstate
I0204 17:07:13.340587  3342 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 17:07:25.598525  3342 solver.cpp:409]     Test net output #0: accuracy = 0.997
I0204 17:07:25.598578  3342 solver.cpp:409]     Test net output #1: loss = 0.00697805 (* 1 = 0.00697805 loss)
I0204 17:07:28.226542  3342 solver.cpp:237] Iteration 900, loss = 0.0188491
I0204 17:07:28.226593  3342 solver.cpp:253]     Train net output #0: loss = 0.0188491 (* 1 = 0.0188491 loss)
I0204 17:07:28.226603  3342 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 17:07:54.297617  3342 solver.cpp:237] Iteration 910, loss = 0.037826
I0204 17:07:54.297819  3342 solver.cpp:253]     Train net output #0: loss = 0.037826 (* 1 = 0.037826 loss)
I0204 17:07:54.297834  3342 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 17:08:20.373543  3342 solver.cpp:237] Iteration 920, loss = 0.00114873
I0204 17:08:20.373600  3342 solver.cpp:253]     Train net output #0: loss = 0.00114878 (* 1 = 0.00114878 loss)
I0204 17:08:20.373612  3342 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 17:08:46.573060  3342 solver.cpp:237] Iteration 930, loss = 0.00507712
I0204 17:08:46.573236  3342 solver.cpp:253]     Train net output #0: loss = 0.00507717 (* 1 = 0.00507717 loss)
I0204 17:08:46.573249  3342 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 17:09:12.614303  3342 solver.cpp:237] Iteration 940, loss = 0.00258582
I0204 17:09:12.614362  3342 solver.cpp:253]     Train net output #0: loss = 0.00258587 (* 1 = 0.00258587 loss)
I0204 17:09:12.614374  3342 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 17:09:38.457231  3342 solver.cpp:237] Iteration 950, loss = 0.00255108
I0204 17:09:38.464063  3342 solver.cpp:253]     Train net output #0: loss = 0.00255112 (* 1 = 0.00255112 loss)
I0204 17:09:38.464078  3342 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 17:10:04.485040  3342 solver.cpp:237] Iteration 960, loss = 0.00334219
I0204 17:10:04.485118  3342 solver.cpp:253]     Train net output #0: loss = 0.00334223 (* 1 = 0.00334223 loss)
I0204 17:10:04.485131  3342 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 17:10:30.375581  3342 solver.cpp:237] Iteration 970, loss = 0.00489377
I0204 17:10:30.375792  3342 solver.cpp:253]     Train net output #0: loss = 0.00489381 (* 1 = 0.00489381 loss)
I0204 17:10:30.375807  3342 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 17:10:56.261211  3342 solver.cpp:237] Iteration 980, loss = 0.0291501
I0204 17:10:56.261270  3342 solver.cpp:253]     Train net output #0: loss = 0.0291501 (* 1 = 0.0291501 loss)
I0204 17:10:56.261283  3342 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 17:11:22.492799  3342 solver.cpp:237] Iteration 990, loss = 0.00454631
I0204 17:11:22.493003  3342 solver.cpp:253]     Train net output #0: loss = 0.00454635 (* 1 = 0.00454635 loss)
I0204 17:11:22.493017  3342 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 17:11:46.093471  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1000.caffemodel
I0204 17:11:46.097046  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1000.solverstate
I0204 17:11:46.098492  3342 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 17:11:58.491314  3342 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:11:58.491562  3342 solver.cpp:409]     Test net output #1: loss = 0.00475093 (* 1 = 0.00475093 loss)
I0204 17:12:01.090483  3342 solver.cpp:237] Iteration 1000, loss = 0.00147189
I0204 17:12:01.090548  3342 solver.cpp:253]     Train net output #0: loss = 0.00147193 (* 1 = 0.00147193 loss)
I0204 17:12:01.090561  3342 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 17:12:27.108031  3342 solver.cpp:237] Iteration 1010, loss = 0.0200822
I0204 17:12:27.108103  3342 solver.cpp:253]     Train net output #0: loss = 0.0200822 (* 1 = 0.0200822 loss)
I0204 17:12:27.108115  3342 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 17:12:53.099830  3342 solver.cpp:237] Iteration 1020, loss = 0.00231982
I0204 17:12:53.100044  3342 solver.cpp:253]     Train net output #0: loss = 0.00231986 (* 1 = 0.00231986 loss)
I0204 17:12:53.100064  3342 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 17:13:19.129648  3342 solver.cpp:237] Iteration 1030, loss = 0.0114192
I0204 17:13:19.129716  3342 solver.cpp:253]     Train net output #0: loss = 0.0114193 (* 1 = 0.0114193 loss)
I0204 17:13:19.129729  3342 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 17:13:45.268434  3342 solver.cpp:237] Iteration 1040, loss = 0.0229141
I0204 17:13:45.268633  3342 solver.cpp:253]     Train net output #0: loss = 0.0229141 (* 1 = 0.0229141 loss)
I0204 17:13:45.268648  3342 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 17:14:11.390753  3342 solver.cpp:237] Iteration 1050, loss = 0.0085358
I0204 17:14:11.390820  3342 solver.cpp:253]     Train net output #0: loss = 0.00853585 (* 1 = 0.00853585 loss)
I0204 17:14:11.390832  3342 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 17:14:37.384176  3342 solver.cpp:237] Iteration 1060, loss = 0.00178592
I0204 17:14:37.384377  3342 solver.cpp:253]     Train net output #0: loss = 0.00178598 (* 1 = 0.00178598 loss)
I0204 17:14:37.384392  3342 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 17:15:03.396553  3342 solver.cpp:237] Iteration 1070, loss = 0.00383367
I0204 17:15:03.396608  3342 solver.cpp:253]     Train net output #0: loss = 0.00383373 (* 1 = 0.00383373 loss)
I0204 17:15:03.396621  3342 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 17:15:29.297096  3342 solver.cpp:237] Iteration 1080, loss = 0.0240041
I0204 17:15:29.297286  3342 solver.cpp:253]     Train net output #0: loss = 0.0240042 (* 1 = 0.0240042 loss)
I0204 17:15:29.297298  3342 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 17:15:55.192425  3342 solver.cpp:237] Iteration 1090, loss = 0.00077089
I0204 17:15:55.192482  3342 solver.cpp:253]     Train net output #0: loss = 0.000770943 (* 1 = 0.000770943 loss)
I0204 17:15:55.192494  3342 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 17:16:18.409476  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1100.caffemodel
I0204 17:16:18.413367  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1100.solverstate
I0204 17:16:18.414829  3342 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 17:16:30.615030  3342 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:16:30.615080  3342 solver.cpp:409]     Test net output #1: loss = 0.00356612 (* 1 = 0.00356612 loss)
I0204 17:16:33.225766  3342 solver.cpp:237] Iteration 1100, loss = 0.000706527
I0204 17:16:33.225816  3342 solver.cpp:253]     Train net output #0: loss = 0.000706582 (* 1 = 0.000706582 loss)
I0204 17:16:33.225828  3342 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 17:16:59.151804  3342 solver.cpp:237] Iteration 1110, loss = 0.0010797
I0204 17:16:59.152004  3342 solver.cpp:253]     Train net output #0: loss = 0.00107975 (* 1 = 0.00107975 loss)
I0204 17:16:59.152017  3342 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 17:17:25.126565  3342 solver.cpp:237] Iteration 1120, loss = 0.0417483
I0204 17:17:25.126633  3342 solver.cpp:253]     Train net output #0: loss = 0.0417483 (* 1 = 0.0417483 loss)
I0204 17:17:25.126646  3342 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 17:17:51.128909  3342 solver.cpp:237] Iteration 1130, loss = 0.00172185
I0204 17:17:51.129123  3342 solver.cpp:253]     Train net output #0: loss = 0.00172191 (* 1 = 0.00172191 loss)
I0204 17:17:51.129137  3342 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 17:18:17.278520  3342 solver.cpp:237] Iteration 1140, loss = 0.0509502
I0204 17:18:17.278574  3342 solver.cpp:253]     Train net output #0: loss = 0.0509502 (* 1 = 0.0509502 loss)
I0204 17:18:17.278586  3342 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 17:18:43.341325  3342 solver.cpp:237] Iteration 1150, loss = 0.0131442
I0204 17:18:43.341531  3342 solver.cpp:253]     Train net output #0: loss = 0.0131442 (* 1 = 0.0131442 loss)
I0204 17:18:43.341545  3342 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 17:19:09.531076  3342 solver.cpp:237] Iteration 1160, loss = 0.00111364
I0204 17:19:09.531132  3342 solver.cpp:253]     Train net output #0: loss = 0.0011137 (* 1 = 0.0011137 loss)
I0204 17:19:09.531144  3342 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 17:19:35.581918  3342 solver.cpp:237] Iteration 1170, loss = 0.00490093
I0204 17:19:35.582124  3342 solver.cpp:253]     Train net output #0: loss = 0.00490098 (* 1 = 0.00490098 loss)
I0204 17:19:35.582139  3342 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 17:20:01.732529  3342 solver.cpp:237] Iteration 1180, loss = 0.0026097
I0204 17:20:01.732585  3342 solver.cpp:253]     Train net output #0: loss = 0.00260976 (* 1 = 0.00260976 loss)
I0204 17:20:01.732596  3342 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 17:20:27.934581  3342 solver.cpp:237] Iteration 1190, loss = 0.00591272
I0204 17:20:27.934779  3342 solver.cpp:253]     Train net output #0: loss = 0.00591278 (* 1 = 0.00591278 loss)
I0204 17:20:27.934793  3342 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 17:20:51.543294  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1200.caffemodel
I0204 17:20:51.547029  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1200.solverstate
I0204 17:20:51.548557  3342 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 17:21:03.973412  3342 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 17:21:03.973594  3342 solver.cpp:409]     Test net output #1: loss = 0.0155762 (* 1 = 0.0155762 loss)
I0204 17:21:06.617071  3342 solver.cpp:237] Iteration 1200, loss = 0.00385445
I0204 17:21:06.617135  3342 solver.cpp:253]     Train net output #0: loss = 0.0038545 (* 1 = 0.0038545 loss)
I0204 17:21:06.617146  3342 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 17:21:32.610718  3342 solver.cpp:237] Iteration 1210, loss = 0.00241338
I0204 17:21:32.610774  3342 solver.cpp:253]     Train net output #0: loss = 0.00241343 (* 1 = 0.00241343 loss)
I0204 17:21:32.610786  3342 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 17:21:58.542896  3342 solver.cpp:237] Iteration 1220, loss = 0.00861356
I0204 17:21:58.543109  3342 solver.cpp:253]     Train net output #0: loss = 0.00861362 (* 1 = 0.00861362 loss)
I0204 17:21:58.543123  3342 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 17:22:24.501549  3342 solver.cpp:237] Iteration 1230, loss = 0.0128342
I0204 17:22:24.501605  3342 solver.cpp:253]     Train net output #0: loss = 0.0128343 (* 1 = 0.0128343 loss)
I0204 17:22:24.501616  3342 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 17:22:50.708305  3342 solver.cpp:237] Iteration 1240, loss = 0.0347121
I0204 17:22:50.708500  3342 solver.cpp:253]     Train net output #0: loss = 0.0347122 (* 1 = 0.0347122 loss)
I0204 17:22:50.708514  3342 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 17:23:16.755193  3342 solver.cpp:237] Iteration 1250, loss = 0.0641808
I0204 17:23:16.755260  3342 solver.cpp:253]     Train net output #0: loss = 0.0641809 (* 1 = 0.0641809 loss)
I0204 17:23:16.755272  3342 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 17:23:42.909376  3342 solver.cpp:237] Iteration 1260, loss = 0.00224684
I0204 17:23:42.909597  3342 solver.cpp:253]     Train net output #0: loss = 0.0022469 (* 1 = 0.0022469 loss)
I0204 17:23:42.909612  3342 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 17:24:08.917100  3342 solver.cpp:237] Iteration 1270, loss = 0.0516142
I0204 17:24:08.917160  3342 solver.cpp:253]     Train net output #0: loss = 0.0516142 (* 1 = 0.0516142 loss)
I0204 17:24:08.917171  3342 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 17:24:35.195410  3342 solver.cpp:237] Iteration 1280, loss = 0.0419572
I0204 17:24:35.195611  3342 solver.cpp:253]     Train net output #0: loss = 0.0419573 (* 1 = 0.0419573 loss)
I0204 17:24:35.195624  3342 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 17:24:59.607383  3342 solver.cpp:237] Iteration 1290, loss = 0.0111004
I0204 17:24:59.607453  3342 solver.cpp:253]     Train net output #0: loss = 0.0111005 (* 1 = 0.0111005 loss)
I0204 17:24:59.607465  3342 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 17:25:21.150869  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1300.caffemodel
I0204 17:25:21.154580  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1300.solverstate
I0204 17:25:21.155930  3342 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 17:25:32.591346  3342 solver.cpp:409]     Test net output #0: accuracy = 0.999
I0204 17:25:32.591409  3342 solver.cpp:409]     Test net output #1: loss = 0.00205571 (* 1 = 0.00205571 loss)
I0204 17:25:34.978067  3342 solver.cpp:237] Iteration 1300, loss = 0.00136648
I0204 17:25:34.978127  3342 solver.cpp:253]     Train net output #0: loss = 0.00136653 (* 1 = 0.00136653 loss)
I0204 17:25:34.978139  3342 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 17:25:58.965348  3342 solver.cpp:237] Iteration 1310, loss = 0.0136981
I0204 17:25:58.965560  3342 solver.cpp:253]     Train net output #0: loss = 0.0136981 (* 1 = 0.0136981 loss)
I0204 17:25:58.965574  3342 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 17:26:22.944169  3342 solver.cpp:237] Iteration 1320, loss = 0.00512041
I0204 17:26:22.944236  3342 solver.cpp:253]     Train net output #0: loss = 0.00512046 (* 1 = 0.00512046 loss)
I0204 17:26:22.944247  3342 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 17:26:46.741775  3342 solver.cpp:237] Iteration 1330, loss = 0.00200836
I0204 17:26:46.748139  3342 solver.cpp:253]     Train net output #0: loss = 0.00200842 (* 1 = 0.00200842 loss)
I0204 17:26:46.748177  3342 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 17:27:10.577880  3342 solver.cpp:237] Iteration 1340, loss = 0.000754151
I0204 17:27:10.577946  3342 solver.cpp:253]     Train net output #0: loss = 0.000754207 (* 1 = 0.000754207 loss)
I0204 17:27:10.577960  3342 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 17:27:34.785573  3342 solver.cpp:237] Iteration 1350, loss = 0.00164028
I0204 17:27:34.785778  3342 solver.cpp:253]     Train net output #0: loss = 0.00164034 (* 1 = 0.00164034 loss)
I0204 17:27:34.785794  3342 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 17:27:58.536660  3342 solver.cpp:237] Iteration 1360, loss = 0.000276756
I0204 17:27:58.536725  3342 solver.cpp:253]     Train net output #0: loss = 0.000276813 (* 1 = 0.000276813 loss)
I0204 17:27:58.536737  3342 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 17:28:21.985810  3342 solver.cpp:237] Iteration 1370, loss = 0.000902438
I0204 17:28:21.986002  3342 solver.cpp:253]     Train net output #0: loss = 0.000902499 (* 1 = 0.000902499 loss)
I0204 17:28:21.986017  3342 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 17:28:45.361826  3342 solver.cpp:237] Iteration 1380, loss = 0.000181892
I0204 17:28:45.361882  3342 solver.cpp:253]     Train net output #0: loss = 0.000181954 (* 1 = 0.000181954 loss)
I0204 17:28:45.361893  3342 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 17:29:08.626873  3342 solver.cpp:237] Iteration 1390, loss = 0.0666716
I0204 17:29:08.627094  3342 solver.cpp:253]     Train net output #0: loss = 0.0666716 (* 1 = 0.0666716 loss)
I0204 17:29:08.627110  3342 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 17:29:29.711663  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1400.caffemodel
I0204 17:29:29.715131  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1400.solverstate
I0204 17:29:29.716490  3342 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 17:29:40.841752  3342 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:29:40.841935  3342 solver.cpp:409]     Test net output #1: loss = 0.00497906 (* 1 = 0.00497906 loss)
I0204 17:29:43.173416  3342 solver.cpp:237] Iteration 1400, loss = 0.000339769
I0204 17:29:43.173477  3342 solver.cpp:253]     Train net output #0: loss = 0.000339829 (* 1 = 0.000339829 loss)
I0204 17:29:43.173490  3342 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 17:30:06.588608  3342 solver.cpp:237] Iteration 1410, loss = 0.0298923
I0204 17:30:06.588672  3342 solver.cpp:253]     Train net output #0: loss = 0.0298923 (* 1 = 0.0298923 loss)
I0204 17:30:06.588685  3342 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 17:30:29.984208  3342 solver.cpp:237] Iteration 1420, loss = 0.00024632
I0204 17:30:29.984390  3342 solver.cpp:253]     Train net output #0: loss = 0.000246384 (* 1 = 0.000246384 loss)
I0204 17:30:29.984405  3342 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 17:30:53.439738  3342 solver.cpp:237] Iteration 1430, loss = 0.00386196
I0204 17:30:53.439807  3342 solver.cpp:253]     Train net output #0: loss = 0.00386203 (* 1 = 0.00386203 loss)
I0204 17:30:53.439820  3342 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 17:31:16.913796  3342 solver.cpp:237] Iteration 1440, loss = 0.00066948
I0204 17:31:16.913990  3342 solver.cpp:253]     Train net output #0: loss = 0.000669553 (* 1 = 0.000669553 loss)
I0204 17:31:16.914005  3342 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 17:31:40.246932  3342 solver.cpp:237] Iteration 1450, loss = 0.00117932
I0204 17:31:40.247004  3342 solver.cpp:253]     Train net output #0: loss = 0.00117939 (* 1 = 0.00117939 loss)
I0204 17:31:40.247016  3342 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 17:32:03.506836  3342 solver.cpp:237] Iteration 1460, loss = 0.00119616
I0204 17:32:03.507035  3342 solver.cpp:253]     Train net output #0: loss = 0.00119624 (* 1 = 0.00119624 loss)
I0204 17:32:03.507055  3342 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 17:32:26.812913  3342 solver.cpp:237] Iteration 1470, loss = 0.000687797
I0204 17:32:26.812978  3342 solver.cpp:253]     Train net output #0: loss = 0.000687873 (* 1 = 0.000687873 loss)
I0204 17:32:26.812990  3342 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 17:32:50.301275  3342 solver.cpp:237] Iteration 1480, loss = 0.000241927
I0204 17:32:50.310302  3342 solver.cpp:253]     Train net output #0: loss = 0.000242002 (* 1 = 0.000242002 loss)
I0204 17:32:50.310333  3342 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 17:33:13.786557  3342 solver.cpp:237] Iteration 1490, loss = 0.017686
I0204 17:33:13.786610  3342 solver.cpp:253]     Train net output #0: loss = 0.0176861 (* 1 = 0.0176861 loss)
I0204 17:33:13.786622  3342 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 17:33:34.791944  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1500.caffemodel
I0204 17:33:34.795644  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1500.solverstate
I0204 17:33:34.797006  3342 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 17:33:46.174161  3342 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 17:33:46.174227  3342 solver.cpp:409]     Test net output #1: loss = 0.0292748 (* 1 = 0.0292748 loss)
I0204 17:33:48.523226  3342 solver.cpp:237] Iteration 1500, loss = 0.00159584
I0204 17:33:48.523291  3342 solver.cpp:253]     Train net output #0: loss = 0.00159591 (* 1 = 0.00159591 loss)
I0204 17:33:48.523304  3342 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 17:34:11.975410  3342 solver.cpp:237] Iteration 1510, loss = 0.00121203
I0204 17:34:11.975613  3342 solver.cpp:253]     Train net output #0: loss = 0.0012121 (* 1 = 0.0012121 loss)
I0204 17:34:11.975628  3342 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 17:34:35.574430  3342 solver.cpp:237] Iteration 1520, loss = 0.00111412
I0204 17:34:35.574497  3342 solver.cpp:253]     Train net output #0: loss = 0.00111419 (* 1 = 0.00111419 loss)
I0204 17:34:35.574511  3342 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 17:34:59.141026  3342 solver.cpp:237] Iteration 1530, loss = 0.023015
I0204 17:34:59.149303  3342 solver.cpp:253]     Train net output #0: loss = 0.0230151 (* 1 = 0.0230151 loss)
I0204 17:34:59.149320  3342 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 17:35:22.734894  3342 solver.cpp:237] Iteration 1540, loss = 0.00426668
I0204 17:35:22.734971  3342 solver.cpp:253]     Train net output #0: loss = 0.00426675 (* 1 = 0.00426675 loss)
I0204 17:35:22.734982  3342 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 17:35:46.419133  3342 solver.cpp:237] Iteration 1550, loss = 0.00102558
I0204 17:35:46.419337  3342 solver.cpp:253]     Train net output #0: loss = 0.00102565 (* 1 = 0.00102565 loss)
I0204 17:35:46.419353  3342 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 17:36:10.132928  3342 solver.cpp:237] Iteration 1560, loss = 0.000235051
I0204 17:36:10.132992  3342 solver.cpp:253]     Train net output #0: loss = 0.00023512 (* 1 = 0.00023512 loss)
I0204 17:36:10.133004  3342 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 17:36:33.812232  3342 solver.cpp:237] Iteration 1570, loss = 0.000448146
I0204 17:36:33.812423  3342 solver.cpp:253]     Train net output #0: loss = 0.000448215 (* 1 = 0.000448215 loss)
I0204 17:36:33.812438  3342 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 17:36:57.516434  3342 solver.cpp:237] Iteration 1580, loss = 0.000188606
I0204 17:36:57.516495  3342 solver.cpp:253]     Train net output #0: loss = 0.000188673 (* 1 = 0.000188673 loss)
I0204 17:36:57.516507  3342 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 17:37:21.536372  3342 solver.cpp:237] Iteration 1590, loss = 0.00209451
I0204 17:37:21.536569  3342 solver.cpp:253]     Train net output #0: loss = 0.00209457 (* 1 = 0.00209457 loss)
I0204 17:37:21.536583  3342 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 17:37:42.974213  3342 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1600.caffemodel
I0204 17:37:42.977792  3342 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num32_conv2num32_conv3num32_conv4num32_conv5num16_seed42/snaps/snap__iter_1600.solverstate
I0204 17:37:44.115588  3342 solver.cpp:321] Iteration 1600, loss = 0.000563211
I0204 17:37:44.115640  3342 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 17:37:55.346875  3342 solver.cpp:409]     Test net output #0: accuracy = 0.998
I0204 17:37:55.347062  3342 solver.cpp:409]     Test net output #1: loss = 0.00722507 (* 1 = 0.00722507 loss)
I0204 17:37:55.347074  3342 solver.cpp:326] Optimization Done.
I0204 17:37:55.347081  3342 caffe.cpp:215] Optimization Done.
