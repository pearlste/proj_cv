Log file created at: 2016/02/04 16:30:48
Running on machine: lp-research-linux-1
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0204 16:30:48.888742  3498 caffe.cpp:177] Use CPU.
I0204 16:30:48.889298  3498 solver.cpp:48] Initializing solver from parameters: 
test_iter: 10
test_interval: 100
base_lr: 0.001
display: 10
max_iter: 1600
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 100000
snapshot: 100
snapshot_prefix: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap_"
solver_mode: CPU
random_seed: 4
net: "/home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/train_val.prototxt"
I0204 16:30:48.889456  3498 solver.cpp:91] Creating training net from net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/train_val.prototxt
I0204 16:30:48.890079  3498 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0204 16:30:48.890110  3498 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0204 16:30:48.890369  3498 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.890502  3498 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.890689  3498 net.cpp:106] Creating Layer data
I0204 16:30:48.890704  3498 net.cpp:411] data -> data
I0204 16:30:48.890749  3498 net.cpp:411] data -> label
I0204 16:30:48.890770  3498 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db/mean_file.binaryproto
I0204 16:30:48.891670  3502 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_train_lum_db
I0204 16:30:48.891830  3498 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:48.925190  3498 net.cpp:150] Setting up data
I0204 16:30:48.925232  3498 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:48.925240  3498 net.cpp:157] Top shape: 100 (100)
I0204 16:30:48.925246  3498 net.cpp:165] Memory required for data: 20612000
I0204 16:30:48.925266  3498 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:48.925292  3498 net.cpp:106] Creating Layer conv1
I0204 16:30:48.925299  3498 net.cpp:454] conv1 <- data
I0204 16:30:48.925319  3498 net.cpp:411] conv1 -> conv1
I0204 16:30:48.925415  3498 net.cpp:150] Setting up conv1
I0204 16:30:48.925426  3498 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.925432  3498 net.cpp:165] Memory required for data: 30292000
I0204 16:30:48.925448  3498 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:48.925459  3498 net.cpp:106] Creating Layer relu1
I0204 16:30:48.925467  3498 net.cpp:454] relu1 <- conv1
I0204 16:30:48.925474  3498 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:48.925487  3498 net.cpp:150] Setting up relu1
I0204 16:30:48.925494  3498 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:48.925499  3498 net.cpp:165] Memory required for data: 39972000
I0204 16:30:48.925505  3498 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:48.925515  3498 net.cpp:106] Creating Layer pool1
I0204 16:30:48.925521  3498 net.cpp:454] pool1 <- conv1
I0204 16:30:48.925529  3498 net.cpp:411] pool1 -> pool1
I0204 16:30:48.925552  3498 net.cpp:150] Setting up pool1
I0204 16:30:48.925560  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.925566  3498 net.cpp:165] Memory required for data: 42304800
I0204 16:30:48.925572  3498 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:48.925600  3498 net.cpp:106] Creating Layer norm1
I0204 16:30:48.925613  3498 net.cpp:454] norm1 <- pool1
I0204 16:30:48.925621  3498 net.cpp:411] norm1 -> norm1
I0204 16:30:48.925638  3498 net.cpp:150] Setting up norm1
I0204 16:30:48.925647  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.925652  3498 net.cpp:165] Memory required for data: 44637600
I0204 16:30:48.925658  3498 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:48.925669  3498 net.cpp:106] Creating Layer conv2
I0204 16:30:48.925675  3498 net.cpp:454] conv2 <- norm1
I0204 16:30:48.925683  3498 net.cpp:411] conv2 -> conv2
I0204 16:30:48.925714  3498 net.cpp:150] Setting up conv2
I0204 16:30:48.925724  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.925729  3498 net.cpp:165] Memory required for data: 46970400
I0204 16:30:48.925740  3498 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:48.925747  3498 net.cpp:106] Creating Layer relu2
I0204 16:30:48.925753  3498 net.cpp:454] relu2 <- conv2
I0204 16:30:48.925761  3498 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:48.925770  3498 net.cpp:150] Setting up relu2
I0204 16:30:48.925776  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:48.925781  3498 net.cpp:165] Memory required for data: 49303200
I0204 16:30:48.925787  3498 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:48.925796  3498 net.cpp:106] Creating Layer pool2
I0204 16:30:48.925801  3498 net.cpp:454] pool2 <- conv2
I0204 16:30:48.925808  3498 net.cpp:411] pool2 -> pool2
I0204 16:30:48.925818  3498 net.cpp:150] Setting up pool2
I0204 16:30:48.925825  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.925830  3498 net.cpp:165] Memory required for data: 49844000
I0204 16:30:48.925835  3498 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:48.925845  3498 net.cpp:106] Creating Layer norm2
I0204 16:30:48.925850  3498 net.cpp:454] norm2 <- pool2
I0204 16:30:48.925858  3498 net.cpp:411] norm2 -> norm2
I0204 16:30:48.925868  3498 net.cpp:150] Setting up norm2
I0204 16:30:48.925874  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.925879  3498 net.cpp:165] Memory required for data: 50384800
I0204 16:30:48.925885  3498 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:48.925895  3498 net.cpp:106] Creating Layer conv3
I0204 16:30:48.925900  3498 net.cpp:454] conv3 <- norm2
I0204 16:30:48.925909  3498 net.cpp:411] conv3 -> conv3
I0204 16:30:48.925936  3498 net.cpp:150] Setting up conv3
I0204 16:30:48.925945  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.925951  3498 net.cpp:165] Memory required for data: 50925600
I0204 16:30:48.925961  3498 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:48.925968  3498 net.cpp:106] Creating Layer relu3
I0204 16:30:48.925974  3498 net.cpp:454] relu3 <- conv3
I0204 16:30:48.925982  3498 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:48.925990  3498 net.cpp:150] Setting up relu3
I0204 16:30:48.925997  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.926003  3498 net.cpp:165] Memory required for data: 51466400
I0204 16:30:48.926008  3498 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:48.926017  3498 net.cpp:106] Creating Layer conv4
I0204 16:30:48.926023  3498 net.cpp:454] conv4 <- conv3
I0204 16:30:48.926030  3498 net.cpp:411] conv4 -> conv4
I0204 16:30:48.926053  3498 net.cpp:150] Setting up conv4
I0204 16:30:48.926059  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.926065  3498 net.cpp:165] Memory required for data: 52007200
I0204 16:30:48.926072  3498 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:48.926080  3498 net.cpp:106] Creating Layer relu4
I0204 16:30:48.926085  3498 net.cpp:454] relu4 <- conv4
I0204 16:30:48.926093  3498 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:48.926100  3498 net.cpp:150] Setting up relu4
I0204 16:30:48.926107  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.926122  3498 net.cpp:165] Memory required for data: 52548000
I0204 16:30:48.926128  3498 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:48.926142  3498 net.cpp:106] Creating Layer conv5
I0204 16:30:48.926156  3498 net.cpp:454] conv5 <- conv4
I0204 16:30:48.926164  3498 net.cpp:411] conv5 -> conv5
I0204 16:30:48.926185  3498 net.cpp:150] Setting up conv5
I0204 16:30:48.926193  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.926199  3498 net.cpp:165] Memory required for data: 53088800
I0204 16:30:48.926209  3498 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:48.926218  3498 net.cpp:106] Creating Layer relu5
I0204 16:30:48.926223  3498 net.cpp:454] relu5 <- conv5
I0204 16:30:48.926231  3498 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:48.926239  3498 net.cpp:150] Setting up relu5
I0204 16:30:48.926245  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:48.926250  3498 net.cpp:165] Memory required for data: 53629600
I0204 16:30:48.926256  3498 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:48.926265  3498 net.cpp:106] Creating Layer pool5
I0204 16:30:48.926270  3498 net.cpp:454] pool5 <- conv5
I0204 16:30:48.926277  3498 net.cpp:411] pool5 -> pool5
I0204 16:30:48.926287  3498 net.cpp:150] Setting up pool5
I0204 16:30:48.926295  3498 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:48.926301  3498 net.cpp:165] Memory required for data: 53744800
I0204 16:30:48.926306  3498 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:48.926319  3498 net.cpp:106] Creating Layer fc6
I0204 16:30:48.926326  3498 net.cpp:454] fc6 <- pool5
I0204 16:30:48.926333  3498 net.cpp:411] fc6 -> fc6
I0204 16:30:48.927078  3498 net.cpp:150] Setting up fc6
I0204 16:30:48.927090  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927095  3498 net.cpp:165] Memory required for data: 53847200
I0204 16:30:48.927103  3498 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:48.927117  3498 net.cpp:106] Creating Layer relu6
I0204 16:30:48.927124  3498 net.cpp:454] relu6 <- fc6
I0204 16:30:48.927131  3498 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:48.927140  3498 net.cpp:150] Setting up relu6
I0204 16:30:48.927147  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927152  3498 net.cpp:165] Memory required for data: 53949600
I0204 16:30:48.927158  3498 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:48.927168  3498 net.cpp:106] Creating Layer drop6
I0204 16:30:48.927175  3498 net.cpp:454] drop6 <- fc6
I0204 16:30:48.927181  3498 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:48.927196  3498 net.cpp:150] Setting up drop6
I0204 16:30:48.927203  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927209  3498 net.cpp:165] Memory required for data: 54052000
I0204 16:30:48.927214  3498 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:48.927224  3498 net.cpp:106] Creating Layer fc7
I0204 16:30:48.927229  3498 net.cpp:454] fc7 <- fc6
I0204 16:30:48.927237  3498 net.cpp:411] fc7 -> fc7
I0204 16:30:48.927877  3498 net.cpp:150] Setting up fc7
I0204 16:30:48.927887  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927892  3498 net.cpp:165] Memory required for data: 54154400
I0204 16:30:48.927901  3498 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:48.927908  3498 net.cpp:106] Creating Layer relu7
I0204 16:30:48.927913  3498 net.cpp:454] relu7 <- fc7
I0204 16:30:48.927920  3498 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:48.927928  3498 net.cpp:150] Setting up relu7
I0204 16:30:48.927935  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927940  3498 net.cpp:165] Memory required for data: 54256800
I0204 16:30:48.927945  3498 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:48.927955  3498 net.cpp:106] Creating Layer drop7
I0204 16:30:48.927960  3498 net.cpp:454] drop7 <- fc7
I0204 16:30:48.927968  3498 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:48.927976  3498 net.cpp:150] Setting up drop7
I0204 16:30:48.927983  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:48.927989  3498 net.cpp:165] Memory required for data: 54359200
I0204 16:30:48.927995  3498 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:48.928005  3498 net.cpp:106] Creating Layer fc8
I0204 16:30:48.928015  3498 net.cpp:454] fc8 <- fc7
I0204 16:30:48.928030  3498 net.cpp:411] fc8 -> fc8
I0204 16:30:48.928051  3498 net.cpp:150] Setting up fc8
I0204 16:30:48.928059  3498 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:48.928064  3498 net.cpp:165] Memory required for data: 54360000
I0204 16:30:48.928072  3498 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.928081  3498 net.cpp:106] Creating Layer loss
I0204 16:30:48.928086  3498 net.cpp:454] loss <- fc8
I0204 16:30:48.928092  3498 net.cpp:454] loss <- label
I0204 16:30:48.928102  3498 net.cpp:411] loss -> loss
I0204 16:30:48.928122  3498 layer_factory.hpp:77] Creating layer loss
I0204 16:30:48.928143  3498 net.cpp:150] Setting up loss
I0204 16:30:48.928151  3498 net.cpp:157] Top shape: (1)
I0204 16:30:48.928156  3498 net.cpp:160]     with loss weight 1
I0204 16:30:48.928184  3498 net.cpp:165] Memory required for data: 54360004
I0204 16:30:48.928191  3498 net.cpp:226] loss needs backward computation.
I0204 16:30:48.928197  3498 net.cpp:226] fc8 needs backward computation.
I0204 16:30:48.928203  3498 net.cpp:226] drop7 needs backward computation.
I0204 16:30:48.928210  3498 net.cpp:226] relu7 needs backward computation.
I0204 16:30:48.928215  3498 net.cpp:226] fc7 needs backward computation.
I0204 16:30:48.928220  3498 net.cpp:226] drop6 needs backward computation.
I0204 16:30:48.928225  3498 net.cpp:226] relu6 needs backward computation.
I0204 16:30:48.928231  3498 net.cpp:226] fc6 needs backward computation.
I0204 16:30:48.928236  3498 net.cpp:226] pool5 needs backward computation.
I0204 16:30:48.928241  3498 net.cpp:226] relu5 needs backward computation.
I0204 16:30:48.928246  3498 net.cpp:226] conv5 needs backward computation.
I0204 16:30:48.928251  3498 net.cpp:226] relu4 needs backward computation.
I0204 16:30:48.928256  3498 net.cpp:226] conv4 needs backward computation.
I0204 16:30:48.928261  3498 net.cpp:226] relu3 needs backward computation.
I0204 16:30:48.928267  3498 net.cpp:226] conv3 needs backward computation.
I0204 16:30:48.928275  3498 net.cpp:226] norm2 needs backward computation.
I0204 16:30:48.928282  3498 net.cpp:226] pool2 needs backward computation.
I0204 16:30:48.928287  3498 net.cpp:226] relu2 needs backward computation.
I0204 16:30:48.928292  3498 net.cpp:226] conv2 needs backward computation.
I0204 16:30:48.928298  3498 net.cpp:226] norm1 needs backward computation.
I0204 16:30:48.928304  3498 net.cpp:226] pool1 needs backward computation.
I0204 16:30:48.928309  3498 net.cpp:226] relu1 needs backward computation.
I0204 16:30:48.928315  3498 net.cpp:226] conv1 needs backward computation.
I0204 16:30:48.928321  3498 net.cpp:228] data does not need backward computation.
I0204 16:30:48.928328  3498 net.cpp:270] This network produces output loss
I0204 16:30:48.928355  3498 net.cpp:283] Network initialization done.
I0204 16:30:48.929054  3498 solver.cpp:181] Creating test net (#0) specified by net file: /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/train_val.prototxt
I0204 16:30:48.929105  3498 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0204 16:30:48.929391  3498 net.cpp:49] Initializing net from parameters: 
name: "CaffeNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto"
  }
  data_param {
    source: "/home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm1"
  type: "LRN"
  bottom: "pool1"
  top: "norm1"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "norm1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 2
    kernel_size: 5
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "norm2"
  type: "LRN"
  bottom: "pool2"
  top: "norm2"
  lrn_param {
    local_size: 5
    alpha: 0.0001
    beta: 0.75
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "norm2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    pad: 1
    kernel_size: 3
    group: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0204 16:30:48.929548  3498 layer_factory.hpp:77] Creating layer data
I0204 16:30:48.930518  3498 net.cpp:106] Creating Layer data
I0204 16:30:48.930562  3498 net.cpp:411] data -> data
I0204 16:30:48.930584  3498 net.cpp:411] data -> label
I0204 16:30:48.930598  3498 data_transformer.cpp:25] Loading mean file from: /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db/mean_file.binaryproto
I0204 16:30:48.945127  3509 db_lmdb.cpp:38] Opened lmdb /home/pearlstl/proj_cv/master/lmdb/synth1_test_lum_db
I0204 16:30:48.951037  3498 data_layer.cpp:41] output data size: 100,1,227,227
I0204 16:30:49.006386  3498 net.cpp:150] Setting up data
I0204 16:30:49.006423  3498 net.cpp:157] Top shape: 100 1 227 227 (5152900)
I0204 16:30:49.006433  3498 net.cpp:157] Top shape: 100 (100)
I0204 16:30:49.006438  3498 net.cpp:165] Memory required for data: 20612000
I0204 16:30:49.006448  3498 layer_factory.hpp:77] Creating layer label_data_1_split
I0204 16:30:49.006469  3498 net.cpp:106] Creating Layer label_data_1_split
I0204 16:30:49.006475  3498 net.cpp:454] label_data_1_split <- label
I0204 16:30:49.006486  3498 net.cpp:411] label_data_1_split -> label_data_1_split_0
I0204 16:30:49.006503  3498 net.cpp:411] label_data_1_split -> label_data_1_split_1
I0204 16:30:49.006517  3498 net.cpp:150] Setting up label_data_1_split
I0204 16:30:49.006526  3498 net.cpp:157] Top shape: 100 (100)
I0204 16:30:49.006532  3498 net.cpp:157] Top shape: 100 (100)
I0204 16:30:49.006537  3498 net.cpp:165] Memory required for data: 20612800
I0204 16:30:49.006543  3498 layer_factory.hpp:77] Creating layer conv1
I0204 16:30:49.006561  3498 net.cpp:106] Creating Layer conv1
I0204 16:30:49.006567  3498 net.cpp:454] conv1 <- data
I0204 16:30:49.006575  3498 net.cpp:411] conv1 -> conv1
I0204 16:30:49.006624  3498 net.cpp:150] Setting up conv1
I0204 16:30:49.006634  3498 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:49.006640  3498 net.cpp:165] Memory required for data: 30292800
I0204 16:30:49.006654  3498 layer_factory.hpp:77] Creating layer relu1
I0204 16:30:49.006664  3498 net.cpp:106] Creating Layer relu1
I0204 16:30:49.006670  3498 net.cpp:454] relu1 <- conv1
I0204 16:30:49.006678  3498 net.cpp:397] relu1 -> conv1 (in-place)
I0204 16:30:49.006687  3498 net.cpp:150] Setting up relu1
I0204 16:30:49.006695  3498 net.cpp:157] Top shape: 100 8 55 55 (2420000)
I0204 16:30:49.006700  3498 net.cpp:165] Memory required for data: 39972800
I0204 16:30:49.006705  3498 layer_factory.hpp:77] Creating layer pool1
I0204 16:30:49.006716  3498 net.cpp:106] Creating Layer pool1
I0204 16:30:49.006721  3498 net.cpp:454] pool1 <- conv1
I0204 16:30:49.006729  3498 net.cpp:411] pool1 -> pool1
I0204 16:30:49.006742  3498 net.cpp:150] Setting up pool1
I0204 16:30:49.006750  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:49.006757  3498 net.cpp:165] Memory required for data: 42305600
I0204 16:30:49.006762  3498 layer_factory.hpp:77] Creating layer norm1
I0204 16:30:49.006772  3498 net.cpp:106] Creating Layer norm1
I0204 16:30:49.006778  3498 net.cpp:454] norm1 <- pool1
I0204 16:30:49.006785  3498 net.cpp:411] norm1 -> norm1
I0204 16:30:49.006796  3498 net.cpp:150] Setting up norm1
I0204 16:30:49.006804  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:49.006809  3498 net.cpp:165] Memory required for data: 44638400
I0204 16:30:49.006814  3498 layer_factory.hpp:77] Creating layer conv2
I0204 16:30:49.006825  3498 net.cpp:106] Creating Layer conv2
I0204 16:30:49.006831  3498 net.cpp:454] conv2 <- norm1
I0204 16:30:49.006840  3498 net.cpp:411] conv2 -> conv2
I0204 16:30:49.006870  3498 net.cpp:150] Setting up conv2
I0204 16:30:49.006878  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:49.006883  3498 net.cpp:165] Memory required for data: 46971200
I0204 16:30:49.006894  3498 layer_factory.hpp:77] Creating layer relu2
I0204 16:30:49.006902  3498 net.cpp:106] Creating Layer relu2
I0204 16:30:49.006908  3498 net.cpp:454] relu2 <- conv2
I0204 16:30:49.006916  3498 net.cpp:397] relu2 -> conv2 (in-place)
I0204 16:30:49.006933  3498 net.cpp:150] Setting up relu2
I0204 16:30:49.006949  3498 net.cpp:157] Top shape: 100 8 27 27 (583200)
I0204 16:30:49.006954  3498 net.cpp:165] Memory required for data: 49304000
I0204 16:30:49.006959  3498 layer_factory.hpp:77] Creating layer pool2
I0204 16:30:49.006969  3498 net.cpp:106] Creating Layer pool2
I0204 16:30:49.006974  3498 net.cpp:454] pool2 <- conv2
I0204 16:30:49.006983  3498 net.cpp:411] pool2 -> pool2
I0204 16:30:49.006994  3498 net.cpp:150] Setting up pool2
I0204 16:30:49.007001  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007012  3498 net.cpp:165] Memory required for data: 49844800
I0204 16:30:49.007019  3498 layer_factory.hpp:77] Creating layer norm2
I0204 16:30:49.007027  3498 net.cpp:106] Creating Layer norm2
I0204 16:30:49.007033  3498 net.cpp:454] norm2 <- pool2
I0204 16:30:49.007040  3498 net.cpp:411] norm2 -> norm2
I0204 16:30:49.007050  3498 net.cpp:150] Setting up norm2
I0204 16:30:49.007057  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007062  3498 net.cpp:165] Memory required for data: 50385600
I0204 16:30:49.007067  3498 layer_factory.hpp:77] Creating layer conv3
I0204 16:30:49.007078  3498 net.cpp:106] Creating Layer conv3
I0204 16:30:49.007083  3498 net.cpp:454] conv3 <- norm2
I0204 16:30:49.007092  3498 net.cpp:411] conv3 -> conv3
I0204 16:30:49.007118  3498 net.cpp:150] Setting up conv3
I0204 16:30:49.007127  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007132  3498 net.cpp:165] Memory required for data: 50926400
I0204 16:30:49.007143  3498 layer_factory.hpp:77] Creating layer relu3
I0204 16:30:49.007150  3498 net.cpp:106] Creating Layer relu3
I0204 16:30:49.007156  3498 net.cpp:454] relu3 <- conv3
I0204 16:30:49.007164  3498 net.cpp:397] relu3 -> conv3 (in-place)
I0204 16:30:49.007171  3498 net.cpp:150] Setting up relu3
I0204 16:30:49.007179  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007184  3498 net.cpp:165] Memory required for data: 51467200
I0204 16:30:49.007189  3498 layer_factory.hpp:77] Creating layer conv4
I0204 16:30:49.007199  3498 net.cpp:106] Creating Layer conv4
I0204 16:30:49.007205  3498 net.cpp:454] conv4 <- conv3
I0204 16:30:49.007212  3498 net.cpp:411] conv4 -> conv4
I0204 16:30:49.007232  3498 net.cpp:150] Setting up conv4
I0204 16:30:49.007241  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007246  3498 net.cpp:165] Memory required for data: 52008000
I0204 16:30:49.007253  3498 layer_factory.hpp:77] Creating layer relu4
I0204 16:30:49.007261  3498 net.cpp:106] Creating Layer relu4
I0204 16:30:49.007267  3498 net.cpp:454] relu4 <- conv4
I0204 16:30:49.007274  3498 net.cpp:397] relu4 -> conv4 (in-place)
I0204 16:30:49.007282  3498 net.cpp:150] Setting up relu4
I0204 16:30:49.007289  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007294  3498 net.cpp:165] Memory required for data: 52548800
I0204 16:30:49.007299  3498 layer_factory.hpp:77] Creating layer conv5
I0204 16:30:49.007310  3498 net.cpp:106] Creating Layer conv5
I0204 16:30:49.007315  3498 net.cpp:454] conv5 <- conv4
I0204 16:30:49.007323  3498 net.cpp:411] conv5 -> conv5
I0204 16:30:49.007345  3498 net.cpp:150] Setting up conv5
I0204 16:30:49.007352  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007357  3498 net.cpp:165] Memory required for data: 53089600
I0204 16:30:49.007367  3498 layer_factory.hpp:77] Creating layer relu5
I0204 16:30:49.007375  3498 net.cpp:106] Creating Layer relu5
I0204 16:30:49.007380  3498 net.cpp:454] relu5 <- conv5
I0204 16:30:49.007387  3498 net.cpp:397] relu5 -> conv5 (in-place)
I0204 16:30:49.007395  3498 net.cpp:150] Setting up relu5
I0204 16:30:49.007401  3498 net.cpp:157] Top shape: 100 8 13 13 (135200)
I0204 16:30:49.007406  3498 net.cpp:165] Memory required for data: 53630400
I0204 16:30:49.007412  3498 layer_factory.hpp:77] Creating layer pool5
I0204 16:30:49.007421  3498 net.cpp:106] Creating Layer pool5
I0204 16:30:49.007427  3498 net.cpp:454] pool5 <- conv5
I0204 16:30:49.007434  3498 net.cpp:411] pool5 -> pool5
I0204 16:30:49.007449  3498 net.cpp:150] Setting up pool5
I0204 16:30:49.007462  3498 net.cpp:157] Top shape: 100 8 6 6 (28800)
I0204 16:30:49.007467  3498 net.cpp:165] Memory required for data: 53745600
I0204 16:30:49.007472  3498 layer_factory.hpp:77] Creating layer fc6
I0204 16:30:49.007484  3498 net.cpp:106] Creating Layer fc6
I0204 16:30:49.007489  3498 net.cpp:454] fc6 <- pool5
I0204 16:30:49.007498  3498 net.cpp:411] fc6 -> fc6
I0204 16:30:49.008184  3498 net.cpp:150] Setting up fc6
I0204 16:30:49.008195  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.008201  3498 net.cpp:165] Memory required for data: 53848000
I0204 16:30:49.008209  3498 layer_factory.hpp:77] Creating layer relu6
I0204 16:30:49.008220  3498 net.cpp:106] Creating Layer relu6
I0204 16:30:49.008226  3498 net.cpp:454] relu6 <- fc6
I0204 16:30:49.008234  3498 net.cpp:397] relu6 -> fc6 (in-place)
I0204 16:30:49.008241  3498 net.cpp:150] Setting up relu6
I0204 16:30:49.008249  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.008254  3498 net.cpp:165] Memory required for data: 53950400
I0204 16:30:49.008258  3498 layer_factory.hpp:77] Creating layer drop6
I0204 16:30:49.008267  3498 net.cpp:106] Creating Layer drop6
I0204 16:30:49.008273  3498 net.cpp:454] drop6 <- fc6
I0204 16:30:49.008282  3498 net.cpp:397] drop6 -> fc6 (in-place)
I0204 16:30:49.008293  3498 net.cpp:150] Setting up drop6
I0204 16:30:49.008299  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.008304  3498 net.cpp:165] Memory required for data: 54052800
I0204 16:30:49.008309  3498 layer_factory.hpp:77] Creating layer fc7
I0204 16:30:49.008319  3498 net.cpp:106] Creating Layer fc7
I0204 16:30:49.008324  3498 net.cpp:454] fc7 <- fc6
I0204 16:30:49.008334  3498 net.cpp:411] fc7 -> fc7
I0204 16:30:49.008983  3498 net.cpp:150] Setting up fc7
I0204 16:30:49.008994  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.008999  3498 net.cpp:165] Memory required for data: 54155200
I0204 16:30:49.009012  3498 layer_factory.hpp:77] Creating layer relu7
I0204 16:30:49.009021  3498 net.cpp:106] Creating Layer relu7
I0204 16:30:49.009027  3498 net.cpp:454] relu7 <- fc7
I0204 16:30:49.009037  3498 net.cpp:397] relu7 -> fc7 (in-place)
I0204 16:30:49.009044  3498 net.cpp:150] Setting up relu7
I0204 16:30:49.009052  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.009057  3498 net.cpp:165] Memory required for data: 54257600
I0204 16:30:49.009063  3498 layer_factory.hpp:77] Creating layer drop7
I0204 16:30:49.009070  3498 net.cpp:106] Creating Layer drop7
I0204 16:30:49.009075  3498 net.cpp:454] drop7 <- fc7
I0204 16:30:49.009083  3498 net.cpp:397] drop7 -> fc7 (in-place)
I0204 16:30:49.009093  3498 net.cpp:150] Setting up drop7
I0204 16:30:49.009099  3498 net.cpp:157] Top shape: 100 256 (25600)
I0204 16:30:49.009104  3498 net.cpp:165] Memory required for data: 54360000
I0204 16:30:49.009109  3498 layer_factory.hpp:77] Creating layer fc8
I0204 16:30:49.009120  3498 net.cpp:106] Creating Layer fc8
I0204 16:30:49.009126  3498 net.cpp:454] fc8 <- fc7
I0204 16:30:49.009135  3498 net.cpp:411] fc8 -> fc8
I0204 16:30:49.009160  3498 net.cpp:150] Setting up fc8
I0204 16:30:49.009169  3498 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:49.009174  3498 net.cpp:165] Memory required for data: 54360800
I0204 16:30:49.009181  3498 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0204 16:30:49.009191  3498 net.cpp:106] Creating Layer fc8_fc8_0_split
I0204 16:30:49.009196  3498 net.cpp:454] fc8_fc8_0_split <- fc8
I0204 16:30:49.009203  3498 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0204 16:30:49.009212  3498 net.cpp:411] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0204 16:30:49.009222  3498 net.cpp:150] Setting up fc8_fc8_0_split
I0204 16:30:49.009232  3498 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:49.009238  3498 net.cpp:157] Top shape: 100 2 (200)
I0204 16:30:49.009243  3498 net.cpp:165] Memory required for data: 54362400
I0204 16:30:49.009248  3498 layer_factory.hpp:77] Creating layer accuracy
I0204 16:30:49.009260  3498 net.cpp:106] Creating Layer accuracy
I0204 16:30:49.009270  3498 net.cpp:454] accuracy <- fc8_fc8_0_split_0
I0204 16:30:49.009284  3498 net.cpp:454] accuracy <- label_data_1_split_0
I0204 16:30:49.009294  3498 net.cpp:411] accuracy -> accuracy
I0204 16:30:49.009310  3498 net.cpp:150] Setting up accuracy
I0204 16:30:49.009316  3498 net.cpp:157] Top shape: (1)
I0204 16:30:49.009321  3498 net.cpp:165] Memory required for data: 54362404
I0204 16:30:49.009327  3498 layer_factory.hpp:77] Creating layer loss
I0204 16:30:49.009335  3498 net.cpp:106] Creating Layer loss
I0204 16:30:49.009341  3498 net.cpp:454] loss <- fc8_fc8_0_split_1
I0204 16:30:49.009348  3498 net.cpp:454] loss <- label_data_1_split_1
I0204 16:30:49.009354  3498 net.cpp:411] loss -> loss
I0204 16:30:49.009366  3498 layer_factory.hpp:77] Creating layer loss
I0204 16:30:49.009385  3498 net.cpp:150] Setting up loss
I0204 16:30:49.009392  3498 net.cpp:157] Top shape: (1)
I0204 16:30:49.009397  3498 net.cpp:160]     with loss weight 1
I0204 16:30:49.009412  3498 net.cpp:165] Memory required for data: 54362408
I0204 16:30:49.009418  3498 net.cpp:226] loss needs backward computation.
I0204 16:30:49.009423  3498 net.cpp:228] accuracy does not need backward computation.
I0204 16:30:49.009429  3498 net.cpp:226] fc8_fc8_0_split needs backward computation.
I0204 16:30:49.009434  3498 net.cpp:226] fc8 needs backward computation.
I0204 16:30:49.009440  3498 net.cpp:226] drop7 needs backward computation.
I0204 16:30:49.009445  3498 net.cpp:226] relu7 needs backward computation.
I0204 16:30:49.009450  3498 net.cpp:226] fc7 needs backward computation.
I0204 16:30:49.009455  3498 net.cpp:226] drop6 needs backward computation.
I0204 16:30:49.009461  3498 net.cpp:226] relu6 needs backward computation.
I0204 16:30:49.009465  3498 net.cpp:226] fc6 needs backward computation.
I0204 16:30:49.009471  3498 net.cpp:226] pool5 needs backward computation.
I0204 16:30:49.009476  3498 net.cpp:226] relu5 needs backward computation.
I0204 16:30:49.009481  3498 net.cpp:226] conv5 needs backward computation.
I0204 16:30:49.009487  3498 net.cpp:226] relu4 needs backward computation.
I0204 16:30:49.009492  3498 net.cpp:226] conv4 needs backward computation.
I0204 16:30:49.009497  3498 net.cpp:226] relu3 needs backward computation.
I0204 16:30:49.009503  3498 net.cpp:226] conv3 needs backward computation.
I0204 16:30:49.009510  3498 net.cpp:226] norm2 needs backward computation.
I0204 16:30:49.009515  3498 net.cpp:226] pool2 needs backward computation.
I0204 16:30:49.009521  3498 net.cpp:226] relu2 needs backward computation.
I0204 16:30:49.009526  3498 net.cpp:226] conv2 needs backward computation.
I0204 16:30:49.009531  3498 net.cpp:226] norm1 needs backward computation.
I0204 16:30:49.009536  3498 net.cpp:226] pool1 needs backward computation.
I0204 16:30:49.009541  3498 net.cpp:226] relu1 needs backward computation.
I0204 16:30:49.009547  3498 net.cpp:226] conv1 needs backward computation.
I0204 16:30:49.009553  3498 net.cpp:228] label_data_1_split does not need backward computation.
I0204 16:30:49.009559  3498 net.cpp:228] data does not need backward computation.
I0204 16:30:49.009564  3498 net.cpp:270] This network produces output accuracy
I0204 16:30:49.009570  3498 net.cpp:270] This network produces output loss
I0204 16:30:49.009598  3498 net.cpp:283] Network initialization done.
I0204 16:30:49.009713  3498 solver.cpp:60] Solver scaffolding done.
I0204 16:30:49.009769  3498 caffe.cpp:212] Starting Optimization
I0204 16:30:49.009775  3498 solver.cpp:288] Solving CaffeNet
I0204 16:30:49.009781  3498 solver.cpp:289] Learning Rate Policy: step
I0204 16:30:49.010124  3498 solver.cpp:341] Iteration 0, Testing net (#0)
I0204 16:30:49.010177  3498 blocking_queue.cpp:50] Data layer prefetch queue empty
I0204 16:30:51.955919  3498 solver.cpp:409]     Test net output #0: accuracy = 0.519
I0204 16:30:51.955978  3498 solver.cpp:409]     Test net output #1: loss = 0.882407 (* 1 = 0.882407 loss)
I0204 16:30:52.567644  3498 solver.cpp:237] Iteration 0, loss = 5.77485
I0204 16:30:52.567697  3498 solver.cpp:253]     Train net output #0: loss = 5.77485 (* 1 = 5.77485 loss)
I0204 16:30:52.567718  3498 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0204 16:30:58.665185  3498 solver.cpp:237] Iteration 10, loss = 1.55422
I0204 16:30:58.665236  3498 solver.cpp:253]     Train net output #0: loss = 1.55422 (* 1 = 1.55422 loss)
I0204 16:30:58.665247  3498 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0204 16:31:07.839017  3498 solver.cpp:237] Iteration 20, loss = 1.03121
I0204 16:31:07.839076  3498 solver.cpp:253]     Train net output #0: loss = 1.03121 (* 1 = 1.03121 loss)
I0204 16:31:07.839088  3498 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0204 16:31:18.495946  3498 solver.cpp:237] Iteration 30, loss = 0.867706
I0204 16:31:18.496002  3498 solver.cpp:253]     Train net output #0: loss = 0.867706 (* 1 = 0.867706 loss)
I0204 16:31:18.496014  3498 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0204 16:31:29.492893  3498 solver.cpp:237] Iteration 40, loss = 0.983551
I0204 16:31:29.493015  3498 solver.cpp:253]     Train net output #0: loss = 0.983551 (* 1 = 0.983551 loss)
I0204 16:31:29.493026  3498 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0204 16:31:40.471271  3498 solver.cpp:237] Iteration 50, loss = 0.876258
I0204 16:31:40.471330  3498 solver.cpp:253]     Train net output #0: loss = 0.876258 (* 1 = 0.876258 loss)
I0204 16:31:40.471343  3498 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0204 16:31:51.541723  3498 solver.cpp:237] Iteration 60, loss = 0.757114
I0204 16:31:51.541785  3498 solver.cpp:253]     Train net output #0: loss = 0.757114 (* 1 = 0.757114 loss)
I0204 16:31:51.541798  3498 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0204 16:32:02.598338  3498 solver.cpp:237] Iteration 70, loss = 0.796156
I0204 16:32:02.598476  3498 solver.cpp:253]     Train net output #0: loss = 0.796156 (* 1 = 0.796156 loss)
I0204 16:32:02.598489  3498 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0204 16:32:13.685346  3498 solver.cpp:237] Iteration 80, loss = 0.761019
I0204 16:32:13.685410  3498 solver.cpp:253]     Train net output #0: loss = 0.761019 (* 1 = 0.761019 loss)
I0204 16:32:13.685421  3498 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0204 16:32:24.785676  3498 solver.cpp:237] Iteration 90, loss = 0.781922
I0204 16:32:24.785739  3498 solver.cpp:253]     Train net output #0: loss = 0.781922 (* 1 = 0.781922 loss)
I0204 16:32:24.785751  3498 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0204 16:32:34.750084  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_100.caffemodel
I0204 16:32:34.752611  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_100.solverstate
I0204 16:32:34.753541  3498 solver.cpp:341] Iteration 100, Testing net (#0)
I0204 16:32:40.291935  3498 solver.cpp:409]     Test net output #0: accuracy = 0.526
I0204 16:32:40.291999  3498 solver.cpp:409]     Test net output #1: loss = 0.690394 (* 1 = 0.690394 loss)
I0204 16:32:41.406926  3498 solver.cpp:237] Iteration 100, loss = 0.70784
I0204 16:32:41.406991  3498 solver.cpp:253]     Train net output #0: loss = 0.70784 (* 1 = 0.70784 loss)
I0204 16:32:41.407019  3498 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0204 16:32:52.477892  3498 solver.cpp:237] Iteration 110, loss = 0.749466
I0204 16:32:52.477958  3498 solver.cpp:253]     Train net output #0: loss = 0.749466 (* 1 = 0.749466 loss)
I0204 16:32:52.477989  3498 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0204 16:33:03.535027  3498 solver.cpp:237] Iteration 120, loss = 0.753489
I0204 16:33:03.535091  3498 solver.cpp:253]     Train net output #0: loss = 0.753489 (* 1 = 0.753489 loss)
I0204 16:33:03.535104  3498 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0204 16:33:14.564134  3498 solver.cpp:237] Iteration 130, loss = 0.72382
I0204 16:33:14.564321  3498 solver.cpp:253]     Train net output #0: loss = 0.72382 (* 1 = 0.72382 loss)
I0204 16:33:14.564334  3498 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0204 16:33:25.594265  3498 solver.cpp:237] Iteration 140, loss = 0.791435
I0204 16:33:25.594336  3498 solver.cpp:253]     Train net output #0: loss = 0.791435 (* 1 = 0.791435 loss)
I0204 16:33:25.594346  3498 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0204 16:33:36.651679  3498 solver.cpp:237] Iteration 150, loss = 0.701595
I0204 16:33:36.651741  3498 solver.cpp:253]     Train net output #0: loss = 0.701595 (* 1 = 0.701595 loss)
I0204 16:33:36.651751  3498 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0204 16:33:47.755172  3498 solver.cpp:237] Iteration 160, loss = 0.721413
I0204 16:33:47.755378  3498 solver.cpp:253]     Train net output #0: loss = 0.721413 (* 1 = 0.721413 loss)
I0204 16:33:47.755391  3498 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0204 16:33:58.834709  3498 solver.cpp:237] Iteration 170, loss = 0.732638
I0204 16:33:58.834771  3498 solver.cpp:253]     Train net output #0: loss = 0.732638 (* 1 = 0.732638 loss)
I0204 16:33:58.834782  3498 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0204 16:34:09.910755  3498 solver.cpp:237] Iteration 180, loss = 0.694109
I0204 16:34:09.910820  3498 solver.cpp:253]     Train net output #0: loss = 0.694109 (* 1 = 0.694109 loss)
I0204 16:34:09.910831  3498 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0204 16:34:20.987324  3498 solver.cpp:237] Iteration 190, loss = 0.738821
I0204 16:34:20.987494  3498 solver.cpp:253]     Train net output #0: loss = 0.738821 (* 1 = 0.738821 loss)
I0204 16:34:20.987507  3498 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0204 16:34:30.961108  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_200.caffemodel
I0204 16:34:30.963366  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_200.solverstate
I0204 16:34:30.964334  3498 solver.cpp:341] Iteration 200, Testing net (#0)
I0204 16:34:36.391824  3498 solver.cpp:409]     Test net output #0: accuracy = 0.5
I0204 16:34:36.391886  3498 solver.cpp:409]     Test net output #1: loss = 0.688371 (* 1 = 0.688371 loss)
I0204 16:34:37.512698  3498 solver.cpp:237] Iteration 200, loss = 0.680987
I0204 16:34:37.512759  3498 solver.cpp:253]     Train net output #0: loss = 0.680987 (* 1 = 0.680987 loss)
I0204 16:34:37.512771  3498 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0204 16:34:48.690053  3498 solver.cpp:237] Iteration 210, loss = 0.695
I0204 16:34:48.690129  3498 solver.cpp:253]     Train net output #0: loss = 0.695 (* 1 = 0.695 loss)
I0204 16:34:48.690140  3498 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0204 16:34:59.807596  3498 solver.cpp:237] Iteration 220, loss = 0.735053
I0204 16:34:59.807788  3498 solver.cpp:253]     Train net output #0: loss = 0.735053 (* 1 = 0.735053 loss)
I0204 16:34:59.807801  3498 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0204 16:35:11.064620  3498 solver.cpp:237] Iteration 230, loss = 0.694166
I0204 16:35:11.064690  3498 solver.cpp:253]     Train net output #0: loss = 0.694166 (* 1 = 0.694166 loss)
I0204 16:35:11.064702  3498 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0204 16:35:22.246109  3498 solver.cpp:237] Iteration 240, loss = 0.712942
I0204 16:35:22.246178  3498 solver.cpp:253]     Train net output #0: loss = 0.712942 (* 1 = 0.712942 loss)
I0204 16:35:22.246191  3498 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0204 16:35:33.399898  3498 solver.cpp:237] Iteration 250, loss = 0.684844
I0204 16:35:33.400099  3498 solver.cpp:253]     Train net output #0: loss = 0.684844 (* 1 = 0.684844 loss)
I0204 16:35:33.400111  3498 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0204 16:35:44.586117  3498 solver.cpp:237] Iteration 260, loss = 0.651527
I0204 16:35:44.586179  3498 solver.cpp:253]     Train net output #0: loss = 0.651527 (* 1 = 0.651527 loss)
I0204 16:35:44.586189  3498 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0204 16:35:55.930708  3498 solver.cpp:237] Iteration 270, loss = 0.661476
I0204 16:35:55.930789  3498 solver.cpp:253]     Train net output #0: loss = 0.661476 (* 1 = 0.661476 loss)
I0204 16:35:55.930807  3498 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0204 16:36:07.328238  3498 solver.cpp:237] Iteration 280, loss = 0.612526
I0204 16:36:07.328446  3498 solver.cpp:253]     Train net output #0: loss = 0.612526 (* 1 = 0.612526 loss)
I0204 16:36:07.328459  3498 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0204 16:36:18.697875  3498 solver.cpp:237] Iteration 290, loss = 0.572246
I0204 16:36:18.697942  3498 solver.cpp:253]     Train net output #0: loss = 0.572246 (* 1 = 0.572246 loss)
I0204 16:36:18.697952  3498 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0204 16:36:29.096635  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_300.caffemodel
I0204 16:36:29.098852  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_300.solverstate
I0204 16:36:29.099756  3498 solver.cpp:341] Iteration 300, Testing net (#0)
I0204 16:36:34.696363  3498 solver.cpp:409]     Test net output #0: accuracy = 0.76
I0204 16:36:34.696425  3498 solver.cpp:409]     Test net output #1: loss = 0.506615 (* 1 = 0.506615 loss)
I0204 16:36:35.857419  3498 solver.cpp:237] Iteration 300, loss = 0.620649
I0204 16:36:35.857477  3498 solver.cpp:253]     Train net output #0: loss = 0.620649 (* 1 = 0.620649 loss)
I0204 16:36:35.857489  3498 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0204 16:36:47.415819  3498 solver.cpp:237] Iteration 310, loss = 0.465834
I0204 16:36:47.425240  3498 solver.cpp:253]     Train net output #0: loss = 0.465834 (* 1 = 0.465834 loss)
I0204 16:36:47.425261  3498 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0204 16:36:59.076941  3498 solver.cpp:237] Iteration 320, loss = 0.414897
I0204 16:36:59.077006  3498 solver.cpp:253]     Train net output #0: loss = 0.414897 (* 1 = 0.414897 loss)
I0204 16:36:59.077018  3498 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0204 16:37:10.767369  3498 solver.cpp:237] Iteration 330, loss = 0.485399
I0204 16:37:10.767429  3498 solver.cpp:253]     Train net output #0: loss = 0.485399 (* 1 = 0.485399 loss)
I0204 16:37:10.767441  3498 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0204 16:37:22.646700  3498 solver.cpp:237] Iteration 340, loss = 0.466126
I0204 16:37:22.646867  3498 solver.cpp:253]     Train net output #0: loss = 0.466126 (* 1 = 0.466126 loss)
I0204 16:37:22.646879  3498 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0204 16:37:34.510248  3498 solver.cpp:237] Iteration 350, loss = 0.50172
I0204 16:37:34.510306  3498 solver.cpp:253]     Train net output #0: loss = 0.50172 (* 1 = 0.50172 loss)
I0204 16:37:34.510318  3498 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0204 16:37:46.389189  3498 solver.cpp:237] Iteration 360, loss = 0.315413
I0204 16:37:46.389250  3498 solver.cpp:253]     Train net output #0: loss = 0.315413 (* 1 = 0.315413 loss)
I0204 16:37:46.389262  3498 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0204 16:37:58.381104  3498 solver.cpp:237] Iteration 370, loss = 0.227734
I0204 16:37:58.381263  3498 solver.cpp:253]     Train net output #0: loss = 0.227734 (* 1 = 0.227734 loss)
I0204 16:37:58.381275  3498 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0204 16:38:10.656308  3498 solver.cpp:237] Iteration 380, loss = 0.210774
I0204 16:38:10.656366  3498 solver.cpp:253]     Train net output #0: loss = 0.210774 (* 1 = 0.210774 loss)
I0204 16:38:10.656378  3498 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0204 16:38:22.886703  3498 solver.cpp:237] Iteration 390, loss = 0.219168
I0204 16:38:22.886762  3498 solver.cpp:253]     Train net output #0: loss = 0.219168 (* 1 = 0.219168 loss)
I0204 16:38:22.886775  3498 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0204 16:38:33.750573  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_400.caffemodel
I0204 16:38:33.752976  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_400.solverstate
I0204 16:38:33.753944  3498 solver.cpp:341] Iteration 400, Testing net (#0)
I0204 16:38:39.789032  3498 solver.cpp:409]     Test net output #0: accuracy = 0.967
I0204 16:38:39.789090  3498 solver.cpp:409]     Test net output #1: loss = 0.0886389 (* 1 = 0.0886389 loss)
I0204 16:38:41.010160  3498 solver.cpp:237] Iteration 400, loss = 0.256848
I0204 16:38:41.010217  3498 solver.cpp:253]     Train net output #0: loss = 0.256848 (* 1 = 0.256848 loss)
I0204 16:38:41.010229  3498 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0204 16:38:53.325774  3498 solver.cpp:237] Iteration 410, loss = 0.121758
I0204 16:38:53.325845  3498 solver.cpp:253]     Train net output #0: loss = 0.121758 (* 1 = 0.121758 loss)
I0204 16:38:53.325858  3498 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0204 16:39:05.457507  3498 solver.cpp:237] Iteration 420, loss = 0.158716
I0204 16:39:05.457674  3498 solver.cpp:253]     Train net output #0: loss = 0.158716 (* 1 = 0.158716 loss)
I0204 16:39:05.457687  3498 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0204 16:39:17.715070  3498 solver.cpp:237] Iteration 430, loss = 0.278821
I0204 16:39:17.715152  3498 solver.cpp:253]     Train net output #0: loss = 0.278821 (* 1 = 0.278821 loss)
I0204 16:39:17.715164  3498 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0204 16:39:29.961942  3498 solver.cpp:237] Iteration 440, loss = 0.121548
I0204 16:39:29.962012  3498 solver.cpp:253]     Train net output #0: loss = 0.121548 (* 1 = 0.121548 loss)
I0204 16:39:29.962024  3498 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0204 16:39:42.089750  3498 solver.cpp:237] Iteration 450, loss = 0.152385
I0204 16:39:42.089913  3498 solver.cpp:253]     Train net output #0: loss = 0.152385 (* 1 = 0.152385 loss)
I0204 16:39:42.089926  3498 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0204 16:39:54.102455  3498 solver.cpp:237] Iteration 460, loss = 0.0817944
I0204 16:39:54.102511  3498 solver.cpp:253]     Train net output #0: loss = 0.0817944 (* 1 = 0.0817944 loss)
I0204 16:39:54.102524  3498 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0204 16:40:06.156175  3498 solver.cpp:237] Iteration 470, loss = 0.217192
I0204 16:40:06.156229  3498 solver.cpp:253]     Train net output #0: loss = 0.217192 (* 1 = 0.217192 loss)
I0204 16:40:06.156241  3498 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0204 16:40:18.532961  3498 solver.cpp:237] Iteration 480, loss = 0.191879
I0204 16:40:18.540139  3498 solver.cpp:253]     Train net output #0: loss = 0.191879 (* 1 = 0.191879 loss)
I0204 16:40:18.540158  3498 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0204 16:40:30.885874  3498 solver.cpp:237] Iteration 490, loss = 0.11686
I0204 16:40:30.885944  3498 solver.cpp:253]     Train net output #0: loss = 0.11686 (* 1 = 0.11686 loss)
I0204 16:40:30.885957  3498 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0204 16:40:42.073102  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_500.caffemodel
I0204 16:40:42.075338  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_500.solverstate
I0204 16:40:42.076249  3498 solver.cpp:341] Iteration 500, Testing net (#0)
I0204 16:40:48.251693  3498 solver.cpp:409]     Test net output #0: accuracy = 0.987
I0204 16:40:48.251754  3498 solver.cpp:409]     Test net output #1: loss = 0.0514157 (* 1 = 0.0514157 loss)
I0204 16:40:49.503909  3498 solver.cpp:237] Iteration 500, loss = 0.146958
I0204 16:40:49.504083  3498 solver.cpp:253]     Train net output #0: loss = 0.146958 (* 1 = 0.146958 loss)
I0204 16:40:49.504097  3498 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0204 16:41:01.952960  3498 solver.cpp:237] Iteration 510, loss = 0.0945886
I0204 16:41:01.953022  3498 solver.cpp:253]     Train net output #0: loss = 0.0945886 (* 1 = 0.0945886 loss)
I0204 16:41:01.953033  3498 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0204 16:41:14.407035  3498 solver.cpp:237] Iteration 520, loss = 0.0800182
I0204 16:41:14.407104  3498 solver.cpp:253]     Train net output #0: loss = 0.0800181 (* 1 = 0.0800181 loss)
I0204 16:41:14.407116  3498 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0204 16:41:26.859596  3498 solver.cpp:237] Iteration 530, loss = 0.0609749
I0204 16:41:26.866034  3498 solver.cpp:253]     Train net output #0: loss = 0.0609749 (* 1 = 0.0609749 loss)
I0204 16:41:26.866053  3498 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0204 16:41:39.251457  3498 solver.cpp:237] Iteration 540, loss = 0.0592502
I0204 16:41:39.251524  3498 solver.cpp:253]     Train net output #0: loss = 0.0592502 (* 1 = 0.0592502 loss)
I0204 16:41:39.251536  3498 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0204 16:41:51.646123  3498 solver.cpp:237] Iteration 550, loss = 0.0535986
I0204 16:41:51.646204  3498 solver.cpp:253]     Train net output #0: loss = 0.0535986 (* 1 = 0.0535986 loss)
I0204 16:41:51.646216  3498 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0204 16:42:04.110134  3498 solver.cpp:237] Iteration 560, loss = 0.160887
I0204 16:42:04.110327  3498 solver.cpp:253]     Train net output #0: loss = 0.160887 (* 1 = 0.160887 loss)
I0204 16:42:04.110339  3498 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0204 16:42:16.507855  3498 solver.cpp:237] Iteration 570, loss = 0.179978
I0204 16:42:16.507920  3498 solver.cpp:253]     Train net output #0: loss = 0.179978 (* 1 = 0.179978 loss)
I0204 16:42:16.507932  3498 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0204 16:42:28.805097  3498 solver.cpp:237] Iteration 580, loss = 0.208346
I0204 16:42:28.805176  3498 solver.cpp:253]     Train net output #0: loss = 0.208346 (* 1 = 0.208346 loss)
I0204 16:42:28.805187  3498 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0204 16:42:41.132171  3498 solver.cpp:237] Iteration 590, loss = 0.106807
I0204 16:42:41.132364  3498 solver.cpp:253]     Train net output #0: loss = 0.106807 (* 1 = 0.106807 loss)
I0204 16:42:41.132377  3498 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0204 16:42:52.417335  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_600.caffemodel
I0204 16:42:52.419601  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_600.solverstate
I0204 16:42:52.420606  3498 solver.cpp:341] Iteration 600, Testing net (#0)
I0204 16:42:58.557334  3498 solver.cpp:409]     Test net output #0: accuracy = 0.961
I0204 16:42:58.557399  3498 solver.cpp:409]     Test net output #1: loss = 0.103313 (* 1 = 0.103313 loss)
I0204 16:42:59.804618  3498 solver.cpp:237] Iteration 600, loss = 0.220889
I0204 16:42:59.804679  3498 solver.cpp:253]     Train net output #0: loss = 0.220889 (* 1 = 0.220889 loss)
I0204 16:42:59.804692  3498 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0204 16:43:12.142168  3498 solver.cpp:237] Iteration 610, loss = 0.0739043
I0204 16:43:12.142354  3498 solver.cpp:253]     Train net output #0: loss = 0.0739043 (* 1 = 0.0739043 loss)
I0204 16:43:12.142366  3498 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0204 16:43:24.511847  3498 solver.cpp:237] Iteration 620, loss = 0.118009
I0204 16:43:24.511919  3498 solver.cpp:253]     Train net output #0: loss = 0.118009 (* 1 = 0.118009 loss)
I0204 16:43:24.511931  3498 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0204 16:43:36.759675  3498 solver.cpp:237] Iteration 630, loss = 0.0237344
I0204 16:43:36.759742  3498 solver.cpp:253]     Train net output #0: loss = 0.0237344 (* 1 = 0.0237344 loss)
I0204 16:43:36.759753  3498 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0204 16:43:49.288209  3498 solver.cpp:237] Iteration 640, loss = 0.0849925
I0204 16:43:49.288416  3498 solver.cpp:253]     Train net output #0: loss = 0.0849925 (* 1 = 0.0849925 loss)
I0204 16:43:49.288430  3498 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0204 16:44:01.616066  3498 solver.cpp:237] Iteration 650, loss = 0.0289042
I0204 16:44:01.616140  3498 solver.cpp:253]     Train net output #0: loss = 0.0289042 (* 1 = 0.0289042 loss)
I0204 16:44:01.616153  3498 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0204 16:44:13.757649  3498 solver.cpp:237] Iteration 660, loss = 0.0706189
I0204 16:44:13.757719  3498 solver.cpp:253]     Train net output #0: loss = 0.0706189 (* 1 = 0.0706189 loss)
I0204 16:44:13.757730  3498 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0204 16:44:26.006966  3498 solver.cpp:237] Iteration 670, loss = 0.223622
I0204 16:44:26.007150  3498 solver.cpp:253]     Train net output #0: loss = 0.223622 (* 1 = 0.223622 loss)
I0204 16:44:26.007164  3498 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0204 16:44:38.371165  3498 solver.cpp:237] Iteration 680, loss = 0.0772061
I0204 16:44:38.371230  3498 solver.cpp:253]     Train net output #0: loss = 0.077206 (* 1 = 0.077206 loss)
I0204 16:44:38.371243  3498 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0204 16:44:50.626194  3498 solver.cpp:237] Iteration 690, loss = 0.0990738
I0204 16:44:50.626265  3498 solver.cpp:253]     Train net output #0: loss = 0.0990737 (* 1 = 0.0990737 loss)
I0204 16:44:50.626276  3498 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0204 16:45:01.612377  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_700.caffemodel
I0204 16:45:01.614701  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_700.solverstate
I0204 16:45:01.615612  3498 solver.cpp:341] Iteration 700, Testing net (#0)
I0204 16:45:07.611497  3498 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 16:45:07.611567  3498 solver.cpp:409]     Test net output #1: loss = 0.0304175 (* 1 = 0.0304175 loss)
I0204 16:45:08.826578  3498 solver.cpp:237] Iteration 700, loss = 0.0534813
I0204 16:45:08.826642  3498 solver.cpp:253]     Train net output #0: loss = 0.0534813 (* 1 = 0.0534813 loss)
I0204 16:45:08.826654  3498 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0204 16:45:21.000398  3498 solver.cpp:237] Iteration 710, loss = 0.0354073
I0204 16:45:21.000473  3498 solver.cpp:253]     Train net output #0: loss = 0.0354072 (* 1 = 0.0354072 loss)
I0204 16:45:21.000490  3498 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0204 16:45:33.171668  3498 solver.cpp:237] Iteration 720, loss = 0.0864757
I0204 16:45:33.171833  3498 solver.cpp:253]     Train net output #0: loss = 0.0864757 (* 1 = 0.0864757 loss)
I0204 16:45:33.171846  3498 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0204 16:45:45.295526  3498 solver.cpp:237] Iteration 730, loss = 0.0192002
I0204 16:45:45.295593  3498 solver.cpp:253]     Train net output #0: loss = 0.0192002 (* 1 = 0.0192002 loss)
I0204 16:45:45.295604  3498 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0204 16:45:57.453285  3498 solver.cpp:237] Iteration 740, loss = 0.0154794
I0204 16:45:57.453346  3498 solver.cpp:253]     Train net output #0: loss = 0.0154794 (* 1 = 0.0154794 loss)
I0204 16:45:57.453357  3498 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0204 16:46:09.471832  3498 solver.cpp:237] Iteration 750, loss = 0.0882957
I0204 16:46:09.472028  3498 solver.cpp:253]     Train net output #0: loss = 0.0882957 (* 1 = 0.0882957 loss)
I0204 16:46:09.472041  3498 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0204 16:46:21.681118  3498 solver.cpp:237] Iteration 760, loss = 0.0397202
I0204 16:46:21.681188  3498 solver.cpp:253]     Train net output #0: loss = 0.0397202 (* 1 = 0.0397202 loss)
I0204 16:46:21.681200  3498 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0204 16:46:33.801535  3498 solver.cpp:237] Iteration 770, loss = 0.051223
I0204 16:46:33.801615  3498 solver.cpp:253]     Train net output #0: loss = 0.0512229 (* 1 = 0.0512229 loss)
I0204 16:46:33.801627  3498 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0204 16:46:46.009717  3498 solver.cpp:237] Iteration 780, loss = 0.129448
I0204 16:46:46.009980  3498 solver.cpp:253]     Train net output #0: loss = 0.129448 (* 1 = 0.129448 loss)
I0204 16:46:46.009995  3498 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0204 16:46:58.422034  3498 solver.cpp:237] Iteration 790, loss = 0.0147322
I0204 16:46:58.422104  3498 solver.cpp:253]     Train net output #0: loss = 0.0147322 (* 1 = 0.0147322 loss)
I0204 16:46:58.422118  3498 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0204 16:47:09.397225  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_800.caffemodel
I0204 16:47:09.399404  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_800.solverstate
I0204 16:47:09.400277  3498 solver.cpp:341] Iteration 800, Testing net (#0)
I0204 16:47:15.330212  3498 solver.cpp:409]     Test net output #0: accuracy = 0.988
I0204 16:47:15.330282  3498 solver.cpp:409]     Test net output #1: loss = 0.0339454 (* 1 = 0.0339454 loss)
I0204 16:47:16.532799  3498 solver.cpp:237] Iteration 800, loss = 0.129434
I0204 16:47:16.532994  3498 solver.cpp:253]     Train net output #0: loss = 0.129434 (* 1 = 0.129434 loss)
I0204 16:47:16.533009  3498 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0204 16:47:28.641247  3498 solver.cpp:237] Iteration 810, loss = 0.0893638
I0204 16:47:28.641311  3498 solver.cpp:253]     Train net output #0: loss = 0.0893638 (* 1 = 0.0893638 loss)
I0204 16:47:28.641324  3498 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0204 16:47:40.728211  3498 solver.cpp:237] Iteration 820, loss = 0.0454397
I0204 16:47:40.728277  3498 solver.cpp:253]     Train net output #0: loss = 0.0454396 (* 1 = 0.0454396 loss)
I0204 16:47:40.728289  3498 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0204 16:47:52.686656  3498 solver.cpp:237] Iteration 830, loss = 0.058584
I0204 16:47:52.686843  3498 solver.cpp:253]     Train net output #0: loss = 0.058584 (* 1 = 0.058584 loss)
I0204 16:47:52.686856  3498 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0204 16:48:04.578282  3498 solver.cpp:237] Iteration 840, loss = 0.0555257
I0204 16:48:04.578352  3498 solver.cpp:253]     Train net output #0: loss = 0.0555257 (* 1 = 0.0555257 loss)
I0204 16:48:04.578364  3498 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0204 16:48:16.562899  3498 solver.cpp:237] Iteration 850, loss = 0.100605
I0204 16:48:16.562960  3498 solver.cpp:253]     Train net output #0: loss = 0.100605 (* 1 = 0.100605 loss)
I0204 16:48:16.562973  3498 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0204 16:48:28.685027  3498 solver.cpp:237] Iteration 860, loss = 0.0108099
I0204 16:48:28.685199  3498 solver.cpp:253]     Train net output #0: loss = 0.0108099 (* 1 = 0.0108099 loss)
I0204 16:48:28.685212  3498 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0204 16:48:40.571138  3498 solver.cpp:237] Iteration 870, loss = 0.055542
I0204 16:48:40.571193  3498 solver.cpp:253]     Train net output #0: loss = 0.055542 (* 1 = 0.055542 loss)
I0204 16:48:40.571204  3498 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0204 16:48:52.414122  3498 solver.cpp:237] Iteration 880, loss = 0.00857626
I0204 16:48:52.414177  3498 solver.cpp:253]     Train net output #0: loss = 0.00857624 (* 1 = 0.00857624 loss)
I0204 16:48:52.414189  3498 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0204 16:49:04.281180  3498 solver.cpp:237] Iteration 890, loss = 0.0323291
I0204 16:49:04.281352  3498 solver.cpp:253]     Train net output #0: loss = 0.0323291 (* 1 = 0.0323291 loss)
I0204 16:49:04.281365  3498 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0204 16:49:14.996315  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_900.caffemodel
I0204 16:49:14.998471  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_900.solverstate
I0204 16:49:14.999369  3498 solver.cpp:341] Iteration 900, Testing net (#0)
I0204 16:49:20.879009  3498 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 16:49:20.879061  3498 solver.cpp:409]     Test net output #1: loss = 0.0239101 (* 1 = 0.0239101 loss)
I0204 16:49:22.099634  3498 solver.cpp:237] Iteration 900, loss = 0.0420691
I0204 16:49:22.099683  3498 solver.cpp:253]     Train net output #0: loss = 0.0420691 (* 1 = 0.0420691 loss)
I0204 16:49:22.099694  3498 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0204 16:49:34.171716  3498 solver.cpp:237] Iteration 910, loss = 0.0574987
I0204 16:49:34.171772  3498 solver.cpp:253]     Train net output #0: loss = 0.0574987 (* 1 = 0.0574987 loss)
I0204 16:49:34.171783  3498 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0204 16:49:45.979467  3498 solver.cpp:237] Iteration 920, loss = 0.102916
I0204 16:49:45.979681  3498 solver.cpp:253]     Train net output #0: loss = 0.102916 (* 1 = 0.102916 loss)
I0204 16:49:45.979693  3498 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0204 16:49:57.840409  3498 solver.cpp:237] Iteration 930, loss = 0.143394
I0204 16:49:57.840464  3498 solver.cpp:253]     Train net output #0: loss = 0.143394 (* 1 = 0.143394 loss)
I0204 16:49:57.840476  3498 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0204 16:50:09.675240  3498 solver.cpp:237] Iteration 940, loss = 0.0306997
I0204 16:50:09.675293  3498 solver.cpp:253]     Train net output #0: loss = 0.0306997 (* 1 = 0.0306997 loss)
I0204 16:50:09.675303  3498 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0204 16:50:21.395758  3498 solver.cpp:237] Iteration 950, loss = 0.00919715
I0204 16:50:21.395946  3498 solver.cpp:253]     Train net output #0: loss = 0.00919715 (* 1 = 0.00919715 loss)
I0204 16:50:21.395961  3498 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0204 16:50:33.084776  3498 solver.cpp:237] Iteration 960, loss = 0.00430204
I0204 16:50:33.084833  3498 solver.cpp:253]     Train net output #0: loss = 0.00430204 (* 1 = 0.00430204 loss)
I0204 16:50:33.084846  3498 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0204 16:50:44.877655  3498 solver.cpp:237] Iteration 970, loss = 0.0228702
I0204 16:50:44.877709  3498 solver.cpp:253]     Train net output #0: loss = 0.0228702 (* 1 = 0.0228702 loss)
I0204 16:50:44.877722  3498 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0204 16:50:56.547399  3498 solver.cpp:237] Iteration 980, loss = 0.0112297
I0204 16:50:56.547547  3498 solver.cpp:253]     Train net output #0: loss = 0.0112297 (* 1 = 0.0112297 loss)
I0204 16:50:56.547560  3498 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0204 16:51:07.925285  3498 solver.cpp:237] Iteration 990, loss = 0.0146567
I0204 16:51:07.925339  3498 solver.cpp:253]     Train net output #0: loss = 0.0146567 (* 1 = 0.0146567 loss)
I0204 16:51:07.925350  3498 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0204 16:51:18.177973  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1000.caffemodel
I0204 16:51:18.180063  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1000.solverstate
I0204 16:51:18.180929  3498 solver.cpp:341] Iteration 1000, Testing net (#0)
I0204 16:51:23.765339  3498 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 16:51:23.765391  3498 solver.cpp:409]     Test net output #1: loss = 0.0222732 (* 1 = 0.0222732 loss)
I0204 16:51:24.887855  3498 solver.cpp:237] Iteration 1000, loss = 0.0650636
I0204 16:51:24.887902  3498 solver.cpp:253]     Train net output #0: loss = 0.0650636 (* 1 = 0.0650636 loss)
I0204 16:51:24.887923  3498 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0204 16:51:36.120430  3498 solver.cpp:237] Iteration 1010, loss = 0.0494454
I0204 16:51:36.120637  3498 solver.cpp:253]     Train net output #0: loss = 0.0494454 (* 1 = 0.0494454 loss)
I0204 16:51:36.120651  3498 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0204 16:51:47.382076  3498 solver.cpp:237] Iteration 1020, loss = 0.0189537
I0204 16:51:47.382133  3498 solver.cpp:253]     Train net output #0: loss = 0.0189537 (* 1 = 0.0189537 loss)
I0204 16:51:47.382143  3498 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0204 16:51:58.608742  3498 solver.cpp:237] Iteration 1030, loss = 0.00742199
I0204 16:51:58.608794  3498 solver.cpp:253]     Train net output #0: loss = 0.00742199 (* 1 = 0.00742199 loss)
I0204 16:51:58.608805  3498 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0204 16:52:09.931138  3498 solver.cpp:237] Iteration 1040, loss = 0.0366509
I0204 16:52:09.931303  3498 solver.cpp:253]     Train net output #0: loss = 0.0366509 (* 1 = 0.0366509 loss)
I0204 16:52:09.931314  3498 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0204 16:52:21.205421  3498 solver.cpp:237] Iteration 1050, loss = 0.0224596
I0204 16:52:21.205477  3498 solver.cpp:253]     Train net output #0: loss = 0.0224596 (* 1 = 0.0224596 loss)
I0204 16:52:21.205488  3498 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0204 16:52:32.524528  3498 solver.cpp:237] Iteration 1060, loss = 0.00459125
I0204 16:52:32.524581  3498 solver.cpp:253]     Train net output #0: loss = 0.00459125 (* 1 = 0.00459125 loss)
I0204 16:52:32.524592  3498 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0204 16:52:43.681939  3498 solver.cpp:237] Iteration 1070, loss = 0.0780131
I0204 16:52:43.682118  3498 solver.cpp:253]     Train net output #0: loss = 0.0780131 (* 1 = 0.0780131 loss)
I0204 16:52:43.682132  3498 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0204 16:52:54.943795  3498 solver.cpp:237] Iteration 1080, loss = 0.0537114
I0204 16:52:54.943857  3498 solver.cpp:253]     Train net output #0: loss = 0.0537114 (* 1 = 0.0537114 loss)
I0204 16:52:54.943868  3498 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0204 16:53:06.172591  3498 solver.cpp:237] Iteration 1090, loss = 0.0305605
I0204 16:53:06.172647  3498 solver.cpp:253]     Train net output #0: loss = 0.0305605 (* 1 = 0.0305605 loss)
I0204 16:53:06.172658  3498 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0204 16:53:15.940836  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1100.caffemodel
I0204 16:53:15.943066  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1100.solverstate
I0204 16:53:15.943929  3498 solver.cpp:341] Iteration 1100, Testing net (#0)
I0204 16:53:21.282091  3498 solver.cpp:409]     Test net output #0: accuracy = 0.996
I0204 16:53:21.282142  3498 solver.cpp:409]     Test net output #1: loss = 0.016593 (* 1 = 0.016593 loss)
I0204 16:53:22.363469  3498 solver.cpp:237] Iteration 1100, loss = 0.00954714
I0204 16:53:22.363512  3498 solver.cpp:253]     Train net output #0: loss = 0.00954714 (* 1 = 0.00954714 loss)
I0204 16:53:22.363523  3498 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0204 16:53:33.111186  3498 solver.cpp:237] Iteration 1110, loss = 0.0113806
I0204 16:53:33.111243  3498 solver.cpp:253]     Train net output #0: loss = 0.0113806 (* 1 = 0.0113806 loss)
I0204 16:53:33.111254  3498 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0204 16:53:44.051348  3498 solver.cpp:237] Iteration 1120, loss = 0.013079
I0204 16:53:44.051401  3498 solver.cpp:253]     Train net output #0: loss = 0.013079 (* 1 = 0.013079 loss)
I0204 16:53:44.051412  3498 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0204 16:53:54.984944  3498 solver.cpp:237] Iteration 1130, loss = 0.00865295
I0204 16:53:54.985160  3498 solver.cpp:253]     Train net output #0: loss = 0.00865294 (* 1 = 0.00865294 loss)
I0204 16:53:54.985178  3498 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0204 16:54:05.740180  3498 solver.cpp:237] Iteration 1140, loss = 0.0404411
I0204 16:54:05.740231  3498 solver.cpp:253]     Train net output #0: loss = 0.0404411 (* 1 = 0.0404411 loss)
I0204 16:54:05.740242  3498 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0204 16:54:16.382771  3498 solver.cpp:237] Iteration 1150, loss = 0.163732
I0204 16:54:16.382822  3498 solver.cpp:253]     Train net output #0: loss = 0.163732 (* 1 = 0.163732 loss)
I0204 16:54:16.382832  3498 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0204 16:54:27.124909  3498 solver.cpp:237] Iteration 1160, loss = 0.0373333
I0204 16:54:27.125104  3498 solver.cpp:253]     Train net output #0: loss = 0.0373333 (* 1 = 0.0373333 loss)
I0204 16:54:27.125118  3498 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0204 16:54:37.994220  3498 solver.cpp:237] Iteration 1170, loss = 0.0150515
I0204 16:54:37.994272  3498 solver.cpp:253]     Train net output #0: loss = 0.0150514 (* 1 = 0.0150514 loss)
I0204 16:54:37.994283  3498 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0204 16:54:48.950099  3498 solver.cpp:237] Iteration 1180, loss = 0.00948012
I0204 16:54:48.950150  3498 solver.cpp:253]     Train net output #0: loss = 0.0094801 (* 1 = 0.0094801 loss)
I0204 16:54:48.950162  3498 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0204 16:54:59.895829  3498 solver.cpp:237] Iteration 1190, loss = 0.0267672
I0204 16:54:59.895994  3498 solver.cpp:253]     Train net output #0: loss = 0.0267672 (* 1 = 0.0267672 loss)
I0204 16:54:59.896006  3498 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0204 16:55:09.849556  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1200.caffemodel
I0204 16:55:09.851691  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1200.solverstate
I0204 16:55:09.852560  3498 solver.cpp:341] Iteration 1200, Testing net (#0)
I0204 16:55:15.270833  3498 solver.cpp:409]     Test net output #0: accuracy = 0.983
I0204 16:55:15.270880  3498 solver.cpp:409]     Test net output #1: loss = 0.0420245 (* 1 = 0.0420245 loss)
I0204 16:55:16.355310  3498 solver.cpp:237] Iteration 1200, loss = 0.0692013
I0204 16:55:16.355355  3498 solver.cpp:253]     Train net output #0: loss = 0.0692013 (* 1 = 0.0692013 loss)
I0204 16:55:16.355365  3498 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0204 16:55:27.460840  3498 solver.cpp:237] Iteration 1210, loss = 0.0606106
I0204 16:55:27.460891  3498 solver.cpp:253]     Train net output #0: loss = 0.0606106 (* 1 = 0.0606106 loss)
I0204 16:55:27.460901  3498 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0204 16:55:38.642094  3498 solver.cpp:237] Iteration 1220, loss = 0.0539141
I0204 16:55:38.642272  3498 solver.cpp:253]     Train net output #0: loss = 0.0539141 (* 1 = 0.0539141 loss)
I0204 16:55:38.642284  3498 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0204 16:55:49.878659  3498 solver.cpp:237] Iteration 1230, loss = 0.0127152
I0204 16:55:49.878715  3498 solver.cpp:253]     Train net output #0: loss = 0.0127152 (* 1 = 0.0127152 loss)
I0204 16:55:49.878727  3498 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0204 16:56:01.060477  3498 solver.cpp:237] Iteration 1240, loss = 0.020747
I0204 16:56:01.060528  3498 solver.cpp:253]     Train net output #0: loss = 0.020747 (* 1 = 0.020747 loss)
I0204 16:56:01.060540  3498 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0204 16:56:12.101483  3498 solver.cpp:237] Iteration 1250, loss = 0.0724589
I0204 16:56:12.101658  3498 solver.cpp:253]     Train net output #0: loss = 0.0724589 (* 1 = 0.0724589 loss)
I0204 16:56:12.101670  3498 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0204 16:56:23.134490  3498 solver.cpp:237] Iteration 1260, loss = 0.0142638
I0204 16:56:23.134546  3498 solver.cpp:253]     Train net output #0: loss = 0.0142638 (* 1 = 0.0142638 loss)
I0204 16:56:23.134567  3498 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0204 16:56:34.131384  3498 solver.cpp:237] Iteration 1270, loss = 0.00922325
I0204 16:56:34.131449  3498 solver.cpp:253]     Train net output #0: loss = 0.00922325 (* 1 = 0.00922325 loss)
I0204 16:56:34.131516  3498 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0204 16:56:45.177315  3498 solver.cpp:237] Iteration 1280, loss = 0.00598725
I0204 16:56:45.177521  3498 solver.cpp:253]     Train net output #0: loss = 0.00598725 (* 1 = 0.00598725 loss)
I0204 16:56:45.177536  3498 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0204 16:56:56.213803  3498 solver.cpp:237] Iteration 1290, loss = 0.130399
I0204 16:56:56.213853  3498 solver.cpp:253]     Train net output #0: loss = 0.130399 (* 1 = 0.130399 loss)
I0204 16:56:56.213865  3498 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0204 16:57:06.018018  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1300.caffemodel
I0204 16:57:06.020151  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1300.solverstate
I0204 16:57:06.021055  3498 solver.cpp:341] Iteration 1300, Testing net (#0)
I0204 16:57:11.422930  3498 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 16:57:11.422986  3498 solver.cpp:409]     Test net output #1: loss = 0.0244485 (* 1 = 0.0244485 loss)
I0204 16:57:12.489867  3498 solver.cpp:237] Iteration 1300, loss = 0.0114459
I0204 16:57:12.489915  3498 solver.cpp:253]     Train net output #0: loss = 0.0114459 (* 1 = 0.0114459 loss)
I0204 16:57:12.489926  3498 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0204 16:57:23.278352  3498 solver.cpp:237] Iteration 1310, loss = 0.0377931
I0204 16:57:23.278532  3498 solver.cpp:253]     Train net output #0: loss = 0.0377931 (* 1 = 0.0377931 loss)
I0204 16:57:23.278545  3498 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0204 16:57:34.254981  3498 solver.cpp:237] Iteration 1320, loss = 0.0320403
I0204 16:57:34.255033  3498 solver.cpp:253]     Train net output #0: loss = 0.0320403 (* 1 = 0.0320403 loss)
I0204 16:57:34.255044  3498 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0204 16:57:45.180481  3498 solver.cpp:237] Iteration 1330, loss = 0.005295
I0204 16:57:45.180537  3498 solver.cpp:253]     Train net output #0: loss = 0.00529498 (* 1 = 0.00529498 loss)
I0204 16:57:45.180548  3498 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0204 16:57:56.091135  3498 solver.cpp:237] Iteration 1340, loss = 0.00767373
I0204 16:57:56.091313  3498 solver.cpp:253]     Train net output #0: loss = 0.00767372 (* 1 = 0.00767372 loss)
I0204 16:57:56.091326  3498 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0204 16:58:06.907903  3498 solver.cpp:237] Iteration 1350, loss = 0.0371962
I0204 16:58:06.907958  3498 solver.cpp:253]     Train net output #0: loss = 0.0371962 (* 1 = 0.0371962 loss)
I0204 16:58:06.907973  3498 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0204 16:58:17.787648  3498 solver.cpp:237] Iteration 1360, loss = 0.0784305
I0204 16:58:17.787699  3498 solver.cpp:253]     Train net output #0: loss = 0.0784305 (* 1 = 0.0784305 loss)
I0204 16:58:17.787710  3498 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0204 16:58:28.898051  3498 solver.cpp:237] Iteration 1370, loss = 0.00447799
I0204 16:58:28.898257  3498 solver.cpp:253]     Train net output #0: loss = 0.00447799 (* 1 = 0.00447799 loss)
I0204 16:58:28.898270  3498 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0204 16:58:39.987452  3498 solver.cpp:237] Iteration 1380, loss = 0.0872297
I0204 16:58:39.987517  3498 solver.cpp:253]     Train net output #0: loss = 0.0872297 (* 1 = 0.0872297 loss)
I0204 16:58:39.987586  3498 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0204 16:58:51.138299  3498 solver.cpp:237] Iteration 1390, loss = 0.00956293
I0204 16:58:51.138367  3498 solver.cpp:253]     Train net output #0: loss = 0.00956293 (* 1 = 0.00956293 loss)
I0204 16:58:51.138399  3498 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0204 16:59:01.189843  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1400.caffemodel
I0204 16:59:01.192164  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1400.solverstate
I0204 16:59:01.193061  3498 solver.cpp:341] Iteration 1400, Testing net (#0)
I0204 16:59:06.695263  3498 solver.cpp:409]     Test net output #0: accuracy = 0.992
I0204 16:59:06.695327  3498 solver.cpp:409]     Test net output #1: loss = 0.0199925 (* 1 = 0.0199925 loss)
I0204 16:59:07.843300  3498 solver.cpp:237] Iteration 1400, loss = 0.0327126
I0204 16:59:07.843349  3498 solver.cpp:253]     Train net output #0: loss = 0.0327126 (* 1 = 0.0327126 loss)
I0204 16:59:07.843361  3498 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0204 16:59:19.019516  3498 solver.cpp:237] Iteration 1410, loss = 0.00416821
I0204 16:59:19.019574  3498 solver.cpp:253]     Train net output #0: loss = 0.00416821 (* 1 = 0.00416821 loss)
I0204 16:59:19.019585  3498 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
I0204 16:59:30.078816  3498 solver.cpp:237] Iteration 1420, loss = 0.00157795
I0204 16:59:30.078871  3498 solver.cpp:253]     Train net output #0: loss = 0.00157794 (* 1 = 0.00157794 loss)
I0204 16:59:30.078883  3498 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0204 16:59:41.137686  3498 solver.cpp:237] Iteration 1430, loss = 0.0562086
I0204 16:59:41.137862  3498 solver.cpp:253]     Train net output #0: loss = 0.0562086 (* 1 = 0.0562086 loss)
I0204 16:59:41.137876  3498 sgd_solver.cpp:106] Iteration 1430, lr = 0.001
I0204 16:59:52.058596  3498 solver.cpp:237] Iteration 1440, loss = 0.00494418
I0204 16:59:52.058648  3498 solver.cpp:253]     Train net output #0: loss = 0.00494418 (* 1 = 0.00494418 loss)
I0204 16:59:52.058660  3498 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0204 17:00:02.971462  3498 solver.cpp:237] Iteration 1450, loss = 0.0121217
I0204 17:00:02.971516  3498 solver.cpp:253]     Train net output #0: loss = 0.0121217 (* 1 = 0.0121217 loss)
I0204 17:00:02.971528  3498 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0204 17:00:13.804159  3498 solver.cpp:237] Iteration 1460, loss = 0.0206421
I0204 17:00:13.804343  3498 solver.cpp:253]     Train net output #0: loss = 0.0206421 (* 1 = 0.0206421 loss)
I0204 17:00:13.804357  3498 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0204 17:00:24.832236  3498 solver.cpp:237] Iteration 1470, loss = 0.0345419
I0204 17:00:24.832289  3498 solver.cpp:253]     Train net output #0: loss = 0.0345419 (* 1 = 0.0345419 loss)
I0204 17:00:24.832300  3498 sgd_solver.cpp:106] Iteration 1470, lr = 0.001
I0204 17:00:35.854467  3498 solver.cpp:237] Iteration 1480, loss = 0.00791562
I0204 17:00:35.854521  3498 solver.cpp:253]     Train net output #0: loss = 0.00791561 (* 1 = 0.00791561 loss)
I0204 17:00:35.854532  3498 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0204 17:00:46.715847  3498 solver.cpp:237] Iteration 1490, loss = 0.010779
I0204 17:00:46.716023  3498 solver.cpp:253]     Train net output #0: loss = 0.010779 (* 1 = 0.010779 loss)
I0204 17:00:46.716042  3498 sgd_solver.cpp:106] Iteration 1490, lr = 0.001
I0204 17:00:56.638067  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1500.caffemodel
I0204 17:00:56.640174  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1500.solverstate
I0204 17:00:56.641054  3498 solver.cpp:341] Iteration 1500, Testing net (#0)
I0204 17:01:02.121554  3498 solver.cpp:409]     Test net output #0: accuracy = 0.994
I0204 17:01:02.121604  3498 solver.cpp:409]     Test net output #1: loss = 0.0158192 (* 1 = 0.0158192 loss)
I0204 17:01:03.228886  3498 solver.cpp:237] Iteration 1500, loss = 0.0030808
I0204 17:01:03.228936  3498 solver.cpp:253]     Train net output #0: loss = 0.00308079 (* 1 = 0.00308079 loss)
I0204 17:01:03.228948  3498 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0204 17:01:14.113991  3498 solver.cpp:237] Iteration 1510, loss = 0.0428881
I0204 17:01:14.114051  3498 solver.cpp:253]     Train net output #0: loss = 0.042888 (* 1 = 0.042888 loss)
I0204 17:01:14.114063  3498 sgd_solver.cpp:106] Iteration 1510, lr = 0.001
I0204 17:01:25.153493  3498 solver.cpp:237] Iteration 1520, loss = 0.0100853
I0204 17:01:25.153707  3498 solver.cpp:253]     Train net output #0: loss = 0.0100853 (* 1 = 0.0100853 loss)
I0204 17:01:25.153720  3498 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0204 17:01:36.278239  3498 solver.cpp:237] Iteration 1530, loss = 0.00386268
I0204 17:01:36.278290  3498 solver.cpp:253]     Train net output #0: loss = 0.00386267 (* 1 = 0.00386267 loss)
I0204 17:01:36.278301  3498 sgd_solver.cpp:106] Iteration 1530, lr = 0.001
I0204 17:01:47.246925  3498 solver.cpp:237] Iteration 1540, loss = 0.00643532
I0204 17:01:47.246979  3498 solver.cpp:253]     Train net output #0: loss = 0.00643531 (* 1 = 0.00643531 loss)
I0204 17:01:47.246991  3498 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0204 17:01:58.160153  3498 solver.cpp:237] Iteration 1550, loss = 0.0297848
I0204 17:01:58.160341  3498 solver.cpp:253]     Train net output #0: loss = 0.0297848 (* 1 = 0.0297848 loss)
I0204 17:01:58.160354  3498 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0204 17:02:09.049379  3498 solver.cpp:237] Iteration 1560, loss = 0.00879265
I0204 17:02:09.049432  3498 solver.cpp:253]     Train net output #0: loss = 0.00879264 (* 1 = 0.00879264 loss)
I0204 17:02:09.049444  3498 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0204 17:02:19.897668  3498 solver.cpp:237] Iteration 1570, loss = 0.0101258
I0204 17:02:19.897716  3498 solver.cpp:253]     Train net output #0: loss = 0.0101258 (* 1 = 0.0101258 loss)
I0204 17:02:19.897727  3498 sgd_solver.cpp:106] Iteration 1570, lr = 0.001
I0204 17:02:30.700582  3498 solver.cpp:237] Iteration 1580, loss = 0.0027896
I0204 17:02:30.700760  3498 solver.cpp:253]     Train net output #0: loss = 0.00278959 (* 1 = 0.00278959 loss)
I0204 17:02:30.700773  3498 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0204 17:02:41.529219  3498 solver.cpp:237] Iteration 1590, loss = 0.00912531
I0204 17:02:41.529270  3498 solver.cpp:253]     Train net output #0: loss = 0.00912531 (* 1 = 0.00912531 loss)
I0204 17:02:41.529283  3498 sgd_solver.cpp:106] Iteration 1590, lr = 0.001
I0204 17:02:51.182059  3498 solver.cpp:459] Snapshotting to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1600.caffemodel
I0204 17:02:51.184140  3498 sgd_solver.cpp:269] Snapshotting solver state to binary proto file /home/pearlstl/proj_cv/master/exp/gray_8000_conv1num8_conv2num8_conv3num8_conv4num8_conv5num8_seed4/snaps/snap__iter_1600.solverstate
I0204 17:02:51.699856  3498 solver.cpp:321] Iteration 1600, loss = 0.0181406
I0204 17:02:51.699908  3498 solver.cpp:341] Iteration 1600, Testing net (#0)
I0204 17:02:56.766273  3498 solver.cpp:409]     Test net output #0: accuracy = 0.991
I0204 17:02:56.766321  3498 solver.cpp:409]     Test net output #1: loss = 0.0197197 (* 1 = 0.0197197 loss)
I0204 17:02:56.766330  3498 solver.cpp:326] Optimization Done.
I0204 17:02:56.766336  3498 caffe.cpp:215] Optimization Done.
